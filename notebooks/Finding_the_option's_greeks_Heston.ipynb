{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Finding Greeks with Autodiff- Heston.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Greeks \n",
    "\n",
    "The Greeks are the quantities representing the sensitivity of the price of options to a change of the underlying parameters.\n",
    "The Greeks in the Black–Scholes model are relatively easy to calculate, a desirable property of financial models, and are very useful for derivatives traders, especially those who seek to hedge their portfolios from adverse changes in market conditions.\n",
    "\n",
    "The most important Greeks are:\n",
    "\n",
    "Delta\n",
    "$$\n",
    "Δ = \\frac{\\partial V}{\\partial S}\n",
    "$$\n",
    "\n",
    "\n",
    "Vega\n",
    "$$\n",
    "\\mathcal{V} = \\frac{\\partial V}{\\partial \\sigma}\n",
    "$$\n",
    "\n",
    "Theta\n",
    "$$\n",
    "\\Theta = \\frac{\\partial V}{\\partial \\tau}\n",
    "$$\n",
    "\n",
    "Gamma\n",
    "\n",
    "$$\n",
    "\\Gamma = \\frac{\\partial^2 V}{\\partial S^2}\n",
    "$$"
   ],
   "metadata": {
    "id": "nyZ6zK-zq-kb",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "d5WqaKnRuqZ5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Set seeds\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ],
   "metadata": {
    "id": "QvVjZvRAu4V6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "synthetic_options_path = '../data/heston_synthetic_options.csv'"
   ],
   "metadata": {
    "id": "de8X7ZZFu5jM",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "    \n",
    "    return df"
   ],
   "metadata": {
    "id": "qlQic-lZu61e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "synthetic_options = pd.read_csv(synthetic_options_path, index_col=0)\n",
    "synthetic_options = reduce_mem_usage(synthetic_options)"
   ],
   "metadata": {
    "id": "ZDbfn4f9u9zi",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paolo/PycharmProjects/backtesting_experiments/venv/lib/python3.8/site-packages/numpy/lib/arraysetops.py:583: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "synthetic_options = shuffle(synthetic_options, random_state=0)\n",
    "synthetic_options = synthetic_options.reset_index()\n",
    "synthetic_options = synthetic_options.drop('index', axis=1)"
   ],
   "metadata": {
    "id": "ckdSVfv6u-fm",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "synthetic_options"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "t_8gd-LSu_jn",
    "outputId": "bfea1e2a-f70e-4772-e17d-cb5deaac7c1d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "         Price  Strike Type     Kappa       Rho     Theta        Xi       V_0  \\\n0           96    78.0    C  1.074219 -0.311279  0.375732  0.180298  0.367432   \n1          100    56.0    C  1.495117 -0.869629  0.011398  0.010925  0.257080   \n2          100    68.0    P  0.988770 -0.664551  0.344482  0.045258  0.328125   \n3          100    75.0    C  1.996094 -0.051880  0.417480  0.208374  0.328613   \n4          100    71.0    P  0.344971 -0.344727  0.227783  0.340820  0.054413   \n...        ...     ...  ...       ...       ...       ...       ...       ...   \n1059740    100    71.0    P  1.039062 -0.757324  0.227661  0.312500  0.445068   \n1059741    100    57.0    C  1.905273 -0.276855  0.322266  0.061432  0.120117   \n1059742     92   132.0    P  0.149536 -0.433350  0.262695  0.054565  0.404541   \n1059743    100   135.0    C  0.971680 -0.711426  0.270508  0.438477  0.483887   \n1059744    100   135.0    P  1.183594 -0.541504  0.479980  0.091614  0.104736   \n\n         Interest Rate  Time to Expiration  Option Price  \n0             0.045074            0.533203     17.828125  \n1             0.050201            0.977051     42.187500  \n2             0.051971            0.588867      0.026703  \n3             0.053741            0.215088     25.312500  \n4             0.016891            0.800781      0.070496  \n...                ...                 ...           ...  \n1059740       0.016006            0.487061      1.505859  \n1059741       0.025070            0.947754     41.687500  \n1059742       0.028809            0.551758     38.375000  \n1059743       0.097107            0.289307      0.180542  \n1059744       0.095215            0.864746     32.093750  \n\n[1059745 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Price</th>\n      <th>Strike</th>\n      <th>Type</th>\n      <th>Kappa</th>\n      <th>Rho</th>\n      <th>Theta</th>\n      <th>Xi</th>\n      <th>V_0</th>\n      <th>Interest Rate</th>\n      <th>Time to Expiration</th>\n      <th>Option Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>96</td>\n      <td>78.0</td>\n      <td>C</td>\n      <td>1.074219</td>\n      <td>-0.311279</td>\n      <td>0.375732</td>\n      <td>0.180298</td>\n      <td>0.367432</td>\n      <td>0.045074</td>\n      <td>0.533203</td>\n      <td>17.828125</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100</td>\n      <td>56.0</td>\n      <td>C</td>\n      <td>1.495117</td>\n      <td>-0.869629</td>\n      <td>0.011398</td>\n      <td>0.010925</td>\n      <td>0.257080</td>\n      <td>0.050201</td>\n      <td>0.977051</td>\n      <td>42.187500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100</td>\n      <td>68.0</td>\n      <td>P</td>\n      <td>0.988770</td>\n      <td>-0.664551</td>\n      <td>0.344482</td>\n      <td>0.045258</td>\n      <td>0.328125</td>\n      <td>0.051971</td>\n      <td>0.588867</td>\n      <td>0.026703</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100</td>\n      <td>75.0</td>\n      <td>C</td>\n      <td>1.996094</td>\n      <td>-0.051880</td>\n      <td>0.417480</td>\n      <td>0.208374</td>\n      <td>0.328613</td>\n      <td>0.053741</td>\n      <td>0.215088</td>\n      <td>25.312500</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100</td>\n      <td>71.0</td>\n      <td>P</td>\n      <td>0.344971</td>\n      <td>-0.344727</td>\n      <td>0.227783</td>\n      <td>0.340820</td>\n      <td>0.054413</td>\n      <td>0.016891</td>\n      <td>0.800781</td>\n      <td>0.070496</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1059740</th>\n      <td>100</td>\n      <td>71.0</td>\n      <td>P</td>\n      <td>1.039062</td>\n      <td>-0.757324</td>\n      <td>0.227661</td>\n      <td>0.312500</td>\n      <td>0.445068</td>\n      <td>0.016006</td>\n      <td>0.487061</td>\n      <td>1.505859</td>\n    </tr>\n    <tr>\n      <th>1059741</th>\n      <td>100</td>\n      <td>57.0</td>\n      <td>C</td>\n      <td>1.905273</td>\n      <td>-0.276855</td>\n      <td>0.322266</td>\n      <td>0.061432</td>\n      <td>0.120117</td>\n      <td>0.025070</td>\n      <td>0.947754</td>\n      <td>41.687500</td>\n    </tr>\n    <tr>\n      <th>1059742</th>\n      <td>92</td>\n      <td>132.0</td>\n      <td>P</td>\n      <td>0.149536</td>\n      <td>-0.433350</td>\n      <td>0.262695</td>\n      <td>0.054565</td>\n      <td>0.404541</td>\n      <td>0.028809</td>\n      <td>0.551758</td>\n      <td>38.375000</td>\n    </tr>\n    <tr>\n      <th>1059743</th>\n      <td>100</td>\n      <td>135.0</td>\n      <td>C</td>\n      <td>0.971680</td>\n      <td>-0.711426</td>\n      <td>0.270508</td>\n      <td>0.438477</td>\n      <td>0.483887</td>\n      <td>0.097107</td>\n      <td>0.289307</td>\n      <td>0.180542</td>\n    </tr>\n    <tr>\n      <th>1059744</th>\n      <td>100</td>\n      <td>135.0</td>\n      <td>P</td>\n      <td>1.183594</td>\n      <td>-0.541504</td>\n      <td>0.479980</td>\n      <td>0.091614</td>\n      <td>0.104736</td>\n      <td>0.095215</td>\n      <td>0.864746</td>\n      <td>32.093750</td>\n    </tr>\n  </tbody>\n</table>\n<p>1059745 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing"
   ],
   "metadata": {
    "id": "iKLZO13NvMTW",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "synthetic_options = pd.get_dummies(synthetic_options, prefix='', prefix_sep='')"
   ],
   "metadata": {
    "id": "cQ9KfnGrvcs4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_cols = synthetic_options.drop('Option Price', axis=1).columns"
   ],
   "metadata": {
    "id": "SsAVHmvJ64Yd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "input_sc = StandardScaler()\n",
    "output_sc = StandardScaler()\n",
    "input_data = input_sc.fit_transform(synthetic_options.drop('Option Price', axis=1))\n",
    "output_data = output_sc.fit_transform(synthetic_options['Option Price'].values.reshape(-1, 1))\n",
    "\n",
    "train_size = 0.8\n",
    "val_size = 0.1\n",
    "\n",
    "last_train_idx = int(np.round(len(input_data) * train_size))\n",
    "last_val_idx = last_train_idx + int(np.round(len(input_data) * val_size))\n",
    "\n",
    "X_train = input_data[0:last_train_idx]\n",
    "X_val = input_data[last_train_idx:last_val_idx]\n",
    "X_test = input_data[last_val_idx:]\n",
    "\n",
    "y_train = output_data[0:last_train_idx]\n",
    "y_val = output_data[last_train_idx:last_val_idx]\n",
    "y_test = output_data[last_val_idx:]"
   ],
   "metadata": {
    "id": "2oZN9QcKvPU8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X_train = Variable(torch.Tensor(X_train))\n",
    "X_val = Variable(torch.Tensor(X_val))\n",
    "X_test = Variable(torch.Tensor(X_test))\n",
    "\n",
    "y_train = Variable(torch.Tensor(y_train))\n",
    "y_val = Variable(torch.Tensor(y_val))\n",
    "y_test = Variable(torch.Tensor(y_test))"
   ],
   "metadata": {
    "id": "Ku4go32rvfhL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "id": "jBAVivmLvg29",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "CUDA = torch.cuda.is_available()\n",
    "device = 'cuda:0' if CUDA else 'cpu'"
   ],
   "metadata": {
    "id": "LYiQyIkBvh-p",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class ResBlock(nn.Module):\n",
    "\n",
    "  def __init__(self, module):\n",
    "    super(ResBlock, self).__init__()\n",
    "    self.module = module\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.module(x) + x"
   ],
   "metadata": {
    "id": "BiH0caYUvjUL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class HiddenLayer(nn.Module):\n",
    "\n",
    "  def __init__(self, layer_size, act_fn):\n",
    "      super(HiddenLayer, self).__init__()\n",
    "      \n",
    "      if act_fn == 'ReLU':\n",
    "        self.layer = nn.Sequential(\n",
    "          nn.Linear(layer_size, layer_size),\n",
    "          nn.ReLU())\n",
    "      elif act_fn == 'LeakyReLU':\n",
    "        self.layer = nn.Sequential(\n",
    "          nn.Linear(layer_size, layer_size),\n",
    "          nn.LeakyReLU())\n",
    "      elif act_fn == 'ELU':\n",
    "        self.layer = nn.Sequential(\n",
    "          nn.Linear(layer_size, layer_size),\n",
    "          nn.ELU())\n",
    "    \n",
    "  def forward(self, x):\n",
    "    return self.layer(x)"
   ],
   "metadata": {
    "id": "7uOXXLiYvk79",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "  def __init__(self, input_size, output_size, hidden_size, num_layers, act_fn):\n",
    "    super(Net, self).__init__()\n",
    "    self.input_size = input_size\n",
    "    self.output_size = output_size\n",
    "    self.hidden_size = hidden_size\n",
    "\n",
    "    if act_fn == 'ReLU':\n",
    "      self.initial_layer = nn.Sequential(\n",
    "          nn.Linear(self.input_size, self.hidden_size),\n",
    "          nn.ReLU())\n",
    "    elif act_fn == 'LeakyReLU':\n",
    "      self.initial_layer = nn.Sequential(\n",
    "          nn.Linear(self.input_size, self.hidden_size),\n",
    "          nn.LeakyReLU())\n",
    "    elif act_fn == 'ELU':\n",
    "      self.initial_layer = nn.Sequential(\n",
    "          nn.Linear(self.input_size, self.hidden_size),\n",
    "          nn.ELU())\n",
    "\n",
    "    self.hidden_layers_list = []\n",
    "\n",
    "    for i in range(num_layers // 2):\n",
    "      self.hidden_layers_list.append(\n",
    "          ResBlock(\n",
    "            nn.Sequential(\n",
    "                HiddenLayer(self.hidden_size, act_fn),\n",
    "                HiddenLayer(self.hidden_size, act_fn)\n",
    "            )\n",
    "        )\n",
    "      )\n",
    "\n",
    "    self.hidden_layers = nn.Sequential(*self.hidden_layers_list)\n",
    "\n",
    "    self.net = nn.Sequential(\n",
    "        self.initial_layer,\n",
    "        self.hidden_layers,\n",
    "        nn.Linear(self.hidden_size, self.output_size)\n",
    "    )\n",
    "  \n",
    "  def forward(self, x):\n",
    "    return self.net(x)"
   ],
   "metadata": {
    "id": "uuAjyuRUvlpe",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def init_weights(m, init_m: str):\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def init_uniform(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "      torch.nn.init.uniform_(m.weight)\n",
    "      m.bias.data.fill_(0.01)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def init_normal(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "      torch.nn.init.normal_(m.weight)\n",
    "      m.bias.data.fill_(0.01)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def init_xuniform(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "      torch.nn.init.xavier_uniform_(m.weight)\n",
    "      m.bias.data.fill_(0.01)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def init_xnormal(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "      torch.nn.init.xavier_normal_(m.weight)\n",
    "      m.bias.data.fill_(0.01)\n",
    "\n",
    "  if init_m == 'uniform':\n",
    "    m.apply(init_uniform)\n",
    "  elif init_m == 'normal':\n",
    "    m.apply(init_normal)\n",
    "  elif init_m == 'xaiver uniform':\n",
    "    m.apply(init_xuniform)\n",
    "  elif init_m == 'xavier normal':\n",
    "    m.apply(init_xnormal)"
   ],
   "metadata": {
    "id": "r1gV4YAkvrFF",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "input_size = 11\n",
    "output_size = 1\n",
    "num_layers = 4\n",
    "hidden_size = 600\n",
    "batch_size = 1141\n",
    "lr = 0.00012243587926335812\n",
    "init_method = 'xaiver uniform'\n",
    "act_fn = 'LeakyReLU'\n",
    "\n",
    "model = Net(input_size, output_size, hidden_size, num_layers, act_fn)\n",
    "init_weights(model, init_method)\n",
    "\n",
    "loss_fn = nn.MSELoss()"
   ],
   "metadata": {
    "id": "6f0_pFsMvtlS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)"
   ],
   "metadata": {
    "id": "9PQyiOVqvwoX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class OptDataset(Dataset):\n",
    "\n",
    "  def __init__(self, X, y):\n",
    "    self.X = X\n",
    "    self.y = y\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.X[idx], self.y[idx]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X)"
   ],
   "metadata": {
    "id": "-GGFW7Ywvyg-",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "save_model_path = '../models/final_heston_model.chkpt'\n",
    "\n",
    "model = Net(input_size, output_size, hidden_size, num_layers, act_fn)\n",
    "model.load_state_dict(torch.load(save_model_path, map_location=device))\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "id": "7EEL4yyXwakY",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "test_size = 30\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_out = model(X_test[0:test_size])\n",
    "\n",
    "test_out = output_sc.inverse_transform(test_out.cpu().detach().numpy())\n",
    "real_out = output_sc.inverse_transform(y_test[0:test_size].cpu().detach().numpy())"
   ],
   "metadata": {
    "id": "5EIzKims8ErS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.zero_grad()\n",
    "inp_g = X_test[0:test_size].clone().detach().requires_grad_(True)\n",
    "test_out_g = model(inp_g)"
   ],
   "metadata": {
    "id": "Ruq7rZqsw4gX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "cols = ['Price', 'Strike', 'Kappa', 'Rho', 'Theta', 'Xi', 'V_0',\n",
    "       'Interest Rate', 'Time to Expiration', 'C', 'P']\n",
    "test_options = pd.DataFrame(input_sc.inverse_transform(X_test[0:test_size].cpu().detach().numpy()), columns=cols)\n",
    "test_options['Prediction'] = test_out\n",
    "test_options['Real'] = real_out"
   ],
   "metadata": {
    "id": "7r98qV_88TOv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_options"
   ],
   "metadata": {
    "id": "08iBR9Cg8lyb",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 990
    },
    "outputId": "59cff63e-ddb9-4a2d-bf0a-408542b7353f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "         Price      Strike     Kappa       Rho     Theta        Xi       V_0  \\\n0    91.997589  165.022598  1.689353 -0.744619  0.207761  0.196682  0.179774   \n1   100.000237   90.006714  1.781204 -0.265676  0.151816  0.362019  0.332520   \n2   119.000381  118.998100  0.743793 -0.631957  0.020763  0.349615  0.302988   \n3   115.996803   91.001205  0.809019 -0.214292  0.486074  0.305426  0.465927   \n4   100.000237   64.013428  0.520082 -0.871746  0.435766  0.169760  0.252438   \n5   119.000381  177.970490  1.700059 -0.272527  0.273446  0.499447  0.381089   \n6   100.000237  101.999115  1.182622 -0.249436  0.069802  0.078282  0.147880   \n7    98.001068   53.015518  1.452399 -0.810086  0.039505  0.261969  0.259040   \n8   100.000237   79.008804  1.810506 -0.489986  0.033022  0.424320  0.236206   \n9   100.000237  148.018738  0.100272 -0.180037  0.220708  0.111194  0.437267   \n10   86.998978  173.017532  1.793037 -0.898135  0.433934  0.209367  0.486851   \n11  100.000237   83.006271  1.107394 -0.298662  0.219369  0.441657  0.458826   \n12  111.999382  157.027664  0.162257 -0.346176  0.005966  0.096042  0.340065   \n13  100.000237   62.024445  0.899884 -0.772531  0.293228  0.100975  0.173560   \n14  101.000053  160.030640  0.441473 -0.495600  0.282729  0.419668  0.053532   \n15  100.000237   57.032486  0.881358 -0.379417  0.128283  0.063763  0.155870   \n16  100.000237   98.996140  1.843753 -0.362289  0.378694  0.173918  0.479750   \n17  101.000053  124.999176  0.079422 -0.249436  0.191908  0.210460  0.278809   \n18  100.000237   79.008804  1.886015 -0.080568  0.268567  0.037546  0.365491   \n19  100.000237   92.999939  1.198259 -0.110510  0.057824  0.484365  0.309789   \n20  100.000237   80.997787  0.331308 -0.006729  0.322010  0.444758  0.355917   \n21  100.000237   83.006271  1.073231 -0.038701  0.463104  0.392042  0.085235   \n22  101.000053  100.994873  1.306733 -0.282550  0.063884  0.056293  0.345962   \n23   89.995193   54.029510  0.506840 -0.728633  0.369394  0.112181  0.247809   \n24   99.000420   81.992279  1.697242 -0.454589  0.002021  0.099283  0.378426   \n25  100.000237  112.000099  1.618351 -0.427248  0.311758  0.265387  0.082825   \n26  100.000237   62.024445  0.214663 -0.574230  0.423929  0.022183  0.388191   \n27  100.000237  123.994934  0.853535 -0.363494  0.375735  0.181882  0.495855   \n28  110.998192  179.998474  0.894530 -0.789025  0.498756  0.010624  0.216169   \n29  100.000237  150.007721  1.003907 -0.005206  0.144630  0.167716  0.423445   \n\n    Interest Rate  Time to Expiration         C         P  Prediction  \\\n0        0.091636            0.966828 -0.000003  1.000003   66.684967   \n1        0.010186            0.874121 -0.000003  1.000003    5.274084   \n2        0.066769            0.478711  0.999997  0.000003    4.311134   \n3        0.075435            0.799731 -0.000003  1.000003    0.453975   \n4        0.041319            0.708434  0.999997  0.000003   34.846703   \n5        0.035153            0.197282  0.999997  0.000003    0.068439   \n6        0.025334            0.582037  0.999997  0.000003    2.661062   \n7        0.057435            0.341413  0.999997  0.000003   42.848530   \n8        0.034151            0.187983 -0.000003  1.000003    0.307016   \n9        0.079532            0.365224 -0.000003  1.000003   44.869846   \n10       0.027186            0.135572  0.999997  0.000003    0.060742   \n11       0.067987            1.057843 -0.000003  1.000003    0.655141   \n12       0.040101            0.373818  0.999997  0.000003    0.442342   \n13       0.062805            0.999514  0.999997  0.000003   35.394611   \n14       0.067258            0.938086  0.999997  0.000003   -0.051184   \n15       0.052979            0.476809 -0.000003  1.000003    0.164068   \n16       0.090164            0.920052  0.999997  0.000003    4.327912   \n17       0.081613            0.361983 -0.000003  1.000003   22.910194   \n18       0.098157            0.492871 -0.000003  1.000003    0.164833   \n19       0.062862            0.422144  0.999997  0.000003    7.049657   \n20       0.016986            0.419467  0.999997  0.000003   20.328989   \n21       0.053101            0.103731 -0.000003  1.000003    0.015902   \n22       0.093031            0.107676  0.999997  0.000003    2.674942   \n23       0.053009            0.530735  0.999997  0.000003   34.486374   \n24       0.062373            0.476528  0.999997  0.000003   15.458697   \n25       0.031588            0.560076 -0.000003  1.000003   11.255805   \n26       0.087424            0.768031 -0.000003  1.000003    0.163287   \n27       0.065431            0.112466 -0.000003  1.000003   20.743811   \n28       0.059782            0.159805 -0.000003  1.000003   65.287148   \n29       0.069522            0.455535  0.999997  0.000003    0.056064   \n\n         Real  \n0   66.739990  \n1    5.499053  \n2    4.794890  \n3    0.336961  \n4   34.719139  \n5    0.156950  \n6    3.164198  \n7   42.787884  \n8    0.241661  \n9   44.842133  \n10  -0.001884  \n11   0.464028  \n12   0.432261  \n13  35.280350  \n14  -0.001884  \n15  -0.001884  \n16   4.286623  \n17  22.674259  \n18   0.029883  \n19   6.880905  \n20  19.984676  \n21   0.040472  \n22   2.761820  \n23  34.560307  \n24  15.578036  \n25  11.079407  \n26   0.008705  \n27  20.829142  \n28  65.003410  \n29   0.104005  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Price</th>\n      <th>Strike</th>\n      <th>Kappa</th>\n      <th>Rho</th>\n      <th>Theta</th>\n      <th>Xi</th>\n      <th>V_0</th>\n      <th>Interest Rate</th>\n      <th>Time to Expiration</th>\n      <th>C</th>\n      <th>P</th>\n      <th>Prediction</th>\n      <th>Real</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>91.997589</td>\n      <td>165.022598</td>\n      <td>1.689353</td>\n      <td>-0.744619</td>\n      <td>0.207761</td>\n      <td>0.196682</td>\n      <td>0.179774</td>\n      <td>0.091636</td>\n      <td>0.966828</td>\n      <td>-0.000003</td>\n      <td>1.000003</td>\n      <td>66.684967</td>\n      <td>66.739990</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100.000237</td>\n      <td>90.006714</td>\n      <td>1.781204</td>\n      <td>-0.265676</td>\n      <td>0.151816</td>\n      <td>0.362019</td>\n      <td>0.332520</td>\n      <td>0.010186</td>\n      <td>0.874121</td>\n      <td>-0.000003</td>\n      <td>1.000003</td>\n      <td>5.274084</td>\n      <td>5.499053</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>119.000381</td>\n      <td>118.998100</td>\n      <td>0.743793</td>\n      <td>-0.631957</td>\n      <td>0.020763</td>\n      <td>0.349615</td>\n      <td>0.302988</td>\n      <td>0.066769</td>\n      <td>0.478711</td>\n      <td>0.999997</td>\n      <td>0.000003</td>\n      <td>4.311134</td>\n      <td>4.794890</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>115.996803</td>\n      <td>91.001205</td>\n      <td>0.809019</td>\n      <td>-0.214292</td>\n      <td>0.486074</td>\n      <td>0.305426</td>\n      <td>0.465927</td>\n      <td>0.075435</td>\n      <td>0.799731</td>\n      <td>-0.000003</td>\n      <td>1.000003</td>\n      <td>0.453975</td>\n      <td>0.336961</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100.000237</td>\n      <td>64.013428</td>\n      <td>0.520082</td>\n      <td>-0.871746</td>\n      <td>0.435766</td>\n      <td>0.169760</td>\n      <td>0.252438</td>\n      <td>0.041319</td>\n      <td>0.708434</td>\n      <td>0.999997</td>\n      <td>0.000003</td>\n      <td>34.846703</td>\n      <td>34.719139</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>119.000381</td>\n      <td>177.970490</td>\n      <td>1.700059</td>\n      <td>-0.272527</td>\n      <td>0.273446</td>\n      <td>0.499447</td>\n      <td>0.381089</td>\n      <td>0.035153</td>\n      <td>0.197282</td>\n      <td>0.999997</td>\n      <td>0.000003</td>\n      <td>0.068439</td>\n      <td>0.156950</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>100.000237</td>\n      <td>101.999115</td>\n      <td>1.182622</td>\n      <td>-0.249436</td>\n      <td>0.069802</td>\n      <td>0.078282</td>\n      <td>0.147880</td>\n      <td>0.025334</td>\n      <td>0.582037</td>\n      <td>0.999997</td>\n      <td>0.000003</td>\n      <td>2.661062</td>\n      <td>3.164198</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>98.001068</td>\n      <td>53.015518</td>\n      <td>1.452399</td>\n      <td>-0.810086</td>\n      <td>0.039505</td>\n      <td>0.261969</td>\n      <td>0.259040</td>\n      <td>0.057435</td>\n      <td>0.341413</td>\n      <td>0.999997</td>\n      <td>0.000003</td>\n      <td>42.848530</td>\n      <td>42.787884</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>100.000237</td>\n      <td>79.008804</td>\n      <td>1.810506</td>\n      <td>-0.489986</td>\n      <td>0.033022</td>\n      <td>0.424320</td>\n      <td>0.236206</td>\n      <td>0.034151</td>\n      <td>0.187983</td>\n      <td>-0.000003</td>\n      <td>1.000003</td>\n      <td>0.307016</td>\n      <td>0.241661</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>100.000237</td>\n      <td>148.018738</td>\n      <td>0.100272</td>\n      <td>-0.180037</td>\n      <td>0.220708</td>\n      <td>0.111194</td>\n      <td>0.437267</td>\n      <td>0.079532</td>\n      <td>0.365224</td>\n      <td>-0.000003</td>\n      <td>1.000003</td>\n      <td>44.869846</td>\n      <td>44.842133</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>86.998978</td>\n      <td>173.017532</td>\n      <td>1.793037</td>\n      <td>-0.898135</td>\n      <td>0.433934</td>\n      <td>0.209367</td>\n      <td>0.486851</td>\n      <td>0.027186</td>\n      <td>0.135572</td>\n      <td>0.999997</td>\n      <td>0.000003</td>\n      <td>0.060742</td>\n      <td>-0.001884</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>100.000237</td>\n      <td>83.006271</td>\n      <td>1.107394</td>\n      <td>-0.298662</td>\n      <td>0.219369</td>\n      <td>0.441657</td>\n      <td>0.458826</td>\n      <td>0.067987</td>\n      <td>1.057843</td>\n      <td>-0.000003</td>\n      <td>1.000003</td>\n      <td>0.655141</td>\n      <td>0.464028</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>111.999382</td>\n      <td>157.027664</td>\n      <td>0.162257</td>\n      <td>-0.346176</td>\n      <td>0.005966</td>\n      <td>0.096042</td>\n      <td>0.340065</td>\n      <td>0.040101</td>\n      <td>0.373818</td>\n      <td>0.999997</td>\n      <td>0.000003</td>\n      <td>0.442342</td>\n      <td>0.432261</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>100.000237</td>\n      <td>62.024445</td>\n      <td>0.899884</td>\n      <td>-0.772531</td>\n      <td>0.293228</td>\n      <td>0.100975</td>\n      <td>0.173560</td>\n      <td>0.062805</td>\n      <td>0.999514</td>\n      <td>0.999997</td>\n      <td>0.000003</td>\n      <td>35.394611</td>\n      <td>35.280350</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>101.000053</td>\n      <td>160.030640</td>\n      <td>0.441473</td>\n      <td>-0.495600</td>\n      <td>0.282729</td>\n      <td>0.419668</td>\n      <td>0.053532</td>\n      <td>0.067258</td>\n      <td>0.938086</td>\n      <td>0.999997</td>\n      <td>0.000003</td>\n      <td>-0.051184</td>\n      <td>-0.001884</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>100.000237</td>\n      <td>57.032486</td>\n      <td>0.881358</td>\n      <td>-0.379417</td>\n      <td>0.128283</td>\n      <td>0.063763</td>\n      <td>0.155870</td>\n      <td>0.052979</td>\n      <td>0.476809</td>\n      <td>-0.000003</td>\n      <td>1.000003</td>\n      <td>0.164068</td>\n      <td>-0.001884</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>100.000237</td>\n      <td>98.996140</td>\n      <td>1.843753</td>\n      <td>-0.362289</td>\n      <td>0.378694</td>\n      <td>0.173918</td>\n      <td>0.479750</td>\n      <td>0.090164</td>\n      <td>0.920052</td>\n      <td>0.999997</td>\n      <td>0.000003</td>\n      <td>4.327912</td>\n      <td>4.286623</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>101.000053</td>\n      <td>124.999176</td>\n      <td>0.079422</td>\n      <td>-0.249436</td>\n      <td>0.191908</td>\n      <td>0.210460</td>\n      <td>0.278809</td>\n      <td>0.081613</td>\n      <td>0.361983</td>\n      <td>-0.000003</td>\n      <td>1.000003</td>\n      <td>22.910194</td>\n      <td>22.674259</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>100.000237</td>\n      <td>79.008804</td>\n      <td>1.886015</td>\n      <td>-0.080568</td>\n      <td>0.268567</td>\n      <td>0.037546</td>\n      <td>0.365491</td>\n      <td>0.098157</td>\n      <td>0.492871</td>\n      <td>-0.000003</td>\n      <td>1.000003</td>\n      <td>0.164833</td>\n      <td>0.029883</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>100.000237</td>\n      <td>92.999939</td>\n      <td>1.198259</td>\n      <td>-0.110510</td>\n      <td>0.057824</td>\n      <td>0.484365</td>\n      <td>0.309789</td>\n      <td>0.062862</td>\n      <td>0.422144</td>\n      <td>0.999997</td>\n      <td>0.000003</td>\n      <td>7.049657</td>\n      <td>6.880905</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>100.000237</td>\n      <td>80.997787</td>\n      <td>0.331308</td>\n      <td>-0.006729</td>\n      <td>0.322010</td>\n      <td>0.444758</td>\n      <td>0.355917</td>\n      <td>0.016986</td>\n      <td>0.419467</td>\n      <td>0.999997</td>\n      <td>0.000003</td>\n      <td>20.328989</td>\n      <td>19.984676</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>100.000237</td>\n      <td>83.006271</td>\n      <td>1.073231</td>\n      <td>-0.038701</td>\n      <td>0.463104</td>\n      <td>0.392042</td>\n      <td>0.085235</td>\n      <td>0.053101</td>\n      <td>0.103731</td>\n      <td>-0.000003</td>\n      <td>1.000003</td>\n      <td>0.015902</td>\n      <td>0.040472</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>101.000053</td>\n      <td>100.994873</td>\n      <td>1.306733</td>\n      <td>-0.282550</td>\n      <td>0.063884</td>\n      <td>0.056293</td>\n      <td>0.345962</td>\n      <td>0.093031</td>\n      <td>0.107676</td>\n      <td>0.999997</td>\n      <td>0.000003</td>\n      <td>2.674942</td>\n      <td>2.761820</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>89.995193</td>\n      <td>54.029510</td>\n      <td>0.506840</td>\n      <td>-0.728633</td>\n      <td>0.369394</td>\n      <td>0.112181</td>\n      <td>0.247809</td>\n      <td>0.053009</td>\n      <td>0.530735</td>\n      <td>0.999997</td>\n      <td>0.000003</td>\n      <td>34.486374</td>\n      <td>34.560307</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>99.000420</td>\n      <td>81.992279</td>\n      <td>1.697242</td>\n      <td>-0.454589</td>\n      <td>0.002021</td>\n      <td>0.099283</td>\n      <td>0.378426</td>\n      <td>0.062373</td>\n      <td>0.476528</td>\n      <td>0.999997</td>\n      <td>0.000003</td>\n      <td>15.458697</td>\n      <td>15.578036</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>100.000237</td>\n      <td>112.000099</td>\n      <td>1.618351</td>\n      <td>-0.427248</td>\n      <td>0.311758</td>\n      <td>0.265387</td>\n      <td>0.082825</td>\n      <td>0.031588</td>\n      <td>0.560076</td>\n      <td>-0.000003</td>\n      <td>1.000003</td>\n      <td>11.255805</td>\n      <td>11.079407</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>100.000237</td>\n      <td>62.024445</td>\n      <td>0.214663</td>\n      <td>-0.574230</td>\n      <td>0.423929</td>\n      <td>0.022183</td>\n      <td>0.388191</td>\n      <td>0.087424</td>\n      <td>0.768031</td>\n      <td>-0.000003</td>\n      <td>1.000003</td>\n      <td>0.163287</td>\n      <td>0.008705</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>100.000237</td>\n      <td>123.994934</td>\n      <td>0.853535</td>\n      <td>-0.363494</td>\n      <td>0.375735</td>\n      <td>0.181882</td>\n      <td>0.495855</td>\n      <td>0.065431</td>\n      <td>0.112466</td>\n      <td>-0.000003</td>\n      <td>1.000003</td>\n      <td>20.743811</td>\n      <td>20.829142</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>110.998192</td>\n      <td>179.998474</td>\n      <td>0.894530</td>\n      <td>-0.789025</td>\n      <td>0.498756</td>\n      <td>0.010624</td>\n      <td>0.216169</td>\n      <td>0.059782</td>\n      <td>0.159805</td>\n      <td>-0.000003</td>\n      <td>1.000003</td>\n      <td>65.287148</td>\n      <td>65.003410</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>100.000237</td>\n      <td>150.007721</td>\n      <td>1.003907</td>\n      <td>-0.005206</td>\n      <td>0.144630</td>\n      <td>0.167716</td>\n      <td>0.423445</td>\n      <td>0.069522</td>\n      <td>0.455535</td>\n      <td>0.999997</td>\n      <td>0.000003</td>\n      <td>0.056064</td>\n      <td>0.104005</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get the Greeks from the Neural Net\n",
    "\n",
    "One method for obtaining the option's Greek from any pricing model is the finite-difference methods. \n",
    "\n",
    "In numerical analysis, finite-difference methods (FDM) are a class of numerical techniques for solving differential equations by approximating derivatives with finite differences. Both the spatial domain and time interval (if applicable) are discretized, or broken into a finite number of steps, and the value of the solution at these discrete points is approximated by solving algebraic equations containing finite differences and values from nearby points.\n",
    "\n",
    "Finite difference methods convert ordinary differential equations (ODE) or partial differential equations (PDE), which may be nonlinear, into a system of linear equations that can be solved by matrix algebra techniques. \n",
    "\n",
    "The essence of the method is that we will approximate the partial derivative representing the particular sensitivity of interest.\n",
    "\n",
    "For example, if we know that the delta of an option is the derivative of the option's value with respect to the underlying price $\\frac{\\partial V}{\\partial S}$. If we calculate the two option prices, one at $S$ and the other at $S + \\Delta S$, subtract the prices and divide by $\\Delta S$, we have a ***forward difference approximation*** to the derivative: \n",
    "\n",
    "$$\n",
    "\\frac{\\partial V}{\\partial S} \\approx \\frac{V(S + \\Delta S, T, \\sigma, r, X) - V(S, T, \\sigma, r, X)}{\\Delta S}\n",
    "$$\n",
    "\n",
    "The same reasoning can be applied to all the first order derivative of an option. \n",
    "\n",
    "However, $\\Gamma$ on the other hand is a second order derivative and the previous formula cannot be used to approximate this greek. It can be proved that $\\Gamma$ can be approximate with the following formula:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial^2 V}{\\partial S^2} = \\frac{V(S + \\Delta S, T, \\sigma, r, X) - 2 * V(S, T, \\sigma, r, X) + V(S - \\Delta S, T, \\sigma, r, X)}{(\\Delta S)^2}\n",
    "$$"
   ],
   "metadata": {
    "id": "aJEjL20s7o78",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def get_d1_d2(S, X, T, t, r, sigma):\n",
    "    \"\"\"\n",
    "    Compute d1 and d2 values for the black-scholes pricing model\n",
    "\n",
    "\n",
    "    :param S: underlying price\n",
    "    :param X: option's strike price\n",
    "    :param T: option's time to maturity (in years)\n",
    "    :param t: current time (in years)\n",
    "    :param r: interest rate\n",
    "    :param sigma: underlying volatility\n",
    "    :return: (d1, d2)\n",
    "    \"\"\"\n",
    "    d1 = (np.log(S / X) + (r + sigma * sigma / 2.) * (T - t)) / (sigma * np.sqrt(T - t))\n",
    "    d2 = d1 - sigma * np.sqrt(T - t)\n",
    "    return d1, d2\n",
    "\n",
    "\n",
    "def black_scholes(S, X, T, t, r, sigma, o_type: str = \"C\") -> np.single:\n",
    "    \"\"\"\n",
    "    Compute option price using the black-scholes model\n",
    "\n",
    "    :param S: underlying price\n",
    "    :param X: option's strike price\n",
    "    :param T: option's time to maturity (in years)\n",
    "    :param t: current time (in years)\n",
    "    :param r: interest rate (in percentual)\n",
    "    :param sigma: underlying volatility\n",
    "    :param o_type: option type, \"C\" for a call option and \"P\" for a put option\n",
    "    :return: the black-scholes option price\n",
    "    \"\"\"\n",
    "    d1, d2 = get_d1_d2(S, X, T, t, r, sigma)\n",
    "    if o_type == \"C\":\n",
    "        return S * stats.norm.cdf(d1, 0, 1) - X * np.exp(-r * (T - t)) * stats.norm.cdf(d2, 0, 1)\n",
    "    else:\n",
    "        return X * np.exp(-r * (T - t)) * stats.norm.cdf(-d2, 0, 1) - S * stats.norm.cdf(-d1, 0, 1)"
   ],
   "metadata": {
    "id": "lRtbY9mUXaxn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def delta_fdm_bs(S, X, sigma, tau, r, delta_S, o_type: str = 'C'):\n",
    "  return (black_scholes(S + delta_S, X, tau, 0, r, sigma, o_type) - black_scholes(S, X, tau, 0, r, sigma, o_type)) / delta_S\n",
    "\n",
    "def theta_fdm_bs(S, X, sigma, tau, r, delta_tau, o_type: str = 'C'):\n",
    "  return (black_scholes(S, X, tau + delta_tau, 0, r, sigma, o_type) - black_scholes(S, X, tau, 0, r, sigma, o_type)) / delta_tau\n",
    "\n",
    "def vega_fdm_bs(S, X, sigma, tau, r, delta_sigma, o_type: str = 'C'):\n",
    "  return (black_scholes(S, X, tau, 0, r, sigma + delta_sigma, o_type) - black_scholes(S, X, tau, 0, r, sigma, o_type)) / delta_sigma\n",
    "\n",
    "def gamma_fdm_bs(S, X, sigma, tau, r, delta_S, o_type: str = 'C'):\n",
    "  return (black_scholes(S + delta_S, X, tau, 0, r, sigma, o_type) - \\\n",
    "          2 * black_scholes(S, X, tau, 0, r, sigma, o_type) + \\\n",
    "          black_scholes(S - delta_S, X, tau, 0, r, sigma, o_type)) / (delta_S ** 2)"
   ],
   "metadata": {
    "id": "kpn9EAeLXbjn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "But we can use the FDM to get the greeks directly from the neural net? That's simple, we just have to replace the BS Model with out neural net pricer. "
   ],
   "metadata": {
    "id": "MSyvk6wVqMaS",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def delta_fdm_net(S, X, kappa, rho, theta, xi, v0, tau, r, delta_S, o_type: str = 'C'):\n",
    "  c = 1 if o_type == 'C' else 0\n",
    "  p = 1 if o_type == 'P' else 0\n",
    "  input_df_1 = pd.DataFrame(np.array([[S + delta_S, X, kappa, rho, theta, xi, v0, r,  tau,  c, p]]), columns=df_cols)\n",
    "  input_df_2 = pd.DataFrame(np.array([[S, X, kappa, rho, theta, xi, v0, r,  tau,  c, p]]), columns=df_cols)\n",
    "  net_input_1 = torch.Tensor(\n",
    "      input_sc.transform(input_df_1)).to(device)\n",
    "  net_input_2 = torch.Tensor(\n",
    "      input_sc.transform(input_df_2)).to(device)\n",
    "  sc_output_1 = output_sc.inverse_transform(model(net_input_1).detach().cpu().numpy())\n",
    "  sc_output_2 = output_sc.inverse_transform(model(net_input_2).detach().cpu().numpy())\n",
    "  return (sc_output_1 - sc_output_2) / delta_S\n",
    "\n",
    "def theta_fdm_net(S, X, kappa, rho, theta, xi, v0, tau, r, delta_tau, o_type: str = 'C'):\n",
    "  c = 1 if o_type == 'C' else 0\n",
    "  p = 1 if o_type == 'P' else 0\n",
    "  input_df_1 = pd.DataFrame(np.array([[S, X, kappa, rho, theta, xi, v0, r,  tau + delta_tau,  c, p]]), columns=df_cols)\n",
    "  input_df_2 = pd.DataFrame(np.array([[S, X, kappa, rho, theta, xi, v0, r,  tau,  c, p]]), columns=df_cols)\n",
    "  net_input_1 = torch.Tensor(\n",
    "      input_sc.transform(input_df_1)).to(device)\n",
    "  net_input_2 = torch.Tensor(\n",
    "      input_sc.transform(input_df_2)).to(device)\n",
    "  sc_output_1 = output_sc.inverse_transform(model(net_input_1).detach().cpu().numpy())\n",
    "  sc_output_2 = output_sc.inverse_transform(model(net_input_2).detach().cpu().numpy())\n",
    "  return (sc_output_1 - sc_output_2) / delta_tau\n",
    "\n",
    "def gamma_fdm_net(S, X, kappa, rho, theta, xi, v0, tau, r, delta_S, o_type: str = 'C'):\n",
    "  c = 1 if o_type == 'C' else 0\n",
    "  p = 1 if o_type == 'P' else 0\n",
    "  input_df_1 = pd.DataFrame(np.array([[S + delta_S, X, kappa, rho, theta, xi, v0, r,  tau,  c, p]]), columns=df_cols)\n",
    "  input_df_2 = pd.DataFrame(np.array([[S, X, kappa, rho, theta, xi, v0, r,  tau,  c, p]]), columns=df_cols)\n",
    "  input_df_3 = pd.DataFrame(np.array([[S - delta_S, X, kappa, rho, theta, xi, v0, r,  tau,  c, p]]), columns=df_cols)\n",
    "  net_input_1 = torch.Tensor(\n",
    "      input_sc.transform(input_df_1)).to(device)\n",
    "  net_input_2 = torch.Tensor(\n",
    "      input_sc.transform(input_df_2)).to(device)\n",
    "  net_input_3 = torch.Tensor(\n",
    "      input_sc.transform(input_df_3)).to(device)\n",
    "  sc_output_1 = output_sc.inverse_transform(model(net_input_1).detach().cpu().numpy())\n",
    "  sc_output_2 = output_sc.inverse_transform(model(net_input_2).detach().cpu().numpy())\n",
    "  sc_output_3 = output_sc.inverse_transform(model(net_input_3).detach().cpu().numpy())\n",
    "  return (sc_output_1 - 2 * sc_output_2 + sc_output_3) / (delta_S ** 2)"
   ],
   "metadata": {
    "id": "2qUfM8N7Zemk",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Example 1"
   ],
   "metadata": {
    "id": "wYJ75niPl9_V",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "S = 92\n",
    "X = 165\n",
    "rho = -0.744619\n",
    "kappa = 1.689353 \n",
    "theta = 0.207761 \n",
    "xi = 0.196682 \n",
    "v0 = 0.179774\n",
    "tau = 0.966828 \n",
    "r = 0.091636 \n",
    "delta_s = 0.1\n",
    "delta_sigma = 0.01\n",
    "delta_tau = 0.0027\n",
    "type_ = 'P'\n",
    "\n",
    "print('Underlying price: ', S)\n",
    "print('Strike price: ', X)\n",
    "print('Time to Expiration: ', tau)\n",
    "print('Interest rate: ', r)\n",
    "print('Option type: ', type_,'\\n')\n",
    "\n",
    "print('ANN\\'s Delta: ', delta_fdm_net(S, X, kappa, rho, theta, xi, v0, tau, r, delta_s, type_))\n",
    "print('-------------')\n",
    "print('ANN\\'s Theta: ', theta_fdm_net(S, X, kappa, rho, theta, xi, v0, tau, r, delta_tau, type_) / 364)\n",
    "print('-------------')\n",
    "print('ANN\\'s Gamma: ', gamma_fdm_net(S, X, kappa, rho, theta, xi, v0, tau, r, delta_s, type_))"
   ],
   "metadata": {
    "id": "Vn2NHViaZjKd",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "280aabb8-74d5-45a9-8351-8624cf9b2956",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Underlying price:  92\n",
      "Strike price:  165\n",
      "Time to Expiration:  0.966828\n",
      "Interest rate:  0.091636\n",
      "Option type:  P \n",
      "\n",
      "ANN's Delta:  [[-1.0305786]]\n",
      "-------------\n",
      "ANN's Theta:  [[0.00670716]]\n",
      "-------------\n",
      "ANN's Gamma:  [[0.18615723]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Example 2"
   ],
   "metadata": {
    "id": "NLu9yKH1leJ4",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "S = 100\n",
    "X = 110\n",
    "rho = -0.723259\n",
    "kappa = 0.549236\n",
    "theta = 0.234988\n",
    "xi = 0.453115\n",
    "v0 = 0.458942\n",
    "tau = 0.910310\n",
    "r = 0.01\n",
    "delta_s = 0.1\n",
    "delta_sigma = 0.01\n",
    "delta_tau = 0.0027\n",
    "type_ = 'C'\n",
    "\n",
    "print('Underlying price: ', S)\n",
    "print('Strike price: ', X)\n",
    "print('Time to Expiration: ', tau)\n",
    "print('Interest rate: ', r)\n",
    "print('Option type: ', type_,'\\n')\n",
    "\n",
    "print('ANN\\'s Delta: ', delta_fdm_net(S, X, kappa, rho, theta, xi, v0, tau, r, delta_s, type_))\n",
    "print('-------------')\n",
    "print('ANN\\'s Theta: ', theta_fdm_net(S, X, kappa, rho, theta, xi, v0, tau, r, delta_tau, type_))\n",
    "print('-------------')\n",
    "print('ANN\\'s Gamma: ', gamma_fdm_net(S, X, kappa, rho, theta, xi, v0, tau, r, delta_s, type_))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "owNhtOJkkRui",
    "outputId": "beadabfb-a55f-460e-cef7-de9925b51e20",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Underlying price:  100\n",
      "Strike price:  110\n",
      "Time to Expiration:  0.91031\n",
      "Interest rate:  0.01\n",
      "Option type:  C \n",
      "\n",
      "ANN's Delta:  [[0.39126396]]\n",
      "-------------\n",
      "ANN's Theta:  [[1.0006516]]\n",
      "-------------\n",
      "ANN's Gamma:  [[-0.08869171]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Autodiff results"
   ],
   "metadata": {
    "id": "Lcx884c9oEvb",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model.zero_grad()\n",
    "inp_g = X_test[0].clone().detach().requires_grad_(True)\n",
    "test_out_g = model(inp_g)\n",
    "grad_ns = torch.autograd.grad(test_out_g, inp_g, retain_graph=True)[0].data\n",
    "grad_ns"
   ],
   "metadata": {
    "id": "mnpfxeY5dgIb",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "de1be438-543f-4113-8051-fd91f178724c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-0.3645,  1.7209, -0.0351,  0.0071,  0.0349, -0.0231, -0.0373, -0.0702,\n         0.0377,  0.1268, -0.1870], device='cuda:0')"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  }
 ]
}