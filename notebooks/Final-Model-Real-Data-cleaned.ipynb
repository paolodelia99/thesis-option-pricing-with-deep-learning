{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ju-WUaXnY5cr",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Models Testing on Heston data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 824,
     "status": "ok",
     "timestamp": 1650891681415,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "hH3-v8y-AuXg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1650891681417,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "QXEzFQ3iAyj_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set seeds\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1650891681418,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "gsH02HCWA0gC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "options_path = '../data/real_options_cleaned.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1650891681421,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "jT4n95T6A4S6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 3413,
     "status": "ok",
     "timestamp": 1650891684820,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "7H8lEQPCA5IS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "options_df = pd.read_csv(options_path, index_col=0)\n",
    "options_df = reduce_mem_usage(options_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1650891684821,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "9TKRgvuOA8pC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "options_df = shuffle(options_df, random_state=0)\n",
    "options_df = options_df.reset_index()\n",
    "options_df['r'] = options_df['r'] / 100\n",
    "options_df = options_df.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1650891684822,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "3HXliAsq132p",
    "outputId": "09bc2eb1-d20d-4471-ed50-5fa0eba727fb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "             contractSymbol        lastTradeDate  strike    lastPrice  \\\n0       TSLA220916P00304000  2022-04-13 15:39:13   304.0     1.679688   \n1       TSLA230915C00375000  2022-03-29 15:21:57   375.0   752.000000   \n2        AMD221021P00090000  2022-05-02 19:41:36    90.0    13.398438   \n3       TSLA230120C01750000  2022-05-24 16:39:03  1750.0     5.769531   \n4       AMZN240119C03850000  2022-04-26 18:58:31  3850.0   228.500000   \n...                     ...                  ...     ...          ...   \n636030  TSLA230915P01425000  2022-05-19 16:13:22  1425.0   734.500000   \n636031  TSLA220520P00580000  2022-05-04 19:53:41   580.0     0.830078   \n636032  MSFT220916C00185000  2022-05-02 17:52:36   185.0    96.625000   \n636033  AMZN230317P03300000  2022-05-24 16:20:29  3300.0  1226.000000   \n636034  NFLX230616P00090000  2022-05-13 18:38:35    90.0     6.199219   \n\n                bid          ask     change  percentChange  volume  \\\n0          1.419922     1.990234  -0.770020     -31.421875     1.0   \n1        503.250000   518.500000   0.000000       0.000000     4.0   \n2         12.898438    13.101562  -1.349609      -9.156250    30.0   \n3          5.000000     6.101562  -1.259766     -17.921875    13.0   \n4         80.000000    98.000000   0.000000       0.000000     2.0   \n...             ...          ...        ...            ...     ...   \n636030   736.500000   754.500000  59.750000       8.851562     2.0   \n636031     0.660156     0.859863  -1.080078     -56.531250   271.0   \n636032    97.375000   100.875000   0.000000       0.000000     2.0   \n636033  1167.000000  1186.000000   0.000000       0.000000    17.0   \n636034     4.800781     5.851562   0.000000       0.000000     2.0   \n\n        openInterest  ...  contractSize  currency  type  expiryDate  \\\n0              153.0  ...       REGULAR       USD   put  2022-09-16   \n1                4.0  ...       REGULAR       USD  call  2023-09-15   \n2             4328.0  ...       REGULAR       USD   put  2022-10-21   \n3              518.0  ...       REGULAR       USD  call  2023-01-20   \n4               54.0  ...       REGULAR       USD  call  2024-01-19   \n...              ...  ...           ...       ...   ...         ...   \n636030          80.0  ...       REGULAR       USD   put  2023-09-15   \n636031         590.0  ...       REGULAR       USD   put  2022-05-20   \n636032        2600.0  ...       REGULAR       USD  call  2022-09-16   \n636033         107.0  ...       REGULAR       USD   put  2023-03-17   \n636034         192.0  ...       REGULAR       USD   put  2023-06-16   \n\n       downloadDate      close       vol  moneyness       tau         r  \n0        2022-04-13  1022.5000  0.581055   0.297363  0.428467  0.007851  \n1        2022-05-04   952.5000  0.653809   2.539062  1.371094  0.008331  \n2        2022-05-02    89.8125  0.541504   1.001953  0.472412  0.009323  \n3        2022-05-24   628.0000  0.859375   0.358887  0.662109  0.010880  \n4        2022-05-05  2328.0000  0.671387   0.604492  1.713867  0.008530  \n...             ...        ...       ...        ...       ...       ...  \n636030   2022-05-19   709.5000  0.834473   2.007812  1.330078  0.010323  \n636031   2022-05-04   952.5000  0.653809   0.608887  0.043945  0.008331  \n636032   2022-05-03   281.7500  0.407227   1.523438  0.373535  0.008812  \n636033   2022-05-25  2136.0000  0.752930   1.544922  0.812988  0.010719  \n636034   2022-05-17   190.5000  1.629883   0.472412  1.084961  0.010437  \n\n[636035 rows x 22 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>contractSymbol</th>\n      <th>lastTradeDate</th>\n      <th>strike</th>\n      <th>lastPrice</th>\n      <th>bid</th>\n      <th>ask</th>\n      <th>change</th>\n      <th>percentChange</th>\n      <th>volume</th>\n      <th>openInterest</th>\n      <th>...</th>\n      <th>contractSize</th>\n      <th>currency</th>\n      <th>type</th>\n      <th>expiryDate</th>\n      <th>downloadDate</th>\n      <th>close</th>\n      <th>vol</th>\n      <th>moneyness</th>\n      <th>tau</th>\n      <th>r</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TSLA220916P00304000</td>\n      <td>2022-04-13 15:39:13</td>\n      <td>304.0</td>\n      <td>1.679688</td>\n      <td>1.419922</td>\n      <td>1.990234</td>\n      <td>-0.770020</td>\n      <td>-31.421875</td>\n      <td>1.0</td>\n      <td>153.0</td>\n      <td>...</td>\n      <td>REGULAR</td>\n      <td>USD</td>\n      <td>put</td>\n      <td>2022-09-16</td>\n      <td>2022-04-13</td>\n      <td>1022.5000</td>\n      <td>0.581055</td>\n      <td>0.297363</td>\n      <td>0.428467</td>\n      <td>0.007851</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TSLA230915C00375000</td>\n      <td>2022-03-29 15:21:57</td>\n      <td>375.0</td>\n      <td>752.000000</td>\n      <td>503.250000</td>\n      <td>518.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>REGULAR</td>\n      <td>USD</td>\n      <td>call</td>\n      <td>2023-09-15</td>\n      <td>2022-05-04</td>\n      <td>952.5000</td>\n      <td>0.653809</td>\n      <td>2.539062</td>\n      <td>1.371094</td>\n      <td>0.008331</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AMD221021P00090000</td>\n      <td>2022-05-02 19:41:36</td>\n      <td>90.0</td>\n      <td>13.398438</td>\n      <td>12.898438</td>\n      <td>13.101562</td>\n      <td>-1.349609</td>\n      <td>-9.156250</td>\n      <td>30.0</td>\n      <td>4328.0</td>\n      <td>...</td>\n      <td>REGULAR</td>\n      <td>USD</td>\n      <td>put</td>\n      <td>2022-10-21</td>\n      <td>2022-05-02</td>\n      <td>89.8125</td>\n      <td>0.541504</td>\n      <td>1.001953</td>\n      <td>0.472412</td>\n      <td>0.009323</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TSLA230120C01750000</td>\n      <td>2022-05-24 16:39:03</td>\n      <td>1750.0</td>\n      <td>5.769531</td>\n      <td>5.000000</td>\n      <td>6.101562</td>\n      <td>-1.259766</td>\n      <td>-17.921875</td>\n      <td>13.0</td>\n      <td>518.0</td>\n      <td>...</td>\n      <td>REGULAR</td>\n      <td>USD</td>\n      <td>call</td>\n      <td>2023-01-20</td>\n      <td>2022-05-24</td>\n      <td>628.0000</td>\n      <td>0.859375</td>\n      <td>0.358887</td>\n      <td>0.662109</td>\n      <td>0.010880</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AMZN240119C03850000</td>\n      <td>2022-04-26 18:58:31</td>\n      <td>3850.0</td>\n      <td>228.500000</td>\n      <td>80.000000</td>\n      <td>98.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.0</td>\n      <td>54.0</td>\n      <td>...</td>\n      <td>REGULAR</td>\n      <td>USD</td>\n      <td>call</td>\n      <td>2024-01-19</td>\n      <td>2022-05-05</td>\n      <td>2328.0000</td>\n      <td>0.671387</td>\n      <td>0.604492</td>\n      <td>1.713867</td>\n      <td>0.008530</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>636030</th>\n      <td>TSLA230915P01425000</td>\n      <td>2022-05-19 16:13:22</td>\n      <td>1425.0</td>\n      <td>734.500000</td>\n      <td>736.500000</td>\n      <td>754.500000</td>\n      <td>59.750000</td>\n      <td>8.851562</td>\n      <td>2.0</td>\n      <td>80.0</td>\n      <td>...</td>\n      <td>REGULAR</td>\n      <td>USD</td>\n      <td>put</td>\n      <td>2023-09-15</td>\n      <td>2022-05-19</td>\n      <td>709.5000</td>\n      <td>0.834473</td>\n      <td>2.007812</td>\n      <td>1.330078</td>\n      <td>0.010323</td>\n    </tr>\n    <tr>\n      <th>636031</th>\n      <td>TSLA220520P00580000</td>\n      <td>2022-05-04 19:53:41</td>\n      <td>580.0</td>\n      <td>0.830078</td>\n      <td>0.660156</td>\n      <td>0.859863</td>\n      <td>-1.080078</td>\n      <td>-56.531250</td>\n      <td>271.0</td>\n      <td>590.0</td>\n      <td>...</td>\n      <td>REGULAR</td>\n      <td>USD</td>\n      <td>put</td>\n      <td>2022-05-20</td>\n      <td>2022-05-04</td>\n      <td>952.5000</td>\n      <td>0.653809</td>\n      <td>0.608887</td>\n      <td>0.043945</td>\n      <td>0.008331</td>\n    </tr>\n    <tr>\n      <th>636032</th>\n      <td>MSFT220916C00185000</td>\n      <td>2022-05-02 17:52:36</td>\n      <td>185.0</td>\n      <td>96.625000</td>\n      <td>97.375000</td>\n      <td>100.875000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.0</td>\n      <td>2600.0</td>\n      <td>...</td>\n      <td>REGULAR</td>\n      <td>USD</td>\n      <td>call</td>\n      <td>2022-09-16</td>\n      <td>2022-05-03</td>\n      <td>281.7500</td>\n      <td>0.407227</td>\n      <td>1.523438</td>\n      <td>0.373535</td>\n      <td>0.008812</td>\n    </tr>\n    <tr>\n      <th>636033</th>\n      <td>AMZN230317P03300000</td>\n      <td>2022-05-24 16:20:29</td>\n      <td>3300.0</td>\n      <td>1226.000000</td>\n      <td>1167.000000</td>\n      <td>1186.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>17.0</td>\n      <td>107.0</td>\n      <td>...</td>\n      <td>REGULAR</td>\n      <td>USD</td>\n      <td>put</td>\n      <td>2023-03-17</td>\n      <td>2022-05-25</td>\n      <td>2136.0000</td>\n      <td>0.752930</td>\n      <td>1.544922</td>\n      <td>0.812988</td>\n      <td>0.010719</td>\n    </tr>\n    <tr>\n      <th>636034</th>\n      <td>NFLX230616P00090000</td>\n      <td>2022-05-13 18:38:35</td>\n      <td>90.0</td>\n      <td>6.199219</td>\n      <td>4.800781</td>\n      <td>5.851562</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.0</td>\n      <td>192.0</td>\n      <td>...</td>\n      <td>REGULAR</td>\n      <td>USD</td>\n      <td>put</td>\n      <td>2023-06-16</td>\n      <td>2022-05-17</td>\n      <td>190.5000</td>\n      <td>1.629883</td>\n      <td>0.472412</td>\n      <td>1.084961</td>\n      <td>0.010437</td>\n    </tr>\n  </tbody>\n</table>\n<p>636035 rows Ã— 22 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pn28_RUMBAFH",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 515,
     "status": "ok",
     "timestamp": 1650891685322,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "32oPe6XUBCTF",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cols_to_drop = ['impliedVolatility',\n",
    "                  'inTheMoney',\n",
    "                  'change',\n",
    "                  'percentChange',\n",
    "                  'bid',\n",
    "                  'ask',\n",
    "                  'volume',\n",
    "                  'openInterest',\n",
    "                  'contractSymbol',\n",
    "                  'lastTradeDate',\n",
    "                  'contractSize',\n",
    "                  'currency',\n",
    "                  'expiryDate',\n",
    "                  'downloadDate']\n",
    "options_df = options_df.drop(cols_to_drop, axis=1)\n",
    "options_df = pd.get_dummies(options_df, prefix='', prefix_sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 1032,
     "status": "ok",
     "timestamp": 1650891686346,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "_Tlc7k7xBDPV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_sc = StandardScaler()\n",
    "output_sc = StandardScaler()\n",
    "input_data = input_sc.fit_transform(options_df.drop(['lastPrice'], axis=1))\n",
    "output_data = output_sc.fit_transform(options_df['lastPrice'].values.reshape(-1, 1))\n",
    "\n",
    "train_size = 0.8\n",
    "val_size = 0.1\n",
    "\n",
    "last_train_idx = int(np.round(len(input_data) * train_size))\n",
    "last_val_idx = last_train_idx + int(np.round(len(input_data) * val_size))\n",
    "\n",
    "X_train = input_data[0:last_train_idx]\n",
    "X_val = input_data[last_train_idx:last_val_idx]\n",
    "X_test = input_data[last_val_idx:]\n",
    "\n",
    "y_train = output_data[0:last_train_idx]\n",
    "y_val = output_data[last_train_idx:last_val_idx]\n",
    "y_test = output_data[last_val_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1650891686347,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "7nEEoQGvvDpL",
    "outputId": "88b4d863-d037-439b-e625-5ebb52ad41ef",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['strike', 'lastPrice', 'close', 'vol', 'moneyness', 'tau', 'r', 'call',\n       'put'],\n      dtype='object')"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cols = options_df.columns\n",
    "df_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1650891686349,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "IwMVtvfABIhR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train = Variable(torch.Tensor(X_train))\n",
    "X_val = Variable(torch.Tensor(X_val))\n",
    "X_test = Variable(torch.Tensor(X_test))\n",
    "\n",
    "y_train = Variable(torch.Tensor(y_train))\n",
    "y_val = Variable(torch.Tensor(y_val))\n",
    "y_test = Variable(torch.Tensor(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ra2l5P1nBVCz",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1650891686350,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "xTLMLFoSBWDy",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "CUDA = torch.cuda.is_available()\n",
    "device = 'cuda:0' if CUDA else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1650891686352,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "CQ9Gl3bUBWsj",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "\n",
    "  def __init__(self, module):\n",
    "    super(ResBlock, self).__init__()\n",
    "    self.module = module\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.module(x) + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1650891686353,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "YL3SicQPBYq0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class HiddenLayer(nn.Module):\n",
    "\n",
    "  def __init__(self, layer_size, act_fn):\n",
    "      super(HiddenLayer, self).__init__()\n",
    "      \n",
    "      if act_fn == 'ReLU':\n",
    "        self.layer = nn.Sequential(\n",
    "          nn.Linear(layer_size, layer_size),\n",
    "          nn.ReLU())\n",
    "      elif act_fn == 'LeakyReLU':\n",
    "        self.layer = nn.Sequential(\n",
    "          nn.Linear(layer_size, layer_size),\n",
    "          nn.LeakyReLU())\n",
    "      elif act_fn == 'ELU':\n",
    "        self.layer = nn.Sequential(\n",
    "          nn.Linear(layer_size, layer_size),\n",
    "          nn.ELU())\n",
    "    \n",
    "  def forward(self, x):\n",
    "    return self.layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 455,
     "status": "ok",
     "timestamp": 1650891686792,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "lHUFGf9xBawS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "  def __init__(self, input_size, output_size, hidden_size, num_layers, act_fn):\n",
    "    super(Net, self).__init__()\n",
    "    self.input_size = input_size\n",
    "    self.output_size = output_size\n",
    "    self.hidden_size = hidden_size\n",
    "\n",
    "    if act_fn == 'ReLU':\n",
    "      self.initial_layer = nn.Sequential(\n",
    "          nn.Linear(self.input_size, self.hidden_size),\n",
    "          nn.ReLU())\n",
    "    elif act_fn == 'LeakyReLU':\n",
    "      self.initial_layer = nn.Sequential(\n",
    "          nn.Linear(self.input_size, self.hidden_size),\n",
    "          nn.LeakyReLU())\n",
    "    elif act_fn == 'ELU':\n",
    "      self.initial_layer = nn.Sequential(\n",
    "          nn.Linear(self.input_size, self.hidden_size),\n",
    "          nn.ELU())\n",
    "\n",
    "    self.hidden_layers_list = []\n",
    "\n",
    "    for i in range(num_layers // 2):\n",
    "      self.hidden_layers_list.append(\n",
    "          ResBlock(\n",
    "            nn.Sequential(\n",
    "                HiddenLayer(self.hidden_size, act_fn),\n",
    "                HiddenLayer(self.hidden_size, act_fn)\n",
    "            )\n",
    "        )\n",
    "      )\n",
    "\n",
    "    self.hidden_layers = nn.Sequential(*self.hidden_layers_list)\n",
    "\n",
    "    self.net = nn.Sequential(\n",
    "        self.initial_layer,\n",
    "        self.hidden_layers,\n",
    "        nn.Linear(self.hidden_size, self.output_size)\n",
    "    )\n",
    "  \n",
    "  def forward(self, x):\n",
    "    return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1650891686793,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "zcq_lQrHBdH8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def init_weights(m, init_m: str):\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def init_uniform(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "      torch.nn.init.uniform_(m.weight)\n",
    "      m.bias.data.fill_(0.01)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def init_normal(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "      torch.nn.init.normal_(m.weight)\n",
    "      m.bias.data.fill_(0.01)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def init_xuniform(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "      torch.nn.init.xavier_uniform_(m.weight)\n",
    "      m.bias.data.fill_(0.01)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def init_xnormal(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "      torch.nn.init.xavier_normal_(m.weight)\n",
    "      m.bias.data.fill_(0.01)\n",
    "\n",
    "  if init_m == 'uniform':\n",
    "    m.apply(init_uniform)\n",
    "  elif init_m == 'normal':\n",
    "    m.apply(init_normal)\n",
    "  elif init_m == 'xaiver uniform':\n",
    "    m.apply(init_xuniform)\n",
    "  elif init_m == 'xavier normal':\n",
    "    m.apply(init_xnormal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vuCpyycNCKEZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1650891686794,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "YbCOnCSNCL25",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_size = 8\n",
    "output_size = 1\n",
    "num_layers = 4\n",
    "hidden_size = 800\n",
    "batch_size = 774\n",
    "epochs = 2000\n",
    "lr = 5.973524887918111e-05\n",
    "init_method = 'xaiver uniform'\n",
    "act_fn = 'LeakyReLU'\n",
    "\n",
    "model = Net(input_size, output_size, hidden_size, num_layers, act_fn)\n",
    "init_weights(model, init_method)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 7351,
     "status": "ok",
     "timestamp": 1650891694138,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "QqZbxrppvDpZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1650891694142,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "Q-9T0GArCMgp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class OptDataset(Dataset):\n",
    "\n",
    "  def __init__(self, X, y):\n",
    "    self.X = X\n",
    "    self.y = y\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.X[idx], self.y[idx]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6-hCH2ivDpb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Losses Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1650891694144,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "mVaO8TruHW4M",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def MAPELoss(output, target):\n",
    "  return torch.mean(torch.abs((target - output) / target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1650891694149,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "tVLW5dHhvDpe",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, loss_fn, X_val, y_val):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for batch, batch_labels in DataLoader(OptDataset(X_val, y_val), batch_size=batch_size):\n",
    "            out = model(batch.to(device))\n",
    "            loss = loss_fn(out, batch_labels.to(device))\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    losses = np.array(losses)\n",
    "    print('\\nVal set: Average loss: {:.8f}\\n'.format(\n",
    "                losses.mean()))\n",
    "    return losses.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68eF5_EovDpf",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Early Stopping class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1650891694150,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "n2So2ffSvDpg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Code took form: https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, \n",
    "                 patience=10, \n",
    "                 verbose=False, \n",
    "                 delta=0, \n",
    "                 path='../models/final_heston_model.chkpt',\n",
    "                 trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score > self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dL_xmnKXvDph",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1650891694152,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "DrBBTGKJvDph",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    epochs,\n",
    "    batch_size,\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val\n",
    "):\n",
    "\n",
    "  training_losses = []\n",
    "  validation_losses = []\n",
    "\n",
    "  early_stopping = EarlyStopping(patience=20)\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "    i = 0\n",
    "\n",
    "    for batch, batch_labels in DataLoader(OptDataset(X_train, y_train), batch_size=batch_size):\n",
    "      out = model(batch.to(device))\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      loss = loss_fn(out, batch_labels.to(device))\n",
    "      epoch_losses.append(loss.item())\n",
    "      total_loss += loss.item()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      if i > 0 and i % 50 == 0:\n",
    "        avg_loss = total_loss / 50\n",
    "        elapsed = time.time() - start_time\n",
    "        print('| Epoch {:3d} | {:5d}/{:5d} batches | lr {:2.5f} | ms/batch {:5.2f} | '\n",
    "                  'loss {:5.8f}'.format(\n",
    "              epoch, i, len(X_train) // batch_size+1, lr, elapsed * 1000 / 50,\n",
    "              avg_loss))\n",
    "        start_time = time.time()\n",
    "        total_loss = 0\n",
    "\n",
    "      i += 1\n",
    "\n",
    "    training_losses.append(np.array(epoch_losses).mean())\n",
    "    val_loss = evaluate(model, loss_fn, X_val, y_val)\n",
    "    validation_losses.append(val_loss)\n",
    "\n",
    "    early_stopping(val_loss, model)\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(f\"Stopping at Epoch: {epoch}\")\n",
    "        break\n",
    "\n",
    "  return training_losses, validation_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2525796,
     "status": "ok",
     "timestamp": 1650894219916,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "hBETWoCfvDpj",
    "outputId": "30acf99f-3a1e-4d87-d1ff-13068ebe4cd4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch   0 |    50/  658 batches | lr 0.00006 | ms/batch 18.03 | loss 0.56602240\n",
      "| Epoch   0 |   100/  658 batches | lr 0.00006 | ms/batch 14.46 | loss 0.20456803\n",
      "| Epoch   0 |   150/  658 batches | lr 0.00006 | ms/batch 12.64 | loss 0.13454285\n",
      "| Epoch   0 |   200/  658 batches | lr 0.00006 | ms/batch 12.69 | loss 0.12160536\n",
      "| Epoch   0 |   250/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.11693148\n",
      "| Epoch   0 |   300/  658 batches | lr 0.00006 | ms/batch 12.89 | loss 0.11221922\n",
      "| Epoch   0 |   350/  658 batches | lr 0.00006 | ms/batch 15.16 | loss 0.11183932\n",
      "| Epoch   0 |   400/  658 batches | lr 0.00006 | ms/batch 14.93 | loss 0.10417253\n",
      "| Epoch   0 |   450/  658 batches | lr 0.00006 | ms/batch 12.68 | loss 0.10507297\n",
      "| Epoch   0 |   500/  658 batches | lr 0.00006 | ms/batch 12.65 | loss 0.10926801\n",
      "| Epoch   0 |   550/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.10623062\n",
      "| Epoch   0 |   600/  658 batches | lr 0.00006 | ms/batch 12.73 | loss 0.09847115\n",
      "| Epoch   0 |   650/  658 batches | lr 0.00006 | ms/batch 14.25 | loss 0.10148999\n",
      "\n",
      "Val set: Average loss: 0.10190532\n",
      "\n",
      "| Epoch   1 |    50/  658 batches | lr 0.00006 | ms/batch 14.30 | loss 0.11077115\n",
      "| Epoch   1 |   100/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.10204127\n",
      "| Epoch   1 |   150/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.09630511\n",
      "| Epoch   1 |   200/  658 batches | lr 0.00006 | ms/batch 14.26 | loss 0.09822239\n",
      "| Epoch   1 |   250/  658 batches | lr 0.00006 | ms/batch 14.24 | loss 0.10195891\n",
      "| Epoch   1 |   300/  658 batches | lr 0.00006 | ms/batch 12.66 | loss 0.09898244\n",
      "| Epoch   1 |   350/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.10132906\n",
      "| Epoch   1 |   400/  658 batches | lr 0.00006 | ms/batch 12.88 | loss 0.09563211\n",
      "| Epoch   1 |   450/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.09610560\n",
      "| Epoch   1 |   500/  658 batches | lr 0.00006 | ms/batch 14.47 | loss 0.09919706\n",
      "| Epoch   1 |   550/  658 batches | lr 0.00006 | ms/batch 14.35 | loss 0.09541453\n",
      "| Epoch   1 |   600/  658 batches | lr 0.00006 | ms/batch 12.71 | loss 0.09174795\n",
      "| Epoch   1 |   650/  658 batches | lr 0.00006 | ms/batch 14.84 | loss 0.09756454\n",
      "\n",
      "Val set: Average loss: 0.11737314\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch   2 |    50/  658 batches | lr 0.00006 | ms/batch 12.77 | loss 0.10957616\n",
      "| Epoch   2 |   100/  658 batches | lr 0.00006 | ms/batch 13.07 | loss 0.09614745\n",
      "| Epoch   2 |   150/  658 batches | lr 0.00006 | ms/batch 14.03 | loss 0.09013116\n",
      "| Epoch   2 |   200/  658 batches | lr 0.00006 | ms/batch 12.58 | loss 0.09136997\n",
      "| Epoch   2 |   250/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.09561231\n",
      "| Epoch   2 |   300/  658 batches | lr 0.00006 | ms/batch 14.18 | loss 0.09373438\n",
      "| Epoch   2 |   350/  658 batches | lr 0.00006 | ms/batch 12.43 | loss 0.09633388\n",
      "| Epoch   2 |   400/  658 batches | lr 0.00006 | ms/batch 12.39 | loss 0.09101106\n",
      "| Epoch   2 |   450/  658 batches | lr 0.00006 | ms/batch 14.28 | loss 0.09144788\n",
      "| Epoch   2 |   500/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.09419593\n",
      "| Epoch   2 |   550/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.09040891\n",
      "| Epoch   2 |   600/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.08799643\n",
      "| Epoch   2 |   650/  658 batches | lr 0.00006 | ms/batch 12.63 | loss 0.09186923\n",
      "\n",
      "Val set: Average loss: 0.09657744\n",
      "\n",
      "| Epoch   3 |    50/  658 batches | lr 0.00006 | ms/batch 12.64 | loss 0.10031826\n",
      "| Epoch   3 |   100/  658 batches | lr 0.00006 | ms/batch 12.86 | loss 0.09264759\n",
      "| Epoch   3 |   150/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.08683011\n",
      "| Epoch   3 |   200/  658 batches | lr 0.00006 | ms/batch 14.25 | loss 0.08795723\n",
      "| Epoch   3 |   250/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.09223559\n",
      "| Epoch   3 |   300/  658 batches | lr 0.00006 | ms/batch 12.64 | loss 0.09069249\n",
      "| Epoch   3 |   350/  658 batches | lr 0.00006 | ms/batch 12.42 | loss 0.09330894\n",
      "| Epoch   3 |   400/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.08815528\n",
      "| Epoch   3 |   450/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.08869731\n",
      "| Epoch   3 |   500/  658 batches | lr 0.00006 | ms/batch 14.04 | loss 0.09127144\n",
      "| Epoch   3 |   550/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.08731280\n",
      "| Epoch   3 |   600/  658 batches | lr 0.00006 | ms/batch 12.75 | loss 0.08560583\n",
      "| Epoch   3 |   650/  658 batches | lr 0.00006 | ms/batch 12.42 | loss 0.08894702\n",
      "\n",
      "Val set: Average loss: 0.09289888\n",
      "\n",
      "| Epoch   4 |    50/  658 batches | lr 0.00006 | ms/batch 12.60 | loss 0.09729324\n",
      "| Epoch   4 |   100/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.09033775\n",
      "| Epoch   4 |   150/  658 batches | lr 0.00006 | ms/batch 12.58 | loss 0.08469899\n",
      "| Epoch   4 |   200/  658 batches | lr 0.00006 | ms/batch 14.27 | loss 0.08563953\n",
      "| Epoch   4 |   250/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.08987713\n",
      "| Epoch   4 |   300/  658 batches | lr 0.00006 | ms/batch 12.38 | loss 0.08858417\n",
      "| Epoch   4 |   350/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.09112348\n",
      "| Epoch   4 |   400/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.08594637\n",
      "| Epoch   4 |   450/  658 batches | lr 0.00006 | ms/batch 12.41 | loss 0.08661321\n",
      "| Epoch   4 |   500/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.08910348\n",
      "| Epoch   4 |   550/  658 batches | lr 0.00006 | ms/batch 14.33 | loss 0.08531917\n",
      "| Epoch   4 |   600/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.08384207\n",
      "| Epoch   4 |   650/  658 batches | lr 0.00006 | ms/batch 12.43 | loss 0.08660579\n",
      "\n",
      "Val set: Average loss: 0.08996075\n",
      "\n",
      "| Epoch   5 |    50/  658 batches | lr 0.00006 | ms/batch 12.89 | loss 0.09497705\n",
      "| Epoch   5 |   100/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.08853577\n",
      "| Epoch   5 |   150/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.08266463\n",
      "| Epoch   5 |   200/  658 batches | lr 0.00006 | ms/batch 14.34 | loss 0.08378721\n",
      "| Epoch   5 |   250/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.08810226\n",
      "| Epoch   5 |   300/  658 batches | lr 0.00006 | ms/batch 12.41 | loss 0.08685397\n",
      "| Epoch   5 |   350/  658 batches | lr 0.00006 | ms/batch 12.68 | loss 0.08934351\n",
      "| Epoch   5 |   400/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.08414963\n",
      "| Epoch   5 |   450/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.08491387\n",
      "| Epoch   5 |   500/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.08733273\n",
      "| Epoch   5 |   550/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.08367129\n",
      "| Epoch   5 |   600/  658 batches | lr 0.00006 | ms/batch 12.39 | loss 0.08232219\n",
      "| Epoch   5 |   650/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.08436235\n",
      "\n",
      "Val set: Average loss: 0.08702524\n",
      "\n",
      "| Epoch   6 |    50/  658 batches | lr 0.00006 | ms/batch 12.72 | loss 0.09288167\n",
      "| Epoch   6 |   100/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.08701459\n",
      "| Epoch   6 |   150/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.08097701\n",
      "| Epoch   6 |   200/  658 batches | lr 0.00006 | ms/batch 14.28 | loss 0.08215126\n",
      "| Epoch   6 |   250/  658 batches | lr 0.00006 | ms/batch 14.18 | loss 0.08650321\n",
      "| Epoch   6 |   300/  658 batches | lr 0.00006 | ms/batch 12.63 | loss 0.08534271\n",
      "| Epoch   6 |   350/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.08777710\n",
      "| Epoch   6 |   400/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.08260121\n",
      "| Epoch   6 |   450/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.08331126\n",
      "| Epoch   6 |   500/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.08563454\n",
      "| Epoch   6 |   550/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.08217035\n",
      "| Epoch   6 |   600/  658 batches | lr 0.00006 | ms/batch 12.35 | loss 0.08093259\n",
      "| Epoch   6 |   650/  658 batches | lr 0.00006 | ms/batch 12.67 | loss 0.08268990\n",
      "\n",
      "Val set: Average loss: 0.08591546\n",
      "\n",
      "| Epoch   7 |    50/  658 batches | lr 0.00006 | ms/batch 12.66 | loss 0.09144543\n",
      "| Epoch   7 |   100/  658 batches | lr 0.00006 | ms/batch 14.01 | loss 0.08559124\n",
      "| Epoch   7 |   150/  658 batches | lr 0.00006 | ms/batch 12.58 | loss 0.07935925\n",
      "| Epoch   7 |   200/  658 batches | lr 0.00006 | ms/batch 14.21 | loss 0.08066693\n",
      "| Epoch   7 |   250/  658 batches | lr 0.00006 | ms/batch 14.35 | loss 0.08508947\n",
      "| Epoch   7 |   300/  658 batches | lr 0.00006 | ms/batch 12.63 | loss 0.08391724\n",
      "| Epoch   7 |   350/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.08633644\n",
      "| Epoch   7 |   400/  658 batches | lr 0.00006 | ms/batch 14.05 | loss 0.08113273\n",
      "| Epoch   7 |   450/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.08168722\n",
      "| Epoch   7 |   500/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.08408568\n",
      "| Epoch   7 |   550/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.08082652\n",
      "| Epoch   7 |   600/  658 batches | lr 0.00006 | ms/batch 12.66 | loss 0.07976177\n",
      "| Epoch   7 |   650/  658 batches | lr 0.00006 | ms/batch 12.39 | loss 0.08123031\n",
      "\n",
      "Val set: Average loss: 0.08407902\n",
      "\n",
      "| Epoch   8 |    50/  658 batches | lr 0.00006 | ms/batch 12.65 | loss 0.08978532\n",
      "| Epoch   8 |   100/  658 batches | lr 0.00006 | ms/batch 13.98 | loss 0.08431823\n",
      "| Epoch   8 |   150/  658 batches | lr 0.00006 | ms/batch 12.43 | loss 0.07804500\n",
      "| Epoch   8 |   200/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.07934248\n",
      "| Epoch   8 |   250/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.08372510\n",
      "| Epoch   8 |   300/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.08260829\n",
      "| Epoch   8 |   350/  658 batches | lr 0.00006 | ms/batch 12.60 | loss 0.08494467\n",
      "| Epoch   8 |   400/  658 batches | lr 0.00006 | ms/batch 14.01 | loss 0.07969486\n",
      "| Epoch   8 |   450/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.08017485\n",
      "| Epoch   8 |   500/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.08265261\n",
      "| Epoch   8 |   550/  658 batches | lr 0.00006 | ms/batch 14.01 | loss 0.07959083\n",
      "| Epoch   8 |   600/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.07884553\n",
      "| Epoch   8 |   650/  658 batches | lr 0.00006 | ms/batch 12.38 | loss 0.07986354\n",
      "\n",
      "Val set: Average loss: 0.08273952\n",
      "\n",
      "| Epoch   9 |    50/  658 batches | lr 0.00006 | ms/batch 12.83 | loss 0.08832278\n",
      "| Epoch   9 |   100/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.08314493\n",
      "| Epoch   9 |   150/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.07680724\n",
      "| Epoch   9 |   200/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.07849917\n",
      "| Epoch   9 |   250/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.08236612\n",
      "| Epoch   9 |   300/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.08136271\n",
      "| Epoch   9 |   350/  658 batches | lr 0.00006 | ms/batch 12.44 | loss 0.08360041\n",
      "| Epoch   9 |   400/  658 batches | lr 0.00006 | ms/batch 14.03 | loss 0.07817921\n",
      "| Epoch   9 |   450/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.07860641\n",
      "| Epoch   9 |   500/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.08135600\n",
      "| Epoch   9 |   550/  658 batches | lr 0.00006 | ms/batch 14.26 | loss 0.07833769\n",
      "| Epoch   9 |   600/  658 batches | lr 0.00006 | ms/batch 12.44 | loss 0.07804115\n",
      "| Epoch   9 |   650/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.07854098\n",
      "\n",
      "Val set: Average loss: 0.08153476\n",
      "\n",
      "| Epoch  10 |    50/  658 batches | lr 0.00006 | ms/batch 12.77 | loss 0.08693236\n",
      "| Epoch  10 |   100/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.08211831\n",
      "| Epoch  10 |   150/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.07560605\n",
      "| Epoch  10 |   200/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.07749508\n",
      "| Epoch  10 |   250/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.08100816\n",
      "| Epoch  10 |   300/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.08017885\n",
      "| Epoch  10 |   350/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.08248177\n",
      "| Epoch  10 |   400/  658 batches | lr 0.00006 | ms/batch 14.03 | loss 0.07679090\n",
      "| Epoch  10 |   450/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.07710325\n",
      "| Epoch  10 |   500/  658 batches | lr 0.00006 | ms/batch 14.21 | loss 0.08006772\n",
      "| Epoch  10 |   550/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.07698434\n",
      "| Epoch  10 |   600/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.07722644\n",
      "| Epoch  10 |   650/  658 batches | lr 0.00006 | ms/batch 12.71 | loss 0.07743044\n",
      "\n",
      "Val set: Average loss: 0.08029950\n",
      "\n",
      "| Epoch  11 |    50/  658 batches | lr 0.00006 | ms/batch 12.69 | loss 0.08572496\n",
      "| Epoch  11 |   100/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.08106001\n",
      "| Epoch  11 |   150/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.07434238\n",
      "| Epoch  11 |   200/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.07655874\n",
      "| Epoch  11 |   250/  658 batches | lr 0.00006 | ms/batch 14.58 | loss 0.07983613\n",
      "| Epoch  11 |   300/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.07905242\n",
      "| Epoch  11 |   350/  658 batches | lr 0.00006 | ms/batch 12.43 | loss 0.08132954\n",
      "| Epoch  11 |   400/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.07534646\n",
      "| Epoch  11 |   450/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.07563225\n",
      "| Epoch  11 |   500/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.07890795\n",
      "| Epoch  11 |   550/  658 batches | lr 0.00006 | ms/batch 14.21 | loss 0.07548519\n",
      "| Epoch  11 |   600/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.07627850\n",
      "| Epoch  11 |   650/  658 batches | lr 0.00006 | ms/batch 12.42 | loss 0.07615935\n",
      "\n",
      "Val set: Average loss: 0.07824472\n",
      "\n",
      "| Epoch  12 |    50/  658 batches | lr 0.00006 | ms/batch 12.68 | loss 0.08435918\n",
      "| Epoch  12 |   100/  658 batches | lr 0.00006 | ms/batch 14.58 | loss 0.08001534\n",
      "| Epoch  12 |   150/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.07305487\n",
      "| Epoch  12 |   200/  658 batches | lr 0.00006 | ms/batch 14.42 | loss 0.07512687\n",
      "| Epoch  12 |   250/  658 batches | lr 0.00006 | ms/batch 14.06 | loss 0.07882097\n",
      "| Epoch  12 |   300/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.07803583\n",
      "| Epoch  12 |   350/  658 batches | lr 0.00006 | ms/batch 12.60 | loss 0.08016137\n",
      "| Epoch  12 |   400/  658 batches | lr 0.00006 | ms/batch 14.04 | loss 0.07398253\n",
      "| Epoch  12 |   450/  658 batches | lr 0.00006 | ms/batch 12.71 | loss 0.07423948\n",
      "| Epoch  12 |   500/  658 batches | lr 0.00006 | ms/batch 14.31 | loss 0.07761227\n",
      "| Epoch  12 |   550/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.07401024\n",
      "| Epoch  12 |   600/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.07526913\n",
      "| Epoch  12 |   650/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.07483688\n",
      "\n",
      "Val set: Average loss: 0.07672773\n",
      "\n",
      "| Epoch  13 |    50/  658 batches | lr 0.00006 | ms/batch 12.70 | loss 0.08295425\n",
      "| Epoch  13 |   100/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.07893366\n",
      "| Epoch  13 |   150/  658 batches | lr 0.00006 | ms/batch 12.70 | loss 0.07190861\n",
      "| Epoch  13 |   200/  658 batches | lr 0.00006 | ms/batch 14.27 | loss 0.07394532\n",
      "| Epoch  13 |   250/  658 batches | lr 0.00006 | ms/batch 14.24 | loss 0.07759705\n",
      "| Epoch  13 |   300/  658 batches | lr 0.00006 | ms/batch 12.60 | loss 0.07679730\n",
      "| Epoch  13 |   350/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.07880587\n",
      "| Epoch  13 |   400/  658 batches | lr 0.00006 | ms/batch 14.01 | loss 0.07257992\n",
      "| Epoch  13 |   450/  658 batches | lr 0.00006 | ms/batch 12.70 | loss 0.07266219\n",
      "| Epoch  13 |   500/  658 batches | lr 0.00006 | ms/batch 14.21 | loss 0.07642492\n",
      "| Epoch  13 |   550/  658 batches | lr 0.00006 | ms/batch 14.27 | loss 0.07271362\n",
      "| Epoch  13 |   600/  658 batches | lr 0.00006 | ms/batch 12.64 | loss 0.07432440\n",
      "| Epoch  13 |   650/  658 batches | lr 0.00006 | ms/batch 12.64 | loss 0.07357213\n",
      "\n",
      "Val set: Average loss: 0.07536892\n",
      "\n",
      "| Epoch  14 |    50/  658 batches | lr 0.00006 | ms/batch 12.66 | loss 0.08181129\n",
      "| Epoch  14 |   100/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.07774701\n",
      "| Epoch  14 |   150/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.07094000\n",
      "| Epoch  14 |   200/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.07316507\n",
      "| Epoch  14 |   250/  658 batches | lr 0.00006 | ms/batch 14.32 | loss 0.07664006\n",
      "| Epoch  14 |   300/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.07570816\n",
      "| Epoch  14 |   350/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.07751743\n",
      "| Epoch  14 |   400/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.07121784\n",
      "| Epoch  14 |   450/  658 batches | lr 0.00006 | ms/batch 12.62 | loss 0.07121020\n",
      "| Epoch  14 |   500/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.07528109\n",
      "| Epoch  14 |   550/  658 batches | lr 0.00006 | ms/batch 14.30 | loss 0.07140509\n",
      "| Epoch  14 |   600/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.07348530\n",
      "| Epoch  14 |   650/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.07245018\n",
      "\n",
      "Val set: Average loss: 0.07412976\n",
      "\n",
      "| Epoch  15 |    50/  658 batches | lr 0.00006 | ms/batch 12.64 | loss 0.08061894\n",
      "| Epoch  15 |   100/  658 batches | lr 0.00006 | ms/batch 14.30 | loss 0.07657544\n",
      "| Epoch  15 |   150/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.06974124\n",
      "| Epoch  15 |   200/  658 batches | lr 0.00006 | ms/batch 14.40 | loss 0.07156308\n",
      "| Epoch  15 |   250/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.07552019\n",
      "| Epoch  15 |   300/  658 batches | lr 0.00006 | ms/batch 12.67 | loss 0.07472882\n",
      "| Epoch  15 |   350/  658 batches | lr 0.00006 | ms/batch 12.43 | loss 0.07651812\n",
      "| Epoch  15 |   400/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.07004064\n",
      "| Epoch  15 |   450/  658 batches | lr 0.00006 | ms/batch 12.58 | loss 0.06995479\n",
      "| Epoch  15 |   500/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.07416703\n",
      "| Epoch  15 |   550/  658 batches | lr 0.00006 | ms/batch 14.21 | loss 0.07033852\n",
      "| Epoch  15 |   600/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.07274454\n",
      "| Epoch  15 |   650/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.07148752\n",
      "\n",
      "Val set: Average loss: 0.07325064\n",
      "\n",
      "| Epoch  16 |    50/  658 batches | lr 0.00006 | ms/batch 12.81 | loss 0.07970807\n",
      "| Epoch  16 |   100/  658 batches | lr 0.00006 | ms/batch 14.38 | loss 0.07548290\n",
      "| Epoch  16 |   150/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06887020\n",
      "| Epoch  16 |   200/  658 batches | lr 0.00006 | ms/batch 14.29 | loss 0.07089849\n",
      "| Epoch  16 |   250/  658 batches | lr 0.00006 | ms/batch 14.44 | loss 0.07477743\n",
      "| Epoch  16 |   300/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.07387561\n",
      "| Epoch  16 |   350/  658 batches | lr 0.00006 | ms/batch 12.72 | loss 0.07560088\n",
      "| Epoch  16 |   400/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.06911485\n",
      "| Epoch  16 |   450/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.06886465\n",
      "| Epoch  16 |   500/  658 batches | lr 0.00006 | ms/batch 14.25 | loss 0.07318007\n",
      "| Epoch  16 |   550/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.06955267\n",
      "| Epoch  16 |   600/  658 batches | lr 0.00006 | ms/batch 12.43 | loss 0.07210427\n",
      "| Epoch  16 |   650/  658 batches | lr 0.00006 | ms/batch 12.71 | loss 0.07081234\n",
      "\n",
      "Val set: Average loss: 0.07245708\n",
      "\n",
      "| Epoch  17 |    50/  658 batches | lr 0.00006 | ms/batch 12.83 | loss 0.07888282\n",
      "| Epoch  17 |   100/  658 batches | lr 0.00006 | ms/batch 14.03 | loss 0.07446892\n",
      "| Epoch  17 |   150/  658 batches | lr 0.00006 | ms/batch 12.59 | loss 0.06816023\n",
      "| Epoch  17 |   200/  658 batches | lr 0.00006 | ms/batch 14.27 | loss 0.07024432\n",
      "| Epoch  17 |   250/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.07409049\n",
      "| Epoch  17 |   300/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.07312338\n",
      "| Epoch  17 |   350/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.07492327\n",
      "| Epoch  17 |   400/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.06837849\n",
      "| Epoch  17 |   450/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.06791473\n",
      "| Epoch  17 |   500/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.07221042\n",
      "| Epoch  17 |   550/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.06875786\n",
      "| Epoch  17 |   600/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.07143149\n",
      "| Epoch  17 |   650/  658 batches | lr 0.00006 | ms/batch 12.41 | loss 0.07023551\n",
      "\n",
      "Val set: Average loss: 0.07167331\n",
      "\n",
      "| Epoch  18 |    50/  658 batches | lr 0.00006 | ms/batch 12.71 | loss 0.07821254\n",
      "| Epoch  18 |   100/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.07368109\n",
      "| Epoch  18 |   150/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.06758873\n",
      "| Epoch  18 |   200/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.06977151\n",
      "| Epoch  18 |   250/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.07357495\n",
      "| Epoch  18 |   300/  658 batches | lr 0.00006 | ms/batch 12.64 | loss 0.07245645\n",
      "| Epoch  18 |   350/  658 batches | lr 0.00006 | ms/batch 12.40 | loss 0.07438277\n",
      "| Epoch  18 |   400/  658 batches | lr 0.00006 | ms/batch 14.00 | loss 0.06780362\n",
      "| Epoch  18 |   450/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.06727400\n",
      "| Epoch  18 |   500/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.07131566\n",
      "| Epoch  18 |   550/  658 batches | lr 0.00006 | ms/batch 14.06 | loss 0.06809268\n",
      "| Epoch  18 |   600/  658 batches | lr 0.00006 | ms/batch 12.64 | loss 0.07070990\n",
      "| Epoch  18 |   650/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06977124\n",
      "\n",
      "Val set: Average loss: 0.07123293\n",
      "\n",
      "| Epoch  19 |    50/  658 batches | lr 0.00006 | ms/batch 12.70 | loss 0.07780470\n",
      "| Epoch  19 |   100/  658 batches | lr 0.00006 | ms/batch 14.21 | loss 0.07301576\n",
      "| Epoch  19 |   150/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.06701130\n",
      "| Epoch  19 |   200/  658 batches | lr 0.00006 | ms/batch 14.25 | loss 0.06922409\n",
      "| Epoch  19 |   250/  658 batches | lr 0.00006 | ms/batch 14.26 | loss 0.07305048\n",
      "| Epoch  19 |   300/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.07208816\n",
      "| Epoch  19 |   350/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.07395007\n",
      "| Epoch  19 |   400/  658 batches | lr 0.00006 | ms/batch 14.06 | loss 0.06730880\n",
      "| Epoch  19 |   450/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.06661442\n",
      "| Epoch  19 |   500/  658 batches | lr 0.00006 | ms/batch 14.25 | loss 0.07068330\n",
      "| Epoch  19 |   550/  658 batches | lr 0.00006 | ms/batch 14.32 | loss 0.06759780\n",
      "| Epoch  19 |   600/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.07032018\n",
      "| Epoch  19 |   650/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.06938882\n",
      "\n",
      "Val set: Average loss: 0.07101352\n",
      "\n",
      "| Epoch  20 |    50/  658 batches | lr 0.00006 | ms/batch 12.74 | loss 0.07734077\n",
      "| Epoch  20 |   100/  658 batches | lr 0.00006 | ms/batch 14.29 | loss 0.07238811\n",
      "| Epoch  20 |   150/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.06664208\n",
      "| Epoch  20 |   200/  658 batches | lr 0.00006 | ms/batch 14.43 | loss 0.06873632\n",
      "| Epoch  20 |   250/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.07263945\n",
      "| Epoch  20 |   300/  658 batches | lr 0.00006 | ms/batch 12.67 | loss 0.07165341\n",
      "| Epoch  20 |   350/  658 batches | lr 0.00006 | ms/batch 12.42 | loss 0.07362435\n",
      "| Epoch  20 |   400/  658 batches | lr 0.00006 | ms/batch 14.27 | loss 0.06683225\n",
      "| Epoch  20 |   450/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.06612545\n",
      "| Epoch  20 |   500/  658 batches | lr 0.00006 | ms/batch 14.70 | loss 0.07009895\n",
      "| Epoch  20 |   550/  658 batches | lr 0.00006 | ms/batch 14.57 | loss 0.06692498\n",
      "| Epoch  20 |   600/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06986085\n",
      "| Epoch  20 |   650/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06895361\n",
      "\n",
      "Val set: Average loss: 0.07071366\n",
      "\n",
      "| Epoch  21 |    50/  658 batches | lr 0.00006 | ms/batch 12.69 | loss 0.07689524\n",
      "| Epoch  21 |   100/  658 batches | lr 0.00006 | ms/batch 14.18 | loss 0.07200104\n",
      "| Epoch  21 |   150/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.06634533\n",
      "| Epoch  21 |   200/  658 batches | lr 0.00006 | ms/batch 14.28 | loss 0.06818740\n",
      "| Epoch  21 |   250/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.07228000\n",
      "| Epoch  21 |   300/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.07129525\n",
      "| Epoch  21 |   350/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.07320968\n",
      "| Epoch  21 |   400/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.06651497\n",
      "| Epoch  21 |   450/  658 batches | lr 0.00006 | ms/batch 12.65 | loss 0.06570998\n",
      "| Epoch  21 |   500/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.06950268\n",
      "| Epoch  21 |   550/  658 batches | lr 0.00006 | ms/batch 14.21 | loss 0.06649635\n",
      "| Epoch  21 |   600/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.06952033\n",
      "| Epoch  21 |   650/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.06860729\n",
      "\n",
      "Val set: Average loss: 0.07050897\n",
      "\n",
      "| Epoch  22 |    50/  658 batches | lr 0.00006 | ms/batch 12.67 | loss 0.07663100\n",
      "| Epoch  22 |   100/  658 batches | lr 0.00006 | ms/batch 13.99 | loss 0.07166100\n",
      "| Epoch  22 |   150/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.06592406\n",
      "| Epoch  22 |   200/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.06769937\n",
      "| Epoch  22 |   250/  658 batches | lr 0.00006 | ms/batch 14.22 | loss 0.07201398\n",
      "| Epoch  22 |   300/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.07097218\n",
      "| Epoch  22 |   350/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.07291097\n",
      "| Epoch  22 |   400/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.06622932\n",
      "| Epoch  22 |   450/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.06534458\n",
      "| Epoch  22 |   500/  658 batches | lr 0.00006 | ms/batch 14.21 | loss 0.06913739\n",
      "| Epoch  22 |   550/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.06617182\n",
      "| Epoch  22 |   600/  658 batches | lr 0.00006 | ms/batch 12.42 | loss 0.06914900\n",
      "| Epoch  22 |   650/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.06826887\n",
      "\n",
      "Val set: Average loss: 0.07039410\n",
      "\n",
      "| Epoch  23 |    50/  658 batches | lr 0.00006 | ms/batch 12.81 | loss 0.07639195\n",
      "| Epoch  23 |   100/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.07135338\n",
      "| Epoch  23 |   150/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.06575707\n",
      "| Epoch  23 |   200/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.06741768\n",
      "| Epoch  23 |   250/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.07168761\n",
      "| Epoch  23 |   300/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.07062408\n",
      "| Epoch  23 |   350/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.07259061\n",
      "| Epoch  23 |   400/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.06601039\n",
      "| Epoch  23 |   450/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.06497606\n",
      "| Epoch  23 |   500/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.06871014\n",
      "| Epoch  23 |   550/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.06593348\n",
      "| Epoch  23 |   600/  658 batches | lr 0.00006 | ms/batch 12.41 | loss 0.06898807\n",
      "| Epoch  23 |   650/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.06791984\n",
      "\n",
      "Val set: Average loss: 0.07005586\n",
      "\n",
      "| Epoch  24 |    50/  658 batches | lr 0.00006 | ms/batch 12.78 | loss 0.07606719\n",
      "| Epoch  24 |   100/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.07102838\n",
      "| Epoch  24 |   150/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.06543431\n",
      "| Epoch  24 |   200/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.06724334\n",
      "| Epoch  24 |   250/  658 batches | lr 0.00006 | ms/batch 14.22 | loss 0.07139365\n",
      "| Epoch  24 |   300/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.07034029\n",
      "| Epoch  24 |   350/  658 batches | lr 0.00006 | ms/batch 12.73 | loss 0.07229156\n",
      "| Epoch  24 |   400/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.06576081\n",
      "| Epoch  24 |   450/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.06471386\n",
      "| Epoch  24 |   500/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.06840871\n",
      "| Epoch  24 |   550/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.06567408\n",
      "| Epoch  24 |   600/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.06862527\n",
      "| Epoch  24 |   650/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.06766052\n",
      "\n",
      "Val set: Average loss: 0.06971602\n",
      "\n",
      "| Epoch  25 |    50/  658 batches | lr 0.00006 | ms/batch 12.77 | loss 0.07583287\n",
      "| Epoch  25 |   100/  658 batches | lr 0.00006 | ms/batch 14.02 | loss 0.07068858\n",
      "| Epoch  25 |   150/  658 batches | lr 0.00006 | ms/batch 12.62 | loss 0.06525265\n",
      "| Epoch  25 |   200/  658 batches | lr 0.00006 | ms/batch 14.48 | loss 0.06693128\n",
      "| Epoch  25 |   250/  658 batches | lr 0.00006 | ms/batch 14.38 | loss 0.07110006\n",
      "| Epoch  25 |   300/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.07010206\n",
      "| Epoch  25 |   350/  658 batches | lr 0.00006 | ms/batch 12.39 | loss 0.07207421\n",
      "| Epoch  25 |   400/  658 batches | lr 0.00006 | ms/batch 14.03 | loss 0.06554832\n",
      "| Epoch  25 |   450/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.06446054\n",
      "| Epoch  25 |   500/  658 batches | lr 0.00006 | ms/batch 14.21 | loss 0.06806676\n",
      "| Epoch  25 |   550/  658 batches | lr 0.00006 | ms/batch 14.26 | loss 0.06547980\n",
      "| Epoch  25 |   600/  658 batches | lr 0.00006 | ms/batch 12.58 | loss 0.06843581\n",
      "| Epoch  25 |   650/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.06750576\n",
      "\n",
      "Val set: Average loss: 0.06947717\n",
      "\n",
      "| Epoch  26 |    50/  658 batches | lr 0.00006 | ms/batch 12.70 | loss 0.07561510\n",
      "| Epoch  26 |   100/  658 batches | lr 0.00006 | ms/batch 14.29 | loss 0.07035011\n",
      "| Epoch  26 |   150/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.06499861\n",
      "| Epoch  26 |   200/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.06647428\n",
      "| Epoch  26 |   250/  658 batches | lr 0.00006 | ms/batch 14.22 | loss 0.07076967\n",
      "| Epoch  26 |   300/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.06985309\n",
      "| Epoch  26 |   350/  658 batches | lr 0.00006 | ms/batch 12.58 | loss 0.07176490\n",
      "| Epoch  26 |   400/  658 batches | lr 0.00006 | ms/batch 14.06 | loss 0.06539059\n",
      "| Epoch  26 |   450/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.06416534\n",
      "| Epoch  26 |   500/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.06790435\n",
      "| Epoch  26 |   550/  658 batches | lr 0.00006 | ms/batch 14.37 | loss 0.06536058\n",
      "| Epoch  26 |   600/  658 batches | lr 0.00006 | ms/batch 12.59 | loss 0.06823362\n",
      "| Epoch  26 |   650/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.06721482\n",
      "\n",
      "Val set: Average loss: 0.06950923\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  27 |    50/  658 batches | lr 0.00006 | ms/batch 12.78 | loss 0.07539099\n",
      "| Epoch  27 |   100/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.07012163\n",
      "| Epoch  27 |   150/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.06478358\n",
      "| Epoch  27 |   200/  658 batches | lr 0.00006 | ms/batch 14.24 | loss 0.06634016\n",
      "| Epoch  27 |   250/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.07063851\n",
      "| Epoch  27 |   300/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.06976513\n",
      "| Epoch  27 |   350/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.07150708\n",
      "| Epoch  27 |   400/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.06521217\n",
      "| Epoch  27 |   450/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.06397969\n",
      "| Epoch  27 |   500/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.06761081\n",
      "| Epoch  27 |   550/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.06510253\n",
      "| Epoch  27 |   600/  658 batches | lr 0.00006 | ms/batch 12.43 | loss 0.06807547\n",
      "| Epoch  27 |   650/  658 batches | lr 0.00006 | ms/batch 12.65 | loss 0.06702867\n",
      "\n",
      "Val set: Average loss: 0.06910476\n",
      "\n",
      "| Epoch  28 |    50/  658 batches | lr 0.00006 | ms/batch 12.83 | loss 0.07524198\n",
      "| Epoch  28 |   100/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.06988359\n",
      "| Epoch  28 |   150/  658 batches | lr 0.00006 | ms/batch 12.60 | loss 0.06454989\n",
      "| Epoch  28 |   200/  658 batches | lr 0.00006 | ms/batch 14.34 | loss 0.06590998\n",
      "| Epoch  28 |   250/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.07031299\n",
      "| Epoch  28 |   300/  658 batches | lr 0.00006 | ms/batch 12.58 | loss 0.06945672\n",
      "| Epoch  28 |   350/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.07127663\n",
      "| Epoch  28 |   400/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.06513785\n",
      "| Epoch  28 |   450/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.06374848\n",
      "| Epoch  28 |   500/  658 batches | lr 0.00006 | ms/batch 14.27 | loss 0.06736681\n",
      "| Epoch  28 |   550/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.06499660\n",
      "| Epoch  28 |   600/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.06777330\n",
      "| Epoch  28 |   650/  658 batches | lr 0.00006 | ms/batch 12.66 | loss 0.06677882\n",
      "\n",
      "Val set: Average loss: 0.06863230\n",
      "\n",
      "| Epoch  29 |    50/  658 batches | lr 0.00006 | ms/batch 12.67 | loss 0.07495222\n",
      "| Epoch  29 |   100/  658 batches | lr 0.00006 | ms/batch 14.02 | loss 0.06975649\n",
      "| Epoch  29 |   150/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.06431236\n",
      "| Epoch  29 |   200/  658 batches | lr 0.00006 | ms/batch 14.22 | loss 0.06579703\n",
      "| Epoch  29 |   250/  658 batches | lr 0.00006 | ms/batch 14.29 | loss 0.07003026\n",
      "| Epoch  29 |   300/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.06931873\n",
      "| Epoch  29 |   350/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.07102548\n",
      "| Epoch  29 |   400/  658 batches | lr 0.00006 | ms/batch 14.06 | loss 0.06497754\n",
      "| Epoch  29 |   450/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.06349248\n",
      "| Epoch  29 |   500/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.06709858\n",
      "| Epoch  29 |   550/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.06485898\n",
      "| Epoch  29 |   600/  658 batches | lr 0.00006 | ms/batch 12.71 | loss 0.06760072\n",
      "| Epoch  29 |   650/  658 batches | lr 0.00006 | ms/batch 13.14 | loss 0.06654890\n",
      "\n",
      "Val set: Average loss: 0.06835492\n",
      "\n",
      "| Epoch  30 |    50/  658 batches | lr 0.00006 | ms/batch 12.71 | loss 0.07482971\n",
      "| Epoch  30 |   100/  658 batches | lr 0.00006 | ms/batch 14.04 | loss 0.06937580\n",
      "| Epoch  30 |   150/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.06408285\n",
      "| Epoch  30 |   200/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.06559989\n",
      "| Epoch  30 |   250/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.06975130\n",
      "| Epoch  30 |   300/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06922163\n",
      "| Epoch  30 |   350/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.07073390\n",
      "| Epoch  30 |   400/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.06475669\n",
      "| Epoch  30 |   450/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.06323069\n",
      "| Epoch  30 |   500/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.06684860\n",
      "| Epoch  30 |   550/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.06475829\n",
      "| Epoch  30 |   600/  658 batches | lr 0.00006 | ms/batch 12.39 | loss 0.06749840\n",
      "| Epoch  30 |   650/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.06637699\n",
      "\n",
      "Val set: Average loss: 0.06824507\n",
      "\n",
      "| Epoch  31 |    50/  658 batches | lr 0.00006 | ms/batch 12.77 | loss 0.07459967\n",
      "| Epoch  31 |   100/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.06912534\n",
      "| Epoch  31 |   150/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.06400271\n",
      "| Epoch  31 |   200/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.06539081\n",
      "| Epoch  31 |   250/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.06966952\n",
      "| Epoch  31 |   300/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.06906663\n",
      "| Epoch  31 |   350/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.07053840\n",
      "| Epoch  31 |   400/  658 batches | lr 0.00006 | ms/batch 14.59 | loss 0.06480565\n",
      "| Epoch  31 |   450/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.06310329\n",
      "| Epoch  31 |   500/  658 batches | lr 0.00006 | ms/batch 14.40 | loss 0.06668838\n",
      "| Epoch  31 |   550/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.06449940\n",
      "| Epoch  31 |   600/  658 batches | lr 0.00006 | ms/batch 12.42 | loss 0.06727522\n",
      "| Epoch  31 |   650/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.06628605\n",
      "\n",
      "Val set: Average loss: 0.06788428\n",
      "\n",
      "| Epoch  32 |    50/  658 batches | lr 0.00006 | ms/batch 12.80 | loss 0.07443752\n",
      "| Epoch  32 |   100/  658 batches | lr 0.00006 | ms/batch 14.02 | loss 0.06893401\n",
      "| Epoch  32 |   150/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.06378540\n",
      "| Epoch  32 |   200/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.06516723\n",
      "| Epoch  32 |   250/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.06938174\n",
      "| Epoch  32 |   300/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.06888639\n",
      "| Epoch  32 |   350/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.07031816\n",
      "| Epoch  32 |   400/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.06463663\n",
      "| Epoch  32 |   450/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.06287568\n",
      "| Epoch  32 |   500/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.06648073\n",
      "| Epoch  32 |   550/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.06441133\n",
      "| Epoch  32 |   600/  658 batches | lr 0.00006 | ms/batch 12.43 | loss 0.06701179\n",
      "| Epoch  32 |   650/  658 batches | lr 0.00006 | ms/batch 12.41 | loss 0.06619396\n",
      "\n",
      "Val set: Average loss: 0.06760280\n",
      "\n",
      "| Epoch  33 |    50/  658 batches | lr 0.00006 | ms/batch 12.87 | loss 0.07415119\n",
      "| Epoch  33 |   100/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.06877912\n",
      "| Epoch  33 |   150/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06364597\n",
      "| Epoch  33 |   200/  658 batches | lr 0.00006 | ms/batch 14.30 | loss 0.06499326\n",
      "| Epoch  33 |   250/  658 batches | lr 0.00006 | ms/batch 14.67 | loss 0.06922248\n",
      "| Epoch  33 |   300/  658 batches | lr 0.00006 | ms/batch 12.80 | loss 0.06871558\n",
      "| Epoch  33 |   350/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.07013330\n",
      "| Epoch  33 |   400/  658 batches | lr 0.00006 | ms/batch 14.33 | loss 0.06442111\n",
      "| Epoch  33 |   450/  658 batches | lr 0.00006 | ms/batch 12.76 | loss 0.06268534\n",
      "| Epoch  33 |   500/  658 batches | lr 0.00006 | ms/batch 14.44 | loss 0.06621234\n",
      "| Epoch  33 |   550/  658 batches | lr 0.00006 | ms/batch 14.49 | loss 0.06434915\n",
      "| Epoch  33 |   600/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.06689940\n",
      "| Epoch  33 |   650/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.06591857\n",
      "\n",
      "Val set: Average loss: 0.06724443\n",
      "\n",
      "| Epoch  34 |    50/  658 batches | lr 0.00006 | ms/batch 12.71 | loss 0.07398499\n",
      "| Epoch  34 |   100/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.06863507\n",
      "| Epoch  34 |   150/  658 batches | lr 0.00006 | ms/batch 12.66 | loss 0.06352615\n",
      "| Epoch  34 |   200/  658 batches | lr 0.00006 | ms/batch 15.08 | loss 0.06487329\n",
      "| Epoch  34 |   250/  658 batches | lr 0.00006 | ms/batch 14.18 | loss 0.06900882\n",
      "| Epoch  34 |   300/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06857805\n",
      "| Epoch  34 |   350/  658 batches | lr 0.00006 | ms/batch 12.42 | loss 0.06978818\n",
      "| Epoch  34 |   400/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.06429759\n",
      "| Epoch  34 |   450/  658 batches | lr 0.00006 | ms/batch 12.66 | loss 0.06249211\n",
      "| Epoch  34 |   500/  658 batches | lr 0.00006 | ms/batch 14.25 | loss 0.06610695\n",
      "| Epoch  34 |   550/  658 batches | lr 0.00006 | ms/batch 14.18 | loss 0.06427110\n",
      "| Epoch  34 |   600/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.06680364\n",
      "| Epoch  34 |   650/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.06583348\n",
      "\n",
      "Val set: Average loss: 0.06704111\n",
      "\n",
      "| Epoch  35 |    50/  658 batches | lr 0.00006 | ms/batch 12.76 | loss 0.07370898\n",
      "| Epoch  35 |   100/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.06850559\n",
      "| Epoch  35 |   150/  658 batches | lr 0.00006 | ms/batch 12.66 | loss 0.06327177\n",
      "| Epoch  35 |   200/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.06461913\n",
      "| Epoch  35 |   250/  658 batches | lr 0.00006 | ms/batch 14.32 | loss 0.06880104\n",
      "| Epoch  35 |   300/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06837317\n",
      "| Epoch  35 |   350/  658 batches | lr 0.00006 | ms/batch 12.62 | loss 0.06967125\n",
      "| Epoch  35 |   400/  658 batches | lr 0.00006 | ms/batch 14.18 | loss 0.06417297\n",
      "| Epoch  35 |   450/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.06239322\n",
      "| Epoch  35 |   500/  658 batches | lr 0.00006 | ms/batch 14.18 | loss 0.06587899\n",
      "| Epoch  35 |   550/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.06404882\n",
      "| Epoch  35 |   600/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.06668452\n",
      "| Epoch  35 |   650/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.06575121\n",
      "\n",
      "Val set: Average loss: 0.06704171\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  36 |    50/  658 batches | lr 0.00006 | ms/batch 12.69 | loss 0.07368232\n",
      "| Epoch  36 |   100/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.06835199\n",
      "| Epoch  36 |   150/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.06320364\n",
      "| Epoch  36 |   200/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.06446350\n",
      "| Epoch  36 |   250/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.06863043\n",
      "| Epoch  36 |   300/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.06811318\n",
      "| Epoch  36 |   350/  658 batches | lr 0.00006 | ms/batch 12.43 | loss 0.06949847\n",
      "| Epoch  36 |   400/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.06397005\n",
      "| Epoch  36 |   450/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.06219322\n",
      "| Epoch  36 |   500/  658 batches | lr 0.00006 | ms/batch 14.29 | loss 0.06560365\n",
      "| Epoch  36 |   550/  658 batches | lr 0.00006 | ms/batch 14.22 | loss 0.06402456\n",
      "| Epoch  36 |   600/  658 batches | lr 0.00006 | ms/batch 12.44 | loss 0.06641600\n",
      "| Epoch  36 |   650/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.06557942\n",
      "\n",
      "Val set: Average loss: 0.06669622\n",
      "\n",
      "| Epoch  37 |    50/  658 batches | lr 0.00006 | ms/batch 12.77 | loss 0.07351758\n",
      "| Epoch  37 |   100/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.06823208\n",
      "| Epoch  37 |   150/  658 batches | lr 0.00006 | ms/batch 12.62 | loss 0.06306512\n",
      "| Epoch  37 |   200/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.06435137\n",
      "| Epoch  37 |   250/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.06842870\n",
      "| Epoch  37 |   300/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.06793319\n",
      "| Epoch  37 |   350/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.06927131\n",
      "| Epoch  37 |   400/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.06396201\n",
      "| Epoch  37 |   450/  658 batches | lr 0.00006 | ms/batch 12.84 | loss 0.06207212\n",
      "| Epoch  37 |   500/  658 batches | lr 0.00006 | ms/batch 14.18 | loss 0.06557604\n",
      "| Epoch  37 |   550/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.06392633\n",
      "| Epoch  37 |   600/  658 batches | lr 0.00006 | ms/batch 12.66 | loss 0.06629078\n",
      "| Epoch  37 |   650/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.06545750\n",
      "\n",
      "Val set: Average loss: 0.06647743\n",
      "\n",
      "| Epoch  38 |    50/  658 batches | lr 0.00006 | ms/batch 12.74 | loss 0.07320906\n",
      "| Epoch  38 |   100/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.06797167\n",
      "| Epoch  38 |   150/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06300071\n",
      "| Epoch  38 |   200/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.06421384\n",
      "| Epoch  38 |   250/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.06834720\n",
      "| Epoch  38 |   300/  658 batches | lr 0.00006 | ms/batch 12.42 | loss 0.06787382\n",
      "| Epoch  38 |   350/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.06904167\n",
      "| Epoch  38 |   400/  658 batches | lr 0.00006 | ms/batch 14.68 | loss 0.06374669\n",
      "| Epoch  38 |   450/  658 batches | lr 0.00006 | ms/batch 12.63 | loss 0.06185578\n",
      "| Epoch  38 |   500/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.06541410\n",
      "| Epoch  38 |   550/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.06392826\n",
      "| Epoch  38 |   600/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.06620915\n",
      "| Epoch  38 |   650/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.06542904\n",
      "\n",
      "Val set: Average loss: 0.06627029\n",
      "\n",
      "| Epoch  39 |    50/  658 batches | lr 0.00006 | ms/batch 12.74 | loss 0.07315483\n",
      "| Epoch  39 |   100/  658 batches | lr 0.00006 | ms/batch 13.99 | loss 0.06785781\n",
      "| Epoch  39 |   150/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.06284069\n",
      "| Epoch  39 |   200/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.06382747\n",
      "| Epoch  39 |   250/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.06827566\n",
      "| Epoch  39 |   300/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.06776270\n",
      "| Epoch  39 |   350/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.06881379\n",
      "| Epoch  39 |   400/  658 batches | lr 0.00006 | ms/batch 14.03 | loss 0.06366712\n",
      "| Epoch  39 |   450/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.06181061\n",
      "| Epoch  39 |   500/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.06527186\n",
      "| Epoch  39 |   550/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.06362463\n",
      "| Epoch  39 |   600/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.06611502\n",
      "| Epoch  39 |   650/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.06537625\n",
      "\n",
      "Val set: Average loss: 0.06591160\n",
      "\n",
      "| Epoch  40 |    50/  658 batches | lr 0.00006 | ms/batch 12.72 | loss 0.07291301\n",
      "| Epoch  40 |   100/  658 batches | lr 0.00006 | ms/batch 14.03 | loss 0.06773570\n",
      "| Epoch  40 |   150/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.06265675\n",
      "| Epoch  40 |   200/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.06376124\n",
      "| Epoch  40 |   250/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.06813651\n",
      "| Epoch  40 |   300/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06755688\n",
      "| Epoch  40 |   350/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.06861967\n",
      "| Epoch  40 |   400/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.06350480\n",
      "| Epoch  40 |   450/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.06161140\n",
      "| Epoch  40 |   500/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.06514474\n",
      "| Epoch  40 |   550/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.06352464\n",
      "| Epoch  40 |   600/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.06597261\n",
      "| Epoch  40 |   650/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.06515958\n",
      "\n",
      "Val set: Average loss: 0.06593902\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  41 |    50/  658 batches | lr 0.00006 | ms/batch 12.95 | loss 0.07277943\n",
      "| Epoch  41 |   100/  658 batches | lr 0.00006 | ms/batch 14.06 | loss 0.06756887\n",
      "| Epoch  41 |   150/  658 batches | lr 0.00006 | ms/batch 12.60 | loss 0.06262258\n",
      "| Epoch  41 |   200/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.06381766\n",
      "| Epoch  41 |   250/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.06796226\n",
      "| Epoch  41 |   300/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.06751516\n",
      "| Epoch  41 |   350/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.06857322\n",
      "| Epoch  41 |   400/  658 batches | lr 0.00006 | ms/batch 14.02 | loss 0.06345098\n",
      "| Epoch  41 |   450/  658 batches | lr 0.00006 | ms/batch 12.58 | loss 0.06154418\n",
      "| Epoch  41 |   500/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.06509955\n",
      "| Epoch  41 |   550/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.06345466\n",
      "| Epoch  41 |   600/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.06581588\n",
      "| Epoch  41 |   650/  658 batches | lr 0.00006 | ms/batch 12.43 | loss 0.06510835\n",
      "\n",
      "Val set: Average loss: 0.06560479\n",
      "\n",
      "| Epoch  42 |    50/  658 batches | lr 0.00006 | ms/batch 12.68 | loss 0.07269295\n",
      "| Epoch  42 |   100/  658 batches | lr 0.00006 | ms/batch 14.18 | loss 0.06747273\n",
      "| Epoch  42 |   150/  658 batches | lr 0.00006 | ms/batch 12.62 | loss 0.06247598\n",
      "| Epoch  42 |   200/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.06347999\n",
      "| Epoch  42 |   250/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.06778047\n",
      "| Epoch  42 |   300/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.06719468\n",
      "| Epoch  42 |   350/  658 batches | lr 0.00006 | ms/batch 12.42 | loss 0.06842346\n",
      "| Epoch  42 |   400/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.06337484\n",
      "| Epoch  42 |   450/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.06136425\n",
      "| Epoch  42 |   500/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.06492034\n",
      "| Epoch  42 |   550/  658 batches | lr 0.00006 | ms/batch 14.26 | loss 0.06349282\n",
      "| Epoch  42 |   600/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06581260\n",
      "| Epoch  42 |   650/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06498352\n",
      "\n",
      "Val set: Average loss: 0.06542422\n",
      "\n",
      "| Epoch  43 |    50/  658 batches | lr 0.00006 | ms/batch 12.79 | loss 0.07252990\n",
      "| Epoch  43 |   100/  658 batches | lr 0.00006 | ms/batch 14.03 | loss 0.06740527\n",
      "| Epoch  43 |   150/  658 batches | lr 0.00006 | ms/batch 12.63 | loss 0.06236702\n",
      "| Epoch  43 |   200/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.06344431\n",
      "| Epoch  43 |   250/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.06786829\n",
      "| Epoch  43 |   300/  658 batches | lr 0.00006 | ms/batch 12.62 | loss 0.06721454\n",
      "| Epoch  43 |   350/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.06815861\n",
      "| Epoch  43 |   400/  658 batches | lr 0.00006 | ms/batch 14.38 | loss 0.06326768\n",
      "| Epoch  43 |   450/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.06126571\n",
      "| Epoch  43 |   500/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.06467397\n",
      "| Epoch  43 |   550/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.06323075\n",
      "| Epoch  43 |   600/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06573434\n",
      "| Epoch  43 |   650/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.06478437\n",
      "\n",
      "Val set: Average loss: 0.06521876\n",
      "\n",
      "| Epoch  44 |    50/  658 batches | lr 0.00006 | ms/batch 12.71 | loss 0.07232697\n",
      "| Epoch  44 |   100/  658 batches | lr 0.00006 | ms/batch 14.06 | loss 0.06731933\n",
      "| Epoch  44 |   150/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.06230674\n",
      "| Epoch  44 |   200/  658 batches | lr 0.00006 | ms/batch 14.22 | loss 0.06306732\n",
      "| Epoch  44 |   250/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.06746296\n",
      "| Epoch  44 |   300/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06697498\n",
      "| Epoch  44 |   350/  658 batches | lr 0.00006 | ms/batch 12.58 | loss 0.06812330\n",
      "| Epoch  44 |   400/  658 batches | lr 0.00006 | ms/batch 14.21 | loss 0.06310017\n",
      "| Epoch  44 |   450/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.06113848\n",
      "| Epoch  44 |   500/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.06461305\n",
      "| Epoch  44 |   550/  658 batches | lr 0.00006 | ms/batch 14.18 | loss 0.06321106\n",
      "| Epoch  44 |   600/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.06550597\n",
      "| Epoch  44 |   650/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.06467129\n",
      "\n",
      "Val set: Average loss: 0.06524260\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  45 |    50/  658 batches | lr 0.00006 | ms/batch 12.78 | loss 0.07226298\n",
      "| Epoch  45 |   100/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.06715267\n",
      "| Epoch  45 |   150/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.06209239\n",
      "| Epoch  45 |   200/  658 batches | lr 0.00006 | ms/batch 14.24 | loss 0.06309117\n",
      "| Epoch  45 |   250/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.06750098\n",
      "| Epoch  45 |   300/  658 batches | lr 0.00006 | ms/batch 12.44 | loss 0.06709214\n",
      "| Epoch  45 |   350/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.06783421\n",
      "| Epoch  45 |   400/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.06315309\n",
      "| Epoch  45 |   450/  658 batches | lr 0.00006 | ms/batch 12.59 | loss 0.06115049\n",
      "| Epoch  45 |   500/  658 batches | lr 0.00006 | ms/batch 14.18 | loss 0.06451857\n",
      "| Epoch  45 |   550/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.06296419\n",
      "| Epoch  45 |   600/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.06548007\n",
      "| Epoch  45 |   650/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06467882\n",
      "\n",
      "Val set: Average loss: 0.06521150\n",
      "\n",
      "| Epoch  46 |    50/  658 batches | lr 0.00006 | ms/batch 12.72 | loss 0.07201890\n",
      "| Epoch  46 |   100/  658 batches | lr 0.00006 | ms/batch 13.99 | loss 0.06692964\n",
      "| Epoch  46 |   150/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.06199560\n",
      "| Epoch  46 |   200/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.06293771\n",
      "| Epoch  46 |   250/  658 batches | lr 0.00006 | ms/batch 14.06 | loss 0.06723695\n",
      "| Epoch  46 |   300/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06674366\n",
      "| Epoch  46 |   350/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.06768001\n",
      "| Epoch  46 |   400/  658 batches | lr 0.00006 | ms/batch 14.06 | loss 0.06304743\n",
      "| Epoch  46 |   450/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.06098778\n",
      "| Epoch  46 |   500/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.06443022\n",
      "| Epoch  46 |   550/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.06287541\n",
      "| Epoch  46 |   600/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06532682\n",
      "| Epoch  46 |   650/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.06448878\n",
      "\n",
      "Val set: Average loss: 0.06497112\n",
      "\n",
      "| Epoch  47 |    50/  658 batches | lr 0.00006 | ms/batch 12.72 | loss 0.07182268\n",
      "| Epoch  47 |   100/  658 batches | lr 0.00006 | ms/batch 14.02 | loss 0.06681530\n",
      "| Epoch  47 |   150/  658 batches | lr 0.00006 | ms/batch 12.95 | loss 0.06194114\n",
      "| Epoch  47 |   200/  658 batches | lr 0.00006 | ms/batch 14.65 | loss 0.06277133\n",
      "| Epoch  47 |   250/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.06717502\n",
      "| Epoch  47 |   300/  658 batches | lr 0.00006 | ms/batch 12.63 | loss 0.06653495\n",
      "| Epoch  47 |   350/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.06742831\n",
      "| Epoch  47 |   400/  658 batches | lr 0.00006 | ms/batch 14.01 | loss 0.06297632\n",
      "| Epoch  47 |   450/  658 batches | lr 0.00006 | ms/batch 12.60 | loss 0.06090086\n",
      "| Epoch  47 |   500/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.06448490\n",
      "| Epoch  47 |   550/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.06290183\n",
      "| Epoch  47 |   600/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.06523094\n",
      "| Epoch  47 |   650/  658 batches | lr 0.00006 | ms/batch 12.42 | loss 0.06441696\n",
      "\n",
      "Val set: Average loss: 0.06472266\n",
      "\n",
      "| Epoch  48 |    50/  658 batches | lr 0.00006 | ms/batch 12.65 | loss 0.07173280\n",
      "| Epoch  48 |   100/  658 batches | lr 0.00006 | ms/batch 14.02 | loss 0.06676744\n",
      "| Epoch  48 |   150/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06184127\n",
      "| Epoch  48 |   200/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.06259220\n",
      "| Epoch  48 |   250/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.06717869\n",
      "| Epoch  48 |   300/  658 batches | lr 0.00006 | ms/batch 12.44 | loss 0.06643406\n",
      "| Epoch  48 |   350/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.06734947\n",
      "| Epoch  48 |   400/  658 batches | lr 0.00006 | ms/batch 14.27 | loss 0.06284973\n",
      "| Epoch  48 |   450/  658 batches | lr 0.00006 | ms/batch 12.62 | loss 0.06068689\n",
      "| Epoch  48 |   500/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.06425656\n",
      "| Epoch  48 |   550/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.06284273\n",
      "| Epoch  48 |   600/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.06512756\n",
      "| Epoch  48 |   650/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.06430542\n",
      "\n",
      "Val set: Average loss: 0.06464815\n",
      "\n",
      "| Epoch  49 |    50/  658 batches | lr 0.00006 | ms/batch 12.71 | loss 0.07157217\n",
      "| Epoch  49 |   100/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.06668291\n",
      "| Epoch  49 |   150/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.06165498\n",
      "| Epoch  49 |   200/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.06270182\n",
      "| Epoch  49 |   250/  658 batches | lr 0.00006 | ms/batch 14.18 | loss 0.06701598\n",
      "| Epoch  49 |   300/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.06625073\n",
      "| Epoch  49 |   350/  658 batches | lr 0.00006 | ms/batch 12.43 | loss 0.06710200\n",
      "| Epoch  49 |   400/  658 batches | lr 0.00006 | ms/batch 14.04 | loss 0.06281362\n",
      "| Epoch  49 |   450/  658 batches | lr 0.00006 | ms/batch 12.73 | loss 0.06063463\n",
      "| Epoch  49 |   500/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.06414729\n",
      "| Epoch  49 |   550/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.06265430\n",
      "| Epoch  49 |   600/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.06504774\n",
      "| Epoch  49 |   650/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06414648\n",
      "\n",
      "Val set: Average loss: 0.06450755\n",
      "\n",
      "| Epoch  50 |    50/  658 batches | lr 0.00006 | ms/batch 12.64 | loss 0.07157334\n",
      "| Epoch  50 |   100/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.06654880\n",
      "| Epoch  50 |   150/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.06165898\n",
      "| Epoch  50 |   200/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.06230173\n",
      "| Epoch  50 |   250/  658 batches | lr 0.00006 | ms/batch 14.21 | loss 0.06680247\n",
      "| Epoch  50 |   300/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06616321\n",
      "| Epoch  50 |   350/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06692760\n",
      "| Epoch  50 |   400/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.06260418\n",
      "| Epoch  50 |   450/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.06051551\n",
      "| Epoch  50 |   500/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.06402842\n",
      "| Epoch  50 |   550/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.06256502\n",
      "| Epoch  50 |   600/  658 batches | lr 0.00006 | ms/batch 12.40 | loss 0.06494638\n",
      "| Epoch  50 |   650/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.06391515\n",
      "\n",
      "Val set: Average loss: 0.06431756\n",
      "\n",
      "| Epoch  51 |    50/  658 batches | lr 0.00006 | ms/batch 12.67 | loss 0.07136710\n",
      "| Epoch  51 |   100/  658 batches | lr 0.00006 | ms/batch 14.06 | loss 0.06639640\n",
      "| Epoch  51 |   150/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.06167471\n",
      "| Epoch  51 |   200/  658 batches | lr 0.00006 | ms/batch 14.25 | loss 0.06244228\n",
      "| Epoch  51 |   250/  658 batches | lr 0.00006 | ms/batch 14.32 | loss 0.06670143\n",
      "| Epoch  51 |   300/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06596932\n",
      "| Epoch  51 |   350/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.06672505\n",
      "| Epoch  51 |   400/  658 batches | lr 0.00006 | ms/batch 14.01 | loss 0.06259710\n",
      "| Epoch  51 |   450/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.06039705\n",
      "| Epoch  51 |   500/  658 batches | lr 0.00006 | ms/batch 14.74 | loss 0.06390963\n",
      "| Epoch  51 |   550/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.06269027\n",
      "| Epoch  51 |   600/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06488631\n",
      "| Epoch  51 |   650/  658 batches | lr 0.00006 | ms/batch 12.65 | loss 0.06378088\n",
      "\n",
      "Val set: Average loss: 0.06427256\n",
      "\n",
      "| Epoch  52 |    50/  658 batches | lr 0.00006 | ms/batch 12.71 | loss 0.07133468\n",
      "| Epoch  52 |   100/  658 batches | lr 0.00006 | ms/batch 14.05 | loss 0.06630212\n",
      "| Epoch  52 |   150/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.06156391\n",
      "| Epoch  52 |   200/  658 batches | lr 0.00006 | ms/batch 14.36 | loss 0.06220397\n",
      "| Epoch  52 |   250/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.06658600\n",
      "| Epoch  52 |   300/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06584700\n",
      "| Epoch  52 |   350/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.06658889\n",
      "| Epoch  52 |   400/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.06243212\n",
      "| Epoch  52 |   450/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.06027781\n",
      "| Epoch  52 |   500/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.06370072\n",
      "| Epoch  52 |   550/  658 batches | lr 0.00006 | ms/batch 14.27 | loss 0.06242776\n",
      "| Epoch  52 |   600/  658 batches | lr 0.00006 | ms/batch 12.43 | loss 0.06486697\n",
      "| Epoch  52 |   650/  658 batches | lr 0.00006 | ms/batch 12.44 | loss 0.06373216\n",
      "\n",
      "Val set: Average loss: 0.06408487\n",
      "\n",
      "| Epoch  53 |    50/  658 batches | lr 0.00006 | ms/batch 12.70 | loss 0.07118957\n",
      "| Epoch  53 |   100/  658 batches | lr 0.00006 | ms/batch 14.03 | loss 0.06625785\n",
      "| Epoch  53 |   150/  658 batches | lr 0.00006 | ms/batch 12.80 | loss 0.06138714\n",
      "| Epoch  53 |   200/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.06225035\n",
      "| Epoch  53 |   250/  658 batches | lr 0.00006 | ms/batch 14.28 | loss 0.06656675\n",
      "| Epoch  53 |   300/  658 batches | lr 0.00006 | ms/batch 12.44 | loss 0.06584652\n",
      "| Epoch  53 |   350/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.06651088\n",
      "| Epoch  53 |   400/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.06243637\n",
      "| Epoch  53 |   450/  658 batches | lr 0.00006 | ms/batch 12.58 | loss 0.06019422\n",
      "| Epoch  53 |   500/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.06372331\n",
      "| Epoch  53 |   550/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.06244304\n",
      "| Epoch  53 |   600/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06477543\n",
      "| Epoch  53 |   650/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.06361076\n",
      "\n",
      "Val set: Average loss: 0.06394351\n",
      "\n",
      "| Epoch  54 |    50/  658 batches | lr 0.00006 | ms/batch 12.81 | loss 0.07097427\n",
      "| Epoch  54 |   100/  658 batches | lr 0.00006 | ms/batch 14.05 | loss 0.06619132\n",
      "| Epoch  54 |   150/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.06138861\n",
      "| Epoch  54 |   200/  658 batches | lr 0.00006 | ms/batch 14.06 | loss 0.06212081\n",
      "| Epoch  54 |   250/  658 batches | lr 0.00006 | ms/batch 14.03 | loss 0.06636678\n",
      "| Epoch  54 |   300/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.06555954\n",
      "| Epoch  54 |   350/  658 batches | lr 0.00006 | ms/batch 12.39 | loss 0.06635438\n",
      "| Epoch  54 |   400/  658 batches | lr 0.00006 | ms/batch 14.05 | loss 0.06223249\n",
      "| Epoch  54 |   450/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.06003377\n",
      "| Epoch  54 |   500/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.06363555\n",
      "| Epoch  54 |   550/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.06258397\n",
      "| Epoch  54 |   600/  658 batches | lr 0.00006 | ms/batch 12.44 | loss 0.06463435\n",
      "| Epoch  54 |   650/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.06353225\n",
      "\n",
      "Val set: Average loss: 0.06390152\n",
      "\n",
      "| Epoch  55 |    50/  658 batches | lr 0.00006 | ms/batch 12.68 | loss 0.07085784\n",
      "| Epoch  55 |   100/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.06598935\n",
      "| Epoch  55 |   150/  658 batches | lr 0.00006 | ms/batch 12.58 | loss 0.06123048\n",
      "| Epoch  55 |   200/  658 batches | lr 0.00006 | ms/batch 14.43 | loss 0.06209808\n",
      "| Epoch  55 |   250/  658 batches | lr 0.00006 | ms/batch 14.79 | loss 0.06629891\n",
      "| Epoch  55 |   300/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.06555699\n",
      "| Epoch  55 |   350/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.06633950\n",
      "| Epoch  55 |   400/  658 batches | lr 0.00006 | ms/batch 14.26 | loss 0.06220071\n",
      "| Epoch  55 |   450/  658 batches | lr 0.00006 | ms/batch 12.64 | loss 0.05996875\n",
      "| Epoch  55 |   500/  658 batches | lr 0.00006 | ms/batch 14.25 | loss 0.06362229\n",
      "| Epoch  55 |   550/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.06246701\n",
      "| Epoch  55 |   600/  658 batches | lr 0.00006 | ms/batch 12.44 | loss 0.06464746\n",
      "| Epoch  55 |   650/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.06358426\n",
      "\n",
      "Val set: Average loss: 0.06386373\n",
      "\n",
      "| Epoch  56 |    50/  658 batches | lr 0.00006 | ms/batch 12.76 | loss 0.07079281\n",
      "| Epoch  56 |   100/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.06595131\n",
      "| Epoch  56 |   150/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.06112827\n",
      "| Epoch  56 |   200/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.06201829\n",
      "| Epoch  56 |   250/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.06623271\n",
      "| Epoch  56 |   300/  658 batches | lr 0.00006 | ms/batch 12.41 | loss 0.06533325\n",
      "| Epoch  56 |   350/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06613597\n",
      "| Epoch  56 |   400/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.06225042\n",
      "| Epoch  56 |   450/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.05998826\n",
      "| Epoch  56 |   500/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.06347267\n",
      "| Epoch  56 |   550/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.06216448\n",
      "| Epoch  56 |   600/  658 batches | lr 0.00006 | ms/batch 12.40 | loss 0.06445895\n",
      "| Epoch  56 |   650/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.06331705\n",
      "\n",
      "Val set: Average loss: 0.06361878\n",
      "\n",
      "| Epoch  57 |    50/  658 batches | lr 0.00006 | ms/batch 12.95 | loss 0.07064156\n",
      "| Epoch  57 |   100/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.06581917\n",
      "| Epoch  57 |   150/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.06113864\n",
      "| Epoch  57 |   200/  658 batches | lr 0.00006 | ms/batch 14.25 | loss 0.06195837\n",
      "| Epoch  57 |   250/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.06600845\n",
      "| Epoch  57 |   300/  658 batches | lr 0.00006 | ms/batch 12.41 | loss 0.06517409\n",
      "| Epoch  57 |   350/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.06605910\n",
      "| Epoch  57 |   400/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.06208815\n",
      "| Epoch  57 |   450/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.05977700\n",
      "| Epoch  57 |   500/  658 batches | lr 0.00006 | ms/batch 14.35 | loss 0.06358103\n",
      "| Epoch  57 |   550/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.06206216\n",
      "| Epoch  57 |   600/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.06445681\n",
      "| Epoch  57 |   650/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06325660\n",
      "\n",
      "Val set: Average loss: 0.06376168\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  58 |    50/  658 batches | lr 0.00006 | ms/batch 12.89 | loss 0.07057349\n",
      "| Epoch  58 |   100/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.06581427\n",
      "| Epoch  58 |   150/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.06098239\n",
      "| Epoch  58 |   200/  658 batches | lr 0.00006 | ms/batch 14.33 | loss 0.06168132\n",
      "| Epoch  58 |   250/  658 batches | lr 0.00006 | ms/batch 14.18 | loss 0.06595594\n",
      "| Epoch  58 |   300/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.06545224\n",
      "| Epoch  58 |   350/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06606654\n",
      "| Epoch  58 |   400/  658 batches | lr 0.00006 | ms/batch 14.04 | loss 0.06200294\n",
      "| Epoch  58 |   450/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.05974421\n",
      "| Epoch  58 |   500/  658 batches | lr 0.00006 | ms/batch 14.22 | loss 0.06334660\n",
      "| Epoch  58 |   550/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.06189594\n",
      "| Epoch  58 |   600/  658 batches | lr 0.00006 | ms/batch 12.43 | loss 0.06437544\n",
      "| Epoch  58 |   650/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.06311135\n",
      "\n",
      "Val set: Average loss: 0.06368172\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  59 |    50/  658 batches | lr 0.00006 | ms/batch 12.88 | loss 0.07048126\n",
      "| Epoch  59 |   100/  658 batches | lr 0.00006 | ms/batch 14.00 | loss 0.06570822\n",
      "| Epoch  59 |   150/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.06083353\n",
      "| Epoch  59 |   200/  658 batches | lr 0.00006 | ms/batch 14.47 | loss 0.06148925\n",
      "| Epoch  59 |   250/  658 batches | lr 0.00006 | ms/batch 14.41 | loss 0.06590856\n",
      "| Epoch  59 |   300/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.06509958\n",
      "| Epoch  59 |   350/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.06591345\n",
      "| Epoch  59 |   400/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.06189733\n",
      "| Epoch  59 |   450/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05951813\n",
      "| Epoch  59 |   500/  658 batches | lr 0.00006 | ms/batch 14.22 | loss 0.06323604\n",
      "| Epoch  59 |   550/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.06193316\n",
      "| Epoch  59 |   600/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.06430838\n",
      "| Epoch  59 |   650/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.06304671\n",
      "\n",
      "Val set: Average loss: 0.06358155\n",
      "\n",
      "| Epoch  60 |    50/  658 batches | lr 0.00006 | ms/batch 12.74 | loss 0.07029856\n",
      "| Epoch  60 |   100/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.06564168\n",
      "| Epoch  60 |   150/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06083057\n",
      "| Epoch  60 |   200/  658 batches | lr 0.00006 | ms/batch 14.24 | loss 0.06133019\n",
      "| Epoch  60 |   250/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.06581516\n",
      "| Epoch  60 |   300/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.06506450\n",
      "| Epoch  60 |   350/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06567865\n",
      "| Epoch  60 |   400/  658 batches | lr 0.00006 | ms/batch 14.05 | loss 0.06196371\n",
      "| Epoch  60 |   450/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.05959175\n",
      "| Epoch  60 |   500/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.06313602\n",
      "| Epoch  60 |   550/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.06180288\n",
      "| Epoch  60 |   600/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.06423553\n",
      "| Epoch  60 |   650/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.06309406\n",
      "\n",
      "Val set: Average loss: 0.06349829\n",
      "\n",
      "| Epoch  61 |    50/  658 batches | lr 0.00006 | ms/batch 12.73 | loss 0.07028502\n",
      "| Epoch  61 |   100/  658 batches | lr 0.00006 | ms/batch 14.25 | loss 0.06551702\n",
      "| Epoch  61 |   150/  658 batches | lr 0.00006 | ms/batch 12.59 | loss 0.06077192\n",
      "| Epoch  61 |   200/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.06135950\n",
      "| Epoch  61 |   250/  658 batches | lr 0.00006 | ms/batch 14.28 | loss 0.06572094\n",
      "| Epoch  61 |   300/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06475760\n",
      "| Epoch  61 |   350/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.06559296\n",
      "| Epoch  61 |   400/  658 batches | lr 0.00006 | ms/batch 14.03 | loss 0.06181553\n",
      "| Epoch  61 |   450/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.05947997\n",
      "| Epoch  61 |   500/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.06328174\n",
      "| Epoch  61 |   550/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.06165597\n",
      "| Epoch  61 |   600/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06404969\n",
      "| Epoch  61 |   650/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.06285152\n",
      "\n",
      "Val set: Average loss: 0.06339404\n",
      "\n",
      "| Epoch  62 |    50/  658 batches | lr 0.00006 | ms/batch 12.77 | loss 0.07016426\n",
      "| Epoch  62 |   100/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.06540705\n",
      "| Epoch  62 |   150/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.06070542\n",
      "| Epoch  62 |   200/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.06105202\n",
      "| Epoch  62 |   250/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.06572936\n",
      "| Epoch  62 |   300/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.06470445\n",
      "| Epoch  62 |   350/  658 batches | lr 0.00006 | ms/batch 12.43 | loss 0.06547947\n",
      "| Epoch  62 |   400/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.06172631\n",
      "| Epoch  62 |   450/  658 batches | lr 0.00006 | ms/batch 12.75 | loss 0.05940642\n",
      "| Epoch  62 |   500/  658 batches | lr 0.00006 | ms/batch 14.18 | loss 0.06314245\n",
      "| Epoch  62 |   550/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.06174617\n",
      "| Epoch  62 |   600/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.06407290\n",
      "| Epoch  62 |   650/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.06290123\n",
      "\n",
      "Val set: Average loss: 0.06325970\n",
      "\n",
      "| Epoch  63 |    50/  658 batches | lr 0.00006 | ms/batch 12.94 | loss 0.07017853\n",
      "| Epoch  63 |   100/  658 batches | lr 0.00006 | ms/batch 14.70 | loss 0.06542020\n",
      "| Epoch  63 |   150/  658 batches | lr 0.00006 | ms/batch 12.90 | loss 0.06074973\n",
      "| Epoch  63 |   200/  658 batches | lr 0.00006 | ms/batch 14.21 | loss 0.06121584\n",
      "| Epoch  63 |   250/  658 batches | lr 0.00006 | ms/batch 14.36 | loss 0.06556547\n",
      "| Epoch  63 |   300/  658 batches | lr 0.00006 | ms/batch 12.80 | loss 0.06462747\n",
      "| Epoch  63 |   350/  658 batches | lr 0.00006 | ms/batch 12.68 | loss 0.06530970\n",
      "| Epoch  63 |   400/  658 batches | lr 0.00006 | ms/batch 14.22 | loss 0.06167687\n",
      "| Epoch  63 |   450/  658 batches | lr 0.00006 | ms/batch 12.62 | loss 0.05931988\n",
      "| Epoch  63 |   500/  658 batches | lr 0.00006 | ms/batch 14.37 | loss 0.06296134\n",
      "| Epoch  63 |   550/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.06153128\n",
      "| Epoch  63 |   600/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.06404727\n",
      "| Epoch  63 |   650/  658 batches | lr 0.00006 | ms/batch 12.66 | loss 0.06291796\n",
      "\n",
      "Val set: Average loss: 0.06317915\n",
      "\n",
      "| Epoch  64 |    50/  658 batches | lr 0.00006 | ms/batch 12.88 | loss 0.06995260\n",
      "| Epoch  64 |   100/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.06535190\n",
      "| Epoch  64 |   150/  658 batches | lr 0.00006 | ms/batch 12.64 | loss 0.06050921\n",
      "| Epoch  64 |   200/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.06098013\n",
      "| Epoch  64 |   250/  658 batches | lr 0.00006 | ms/batch 14.05 | loss 0.06550389\n",
      "| Epoch  64 |   300/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.06444977\n",
      "| Epoch  64 |   350/  658 batches | lr 0.00006 | ms/batch 12.42 | loss 0.06525733\n",
      "| Epoch  64 |   400/  658 batches | lr 0.00006 | ms/batch 14.06 | loss 0.06160520\n",
      "| Epoch  64 |   450/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.05919920\n",
      "| Epoch  64 |   500/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.06286520\n",
      "| Epoch  64 |   550/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.06155712\n",
      "| Epoch  64 |   600/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.06392634\n",
      "| Epoch  64 |   650/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06259577\n",
      "\n",
      "Val set: Average loss: 0.06315497\n",
      "\n",
      "| Epoch  65 |    50/  658 batches | lr 0.00006 | ms/batch 12.86 | loss 0.06992863\n",
      "| Epoch  65 |   100/  658 batches | lr 0.00006 | ms/batch 14.31 | loss 0.06523282\n",
      "| Epoch  65 |   150/  658 batches | lr 0.00006 | ms/batch 12.63 | loss 0.06044317\n",
      "| Epoch  65 |   200/  658 batches | lr 0.00006 | ms/batch 14.48 | loss 0.06098676\n",
      "| Epoch  65 |   250/  658 batches | lr 0.00006 | ms/batch 14.29 | loss 0.06539172\n",
      "| Epoch  65 |   300/  658 batches | lr 0.00006 | ms/batch 12.81 | loss 0.06433525\n",
      "| Epoch  65 |   350/  658 batches | lr 0.00006 | ms/batch 12.67 | loss 0.06519444\n",
      "| Epoch  65 |   400/  658 batches | lr 0.00006 | ms/batch 14.45 | loss 0.06157729\n",
      "| Epoch  65 |   450/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.05920776\n",
      "| Epoch  65 |   500/  658 batches | lr 0.00006 | ms/batch 14.18 | loss 0.06283034\n",
      "| Epoch  65 |   550/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.06153771\n",
      "| Epoch  65 |   600/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.06388388\n",
      "| Epoch  65 |   650/  658 batches | lr 0.00006 | ms/batch 12.38 | loss 0.06253955\n",
      "\n",
      "Val set: Average loss: 0.06305731\n",
      "\n",
      "| Epoch  66 |    50/  658 batches | lr 0.00006 | ms/batch 12.75 | loss 0.06974829\n",
      "| Epoch  66 |   100/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.06504432\n",
      "| Epoch  66 |   150/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.06037565\n",
      "| Epoch  66 |   200/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.06100123\n",
      "| Epoch  66 |   250/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.06532738\n",
      "| Epoch  66 |   300/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.06433368\n",
      "| Epoch  66 |   350/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06506242\n",
      "| Epoch  66 |   400/  658 batches | lr 0.00006 | ms/batch 14.02 | loss 0.06148948\n",
      "| Epoch  66 |   450/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.05909022\n",
      "| Epoch  66 |   500/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.06282300\n",
      "| Epoch  66 |   550/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.06134571\n",
      "| Epoch  66 |   600/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.06383622\n",
      "| Epoch  66 |   650/  658 batches | lr 0.00006 | ms/batch 12.58 | loss 0.06240307\n",
      "\n",
      "Val set: Average loss: 0.06302343\n",
      "\n",
      "| Epoch  67 |    50/  658 batches | lr 0.00006 | ms/batch 12.69 | loss 0.06971707\n",
      "| Epoch  67 |   100/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.06503693\n",
      "| Epoch  67 |   150/  658 batches | lr 0.00006 | ms/batch 12.63 | loss 0.06033675\n",
      "| Epoch  67 |   200/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.06071846\n",
      "| Epoch  67 |   250/  658 batches | lr 0.00006 | ms/batch 14.18 | loss 0.06529412\n",
      "| Epoch  67 |   300/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.06413728\n",
      "| Epoch  67 |   350/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.06491550\n",
      "| Epoch  67 |   400/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.06147549\n",
      "| Epoch  67 |   450/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.05896108\n",
      "| Epoch  67 |   500/  658 batches | lr 0.00006 | ms/batch 14.18 | loss 0.06266489\n",
      "| Epoch  67 |   550/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.06127650\n",
      "| Epoch  67 |   600/  658 batches | lr 0.00006 | ms/batch 12.44 | loss 0.06378055\n",
      "| Epoch  67 |   650/  658 batches | lr 0.00006 | ms/batch 12.42 | loss 0.06234198\n",
      "\n",
      "Val set: Average loss: 0.06297137\n",
      "\n",
      "| Epoch  68 |    50/  658 batches | lr 0.00006 | ms/batch 12.71 | loss 0.06963749\n",
      "| Epoch  68 |   100/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.06500756\n",
      "| Epoch  68 |   150/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06027827\n",
      "| Epoch  68 |   200/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.06069885\n",
      "| Epoch  68 |   250/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.06518319\n",
      "| Epoch  68 |   300/  658 batches | lr 0.00006 | ms/batch 12.43 | loss 0.06414338\n",
      "| Epoch  68 |   350/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06483841\n",
      "| Epoch  68 |   400/  658 batches | lr 0.00006 | ms/batch 14.26 | loss 0.06139168\n",
      "| Epoch  68 |   450/  658 batches | lr 0.00006 | ms/batch 12.72 | loss 0.05890250\n",
      "| Epoch  68 |   500/  658 batches | lr 0.00006 | ms/batch 14.21 | loss 0.06273554\n",
      "| Epoch  68 |   550/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.06119891\n",
      "| Epoch  68 |   600/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06368989\n",
      "| Epoch  68 |   650/  658 batches | lr 0.00006 | ms/batch 12.38 | loss 0.06229071\n",
      "\n",
      "Val set: Average loss: 0.06275437\n",
      "\n",
      "| Epoch  69 |    50/  658 batches | lr 0.00006 | ms/batch 12.76 | loss 0.06968016\n",
      "| Epoch  69 |   100/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.06500623\n",
      "| Epoch  69 |   150/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.06030664\n",
      "| Epoch  69 |   200/  658 batches | lr 0.00006 | ms/batch 14.21 | loss 0.06064804\n",
      "| Epoch  69 |   250/  658 batches | lr 0.00006 | ms/batch 14.25 | loss 0.06506299\n",
      "| Epoch  69 |   300/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06394118\n",
      "| Epoch  69 |   350/  658 batches | lr 0.00006 | ms/batch 12.58 | loss 0.06474001\n",
      "| Epoch  69 |   400/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.06130121\n",
      "| Epoch  69 |   450/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.05881186\n",
      "| Epoch  69 |   500/  658 batches | lr 0.00006 | ms/batch 14.28 | loss 0.06256814\n",
      "| Epoch  69 |   550/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.06106686\n",
      "| Epoch  69 |   600/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06372974\n",
      "| Epoch  69 |   650/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.06215074\n",
      "\n",
      "Val set: Average loss: 0.06293048\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  70 |    50/  658 batches | lr 0.00006 | ms/batch 12.77 | loss 0.06931732\n",
      "| Epoch  70 |   100/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.06486823\n",
      "| Epoch  70 |   150/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06017487\n",
      "| Epoch  70 |   200/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.06048153\n",
      "| Epoch  70 |   250/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.06489115\n",
      "| Epoch  70 |   300/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.06389612\n",
      "| Epoch  70 |   350/  658 batches | lr 0.00006 | ms/batch 12.58 | loss 0.06461819\n",
      "| Epoch  70 |   400/  658 batches | lr 0.00006 | ms/batch 14.00 | loss 0.06123443\n",
      "| Epoch  70 |   450/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.05869411\n",
      "| Epoch  70 |   500/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.06249680\n",
      "| Epoch  70 |   550/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.06099414\n",
      "| Epoch  70 |   600/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.06357106\n",
      "| Epoch  70 |   650/  658 batches | lr 0.00006 | ms/batch 12.60 | loss 0.06210459\n",
      "\n",
      "Val set: Average loss: 0.06284912\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  71 |    50/  658 batches | lr 0.00006 | ms/batch 12.93 | loss 0.06935341\n",
      "| Epoch  71 |   100/  658 batches | lr 0.00006 | ms/batch 15.08 | loss 0.06482994\n",
      "| Epoch  71 |   150/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.06018525\n",
      "| Epoch  71 |   200/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.06040529\n",
      "| Epoch  71 |   250/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.06484929\n",
      "| Epoch  71 |   300/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.06387393\n",
      "| Epoch  71 |   350/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.06453107\n",
      "| Epoch  71 |   400/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.06103858\n",
      "| Epoch  71 |   450/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05866004\n",
      "| Epoch  71 |   500/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.06247561\n",
      "| Epoch  71 |   550/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.06091256\n",
      "| Epoch  71 |   600/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06351055\n",
      "| Epoch  71 |   650/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.06199335\n",
      "\n",
      "Val set: Average loss: 0.06287142\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  72 |    50/  658 batches | lr 0.00006 | ms/batch 12.82 | loss 0.06904858\n",
      "| Epoch  72 |   100/  658 batches | lr 0.00006 | ms/batch 14.02 | loss 0.06462634\n",
      "| Epoch  72 |   150/  658 batches | lr 0.00006 | ms/batch 12.67 | loss 0.06007987\n",
      "| Epoch  72 |   200/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.06027067\n",
      "| Epoch  72 |   250/  658 batches | lr 0.00006 | ms/batch 14.22 | loss 0.06472706\n",
      "| Epoch  72 |   300/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.06364237\n",
      "| Epoch  72 |   350/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.06451048\n",
      "| Epoch  72 |   400/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.06104820\n",
      "| Epoch  72 |   450/  658 batches | lr 0.00006 | ms/batch 12.59 | loss 0.05857132\n",
      "| Epoch  72 |   500/  658 batches | lr 0.00006 | ms/batch 14.26 | loss 0.06238992\n",
      "| Epoch  72 |   550/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.06086666\n",
      "| Epoch  72 |   600/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.06341606\n",
      "| Epoch  72 |   650/  658 batches | lr 0.00006 | ms/batch 12.43 | loss 0.06200121\n",
      "\n",
      "Val set: Average loss: 0.06274738\n",
      "\n",
      "| Epoch  73 |    50/  658 batches | lr 0.00006 | ms/batch 12.71 | loss 0.06917895\n",
      "| Epoch  73 |   100/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.06460399\n",
      "| Epoch  73 |   150/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.05991539\n",
      "| Epoch  73 |   200/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.06018279\n",
      "| Epoch  73 |   250/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.06472802\n",
      "| Epoch  73 |   300/  658 batches | lr 0.00006 | ms/batch 12.44 | loss 0.06372711\n",
      "| Epoch  73 |   350/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.06441674\n",
      "| Epoch  73 |   400/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.06105369\n",
      "| Epoch  73 |   450/  658 batches | lr 0.00006 | ms/batch 12.64 | loss 0.05852124\n",
      "| Epoch  73 |   500/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.06230026\n",
      "| Epoch  73 |   550/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.06099083\n",
      "| Epoch  73 |   600/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.06331661\n",
      "| Epoch  73 |   650/  658 batches | lr 0.00006 | ms/batch 12.44 | loss 0.06188396\n",
      "\n",
      "Val set: Average loss: 0.06269815\n",
      "\n",
      "| Epoch  74 |    50/  658 batches | lr 0.00006 | ms/batch 12.65 | loss 0.06890212\n",
      "| Epoch  74 |   100/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.06444458\n",
      "| Epoch  74 |   150/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.06003099\n",
      "| Epoch  74 |   200/  658 batches | lr 0.00006 | ms/batch 14.40 | loss 0.06019341\n",
      "| Epoch  74 |   250/  658 batches | lr 0.00006 | ms/batch 14.22 | loss 0.06458211\n",
      "| Epoch  74 |   300/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.06370541\n",
      "| Epoch  74 |   350/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.06423701\n",
      "| Epoch  74 |   400/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.06098764\n",
      "| Epoch  74 |   450/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.05840913\n",
      "| Epoch  74 |   500/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.06225943\n",
      "| Epoch  74 |   550/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.06093470\n",
      "| Epoch  74 |   600/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.06324435\n",
      "| Epoch  74 |   650/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.06178384\n",
      "\n",
      "Val set: Average loss: 0.06244459\n",
      "\n",
      "| Epoch  75 |    50/  658 batches | lr 0.00006 | ms/batch 12.69 | loss 0.06897446\n",
      "| Epoch  75 |   100/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.06434821\n",
      "| Epoch  75 |   150/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.05999406\n",
      "| Epoch  75 |   200/  658 batches | lr 0.00006 | ms/batch 14.36 | loss 0.06003345\n",
      "| Epoch  75 |   250/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.06442198\n",
      "| Epoch  75 |   300/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06333533\n",
      "| Epoch  75 |   350/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06419104\n",
      "| Epoch  75 |   400/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.06079541\n",
      "| Epoch  75 |   450/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.05840186\n",
      "| Epoch  75 |   500/  658 batches | lr 0.00006 | ms/batch 14.18 | loss 0.06218450\n",
      "| Epoch  75 |   550/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.06074558\n",
      "| Epoch  75 |   600/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.06317228\n",
      "| Epoch  75 |   650/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.06164003\n",
      "\n",
      "Val set: Average loss: 0.06246511\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  76 |    50/  658 batches | lr 0.00006 | ms/batch 12.85 | loss 0.06876455\n",
      "| Epoch  76 |   100/  658 batches | lr 0.00006 | ms/batch 14.06 | loss 0.06438470\n",
      "| Epoch  76 |   150/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.05980988\n",
      "| Epoch  76 |   200/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.06002406\n",
      "| Epoch  76 |   250/  658 batches | lr 0.00006 | ms/batch 14.02 | loss 0.06428596\n",
      "| Epoch  76 |   300/  658 batches | lr 0.00006 | ms/batch 12.40 | loss 0.06332106\n",
      "| Epoch  76 |   350/  658 batches | lr 0.00006 | ms/batch 12.44 | loss 0.06406935\n",
      "| Epoch  76 |   400/  658 batches | lr 0.00006 | ms/batch 14.04 | loss 0.06081548\n",
      "| Epoch  76 |   450/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.05834125\n",
      "| Epoch  76 |   500/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.06217518\n",
      "| Epoch  76 |   550/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.06077693\n",
      "| Epoch  76 |   600/  658 batches | lr 0.00006 | ms/batch 12.43 | loss 0.06316528\n",
      "| Epoch  76 |   650/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06165867\n",
      "\n",
      "Val set: Average loss: 0.06241610\n",
      "\n",
      "| Epoch  77 |    50/  658 batches | lr 0.00006 | ms/batch 12.68 | loss 0.06865545\n",
      "| Epoch  77 |   100/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.06422714\n",
      "| Epoch  77 |   150/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.05972937\n",
      "| Epoch  77 |   200/  658 batches | lr 0.00006 | ms/batch 14.27 | loss 0.05990490\n",
      "| Epoch  77 |   250/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.06420187\n",
      "| Epoch  77 |   300/  658 batches | lr 0.00006 | ms/batch 12.41 | loss 0.06324798\n",
      "| Epoch  77 |   350/  658 batches | lr 0.00006 | ms/batch 12.42 | loss 0.06396171\n",
      "| Epoch  77 |   400/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.06079966\n",
      "| Epoch  77 |   450/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05828972\n",
      "| Epoch  77 |   500/  658 batches | lr 0.00006 | ms/batch 14.18 | loss 0.06211728\n",
      "| Epoch  77 |   550/  658 batches | lr 0.00006 | ms/batch 14.22 | loss 0.06060354\n",
      "| Epoch  77 |   600/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.06309315\n",
      "| Epoch  77 |   650/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06157454\n",
      "\n",
      "Val set: Average loss: 0.06236056\n",
      "\n",
      "| Epoch  78 |    50/  658 batches | lr 0.00006 | ms/batch 12.66 | loss 0.06857718\n",
      "| Epoch  78 |   100/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.06426788\n",
      "| Epoch  78 |   150/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.05986938\n",
      "| Epoch  78 |   200/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.05973124\n",
      "| Epoch  78 |   250/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.06421992\n",
      "| Epoch  78 |   300/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.06313068\n",
      "| Epoch  78 |   350/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.06387554\n",
      "| Epoch  78 |   400/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.06077399\n",
      "| Epoch  78 |   450/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.05828296\n",
      "| Epoch  78 |   500/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.06212328\n",
      "| Epoch  78 |   550/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.06078358\n",
      "| Epoch  78 |   600/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06300105\n",
      "| Epoch  78 |   650/  658 batches | lr 0.00006 | ms/batch 12.42 | loss 0.06158095\n",
      "\n",
      "Val set: Average loss: 0.06228124\n",
      "\n",
      "| Epoch  79 |    50/  658 batches | lr 0.00006 | ms/batch 12.75 | loss 0.06833558\n",
      "| Epoch  79 |   100/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.06414895\n",
      "| Epoch  79 |   150/  658 batches | lr 0.00006 | ms/batch 12.58 | loss 0.05976845\n",
      "| Epoch  79 |   200/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.05975397\n",
      "| Epoch  79 |   250/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.06402369\n",
      "| Epoch  79 |   300/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06344432\n",
      "| Epoch  79 |   350/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.06382413\n",
      "| Epoch  79 |   400/  658 batches | lr 0.00006 | ms/batch 14.06 | loss 0.06074470\n",
      "| Epoch  79 |   450/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.05814246\n",
      "| Epoch  79 |   500/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.06201190\n",
      "| Epoch  79 |   550/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.06081272\n",
      "| Epoch  79 |   600/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.06291979\n",
      "| Epoch  79 |   650/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06140609\n",
      "\n",
      "Val set: Average loss: 0.06223838\n",
      "\n",
      "| Epoch  80 |    50/  658 batches | lr 0.00006 | ms/batch 12.85 | loss 0.06838479\n",
      "| Epoch  80 |   100/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.06403402\n",
      "| Epoch  80 |   150/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.05961721\n",
      "| Epoch  80 |   200/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.05971086\n",
      "| Epoch  80 |   250/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.06409490\n",
      "| Epoch  80 |   300/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.06341299\n",
      "| Epoch  80 |   350/  658 batches | lr 0.00006 | ms/batch 12.42 | loss 0.06380257\n",
      "| Epoch  80 |   400/  658 batches | lr 0.00006 | ms/batch 14.05 | loss 0.06055954\n",
      "| Epoch  80 |   450/  658 batches | lr 0.00006 | ms/batch 12.59 | loss 0.05815448\n",
      "| Epoch  80 |   500/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.06191766\n",
      "| Epoch  80 |   550/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.06071468\n",
      "| Epoch  80 |   600/  658 batches | lr 0.00006 | ms/batch 12.44 | loss 0.06286441\n",
      "| Epoch  80 |   650/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.06138584\n",
      "\n",
      "Val set: Average loss: 0.06220233\n",
      "\n",
      "| Epoch  81 |    50/  658 batches | lr 0.00006 | ms/batch 12.74 | loss 0.06830299\n",
      "| Epoch  81 |   100/  658 batches | lr 0.00006 | ms/batch 14.22 | loss 0.06401211\n",
      "| Epoch  81 |   150/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.05955359\n",
      "| Epoch  81 |   200/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.05967995\n",
      "| Epoch  81 |   250/  658 batches | lr 0.00006 | ms/batch 14.30 | loss 0.06389830\n",
      "| Epoch  81 |   300/  658 batches | lr 0.00006 | ms/batch 12.44 | loss 0.06333382\n",
      "| Epoch  81 |   350/  658 batches | lr 0.00006 | ms/batch 12.42 | loss 0.06364681\n",
      "| Epoch  81 |   400/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.06062773\n",
      "| Epoch  81 |   450/  658 batches | lr 0.00006 | ms/batch 12.73 | loss 0.05797239\n",
      "| Epoch  81 |   500/  658 batches | lr 0.00006 | ms/batch 15.00 | loss 0.06186426\n",
      "| Epoch  81 |   550/  658 batches | lr 0.00006 | ms/batch 14.33 | loss 0.06063233\n",
      "| Epoch  81 |   600/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.06275442\n",
      "| Epoch  81 |   650/  658 batches | lr 0.00006 | ms/batch 12.41 | loss 0.06130280\n",
      "\n",
      "Val set: Average loss: 0.06201837\n",
      "\n",
      "| Epoch  82 |    50/  658 batches | lr 0.00006 | ms/batch 12.63 | loss 0.06806454\n",
      "| Epoch  82 |   100/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.06395343\n",
      "| Epoch  82 |   150/  658 batches | lr 0.00006 | ms/batch 12.59 | loss 0.05956370\n",
      "| Epoch  82 |   200/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.05963855\n",
      "| Epoch  82 |   250/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.06380942\n",
      "| Epoch  82 |   300/  658 batches | lr 0.00006 | ms/batch 12.40 | loss 0.06294492\n",
      "| Epoch  82 |   350/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.06373065\n",
      "| Epoch  82 |   400/  658 batches | lr 0.00006 | ms/batch 14.04 | loss 0.06052353\n",
      "| Epoch  82 |   450/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.05797948\n",
      "| Epoch  82 |   500/  658 batches | lr 0.00006 | ms/batch 14.21 | loss 0.06182288\n",
      "| Epoch  82 |   550/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.06056569\n",
      "| Epoch  82 |   600/  658 batches | lr 0.00006 | ms/batch 12.42 | loss 0.06271816\n",
      "| Epoch  82 |   650/  658 batches | lr 0.00006 | ms/batch 12.40 | loss 0.06106487\n",
      "\n",
      "Val set: Average loss: 0.06208892\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  83 |    50/  658 batches | lr 0.00006 | ms/batch 12.80 | loss 0.06801209\n",
      "| Epoch  83 |   100/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.06373880\n",
      "| Epoch  83 |   150/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.05954136\n",
      "| Epoch  83 |   200/  658 batches | lr 0.00006 | ms/batch 14.22 | loss 0.05939515\n",
      "| Epoch  83 |   250/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.06378200\n",
      "| Epoch  83 |   300/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.06307674\n",
      "| Epoch  83 |   350/  658 batches | lr 0.00006 | ms/batch 12.65 | loss 0.06365117\n",
      "| Epoch  83 |   400/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.06061519\n",
      "| Epoch  83 |   450/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05794786\n",
      "| Epoch  83 |   500/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.06170016\n",
      "| Epoch  83 |   550/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.06052496\n",
      "| Epoch  83 |   600/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.06273461\n",
      "| Epoch  83 |   650/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.06112049\n",
      "\n",
      "Val set: Average loss: 0.06196551\n",
      "\n",
      "| Epoch  84 |    50/  658 batches | lr 0.00006 | ms/batch 12.75 | loss 0.06793727\n",
      "| Epoch  84 |   100/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.06374997\n",
      "| Epoch  84 |   150/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.05942745\n",
      "| Epoch  84 |   200/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.05940706\n",
      "| Epoch  84 |   250/  658 batches | lr 0.00006 | ms/batch 14.24 | loss 0.06366263\n",
      "| Epoch  84 |   300/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.06309429\n",
      "| Epoch  84 |   350/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.06342501\n",
      "| Epoch  84 |   400/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.06040639\n",
      "| Epoch  84 |   450/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.05773432\n",
      "| Epoch  84 |   500/  658 batches | lr 0.00006 | ms/batch 14.28 | loss 0.06168560\n",
      "| Epoch  84 |   550/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.06064176\n",
      "| Epoch  84 |   600/  658 batches | lr 0.00006 | ms/batch 12.41 | loss 0.06270489\n",
      "| Epoch  84 |   650/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.06090543\n",
      "\n",
      "Val set: Average loss: 0.06201689\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  85 |    50/  658 batches | lr 0.00006 | ms/batch 12.82 | loss 0.06783383\n",
      "| Epoch  85 |   100/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.06358272\n",
      "| Epoch  85 |   150/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.05948995\n",
      "| Epoch  85 |   200/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.05934568\n",
      "| Epoch  85 |   250/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.06359796\n",
      "| Epoch  85 |   300/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.06301042\n",
      "| Epoch  85 |   350/  658 batches | lr 0.00006 | ms/batch 12.44 | loss 0.06333105\n",
      "| Epoch  85 |   400/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.06043902\n",
      "| Epoch  85 |   450/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.05768897\n",
      "| Epoch  85 |   500/  658 batches | lr 0.00006 | ms/batch 14.21 | loss 0.06163912\n",
      "| Epoch  85 |   550/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.06044963\n",
      "| Epoch  85 |   600/  658 batches | lr 0.00006 | ms/batch 12.41 | loss 0.06257303\n",
      "| Epoch  85 |   650/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.06099266\n",
      "\n",
      "Val set: Average loss: 0.06185084\n",
      "\n",
      "| Epoch  86 |    50/  658 batches | lr 0.00006 | ms/batch 12.84 | loss 0.06783505\n",
      "| Epoch  86 |   100/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.06358077\n",
      "| Epoch  86 |   150/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.05939127\n",
      "| Epoch  86 |   200/  658 batches | lr 0.00006 | ms/batch 14.33 | loss 0.05935438\n",
      "| Epoch  86 |   250/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.06352713\n",
      "| Epoch  86 |   300/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.06290451\n",
      "| Epoch  86 |   350/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.06324996\n",
      "| Epoch  86 |   400/  658 batches | lr 0.00006 | ms/batch 14.06 | loss 0.06038209\n",
      "| Epoch  86 |   450/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.05765818\n",
      "| Epoch  86 |   500/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.06164618\n",
      "| Epoch  86 |   550/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.06042099\n",
      "| Epoch  86 |   600/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.06243125\n",
      "| Epoch  86 |   650/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.06089376\n",
      "\n",
      "Val set: Average loss: 0.06180112\n",
      "\n",
      "| Epoch  87 |    50/  658 batches | lr 0.00006 | ms/batch 12.78 | loss 0.06756225\n",
      "| Epoch  87 |   100/  658 batches | lr 0.00006 | ms/batch 14.00 | loss 0.06343620\n",
      "| Epoch  87 |   150/  658 batches | lr 0.00006 | ms/batch 12.58 | loss 0.05930072\n",
      "| Epoch  87 |   200/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.05916726\n",
      "| Epoch  87 |   250/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.06343204\n",
      "| Epoch  87 |   300/  658 batches | lr 0.00006 | ms/batch 12.41 | loss 0.06287992\n",
      "| Epoch  87 |   350/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.06327468\n",
      "| Epoch  87 |   400/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.06033878\n",
      "| Epoch  87 |   450/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.05745675\n",
      "| Epoch  87 |   500/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.06158477\n",
      "| Epoch  87 |   550/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.06048099\n",
      "| Epoch  87 |   600/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.06238202\n",
      "| Epoch  87 |   650/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.06077251\n",
      "\n",
      "Val set: Average loss: 0.06174405\n",
      "\n",
      "| Epoch  88 |    50/  658 batches | lr 0.00006 | ms/batch 12.68 | loss 0.06745183\n",
      "| Epoch  88 |   100/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.06335159\n",
      "| Epoch  88 |   150/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.05941526\n",
      "| Epoch  88 |   200/  658 batches | lr 0.00006 | ms/batch 14.21 | loss 0.05917859\n",
      "| Epoch  88 |   250/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.06335450\n",
      "| Epoch  88 |   300/  658 batches | lr 0.00006 | ms/batch 12.68 | loss 0.06248706\n",
      "| Epoch  88 |   350/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.06313678\n",
      "| Epoch  88 |   400/  658 batches | lr 0.00006 | ms/batch 14.06 | loss 0.06026275\n",
      "| Epoch  88 |   450/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.05749629\n",
      "| Epoch  88 |   500/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.06151895\n",
      "| Epoch  88 |   550/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.06028653\n",
      "| Epoch  88 |   600/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.06241547\n",
      "| Epoch  88 |   650/  658 batches | lr 0.00006 | ms/batch 12.44 | loss 0.06066916\n",
      "\n",
      "Val set: Average loss: 0.06173497\n",
      "\n",
      "| Epoch  89 |    50/  658 batches | lr 0.00006 | ms/batch 12.68 | loss 0.06749166\n",
      "| Epoch  89 |   100/  658 batches | lr 0.00006 | ms/batch 14.27 | loss 0.06333961\n",
      "| Epoch  89 |   150/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.05924178\n",
      "| Epoch  89 |   200/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.05911796\n",
      "| Epoch  89 |   250/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.06330703\n",
      "| Epoch  89 |   300/  658 batches | lr 0.00006 | ms/batch 12.40 | loss 0.06231020\n",
      "| Epoch  89 |   350/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.06306116\n",
      "| Epoch  89 |   400/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.06012073\n",
      "| Epoch  89 |   450/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05740968\n",
      "| Epoch  89 |   500/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.06150851\n",
      "| Epoch  89 |   550/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.06033922\n",
      "| Epoch  89 |   600/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.06235231\n",
      "| Epoch  89 |   650/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.06075900\n",
      "\n",
      "Val set: Average loss: 0.06166112\n",
      "\n",
      "| Epoch  90 |    50/  658 batches | lr 0.00006 | ms/batch 12.69 | loss 0.06731655\n",
      "| Epoch  90 |   100/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.06321498\n",
      "| Epoch  90 |   150/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.05916650\n",
      "| Epoch  90 |   200/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.05902203\n",
      "| Epoch  90 |   250/  658 batches | lr 0.00006 | ms/batch 14.06 | loss 0.06322150\n",
      "| Epoch  90 |   300/  658 batches | lr 0.00006 | ms/batch 12.44 | loss 0.06273957\n",
      "| Epoch  90 |   350/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.06306922\n",
      "| Epoch  90 |   400/  658 batches | lr 0.00006 | ms/batch 14.00 | loss 0.06011134\n",
      "| Epoch  90 |   450/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.05735443\n",
      "| Epoch  90 |   500/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.06132733\n",
      "| Epoch  90 |   550/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.06014680\n",
      "| Epoch  90 |   600/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.06222326\n",
      "| Epoch  90 |   650/  658 batches | lr 0.00006 | ms/batch 12.43 | loss 0.06046438\n",
      "\n",
      "Val set: Average loss: 0.06161829\n",
      "\n",
      "| Epoch  91 |    50/  658 batches | lr 0.00006 | ms/batch 12.74 | loss 0.06720173\n",
      "| Epoch  91 |   100/  658 batches | lr 0.00006 | ms/batch 14.04 | loss 0.06323485\n",
      "| Epoch  91 |   150/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.05910579\n",
      "| Epoch  91 |   200/  658 batches | lr 0.00006 | ms/batch 14.29 | loss 0.05896843\n",
      "| Epoch  91 |   250/  658 batches | lr 0.00006 | ms/batch 14.26 | loss 0.06307555\n",
      "| Epoch  91 |   300/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.06216800\n",
      "| Epoch  91 |   350/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.06286581\n",
      "| Epoch  91 |   400/  658 batches | lr 0.00006 | ms/batch 14.05 | loss 0.05990363\n",
      "| Epoch  91 |   450/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05729719\n",
      "| Epoch  91 |   500/  658 batches | lr 0.00006 | ms/batch 14.26 | loss 0.06138894\n",
      "| Epoch  91 |   550/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.06029588\n",
      "| Epoch  91 |   600/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.06218619\n",
      "| Epoch  91 |   650/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.06030561\n",
      "\n",
      "Val set: Average loss: 0.06148872\n",
      "\n",
      "| Epoch  92 |    50/  658 batches | lr 0.00006 | ms/batch 12.71 | loss 0.06704500\n",
      "| Epoch  92 |   100/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.06302492\n",
      "| Epoch  92 |   150/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.05928978\n",
      "| Epoch  92 |   200/  658 batches | lr 0.00006 | ms/batch 14.53 | loss 0.05889631\n",
      "| Epoch  92 |   250/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.06298565\n",
      "| Epoch  92 |   300/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.06203310\n",
      "| Epoch  92 |   350/  658 batches | lr 0.00006 | ms/batch 12.58 | loss 0.06285385\n",
      "| Epoch  92 |   400/  658 batches | lr 0.00006 | ms/batch 14.02 | loss 0.05996020\n",
      "| Epoch  92 |   450/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.05724666\n",
      "| Epoch  92 |   500/  658 batches | lr 0.00006 | ms/batch 14.24 | loss 0.06124844\n",
      "| Epoch  92 |   550/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.06033278\n",
      "| Epoch  92 |   600/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06216950\n",
      "| Epoch  92 |   650/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.06047660\n",
      "\n",
      "Val set: Average loss: 0.06137800\n",
      "\n",
      "| Epoch  93 |    50/  658 batches | lr 0.00006 | ms/batch 12.70 | loss 0.06715512\n",
      "| Epoch  93 |   100/  658 batches | lr 0.00006 | ms/batch 14.27 | loss 0.06301827\n",
      "| Epoch  93 |   150/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05904542\n",
      "| Epoch  93 |   200/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.05887796\n",
      "| Epoch  93 |   250/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.06299872\n",
      "| Epoch  93 |   300/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.06211761\n",
      "| Epoch  93 |   350/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.06283046\n",
      "| Epoch  93 |   400/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.05991294\n",
      "| Epoch  93 |   450/  658 batches | lr 0.00006 | ms/batch 12.63 | loss 0.05719708\n",
      "| Epoch  93 |   500/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.06116840\n",
      "| Epoch  93 |   550/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.06044807\n",
      "| Epoch  93 |   600/  658 batches | lr 0.00006 | ms/batch 12.42 | loss 0.06206306\n",
      "| Epoch  93 |   650/  658 batches | lr 0.00006 | ms/batch 12.44 | loss 0.06030551\n",
      "\n",
      "Val set: Average loss: 0.06140461\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  94 |    50/  658 batches | lr 0.00006 | ms/batch 12.69 | loss 0.06683090\n",
      "| Epoch  94 |   100/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.06284484\n",
      "| Epoch  94 |   150/  658 batches | lr 0.00006 | ms/batch 12.58 | loss 0.05902597\n",
      "| Epoch  94 |   200/  658 batches | lr 0.00006 | ms/batch 14.51 | loss 0.05890677\n",
      "| Epoch  94 |   250/  658 batches | lr 0.00006 | ms/batch 14.31 | loss 0.06285816\n",
      "| Epoch  94 |   300/  658 batches | lr 0.00006 | ms/batch 12.62 | loss 0.06229844\n",
      "| Epoch  94 |   350/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.06268168\n",
      "| Epoch  94 |   400/  658 batches | lr 0.00006 | ms/batch 14.35 | loss 0.05986223\n",
      "| Epoch  94 |   450/  658 batches | lr 0.00006 | ms/batch 12.63 | loss 0.05711026\n",
      "| Epoch  94 |   500/  658 batches | lr 0.00006 | ms/batch 14.29 | loss 0.06118946\n",
      "| Epoch  94 |   550/  658 batches | lr 0.00006 | ms/batch 14.37 | loss 0.06045230\n",
      "| Epoch  94 |   600/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.06209836\n",
      "| Epoch  94 |   650/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.06026711\n",
      "\n",
      "Val set: Average loss: 0.06129375\n",
      "\n",
      "| Epoch  95 |    50/  658 batches | lr 0.00006 | ms/batch 12.85 | loss 0.06682519\n",
      "| Epoch  95 |   100/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.06285506\n",
      "| Epoch  95 |   150/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.05899625\n",
      "| Epoch  95 |   200/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.05882695\n",
      "| Epoch  95 |   250/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.06286653\n",
      "| Epoch  95 |   300/  658 batches | lr 0.00006 | ms/batch 12.42 | loss 0.06191709\n",
      "| Epoch  95 |   350/  658 batches | lr 0.00006 | ms/batch 12.43 | loss 0.06270380\n",
      "| Epoch  95 |   400/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.05979507\n",
      "| Epoch  95 |   450/  658 batches | lr 0.00006 | ms/batch 12.66 | loss 0.05700864\n",
      "| Epoch  95 |   500/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.06108505\n",
      "| Epoch  95 |   550/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.06002924\n",
      "| Epoch  95 |   600/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06191427\n",
      "| Epoch  95 |   650/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.06021737\n",
      "\n",
      "Val set: Average loss: 0.06126187\n",
      "\n",
      "| Epoch  96 |    50/  658 batches | lr 0.00006 | ms/batch 12.69 | loss 0.06678270\n",
      "| Epoch  96 |   100/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.06280494\n",
      "| Epoch  96 |   150/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.05905672\n",
      "| Epoch  96 |   200/  658 batches | lr 0.00006 | ms/batch 14.30 | loss 0.05875678\n",
      "| Epoch  96 |   250/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.06276436\n",
      "| Epoch  96 |   300/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06206249\n",
      "| Epoch  96 |   350/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.06262226\n",
      "| Epoch  96 |   400/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.05976812\n",
      "| Epoch  96 |   450/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.05700758\n",
      "| Epoch  96 |   500/  658 batches | lr 0.00006 | ms/batch 14.36 | loss 0.06101868\n",
      "| Epoch  96 |   550/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.05996178\n",
      "| Epoch  96 |   600/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.06193644\n",
      "| Epoch  96 |   650/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.05999997\n",
      "\n",
      "Val set: Average loss: 0.06118034\n",
      "\n",
      "| Epoch  97 |    50/  658 batches | lr 0.00006 | ms/batch 12.93 | loss 0.06671528\n",
      "| Epoch  97 |   100/  658 batches | lr 0.00006 | ms/batch 14.39 | loss 0.06266520\n",
      "| Epoch  97 |   150/  658 batches | lr 0.00006 | ms/batch 12.84 | loss 0.05909170\n",
      "| Epoch  97 |   200/  658 batches | lr 0.00006 | ms/batch 14.30 | loss 0.05862959\n",
      "| Epoch  97 |   250/  658 batches | lr 0.00006 | ms/batch 14.37 | loss 0.06263167\n",
      "| Epoch  97 |   300/  658 batches | lr 0.00006 | ms/batch 12.71 | loss 0.06203704\n",
      "| Epoch  97 |   350/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.06254427\n",
      "| Epoch  97 |   400/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.05989552\n",
      "| Epoch  97 |   450/  658 batches | lr 0.00006 | ms/batch 12.58 | loss 0.05695238\n",
      "| Epoch  97 |   500/  658 batches | lr 0.00006 | ms/batch 14.68 | loss 0.06103205\n",
      "| Epoch  97 |   550/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.06021446\n",
      "| Epoch  97 |   600/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.06186403\n",
      "| Epoch  97 |   650/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.05979545\n",
      "\n",
      "Val set: Average loss: 0.06112264\n",
      "\n",
      "| Epoch  98 |    50/  658 batches | lr 0.00006 | ms/batch 12.84 | loss 0.06664934\n",
      "| Epoch  98 |   100/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.06255684\n",
      "| Epoch  98 |   150/  658 batches | lr 0.00006 | ms/batch 12.66 | loss 0.05901172\n",
      "| Epoch  98 |   200/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.05859976\n",
      "| Epoch  98 |   250/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.06253849\n",
      "| Epoch  98 |   300/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.06182204\n",
      "| Epoch  98 |   350/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.06250630\n",
      "| Epoch  98 |   400/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.05966280\n",
      "| Epoch  98 |   450/  658 batches | lr 0.00006 | ms/batch 12.66 | loss 0.05690270\n",
      "| Epoch  98 |   500/  658 batches | lr 0.00006 | ms/batch 14.18 | loss 0.06092430\n",
      "| Epoch  98 |   550/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.05982493\n",
      "| Epoch  98 |   600/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.06182361\n",
      "| Epoch  98 |   650/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.05989635\n",
      "\n",
      "Val set: Average loss: 0.06109882\n",
      "\n",
      "| Epoch  99 |    50/  658 batches | lr 0.00006 | ms/batch 12.76 | loss 0.06662466\n",
      "| Epoch  99 |   100/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.06247734\n",
      "| Epoch  99 |   150/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.05870274\n",
      "| Epoch  99 |   200/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.05860183\n",
      "| Epoch  99 |   250/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.06246623\n",
      "| Epoch  99 |   300/  658 batches | lr 0.00006 | ms/batch 12.43 | loss 0.06166949\n",
      "| Epoch  99 |   350/  658 batches | lr 0.00006 | ms/batch 12.43 | loss 0.06243748\n",
      "| Epoch  99 |   400/  658 batches | lr 0.00006 | ms/batch 14.03 | loss 0.05967544\n",
      "| Epoch  99 |   450/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.05671101\n",
      "| Epoch  99 |   500/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.06087637\n",
      "| Epoch  99 |   550/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.05995089\n",
      "| Epoch  99 |   600/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.06178654\n",
      "| Epoch  99 |   650/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.05987301\n",
      "\n",
      "Val set: Average loss: 0.06108619\n",
      "\n",
      "| Epoch 100 |    50/  658 batches | lr 0.00006 | ms/batch 12.72 | loss 0.06647109\n",
      "| Epoch 100 |   100/  658 batches | lr 0.00006 | ms/batch 14.06 | loss 0.06251030\n",
      "| Epoch 100 |   150/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05894062\n",
      "| Epoch 100 |   200/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.05844816\n",
      "| Epoch 100 |   250/  658 batches | lr 0.00006 | ms/batch 14.24 | loss 0.06247726\n",
      "| Epoch 100 |   300/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.06174863\n",
      "| Epoch 100 |   350/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.06235815\n",
      "| Epoch 100 |   400/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.05953745\n",
      "| Epoch 100 |   450/  658 batches | lr 0.00006 | ms/batch 12.60 | loss 0.05679579\n",
      "| Epoch 100 |   500/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.06090627\n",
      "| Epoch 100 |   550/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.05980284\n",
      "| Epoch 100 |   600/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.06178148\n",
      "| Epoch 100 |   650/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.05986909\n",
      "\n",
      "Val set: Average loss: 0.06102333\n",
      "\n",
      "| Epoch 101 |    50/  658 batches | lr 0.00006 | ms/batch 12.72 | loss 0.06634087\n",
      "| Epoch 101 |   100/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.06242201\n",
      "| Epoch 101 |   150/  658 batches | lr 0.00006 | ms/batch 12.59 | loss 0.05882655\n",
      "| Epoch 101 |   200/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.05841020\n",
      "| Epoch 101 |   250/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.06241238\n",
      "| Epoch 101 |   300/  658 batches | lr 0.00006 | ms/batch 12.43 | loss 0.06171563\n",
      "| Epoch 101 |   350/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.06221617\n",
      "| Epoch 101 |   400/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.05951847\n",
      "| Epoch 101 |   450/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.05656613\n",
      "| Epoch 101 |   500/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.06087953\n",
      "| Epoch 101 |   550/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.05974898\n",
      "| Epoch 101 |   600/  658 batches | lr 0.00006 | ms/batch 12.40 | loss 0.06170210\n",
      "| Epoch 101 |   650/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.05979329\n",
      "\n",
      "Val set: Average loss: 0.06101893\n",
      "\n",
      "| Epoch 102 |    50/  658 batches | lr 0.00006 | ms/batch 12.69 | loss 0.06624550\n",
      "| Epoch 102 |   100/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.06234352\n",
      "| Epoch 102 |   150/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.05883120\n",
      "| Epoch 102 |   200/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.05833001\n",
      "| Epoch 102 |   250/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.06234536\n",
      "| Epoch 102 |   300/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.06166910\n",
      "| Epoch 102 |   350/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.06217765\n",
      "| Epoch 102 |   400/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.05956476\n",
      "| Epoch 102 |   450/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.05659604\n",
      "| Epoch 102 |   500/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.06080649\n",
      "| Epoch 102 |   550/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.05989344\n",
      "| Epoch 102 |   600/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.06172678\n",
      "| Epoch 102 |   650/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.05977972\n",
      "\n",
      "Val set: Average loss: 0.06106364\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 103 |    50/  658 batches | lr 0.00006 | ms/batch 12.72 | loss 0.06624737\n",
      "| Epoch 103 |   100/  658 batches | lr 0.00006 | ms/batch 14.03 | loss 0.06224428\n",
      "| Epoch 103 |   150/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05872498\n",
      "| Epoch 103 |   200/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.05828633\n",
      "| Epoch 103 |   250/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.06221236\n",
      "| Epoch 103 |   300/  658 batches | lr 0.00006 | ms/batch 12.42 | loss 0.06157127\n",
      "| Epoch 103 |   350/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.06216210\n",
      "| Epoch 103 |   400/  658 batches | lr 0.00006 | ms/batch 14.04 | loss 0.05948777\n",
      "| Epoch 103 |   450/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.05647642\n",
      "| Epoch 103 |   500/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.06072306\n",
      "| Epoch 103 |   550/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.05959438\n",
      "| Epoch 103 |   600/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.06154539\n",
      "| Epoch 103 |   650/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.05967887\n",
      "\n",
      "Val set: Average loss: 0.06093639\n",
      "\n",
      "| Epoch 104 |    50/  658 batches | lr 0.00006 | ms/batch 12.71 | loss 0.06603836\n",
      "| Epoch 104 |   100/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.06218391\n",
      "| Epoch 104 |   150/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.05875009\n",
      "| Epoch 104 |   200/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.05827943\n",
      "| Epoch 104 |   250/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.06219216\n",
      "| Epoch 104 |   300/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.06149563\n",
      "| Epoch 104 |   350/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06215698\n",
      "| Epoch 104 |   400/  658 batches | lr 0.00006 | ms/batch 14.02 | loss 0.05947442\n",
      "| Epoch 104 |   450/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.05642673\n",
      "| Epoch 104 |   500/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.06066270\n",
      "| Epoch 104 |   550/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.05957992\n",
      "| Epoch 104 |   600/  658 batches | lr 0.00006 | ms/batch 12.41 | loss 0.06156101\n",
      "| Epoch 104 |   650/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.05961737\n",
      "\n",
      "Val set: Average loss: 0.06093993\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 105 |    50/  658 batches | lr 0.00006 | ms/batch 12.69 | loss 0.06617986\n",
      "| Epoch 105 |   100/  658 batches | lr 0.00006 | ms/batch 14.04 | loss 0.06222793\n",
      "| Epoch 105 |   150/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.05858134\n",
      "| Epoch 105 |   200/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.05823998\n",
      "| Epoch 105 |   250/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.06230493\n",
      "| Epoch 105 |   300/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.06153088\n",
      "| Epoch 105 |   350/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.06198536\n",
      "| Epoch 105 |   400/  658 batches | lr 0.00006 | ms/batch 14.04 | loss 0.05931126\n",
      "| Epoch 105 |   450/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05638628\n",
      "| Epoch 105 |   500/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.06062186\n",
      "| Epoch 105 |   550/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.05940757\n",
      "| Epoch 105 |   600/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.06147267\n",
      "| Epoch 105 |   650/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.05942835\n",
      "\n",
      "Val set: Average loss: 0.06095376\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch 106 |    50/  658 batches | lr 0.00006 | ms/batch 12.79 | loss 0.06607997\n",
      "| Epoch 106 |   100/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.06210661\n",
      "| Epoch 106 |   150/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.05852857\n",
      "| Epoch 106 |   200/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.05817128\n",
      "| Epoch 106 |   250/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.06197858\n",
      "| Epoch 106 |   300/  658 batches | lr 0.00006 | ms/batch 12.72 | loss 0.06113842\n",
      "| Epoch 106 |   350/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.06206678\n",
      "| Epoch 106 |   400/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.05929983\n",
      "| Epoch 106 |   450/  658 batches | lr 0.00006 | ms/batch 12.62 | loss 0.05627139\n",
      "| Epoch 106 |   500/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.06056232\n",
      "| Epoch 106 |   550/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.05949092\n",
      "| Epoch 106 |   600/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.06143928\n",
      "| Epoch 106 |   650/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.05948456\n",
      "\n",
      "Val set: Average loss: 0.06079348\n",
      "\n",
      "| Epoch 107 |    50/  658 batches | lr 0.00006 | ms/batch 12.71 | loss 0.06592367\n",
      "| Epoch 107 |   100/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.06205404\n",
      "| Epoch 107 |   150/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.05836782\n",
      "| Epoch 107 |   200/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.05803988\n",
      "| Epoch 107 |   250/  658 batches | lr 0.00006 | ms/batch 14.24 | loss 0.06195761\n",
      "| Epoch 107 |   300/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.06114069\n",
      "| Epoch 107 |   350/  658 batches | lr 0.00006 | ms/batch 12.44 | loss 0.06206094\n",
      "| Epoch 107 |   400/  658 batches | lr 0.00006 | ms/batch 14.00 | loss 0.05923407\n",
      "| Epoch 107 |   450/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.05623761\n",
      "| Epoch 107 |   500/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.06051848\n",
      "| Epoch 107 |   550/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.05939276\n",
      "| Epoch 107 |   600/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.06135650\n",
      "| Epoch 107 |   650/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.05948816\n",
      "\n",
      "Val set: Average loss: 0.06074504\n",
      "\n",
      "| Epoch 108 |    50/  658 batches | lr 0.00006 | ms/batch 12.69 | loss 0.06612463\n",
      "| Epoch 108 |   100/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.06194834\n",
      "| Epoch 108 |   150/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05839702\n",
      "| Epoch 108 |   200/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.05786553\n",
      "| Epoch 108 |   250/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.06189181\n",
      "| Epoch 108 |   300/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06117524\n",
      "| Epoch 108 |   350/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06199202\n",
      "| Epoch 108 |   400/  658 batches | lr 0.00006 | ms/batch 14.18 | loss 0.05929643\n",
      "| Epoch 108 |   450/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.05620915\n",
      "| Epoch 108 |   500/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.06050349\n",
      "| Epoch 108 |   550/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.05931735\n",
      "| Epoch 108 |   600/  658 batches | lr 0.00006 | ms/batch 12.43 | loss 0.06128005\n",
      "| Epoch 108 |   650/  658 batches | lr 0.00006 | ms/batch 12.41 | loss 0.05944479\n",
      "\n",
      "Val set: Average loss: 0.06062815\n",
      "\n",
      "| Epoch 109 |    50/  658 batches | lr 0.00006 | ms/batch 12.81 | loss 0.06571943\n",
      "| Epoch 109 |   100/  658 batches | lr 0.00006 | ms/batch 14.04 | loss 0.06197171\n",
      "| Epoch 109 |   150/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05846822\n",
      "| Epoch 109 |   200/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.05801256\n",
      "| Epoch 109 |   250/  658 batches | lr 0.00006 | ms/batch 14.21 | loss 0.06191148\n",
      "| Epoch 109 |   300/  658 batches | lr 0.00006 | ms/batch 12.42 | loss 0.06122694\n",
      "| Epoch 109 |   350/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.06189911\n",
      "| Epoch 109 |   400/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.05911642\n",
      "| Epoch 109 |   450/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.05619493\n",
      "| Epoch 109 |   500/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.06051895\n",
      "| Epoch 109 |   550/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.05925477\n",
      "| Epoch 109 |   600/  658 batches | lr 0.00006 | ms/batch 12.73 | loss 0.06129916\n",
      "| Epoch 109 |   650/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.05940874\n",
      "\n",
      "Val set: Average loss: 0.06068322\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 110 |    50/  658 batches | lr 0.00006 | ms/batch 12.69 | loss 0.06563763\n",
      "| Epoch 110 |   100/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.06183607\n",
      "| Epoch 110 |   150/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.05836812\n",
      "| Epoch 110 |   200/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.05786844\n",
      "| Epoch 110 |   250/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.06171350\n",
      "| Epoch 110 |   300/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.06121115\n",
      "| Epoch 110 |   350/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.06182525\n",
      "| Epoch 110 |   400/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.05900069\n",
      "| Epoch 110 |   450/  658 batches | lr 0.00006 | ms/batch 12.63 | loss 0.05614103\n",
      "| Epoch 110 |   500/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.06033082\n",
      "| Epoch 110 |   550/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.05914196\n",
      "| Epoch 110 |   600/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.06128905\n",
      "| Epoch 110 |   650/  658 batches | lr 0.00006 | ms/batch 12.43 | loss 0.05936906\n",
      "\n",
      "Val set: Average loss: 0.06062457\n",
      "\n",
      "| Epoch 111 |    50/  658 batches | lr 0.00006 | ms/batch 12.87 | loss 0.06564418\n",
      "| Epoch 111 |   100/  658 batches | lr 0.00006 | ms/batch 14.05 | loss 0.06178517\n",
      "| Epoch 111 |   150/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.05836860\n",
      "| Epoch 111 |   200/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.05777357\n",
      "| Epoch 111 |   250/  658 batches | lr 0.00006 | ms/batch 14.06 | loss 0.06165246\n",
      "| Epoch 111 |   300/  658 batches | lr 0.00006 | ms/batch 12.39 | loss 0.06107985\n",
      "| Epoch 111 |   350/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.06174271\n",
      "| Epoch 111 |   400/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.05890596\n",
      "| Epoch 111 |   450/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.05607945\n",
      "| Epoch 111 |   500/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.06028632\n",
      "| Epoch 111 |   550/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.05911731\n",
      "| Epoch 111 |   600/  658 batches | lr 0.00006 | ms/batch 12.42 | loss 0.06121165\n",
      "| Epoch 111 |   650/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.05920866\n",
      "\n",
      "Val set: Average loss: 0.06055459\n",
      "\n",
      "| Epoch 112 |    50/  658 batches | lr 0.00006 | ms/batch 12.70 | loss 0.06557308\n",
      "| Epoch 112 |   100/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.06167049\n",
      "| Epoch 112 |   150/  658 batches | lr 0.00006 | ms/batch 12.60 | loss 0.05820768\n",
      "| Epoch 112 |   200/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.05786239\n",
      "| Epoch 112 |   250/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.06162811\n",
      "| Epoch 112 |   300/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.06099641\n",
      "| Epoch 112 |   350/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.06173292\n",
      "| Epoch 112 |   400/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.05897989\n",
      "| Epoch 112 |   450/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.05608987\n",
      "| Epoch 112 |   500/  658 batches | lr 0.00006 | ms/batch 14.28 | loss 0.06037747\n",
      "| Epoch 112 |   550/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.05916455\n",
      "| Epoch 112 |   600/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.06134326\n",
      "| Epoch 112 |   650/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.05917899\n",
      "\n",
      "Val set: Average loss: 0.06060061\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 113 |    50/  658 batches | lr 0.00006 | ms/batch 12.70 | loss 0.06549873\n",
      "| Epoch 113 |   100/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.06174419\n",
      "| Epoch 113 |   150/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.05812667\n",
      "| Epoch 113 |   200/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.05773822\n",
      "| Epoch 113 |   250/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.06159735\n",
      "| Epoch 113 |   300/  658 batches | lr 0.00006 | ms/batch 12.43 | loss 0.06095053\n",
      "| Epoch 113 |   350/  658 batches | lr 0.00006 | ms/batch 12.59 | loss 0.06168880\n",
      "| Epoch 113 |   400/  658 batches | lr 0.00006 | ms/batch 14.03 | loss 0.05890087\n",
      "| Epoch 113 |   450/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.05607113\n",
      "| Epoch 113 |   500/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.06019885\n",
      "| Epoch 113 |   550/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.05888756\n",
      "| Epoch 113 |   600/  658 batches | lr 0.00006 | ms/batch 12.43 | loss 0.06137749\n",
      "| Epoch 113 |   650/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.05915988\n",
      "\n",
      "Val set: Average loss: 0.06050843\n",
      "\n",
      "| Epoch 114 |    50/  658 batches | lr 0.00006 | ms/batch 12.70 | loss 0.06525301\n",
      "| Epoch 114 |   100/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.06165998\n",
      "| Epoch 114 |   150/  658 batches | lr 0.00006 | ms/batch 12.58 | loss 0.05802877\n",
      "| Epoch 114 |   200/  658 batches | lr 0.00006 | ms/batch 14.22 | loss 0.05766760\n",
      "| Epoch 114 |   250/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.06155117\n",
      "| Epoch 114 |   300/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.06090046\n",
      "| Epoch 114 |   350/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.06159349\n",
      "| Epoch 114 |   400/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.05885110\n",
      "| Epoch 114 |   450/  658 batches | lr 0.00006 | ms/batch 12.66 | loss 0.05603189\n",
      "| Epoch 114 |   500/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.06018385\n",
      "| Epoch 114 |   550/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.05896892\n",
      "| Epoch 114 |   600/  658 batches | lr 0.00006 | ms/batch 12.64 | loss 0.06128444\n",
      "| Epoch 114 |   650/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.05911508\n",
      "\n",
      "Val set: Average loss: 0.06049846\n",
      "\n",
      "| Epoch 115 |    50/  658 batches | lr 0.00006 | ms/batch 12.72 | loss 0.06527626\n",
      "| Epoch 115 |   100/  658 batches | lr 0.00006 | ms/batch 14.06 | loss 0.06152908\n",
      "| Epoch 115 |   150/  658 batches | lr 0.00006 | ms/batch 12.66 | loss 0.05792494\n",
      "| Epoch 115 |   200/  658 batches | lr 0.00006 | ms/batch 14.40 | loss 0.05761994\n",
      "| Epoch 115 |   250/  658 batches | lr 0.00006 | ms/batch 14.31 | loss 0.06144596\n",
      "| Epoch 115 |   300/  658 batches | lr 0.00006 | ms/batch 12.43 | loss 0.06088838\n",
      "| Epoch 115 |   350/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06146207\n",
      "| Epoch 115 |   400/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.05890352\n",
      "| Epoch 115 |   450/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.05584409\n",
      "| Epoch 115 |   500/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.06024972\n",
      "| Epoch 115 |   550/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.05894955\n",
      "| Epoch 115 |   600/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06130869\n",
      "| Epoch 115 |   650/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.05918310\n",
      "\n",
      "Val set: Average loss: 0.06040591\n",
      "\n",
      "| Epoch 116 |    50/  658 batches | lr 0.00006 | ms/batch 12.68 | loss 0.06529454\n",
      "| Epoch 116 |   100/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.06150061\n",
      "| Epoch 116 |   150/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05813602\n",
      "| Epoch 116 |   200/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.05754674\n",
      "| Epoch 116 |   250/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.06141938\n",
      "| Epoch 116 |   300/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.06092767\n",
      "| Epoch 116 |   350/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06152077\n",
      "| Epoch 116 |   400/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.05870252\n",
      "| Epoch 116 |   450/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.05591218\n",
      "| Epoch 116 |   500/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.06008882\n",
      "| Epoch 116 |   550/  658 batches | lr 0.00006 | ms/batch 14.24 | loss 0.05889359\n",
      "| Epoch 116 |   600/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06130362\n",
      "| Epoch 116 |   650/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.05912794\n",
      "\n",
      "Val set: Average loss: 0.06038920\n",
      "\n",
      "| Epoch 117 |    50/  658 batches | lr 0.00006 | ms/batch 12.66 | loss 0.06518000\n",
      "| Epoch 117 |   100/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.06142876\n",
      "| Epoch 117 |   150/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.05812383\n",
      "| Epoch 117 |   200/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.05759536\n",
      "| Epoch 117 |   250/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.06140390\n",
      "| Epoch 117 |   300/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06074381\n",
      "| Epoch 117 |   350/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06150912\n",
      "| Epoch 117 |   400/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.05852296\n",
      "| Epoch 117 |   450/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.05579559\n",
      "| Epoch 117 |   500/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.06002740\n",
      "| Epoch 117 |   550/  658 batches | lr 0.00006 | ms/batch 14.18 | loss 0.05903377\n",
      "| Epoch 117 |   600/  658 batches | lr 0.00006 | ms/batch 12.39 | loss 0.06108691\n",
      "| Epoch 117 |   650/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.05903537\n",
      "\n",
      "Val set: Average loss: 0.06036266\n",
      "\n",
      "| Epoch 118 |    50/  658 batches | lr 0.00006 | ms/batch 12.80 | loss 0.06510252\n",
      "| Epoch 118 |   100/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.06139617\n",
      "| Epoch 118 |   150/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.05787245\n",
      "| Epoch 118 |   200/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.05756603\n",
      "| Epoch 118 |   250/  658 batches | lr 0.00006 | ms/batch 14.22 | loss 0.06132990\n",
      "| Epoch 118 |   300/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.06067900\n",
      "| Epoch 118 |   350/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.06140836\n",
      "| Epoch 118 |   400/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.05857050\n",
      "| Epoch 118 |   450/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.05577086\n",
      "| Epoch 118 |   500/  658 batches | lr 0.00006 | ms/batch 14.28 | loss 0.05999498\n",
      "| Epoch 118 |   550/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.05896379\n",
      "| Epoch 118 |   600/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.06117562\n",
      "| Epoch 118 |   650/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.05897525\n",
      "\n",
      "Val set: Average loss: 0.06039047\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 119 |    50/  658 batches | lr 0.00006 | ms/batch 12.78 | loss 0.06489223\n",
      "| Epoch 119 |   100/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.06137016\n",
      "| Epoch 119 |   150/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.05791562\n",
      "| Epoch 119 |   200/  658 batches | lr 0.00006 | ms/batch 14.24 | loss 0.05735254\n",
      "| Epoch 119 |   250/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.06125193\n",
      "| Epoch 119 |   300/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06054214\n",
      "| Epoch 119 |   350/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.06140252\n",
      "| Epoch 119 |   400/  658 batches | lr 0.00006 | ms/batch 14.05 | loss 0.05867228\n",
      "| Epoch 119 |   450/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.05572552\n",
      "| Epoch 119 |   500/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.05992535\n",
      "| Epoch 119 |   550/  658 batches | lr 0.00006 | ms/batch 14.04 | loss 0.05899484\n",
      "| Epoch 119 |   600/  658 batches | lr 0.00006 | ms/batch 12.43 | loss 0.06089853\n",
      "| Epoch 119 |   650/  658 batches | lr 0.00006 | ms/batch 12.42 | loss 0.05885130\n",
      "\n",
      "Val set: Average loss: 0.06034364\n",
      "\n",
      "| Epoch 120 |    50/  658 batches | lr 0.00006 | ms/batch 12.76 | loss 0.06507775\n",
      "| Epoch 120 |   100/  658 batches | lr 0.00006 | ms/batch 14.05 | loss 0.06127700\n",
      "| Epoch 120 |   150/  658 batches | lr 0.00006 | ms/batch 12.70 | loss 0.05794978\n",
      "| Epoch 120 |   200/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.05746682\n",
      "| Epoch 120 |   250/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.06120874\n",
      "| Epoch 120 |   300/  658 batches | lr 0.00006 | ms/batch 12.43 | loss 0.06023909\n",
      "| Epoch 120 |   350/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.06140233\n",
      "| Epoch 120 |   400/  658 batches | lr 0.00006 | ms/batch 14.05 | loss 0.05854073\n",
      "| Epoch 120 |   450/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.05571380\n",
      "| Epoch 120 |   500/  658 batches | lr 0.00006 | ms/batch 14.21 | loss 0.06008678\n",
      "| Epoch 120 |   550/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.05938785\n",
      "| Epoch 120 |   600/  658 batches | lr 0.00006 | ms/batch 12.42 | loss 0.06069285\n",
      "| Epoch 120 |   650/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.05878289\n",
      "\n",
      "Val set: Average loss: 0.06030308\n",
      "\n",
      "| Epoch 121 |    50/  658 batches | lr 0.00006 | ms/batch 12.68 | loss 0.06490760\n",
      "| Epoch 121 |   100/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.06118936\n",
      "| Epoch 121 |   150/  658 batches | lr 0.00006 | ms/batch 12.58 | loss 0.05785751\n",
      "| Epoch 121 |   200/  658 batches | lr 0.00006 | ms/batch 14.48 | loss 0.05742430\n",
      "| Epoch 121 |   250/  658 batches | lr 0.00006 | ms/batch 14.21 | loss 0.06103718\n",
      "| Epoch 121 |   300/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.06068582\n",
      "| Epoch 121 |   350/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.06148155\n",
      "| Epoch 121 |   400/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.05844049\n",
      "| Epoch 121 |   450/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.05558073\n",
      "| Epoch 121 |   500/  658 batches | lr 0.00006 | ms/batch 14.27 | loss 0.05991060\n",
      "| Epoch 121 |   550/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.05897297\n",
      "| Epoch 121 |   600/  658 batches | lr 0.00006 | ms/batch 12.44 | loss 0.06071556\n",
      "| Epoch 121 |   650/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.05883746\n",
      "\n",
      "Val set: Average loss: 0.06037156\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 122 |    50/  658 batches | lr 0.00006 | ms/batch 12.79 | loss 0.06469209\n",
      "| Epoch 122 |   100/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.06120832\n",
      "| Epoch 122 |   150/  658 batches | lr 0.00006 | ms/batch 12.59 | loss 0.05779622\n",
      "| Epoch 122 |   200/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.05743164\n",
      "| Epoch 122 |   250/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.06107699\n",
      "| Epoch 122 |   300/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.06070518\n",
      "| Epoch 122 |   350/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06137297\n",
      "| Epoch 122 |   400/  658 batches | lr 0.00006 | ms/batch 14.01 | loss 0.05853949\n",
      "| Epoch 122 |   450/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.05553945\n",
      "| Epoch 122 |   500/  658 batches | lr 0.00006 | ms/batch 14.18 | loss 0.05968413\n",
      "| Epoch 122 |   550/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.05875073\n",
      "| Epoch 122 |   600/  658 batches | lr 0.00006 | ms/batch 12.67 | loss 0.06098760\n",
      "| Epoch 122 |   650/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.05872380\n",
      "\n",
      "Val set: Average loss: 0.06023694\n",
      "\n",
      "| Epoch 123 |    50/  658 batches | lr 0.00006 | ms/batch 12.66 | loss 0.06454188\n",
      "| Epoch 123 |   100/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.06108196\n",
      "| Epoch 123 |   150/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05770766\n",
      "| Epoch 123 |   200/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.05725942\n",
      "| Epoch 123 |   250/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.06101942\n",
      "| Epoch 123 |   300/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.06040223\n",
      "| Epoch 123 |   350/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06131561\n",
      "| Epoch 123 |   400/  658 batches | lr 0.00006 | ms/batch 14.00 | loss 0.05837234\n",
      "| Epoch 123 |   450/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.05544896\n",
      "| Epoch 123 |   500/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.05965936\n",
      "| Epoch 123 |   550/  658 batches | lr 0.00006 | ms/batch 14.22 | loss 0.05881040\n",
      "| Epoch 123 |   600/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06072495\n",
      "| Epoch 123 |   650/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.05875653\n",
      "\n",
      "Val set: Average loss: 0.06015528\n",
      "\n",
      "| Epoch 124 |    50/  658 batches | lr 0.00006 | ms/batch 12.74 | loss 0.06455359\n",
      "| Epoch 124 |   100/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.06105757\n",
      "| Epoch 124 |   150/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.05766741\n",
      "| Epoch 124 |   200/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.05713409\n",
      "| Epoch 124 |   250/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.06084262\n",
      "| Epoch 124 |   300/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.06048237\n",
      "| Epoch 124 |   350/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.06123139\n",
      "| Epoch 124 |   400/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.05841118\n",
      "| Epoch 124 |   450/  658 batches | lr 0.00006 | ms/batch 12.81 | loss 0.05536608\n",
      "| Epoch 124 |   500/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.05956292\n",
      "| Epoch 124 |   550/  658 batches | lr 0.00006 | ms/batch 14.25 | loss 0.05882254\n",
      "| Epoch 124 |   600/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.06067822\n",
      "| Epoch 124 |   650/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.05865258\n",
      "\n",
      "Val set: Average loss: 0.06011408\n",
      "\n",
      "| Epoch 125 |    50/  658 batches | lr 0.00006 | ms/batch 12.87 | loss 0.06444446\n",
      "| Epoch 125 |   100/  658 batches | lr 0.00006 | ms/batch 14.25 | loss 0.06089947\n",
      "| Epoch 125 |   150/  658 batches | lr 0.00006 | ms/batch 12.58 | loss 0.05761353\n",
      "| Epoch 125 |   200/  658 batches | lr 0.00006 | ms/batch 14.22 | loss 0.05700200\n",
      "| Epoch 125 |   250/  658 batches | lr 0.00006 | ms/batch 14.24 | loss 0.06084317\n",
      "| Epoch 125 |   300/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06048610\n",
      "| Epoch 125 |   350/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.06122567\n",
      "| Epoch 125 |   400/  658 batches | lr 0.00006 | ms/batch 14.26 | loss 0.05826734\n",
      "| Epoch 125 |   450/  658 batches | lr 0.00006 | ms/batch 12.74 | loss 0.05530403\n",
      "| Epoch 125 |   500/  658 batches | lr 0.00006 | ms/batch 14.33 | loss 0.05979906\n",
      "| Epoch 125 |   550/  658 batches | lr 0.00006 | ms/batch 14.29 | loss 0.05908100\n",
      "| Epoch 125 |   600/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.06069522\n",
      "| Epoch 125 |   650/  658 batches | lr 0.00006 | ms/batch 12.59 | loss 0.05853433\n",
      "\n",
      "Val set: Average loss: 0.06012194\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 126 |    50/  658 batches | lr 0.00006 | ms/batch 12.92 | loss 0.06441095\n",
      "| Epoch 126 |   100/  658 batches | lr 0.00006 | ms/batch 14.26 | loss 0.06081635\n",
      "| Epoch 126 |   150/  658 batches | lr 0.00006 | ms/batch 12.70 | loss 0.05757391\n",
      "| Epoch 126 |   200/  658 batches | lr 0.00006 | ms/batch 14.50 | loss 0.05698500\n",
      "| Epoch 126 |   250/  658 batches | lr 0.00006 | ms/batch 14.45 | loss 0.06071987\n",
      "| Epoch 126 |   300/  658 batches | lr 0.00006 | ms/batch 12.58 | loss 0.06043382\n",
      "| Epoch 126 |   350/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.06115670\n",
      "| Epoch 126 |   400/  658 batches | lr 0.00006 | ms/batch 14.28 | loss 0.05822561\n",
      "| Epoch 126 |   450/  658 batches | lr 0.00006 | ms/batch 12.82 | loss 0.05528943\n",
      "| Epoch 126 |   500/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.05963073\n",
      "| Epoch 126 |   550/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.05869223\n",
      "| Epoch 126 |   600/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.06057674\n",
      "| Epoch 126 |   650/  658 batches | lr 0.00006 | ms/batch 12.44 | loss 0.05866241\n",
      "\n",
      "Val set: Average loss: 0.06026905\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch 127 |    50/  658 batches | lr 0.00006 | ms/batch 12.75 | loss 0.06445310\n",
      "| Epoch 127 |   100/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.06094707\n",
      "| Epoch 127 |   150/  658 batches | lr 0.00006 | ms/batch 12.60 | loss 0.05768030\n",
      "| Epoch 127 |   200/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.05715179\n",
      "| Epoch 127 |   250/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.06077837\n",
      "| Epoch 127 |   300/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.06034793\n",
      "| Epoch 127 |   350/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06118303\n",
      "| Epoch 127 |   400/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.05838099\n",
      "| Epoch 127 |   450/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.05517574\n",
      "| Epoch 127 |   500/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.05953323\n",
      "| Epoch 127 |   550/  658 batches | lr 0.00006 | ms/batch 14.26 | loss 0.05882653\n",
      "| Epoch 127 |   600/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.06053192\n",
      "| Epoch 127 |   650/  658 batches | lr 0.00006 | ms/batch 12.59 | loss 0.05864761\n",
      "\n",
      "Val set: Average loss: 0.06024929\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch 128 |    50/  658 batches | lr 0.00006 | ms/batch 12.74 | loss 0.06439270\n",
      "| Epoch 128 |   100/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.06079140\n",
      "| Epoch 128 |   150/  658 batches | lr 0.00006 | ms/batch 12.63 | loss 0.05764151\n",
      "| Epoch 128 |   200/  658 batches | lr 0.00006 | ms/batch 14.25 | loss 0.05699813\n",
      "| Epoch 128 |   250/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.06068787\n",
      "| Epoch 128 |   300/  658 batches | lr 0.00006 | ms/batch 12.43 | loss 0.06022464\n",
      "| Epoch 128 |   350/  658 batches | lr 0.00006 | ms/batch 12.41 | loss 0.06104813\n",
      "| Epoch 128 |   400/  658 batches | lr 0.00006 | ms/batch 14.33 | loss 0.05824956\n",
      "| Epoch 128 |   450/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.05515583\n",
      "| Epoch 128 |   500/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.05949352\n",
      "| Epoch 128 |   550/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.05860690\n",
      "| Epoch 128 |   600/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.06047560\n",
      "| Epoch 128 |   650/  658 batches | lr 0.00006 | ms/batch 12.63 | loss 0.05854998\n",
      "\n",
      "Val set: Average loss: 0.06023295\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch 129 |    50/  658 batches | lr 0.00006 | ms/batch 12.95 | loss 0.06435625\n",
      "| Epoch 129 |   100/  658 batches | lr 0.00006 | ms/batch 14.51 | loss 0.06078063\n",
      "| Epoch 129 |   150/  658 batches | lr 0.00006 | ms/batch 12.74 | loss 0.05750271\n",
      "| Epoch 129 |   200/  658 batches | lr 0.00006 | ms/batch 14.54 | loss 0.05702859\n",
      "| Epoch 129 |   250/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.06073266\n",
      "| Epoch 129 |   300/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.06016806\n",
      "| Epoch 129 |   350/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06098206\n",
      "| Epoch 129 |   400/  658 batches | lr 0.00006 | ms/batch 14.26 | loss 0.05810814\n",
      "| Epoch 129 |   450/  658 batches | lr 0.00006 | ms/batch 12.60 | loss 0.05499265\n",
      "| Epoch 129 |   500/  658 batches | lr 0.00006 | ms/batch 14.31 | loss 0.05935377\n",
      "| Epoch 129 |   550/  658 batches | lr 0.00006 | ms/batch 14.27 | loss 0.05878338\n",
      "| Epoch 129 |   600/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.06065202\n",
      "| Epoch 129 |   650/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.05842323\n",
      "\n",
      "Val set: Average loss: 0.06003944\n",
      "\n",
      "| Epoch 130 |    50/  658 batches | lr 0.00006 | ms/batch 12.82 | loss 0.06430080\n",
      "| Epoch 130 |   100/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.06065086\n",
      "| Epoch 130 |   150/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.05747324\n",
      "| Epoch 130 |   200/  658 batches | lr 0.00006 | ms/batch 14.30 | loss 0.05681035\n",
      "| Epoch 130 |   250/  658 batches | lr 0.00006 | ms/batch 14.26 | loss 0.06061923\n",
      "| Epoch 130 |   300/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.06009389\n",
      "| Epoch 130 |   350/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.06098239\n",
      "| Epoch 130 |   400/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.05801784\n",
      "| Epoch 130 |   450/  658 batches | lr 0.00006 | ms/batch 12.60 | loss 0.05495210\n",
      "| Epoch 130 |   500/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.05937027\n",
      "| Epoch 130 |   550/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.05857312\n",
      "| Epoch 130 |   600/  658 batches | lr 0.00006 | ms/batch 12.60 | loss 0.06043516\n",
      "| Epoch 130 |   650/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.05840514\n",
      "\n",
      "Val set: Average loss: 0.05994254\n",
      "\n",
      "| Epoch 131 |    50/  658 batches | lr 0.00006 | ms/batch 12.69 | loss 0.06418490\n",
      "| Epoch 131 |   100/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.06069873\n",
      "| Epoch 131 |   150/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.05744829\n",
      "| Epoch 131 |   200/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.05688776\n",
      "| Epoch 131 |   250/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.06057996\n",
      "| Epoch 131 |   300/  658 batches | lr 0.00006 | ms/batch 12.67 | loss 0.06007874\n",
      "| Epoch 131 |   350/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.06092414\n",
      "| Epoch 131 |   400/  658 batches | lr 0.00006 | ms/batch 14.00 | loss 0.05807814\n",
      "| Epoch 131 |   450/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.05495755\n",
      "| Epoch 131 |   500/  658 batches | lr 0.00006 | ms/batch 14.22 | loss 0.05923779\n",
      "| Epoch 131 |   550/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.05848030\n",
      "| Epoch 131 |   600/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.06036675\n",
      "| Epoch 131 |   650/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.05831835\n",
      "\n",
      "Val set: Average loss: 0.05999777\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 132 |    50/  658 batches | lr 0.00006 | ms/batch 12.77 | loss 0.06413710\n",
      "| Epoch 132 |   100/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.06068211\n",
      "| Epoch 132 |   150/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.05751248\n",
      "| Epoch 132 |   200/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.05676257\n",
      "| Epoch 132 |   250/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.06052612\n",
      "| Epoch 132 |   300/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05995951\n",
      "| Epoch 132 |   350/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.06087394\n",
      "| Epoch 132 |   400/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.05802124\n",
      "| Epoch 132 |   450/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05489548\n",
      "| Epoch 132 |   500/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.05929141\n",
      "| Epoch 132 |   550/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.05867045\n",
      "| Epoch 132 |   600/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.06036600\n",
      "| Epoch 132 |   650/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.05812283\n",
      "\n",
      "Val set: Average loss: 0.05987366\n",
      "\n",
      "| Epoch 133 |    50/  658 batches | lr 0.00006 | ms/batch 12.70 | loss 0.06413311\n",
      "| Epoch 133 |   100/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.06053947\n",
      "| Epoch 133 |   150/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.05745754\n",
      "| Epoch 133 |   200/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.05667972\n",
      "| Epoch 133 |   250/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.06044550\n",
      "| Epoch 133 |   300/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.06012033\n",
      "| Epoch 133 |   350/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06079326\n",
      "| Epoch 133 |   400/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.05796192\n",
      "| Epoch 133 |   450/  658 batches | lr 0.00006 | ms/batch 12.72 | loss 0.05484368\n",
      "| Epoch 133 |   500/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.05929314\n",
      "| Epoch 133 |   550/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.05860306\n",
      "| Epoch 133 |   600/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.06034070\n",
      "| Epoch 133 |   650/  658 batches | lr 0.00006 | ms/batch 12.42 | loss 0.05815179\n",
      "\n",
      "Val set: Average loss: 0.05987612\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 134 |    50/  658 batches | lr 0.00006 | ms/batch 12.71 | loss 0.06387198\n",
      "| Epoch 134 |   100/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.06050003\n",
      "| Epoch 134 |   150/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.05737867\n",
      "| Epoch 134 |   200/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.05673337\n",
      "| Epoch 134 |   250/  658 batches | lr 0.00006 | ms/batch 14.52 | loss 0.06043900\n",
      "| Epoch 134 |   300/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.05999311\n",
      "| Epoch 134 |   350/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.06079107\n",
      "| Epoch 134 |   400/  658 batches | lr 0.00006 | ms/batch 14.04 | loss 0.05798706\n",
      "| Epoch 134 |   450/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.05482140\n",
      "| Epoch 134 |   500/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.05924305\n",
      "| Epoch 134 |   550/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.05857198\n",
      "| Epoch 134 |   600/  658 batches | lr 0.00006 | ms/batch 12.41 | loss 0.06017010\n",
      "| Epoch 134 |   650/  658 batches | lr 0.00006 | ms/batch 12.44 | loss 0.05803114\n",
      "\n",
      "Val set: Average loss: 0.05980176\n",
      "\n",
      "| Epoch 135 |    50/  658 batches | lr 0.00006 | ms/batch 12.70 | loss 0.06395296\n",
      "| Epoch 135 |   100/  658 batches | lr 0.00006 | ms/batch 14.18 | loss 0.06043960\n",
      "| Epoch 135 |   150/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05734608\n",
      "| Epoch 135 |   200/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.05669032\n",
      "| Epoch 135 |   250/  658 batches | lr 0.00006 | ms/batch 14.24 | loss 0.06039810\n",
      "| Epoch 135 |   300/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.05981693\n",
      "| Epoch 135 |   350/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06076063\n",
      "| Epoch 135 |   400/  658 batches | lr 0.00006 | ms/batch 14.29 | loss 0.05797754\n",
      "| Epoch 135 |   450/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.05472696\n",
      "| Epoch 135 |   500/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.05907642\n",
      "| Epoch 135 |   550/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.05834096\n",
      "| Epoch 135 |   600/  658 batches | lr 0.00006 | ms/batch 12.44 | loss 0.06020886\n",
      "| Epoch 135 |   650/  658 batches | lr 0.00006 | ms/batch 12.44 | loss 0.05797894\n",
      "\n",
      "Val set: Average loss: 0.05975320\n",
      "\n",
      "| Epoch 136 |    50/  658 batches | lr 0.00006 | ms/batch 12.71 | loss 0.06384699\n",
      "| Epoch 136 |   100/  658 batches | lr 0.00006 | ms/batch 14.06 | loss 0.06041663\n",
      "| Epoch 136 |   150/  658 batches | lr 0.00006 | ms/batch 12.62 | loss 0.05735687\n",
      "| Epoch 136 |   200/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.05666410\n",
      "| Epoch 136 |   250/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.06030307\n",
      "| Epoch 136 |   300/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.05977579\n",
      "| Epoch 136 |   350/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.06069858\n",
      "| Epoch 136 |   400/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.05803874\n",
      "| Epoch 136 |   450/  658 batches | lr 0.00006 | ms/batch 12.58 | loss 0.05466514\n",
      "| Epoch 136 |   500/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.05907906\n",
      "| Epoch 136 |   550/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.05839978\n",
      "| Epoch 136 |   600/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.06017792\n",
      "| Epoch 136 |   650/  658 batches | lr 0.00006 | ms/batch 12.44 | loss 0.05788756\n",
      "\n",
      "Val set: Average loss: 0.05959200\n",
      "\n",
      "| Epoch 137 |    50/  658 batches | lr 0.00006 | ms/batch 12.70 | loss 0.06383374\n",
      "| Epoch 137 |   100/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.06038026\n",
      "| Epoch 137 |   150/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.05716979\n",
      "| Epoch 137 |   200/  658 batches | lr 0.00006 | ms/batch 14.33 | loss 0.05649098\n",
      "| Epoch 137 |   250/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.06030298\n",
      "| Epoch 137 |   300/  658 batches | lr 0.00006 | ms/batch 12.42 | loss 0.05974921\n",
      "| Epoch 137 |   350/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.06074257\n",
      "| Epoch 137 |   400/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.05798966\n",
      "| Epoch 137 |   450/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.05465017\n",
      "| Epoch 137 |   500/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.05901596\n",
      "| Epoch 137 |   550/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.05844575\n",
      "| Epoch 137 |   600/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.06027068\n",
      "| Epoch 137 |   650/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.05788840\n",
      "\n",
      "Val set: Average loss: 0.05962152\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 138 |    50/  658 batches | lr 0.00006 | ms/batch 12.83 | loss 0.06372616\n",
      "| Epoch 138 |   100/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.06034026\n",
      "| Epoch 138 |   150/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.05728030\n",
      "| Epoch 138 |   200/  658 batches | lr 0.00006 | ms/batch 14.25 | loss 0.05658070\n",
      "| Epoch 138 |   250/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.06020951\n",
      "| Epoch 138 |   300/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.05974727\n",
      "| Epoch 138 |   350/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.06070321\n",
      "| Epoch 138 |   400/  658 batches | lr 0.00006 | ms/batch 14.06 | loss 0.05784708\n",
      "| Epoch 138 |   450/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.05464231\n",
      "| Epoch 138 |   500/  658 batches | lr 0.00006 | ms/batch 14.21 | loss 0.05914510\n",
      "| Epoch 138 |   550/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.05828154\n",
      "| Epoch 138 |   600/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.06014125\n",
      "| Epoch 138 |   650/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.05784433\n",
      "\n",
      "Val set: Average loss: 0.05964393\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch 139 |    50/  658 batches | lr 0.00006 | ms/batch 12.77 | loss 0.06368962\n",
      "| Epoch 139 |   100/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.06021484\n",
      "| Epoch 139 |   150/  658 batches | lr 0.00006 | ms/batch 12.81 | loss 0.05701386\n",
      "| Epoch 139 |   200/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.05639418\n",
      "| Epoch 139 |   250/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.06018794\n",
      "| Epoch 139 |   300/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.05970671\n",
      "| Epoch 139 |   350/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.06067581\n",
      "| Epoch 139 |   400/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.05790814\n",
      "| Epoch 139 |   450/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.05456532\n",
      "| Epoch 139 |   500/  658 batches | lr 0.00006 | ms/batch 14.18 | loss 0.05900113\n",
      "| Epoch 139 |   550/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.05826640\n",
      "| Epoch 139 |   600/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.06014553\n",
      "| Epoch 139 |   650/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.05772649\n",
      "\n",
      "Val set: Average loss: 0.05965293\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch 140 |    50/  658 batches | lr 0.00006 | ms/batch 12.80 | loss 0.06360027\n",
      "| Epoch 140 |   100/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.06018140\n",
      "| Epoch 140 |   150/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05711855\n",
      "| Epoch 140 |   200/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.05640811\n",
      "| Epoch 140 |   250/  658 batches | lr 0.00006 | ms/batch 14.05 | loss 0.06015178\n",
      "| Epoch 140 |   300/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.05954990\n",
      "| Epoch 140 |   350/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.06063900\n",
      "| Epoch 140 |   400/  658 batches | lr 0.00006 | ms/batch 14.06 | loss 0.05805464\n",
      "| Epoch 140 |   450/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05463813\n",
      "| Epoch 140 |   500/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.05888682\n",
      "| Epoch 140 |   550/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.05818495\n",
      "| Epoch 140 |   600/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.06030749\n",
      "| Epoch 140 |   650/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.05789583\n",
      "\n",
      "Val set: Average loss: 0.05956546\n",
      "\n",
      "| Epoch 141 |    50/  658 batches | lr 0.00006 | ms/batch 12.82 | loss 0.06346722\n",
      "| Epoch 141 |   100/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.06005984\n",
      "| Epoch 141 |   150/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.05706444\n",
      "| Epoch 141 |   200/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.05646621\n",
      "| Epoch 141 |   250/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.06007031\n",
      "| Epoch 141 |   300/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.05965263\n",
      "| Epoch 141 |   350/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.06060099\n",
      "| Epoch 141 |   400/  658 batches | lr 0.00006 | ms/batch 14.24 | loss 0.05801523\n",
      "| Epoch 141 |   450/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.05447867\n",
      "| Epoch 141 |   500/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.05891000\n",
      "| Epoch 141 |   550/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.05831339\n",
      "| Epoch 141 |   600/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.06001715\n",
      "| Epoch 141 |   650/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.05782547\n",
      "\n",
      "Val set: Average loss: 0.05967163\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 142 |    50/  658 batches | lr 0.00006 | ms/batch 12.75 | loss 0.06344340\n",
      "| Epoch 142 |   100/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.06006802\n",
      "| Epoch 142 |   150/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05702969\n",
      "| Epoch 142 |   200/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.05627791\n",
      "| Epoch 142 |   250/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.06005695\n",
      "| Epoch 142 |   300/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.05951660\n",
      "| Epoch 142 |   350/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06054952\n",
      "| Epoch 142 |   400/  658 batches | lr 0.00006 | ms/batch 14.27 | loss 0.05764822\n",
      "| Epoch 142 |   450/  658 batches | lr 0.00006 | ms/batch 12.60 | loss 0.05434034\n",
      "| Epoch 142 |   500/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.05878642\n",
      "| Epoch 142 |   550/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.05832177\n",
      "| Epoch 142 |   600/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.06005992\n",
      "| Epoch 142 |   650/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.05784432\n",
      "\n",
      "Val set: Average loss: 0.05974485\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch 143 |    50/  658 batches | lr 0.00006 | ms/batch 12.70 | loss 0.06341856\n",
      "| Epoch 143 |   100/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.06010449\n",
      "| Epoch 143 |   150/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.05700418\n",
      "| Epoch 143 |   200/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.05613104\n",
      "| Epoch 143 |   250/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.05995237\n",
      "| Epoch 143 |   300/  658 batches | lr 0.00006 | ms/batch 12.43 | loss 0.05956537\n",
      "| Epoch 143 |   350/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06054083\n",
      "| Epoch 143 |   400/  658 batches | lr 0.00006 | ms/batch 14.05 | loss 0.05785415\n",
      "| Epoch 143 |   450/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.05431806\n",
      "| Epoch 143 |   500/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.05893494\n",
      "| Epoch 143 |   550/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.05831810\n",
      "| Epoch 143 |   600/  658 batches | lr 0.00006 | ms/batch 12.44 | loss 0.05981939\n",
      "| Epoch 143 |   650/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.05753159\n",
      "\n",
      "Val set: Average loss: 0.05957025\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch 144 |    50/  658 batches | lr 0.00006 | ms/batch 12.69 | loss 0.06337955\n",
      "| Epoch 144 |   100/  658 batches | lr 0.00006 | ms/batch 14.21 | loss 0.05987603\n",
      "| Epoch 144 |   150/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.05680687\n",
      "| Epoch 144 |   200/  658 batches | lr 0.00006 | ms/batch 14.22 | loss 0.05610490\n",
      "| Epoch 144 |   250/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.05995536\n",
      "| Epoch 144 |   300/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.05949529\n",
      "| Epoch 144 |   350/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.06042879\n",
      "| Epoch 144 |   400/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.05794086\n",
      "| Epoch 144 |   450/  658 batches | lr 0.00006 | ms/batch 12.59 | loss 0.05424839\n",
      "| Epoch 144 |   500/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.05880682\n",
      "| Epoch 144 |   550/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.05802091\n",
      "| Epoch 144 |   600/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.05978091\n",
      "| Epoch 144 |   650/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.05758074\n",
      "\n",
      "Val set: Average loss: 0.05946549\n",
      "\n",
      "| Epoch 145 |    50/  658 batches | lr 0.00006 | ms/batch 12.69 | loss 0.06322986\n",
      "| Epoch 145 |   100/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.05992234\n",
      "| Epoch 145 |   150/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.05697747\n",
      "| Epoch 145 |   200/  658 batches | lr 0.00006 | ms/batch 14.18 | loss 0.05606002\n",
      "| Epoch 145 |   250/  658 batches | lr 0.00006 | ms/batch 14.27 | loss 0.05989048\n",
      "| Epoch 145 |   300/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.05940859\n",
      "| Epoch 145 |   350/  658 batches | lr 0.00006 | ms/batch 12.41 | loss 0.06044287\n",
      "| Epoch 145 |   400/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.05778886\n",
      "| Epoch 145 |   450/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.05424760\n",
      "| Epoch 145 |   500/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.05883964\n",
      "| Epoch 145 |   550/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.05814433\n",
      "| Epoch 145 |   600/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.05984540\n",
      "| Epoch 145 |   650/  658 batches | lr 0.00006 | ms/batch 12.58 | loss 0.05747940\n",
      "\n",
      "Val set: Average loss: 0.05940040\n",
      "\n",
      "| Epoch 146 |    50/  658 batches | lr 0.00006 | ms/batch 12.82 | loss 0.06322302\n",
      "| Epoch 146 |   100/  658 batches | lr 0.00006 | ms/batch 14.05 | loss 0.05983500\n",
      "| Epoch 146 |   150/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.05681663\n",
      "| Epoch 146 |   200/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.05608680\n",
      "| Epoch 146 |   250/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.05982669\n",
      "| Epoch 146 |   300/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.05956212\n",
      "| Epoch 146 |   350/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.06039890\n",
      "| Epoch 146 |   400/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.05763837\n",
      "| Epoch 146 |   450/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.05422864\n",
      "| Epoch 146 |   500/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.05868419\n",
      "| Epoch 146 |   550/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.05802587\n",
      "| Epoch 146 |   600/  658 batches | lr 0.00006 | ms/batch 12.42 | loss 0.05991290\n",
      "| Epoch 146 |   650/  658 batches | lr 0.00006 | ms/batch 12.44 | loss 0.05749343\n",
      "\n",
      "Val set: Average loss: 0.05942213\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 147 |    50/  658 batches | lr 0.00006 | ms/batch 12.85 | loss 0.06317519\n",
      "| Epoch 147 |   100/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.05976781\n",
      "| Epoch 147 |   150/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05671322\n",
      "| Epoch 147 |   200/  658 batches | lr 0.00006 | ms/batch 14.18 | loss 0.05599695\n",
      "| Epoch 147 |   250/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.05978631\n",
      "| Epoch 147 |   300/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.05943144\n",
      "| Epoch 147 |   350/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06039999\n",
      "| Epoch 147 |   400/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.05769433\n",
      "| Epoch 147 |   450/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.05422685\n",
      "| Epoch 147 |   500/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.05855297\n",
      "| Epoch 147 |   550/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.05796295\n",
      "| Epoch 147 |   600/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.05980139\n",
      "| Epoch 147 |   650/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.05737227\n",
      "\n",
      "Val set: Average loss: 0.05945320\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch 148 |    50/  658 batches | lr 0.00006 | ms/batch 12.72 | loss 0.06307622\n",
      "| Epoch 148 |   100/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.05967838\n",
      "| Epoch 148 |   150/  658 batches | lr 0.00006 | ms/batch 12.60 | loss 0.05659774\n",
      "| Epoch 148 |   200/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.05587639\n",
      "| Epoch 148 |   250/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.05969161\n",
      "| Epoch 148 |   300/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.05931661\n",
      "| Epoch 148 |   350/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.06038053\n",
      "| Epoch 148 |   400/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.05763672\n",
      "| Epoch 148 |   450/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05413054\n",
      "| Epoch 148 |   500/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.05865138\n",
      "| Epoch 148 |   550/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.05798156\n",
      "| Epoch 148 |   600/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.05987513\n",
      "| Epoch 148 |   650/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05729365\n",
      "\n",
      "Val set: Average loss: 0.05936806\n",
      "\n",
      "| Epoch 149 |    50/  658 batches | lr 0.00006 | ms/batch 12.79 | loss 0.06301157\n",
      "| Epoch 149 |   100/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.05976119\n",
      "| Epoch 149 |   150/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.05673676\n",
      "| Epoch 149 |   200/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.05595709\n",
      "| Epoch 149 |   250/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.05966814\n",
      "| Epoch 149 |   300/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.05925601\n",
      "| Epoch 149 |   350/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.06031236\n",
      "| Epoch 149 |   400/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.05783664\n",
      "| Epoch 149 |   450/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05421788\n",
      "| Epoch 149 |   500/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.05861255\n",
      "| Epoch 149 |   550/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.05792903\n",
      "| Epoch 149 |   600/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.05980839\n",
      "| Epoch 149 |   650/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.05719369\n",
      "\n",
      "Val set: Average loss: 0.05929787\n",
      "\n",
      "| Epoch 150 |    50/  658 batches | lr 0.00006 | ms/batch 12.69 | loss 0.06307581\n",
      "| Epoch 150 |   100/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.05960715\n",
      "| Epoch 150 |   150/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05668452\n",
      "| Epoch 150 |   200/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.05587675\n",
      "| Epoch 150 |   250/  658 batches | lr 0.00006 | ms/batch 14.18 | loss 0.05965644\n",
      "| Epoch 150 |   300/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.05920195\n",
      "| Epoch 150 |   350/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.06027725\n",
      "| Epoch 150 |   400/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.05778520\n",
      "| Epoch 150 |   450/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.05407924\n",
      "| Epoch 150 |   500/  658 batches | lr 0.00006 | ms/batch 14.18 | loss 0.05855328\n",
      "| Epoch 150 |   550/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.05782956\n",
      "| Epoch 150 |   600/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.05984426\n",
      "| Epoch 150 |   650/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.05721201\n",
      "\n",
      "Val set: Average loss: 0.05931728\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 151 |    50/  658 batches | lr 0.00006 | ms/batch 12.81 | loss 0.06298464\n",
      "| Epoch 151 |   100/  658 batches | lr 0.00006 | ms/batch 14.06 | loss 0.05956047\n",
      "| Epoch 151 |   150/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.05659130\n",
      "| Epoch 151 |   200/  658 batches | lr 0.00006 | ms/batch 14.27 | loss 0.05589073\n",
      "| Epoch 151 |   250/  658 batches | lr 0.00006 | ms/batch 14.25 | loss 0.05955898\n",
      "| Epoch 151 |   300/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.05923653\n",
      "| Epoch 151 |   350/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06032183\n",
      "| Epoch 151 |   400/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.05763686\n",
      "| Epoch 151 |   450/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.05409142\n",
      "| Epoch 151 |   500/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.05858420\n",
      "| Epoch 151 |   550/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.05776854\n",
      "| Epoch 151 |   600/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.05982737\n",
      "| Epoch 151 |   650/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.05722926\n",
      "\n",
      "Val set: Average loss: 0.05933344\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch 152 |    50/  658 batches | lr 0.00006 | ms/batch 12.74 | loss 0.06301563\n",
      "| Epoch 152 |   100/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.05951612\n",
      "| Epoch 152 |   150/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.05644713\n",
      "| Epoch 152 |   200/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.05579475\n",
      "| Epoch 152 |   250/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.05957404\n",
      "| Epoch 152 |   300/  658 batches | lr 0.00006 | ms/batch 12.41 | loss 0.05918606\n",
      "| Epoch 152 |   350/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.06025028\n",
      "| Epoch 152 |   400/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.05756212\n",
      "| Epoch 152 |   450/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.05399664\n",
      "| Epoch 152 |   500/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.05851091\n",
      "| Epoch 152 |   550/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.05768466\n",
      "| Epoch 152 |   600/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.05976285\n",
      "| Epoch 152 |   650/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.05702759\n",
      "\n",
      "Val set: Average loss: 0.05919297\n",
      "\n",
      "| Epoch 153 |    50/  658 batches | lr 0.00006 | ms/batch 12.77 | loss 0.06286681\n",
      "| Epoch 153 |   100/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.05957531\n",
      "| Epoch 153 |   150/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.05640800\n",
      "| Epoch 153 |   200/  658 batches | lr 0.00006 | ms/batch 14.25 | loss 0.05570515\n",
      "| Epoch 153 |   250/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.05951074\n",
      "| Epoch 153 |   300/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.05914127\n",
      "| Epoch 153 |   350/  658 batches | lr 0.00006 | ms/batch 12.43 | loss 0.06016160\n",
      "| Epoch 153 |   400/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.05759181\n",
      "| Epoch 153 |   450/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.05401610\n",
      "| Epoch 153 |   500/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.05848839\n",
      "| Epoch 153 |   550/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.05758881\n",
      "| Epoch 153 |   600/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.05985100\n",
      "| Epoch 153 |   650/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.05711158\n",
      "\n",
      "Val set: Average loss: 0.05911831\n",
      "\n",
      "| Epoch 154 |    50/  658 batches | lr 0.00006 | ms/batch 12.72 | loss 0.06300862\n",
      "| Epoch 154 |   100/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.05939988\n",
      "| Epoch 154 |   150/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.05633503\n",
      "| Epoch 154 |   200/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.05581724\n",
      "| Epoch 154 |   250/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.05950057\n",
      "| Epoch 154 |   300/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.05914419\n",
      "| Epoch 154 |   350/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.06020074\n",
      "| Epoch 154 |   400/  658 batches | lr 0.00006 | ms/batch 14.05 | loss 0.05754106\n",
      "| Epoch 154 |   450/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.05397220\n",
      "| Epoch 154 |   500/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.05850939\n",
      "| Epoch 154 |   550/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.05770332\n",
      "| Epoch 154 |   600/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.05976731\n",
      "| Epoch 154 |   650/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05701178\n",
      "\n",
      "Val set: Average loss: 0.05912419\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 155 |    50/  658 batches | lr 0.00006 | ms/batch 12.73 | loss 0.06286927\n",
      "| Epoch 155 |   100/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.05936009\n",
      "| Epoch 155 |   150/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.05638246\n",
      "| Epoch 155 |   200/  658 batches | lr 0.00006 | ms/batch 14.21 | loss 0.05579878\n",
      "| Epoch 155 |   250/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.05942238\n",
      "| Epoch 155 |   300/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.05909499\n",
      "| Epoch 155 |   350/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.06014717\n",
      "| Epoch 155 |   400/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.05754447\n",
      "| Epoch 155 |   450/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.05386935\n",
      "| Epoch 155 |   500/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.05838641\n",
      "| Epoch 155 |   550/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.05740904\n",
      "| Epoch 155 |   600/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.05972035\n",
      "| Epoch 155 |   650/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.05699858\n",
      "\n",
      "Val set: Average loss: 0.05913204\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch 156 |    50/  658 batches | lr 0.00006 | ms/batch 12.76 | loss 0.06280977\n",
      "| Epoch 156 |   100/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.05933934\n",
      "| Epoch 156 |   150/  658 batches | lr 0.00006 | ms/batch 12.60 | loss 0.05620178\n",
      "| Epoch 156 |   200/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.05572321\n",
      "| Epoch 156 |   250/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.05934306\n",
      "| Epoch 156 |   300/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.05905882\n",
      "| Epoch 156 |   350/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.06015099\n",
      "| Epoch 156 |   400/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.05742620\n",
      "| Epoch 156 |   450/  658 batches | lr 0.00006 | ms/batch 12.64 | loss 0.05386955\n",
      "| Epoch 156 |   500/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.05835501\n",
      "| Epoch 156 |   550/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.05754533\n",
      "| Epoch 156 |   600/  658 batches | lr 0.00006 | ms/batch 12.43 | loss 0.05968575\n",
      "| Epoch 156 |   650/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.05703429\n",
      "\n",
      "Val set: Average loss: 0.05919076\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch 157 |    50/  658 batches | lr 0.00006 | ms/batch 12.67 | loss 0.06256536\n",
      "| Epoch 157 |   100/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.05926973\n",
      "| Epoch 157 |   150/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.05618859\n",
      "| Epoch 157 |   200/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.05543868\n",
      "| Epoch 157 |   250/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.05933367\n",
      "| Epoch 157 |   300/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.05888548\n",
      "| Epoch 157 |   350/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.06005935\n",
      "| Epoch 157 |   400/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.05743426\n",
      "| Epoch 157 |   450/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.05387989\n",
      "| Epoch 157 |   500/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.05826880\n",
      "| Epoch 157 |   550/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.05744791\n",
      "| Epoch 157 |   600/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.05966671\n",
      "| Epoch 157 |   650/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.05684889\n",
      "\n",
      "Val set: Average loss: 0.05915525\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch 158 |    50/  658 batches | lr 0.00006 | ms/batch 12.69 | loss 0.06277670\n",
      "| Epoch 158 |   100/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.05932044\n",
      "| Epoch 158 |   150/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.05620429\n",
      "| Epoch 158 |   200/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.05562268\n",
      "| Epoch 158 |   250/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.05932283\n",
      "| Epoch 158 |   300/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.05904325\n",
      "| Epoch 158 |   350/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.06006650\n",
      "| Epoch 158 |   400/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.05740670\n",
      "| Epoch 158 |   450/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.05381571\n",
      "| Epoch 158 |   500/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.05826745\n",
      "| Epoch 158 |   550/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.05725541\n",
      "| Epoch 158 |   600/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.05949077\n",
      "| Epoch 158 |   650/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.05694010\n",
      "\n",
      "Val set: Average loss: 0.05897081\n",
      "\n",
      "| Epoch 159 |    50/  658 batches | lr 0.00006 | ms/batch 12.83 | loss 0.06253443\n",
      "| Epoch 159 |   100/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.05920372\n",
      "| Epoch 159 |   150/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.05607136\n",
      "| Epoch 159 |   200/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.05537676\n",
      "| Epoch 159 |   250/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.05921919\n",
      "| Epoch 159 |   300/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05898634\n",
      "| Epoch 159 |   350/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.05998974\n",
      "| Epoch 159 |   400/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.05738055\n",
      "| Epoch 159 |   450/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.05383002\n",
      "| Epoch 159 |   500/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.05827134\n",
      "| Epoch 159 |   550/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.05740446\n",
      "| Epoch 159 |   600/  658 batches | lr 0.00006 | ms/batch 12.44 | loss 0.05937497\n",
      "| Epoch 159 |   650/  658 batches | lr 0.00006 | ms/batch 12.44 | loss 0.05680958\n",
      "\n",
      "Val set: Average loss: 0.05909040\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 160 |    50/  658 batches | lr 0.00006 | ms/batch 12.71 | loss 0.06256479\n",
      "| Epoch 160 |   100/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.05917149\n",
      "| Epoch 160 |   150/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.05619873\n",
      "| Epoch 160 |   200/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.05559081\n",
      "| Epoch 160 |   250/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.05921017\n",
      "| Epoch 160 |   300/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.05890892\n",
      "| Epoch 160 |   350/  658 batches | lr 0.00006 | ms/batch 12.43 | loss 0.05990800\n",
      "| Epoch 160 |   400/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.05731297\n",
      "| Epoch 160 |   450/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.05380016\n",
      "| Epoch 160 |   500/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.05815457\n",
      "| Epoch 160 |   550/  658 batches | lr 0.00006 | ms/batch 14.47 | loss 0.05729857\n",
      "| Epoch 160 |   600/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.05947721\n",
      "| Epoch 160 |   650/  658 batches | lr 0.00006 | ms/batch 12.59 | loss 0.05678390\n",
      "\n",
      "Val set: Average loss: 0.05897200\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch 161 |    50/  658 batches | lr 0.00006 | ms/batch 12.91 | loss 0.06254428\n",
      "| Epoch 161 |   100/  658 batches | lr 0.00006 | ms/batch 14.39 | loss 0.05914656\n",
      "| Epoch 161 |   150/  658 batches | lr 0.00006 | ms/batch 12.74 | loss 0.05607141\n",
      "| Epoch 161 |   200/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.05551111\n",
      "| Epoch 161 |   250/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.05912463\n",
      "| Epoch 161 |   300/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.05894233\n",
      "| Epoch 161 |   350/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.05995893\n",
      "| Epoch 161 |   400/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.05738299\n",
      "| Epoch 161 |   450/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.05379689\n",
      "| Epoch 161 |   500/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.05814053\n",
      "| Epoch 161 |   550/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.05721810\n",
      "| Epoch 161 |   600/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.05928748\n",
      "| Epoch 161 |   650/  658 batches | lr 0.00006 | ms/batch 12.60 | loss 0.05670643\n",
      "\n",
      "Val set: Average loss: 0.05900217\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch 162 |    50/  658 batches | lr 0.00006 | ms/batch 12.72 | loss 0.06249130\n",
      "| Epoch 162 |   100/  658 batches | lr 0.00006 | ms/batch 14.00 | loss 0.05898303\n",
      "| Epoch 162 |   150/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.05604505\n",
      "| Epoch 162 |   200/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.05531745\n",
      "| Epoch 162 |   250/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.05906155\n",
      "| Epoch 162 |   300/  658 batches | lr 0.00006 | ms/batch 12.43 | loss 0.05891574\n",
      "| Epoch 162 |   350/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.05991764\n",
      "| Epoch 162 |   400/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.05728841\n",
      "| Epoch 162 |   450/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05374308\n",
      "| Epoch 162 |   500/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.05812704\n",
      "| Epoch 162 |   550/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.05709002\n",
      "| Epoch 162 |   600/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.05933050\n",
      "| Epoch 162 |   650/  658 batches | lr 0.00006 | ms/batch 12.40 | loss 0.05672786\n",
      "\n",
      "Val set: Average loss: 0.05896046\n",
      "\n",
      "| Epoch 163 |    50/  658 batches | lr 0.00006 | ms/batch 12.82 | loss 0.06247873\n",
      "| Epoch 163 |   100/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.05898859\n",
      "| Epoch 163 |   150/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.05596761\n",
      "| Epoch 163 |   200/  658 batches | lr 0.00006 | ms/batch 14.22 | loss 0.05552511\n",
      "| Epoch 163 |   250/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.05902299\n",
      "| Epoch 163 |   300/  658 batches | lr 0.00006 | ms/batch 12.40 | loss 0.05888159\n",
      "| Epoch 163 |   350/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.05990785\n",
      "| Epoch 163 |   400/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.05738387\n",
      "| Epoch 163 |   450/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.05371294\n",
      "| Epoch 163 |   500/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.05805009\n",
      "| Epoch 163 |   550/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.05700463\n",
      "| Epoch 163 |   600/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05926565\n",
      "| Epoch 163 |   650/  658 batches | lr 0.00006 | ms/batch 12.44 | loss 0.05662433\n",
      "\n",
      "Val set: Average loss: 0.05900452\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 164 |    50/  658 batches | lr 0.00006 | ms/batch 12.70 | loss 0.06246786\n",
      "| Epoch 164 |   100/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.05892907\n",
      "| Epoch 164 |   150/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.05597993\n",
      "| Epoch 164 |   200/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.05517166\n",
      "| Epoch 164 |   250/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.05900835\n",
      "| Epoch 164 |   300/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.05895492\n",
      "| Epoch 164 |   350/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.05994493\n",
      "| Epoch 164 |   400/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.05727762\n",
      "| Epoch 164 |   450/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.05378851\n",
      "| Epoch 164 |   500/  658 batches | lr 0.00006 | ms/batch 14.18 | loss 0.05806630\n",
      "| Epoch 164 |   550/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.05695358\n",
      "| Epoch 164 |   600/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.05931939\n",
      "| Epoch 164 |   650/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.05661243\n",
      "\n",
      "Val set: Average loss: 0.05894347\n",
      "\n",
      "| Epoch 165 |    50/  658 batches | lr 0.00006 | ms/batch 12.76 | loss 0.06239635\n",
      "| Epoch 165 |   100/  658 batches | lr 0.00006 | ms/batch 14.33 | loss 0.05884400\n",
      "| Epoch 165 |   150/  658 batches | lr 0.00006 | ms/batch 12.59 | loss 0.05588088\n",
      "| Epoch 165 |   200/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.05540224\n",
      "| Epoch 165 |   250/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.05894793\n",
      "| Epoch 165 |   300/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.05883946\n",
      "| Epoch 165 |   350/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.05981367\n",
      "| Epoch 165 |   400/  658 batches | lr 0.00006 | ms/batch 14.05 | loss 0.05725735\n",
      "| Epoch 165 |   450/  658 batches | lr 0.00006 | ms/batch 12.73 | loss 0.05364324\n",
      "| Epoch 165 |   500/  658 batches | lr 0.00006 | ms/batch 14.21 | loss 0.05798937\n",
      "| Epoch 165 |   550/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.05687915\n",
      "| Epoch 165 |   600/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.05917854\n",
      "| Epoch 165 |   650/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.05661323\n",
      "\n",
      "Val set: Average loss: 0.05893410\n",
      "\n",
      "| Epoch 166 |    50/  658 batches | lr 0.00006 | ms/batch 12.68 | loss 0.06252617\n",
      "| Epoch 166 |   100/  658 batches | lr 0.00006 | ms/batch 14.05 | loss 0.05885129\n",
      "| Epoch 166 |   150/  658 batches | lr 0.00006 | ms/batch 12.68 | loss 0.05582505\n",
      "| Epoch 166 |   200/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.05520325\n",
      "| Epoch 166 |   250/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.05900656\n",
      "| Epoch 166 |   300/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.05881304\n",
      "| Epoch 166 |   350/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.05989417\n",
      "| Epoch 166 |   400/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.05730792\n",
      "| Epoch 166 |   450/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05361135\n",
      "| Epoch 166 |   500/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.05793619\n",
      "| Epoch 166 |   550/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.05691593\n",
      "| Epoch 166 |   600/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.05924635\n",
      "| Epoch 166 |   650/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.05651435\n",
      "\n",
      "Val set: Average loss: 0.05889119\n",
      "\n",
      "| Epoch 167 |    50/  658 batches | lr 0.00006 | ms/batch 12.73 | loss 0.06229827\n",
      "| Epoch 167 |   100/  658 batches | lr 0.00006 | ms/batch 14.35 | loss 0.05874678\n",
      "| Epoch 167 |   150/  658 batches | lr 0.00006 | ms/batch 12.45 | loss 0.05578990\n",
      "| Epoch 167 |   200/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.05519460\n",
      "| Epoch 167 |   250/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.05899755\n",
      "| Epoch 167 |   300/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.05885734\n",
      "| Epoch 167 |   350/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.05979867\n",
      "| Epoch 167 |   400/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.05707418\n",
      "| Epoch 167 |   450/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.05356131\n",
      "| Epoch 167 |   500/  658 batches | lr 0.00006 | ms/batch 14.21 | loss 0.05797415\n",
      "| Epoch 167 |   550/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.05680365\n",
      "| Epoch 167 |   600/  658 batches | lr 0.00006 | ms/batch 12.41 | loss 0.05917372\n",
      "| Epoch 167 |   650/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.05644411\n",
      "\n",
      "Val set: Average loss: 0.05880003\n",
      "\n",
      "| Epoch 168 |    50/  658 batches | lr 0.00006 | ms/batch 12.69 | loss 0.06227833\n",
      "| Epoch 168 |   100/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.05872482\n",
      "| Epoch 168 |   150/  658 batches | lr 0.00006 | ms/batch 12.58 | loss 0.05569155\n",
      "| Epoch 168 |   200/  658 batches | lr 0.00006 | ms/batch 14.18 | loss 0.05536649\n",
      "| Epoch 168 |   250/  658 batches | lr 0.00006 | ms/batch 14.39 | loss 0.05883601\n",
      "| Epoch 168 |   300/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.05889134\n",
      "| Epoch 168 |   350/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.05990075\n",
      "| Epoch 168 |   400/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.05706096\n",
      "| Epoch 168 |   450/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.05354740\n",
      "| Epoch 168 |   500/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.05792385\n",
      "| Epoch 168 |   550/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.05682239\n",
      "| Epoch 168 |   600/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.05922054\n",
      "| Epoch 168 |   650/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.05646892\n",
      "\n",
      "Val set: Average loss: 0.05885349\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 169 |    50/  658 batches | lr 0.00006 | ms/batch 12.77 | loss 0.06216063\n",
      "| Epoch 169 |   100/  658 batches | lr 0.00006 | ms/batch 14.06 | loss 0.05877798\n",
      "| Epoch 169 |   150/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.05568468\n",
      "| Epoch 169 |   200/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.05510639\n",
      "| Epoch 169 |   250/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.05882366\n",
      "| Epoch 169 |   300/  658 batches | lr 0.00006 | ms/batch 12.44 | loss 0.05883895\n",
      "| Epoch 169 |   350/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.05976210\n",
      "| Epoch 169 |   400/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.05696706\n",
      "| Epoch 169 |   450/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05339690\n",
      "| Epoch 169 |   500/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.05790661\n",
      "| Epoch 169 |   550/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.05680804\n",
      "| Epoch 169 |   600/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.05900669\n",
      "| Epoch 169 |   650/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.05628600\n",
      "\n",
      "Val set: Average loss: 0.05883575\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch 170 |    50/  658 batches | lr 0.00006 | ms/batch 12.81 | loss 0.06214752\n",
      "| Epoch 170 |   100/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.05874820\n",
      "| Epoch 170 |   150/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.05566369\n",
      "| Epoch 170 |   200/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.05512996\n",
      "| Epoch 170 |   250/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.05876184\n",
      "| Epoch 170 |   300/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.05874721\n",
      "| Epoch 170 |   350/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.05973944\n",
      "| Epoch 170 |   400/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.05696831\n",
      "| Epoch 170 |   450/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.05347373\n",
      "| Epoch 170 |   500/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.05787042\n",
      "| Epoch 170 |   550/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.05660358\n",
      "| Epoch 170 |   600/  658 batches | lr 0.00006 | ms/batch 12.44 | loss 0.05914721\n",
      "| Epoch 170 |   650/  658 batches | lr 0.00006 | ms/batch 12.44 | loss 0.05636316\n",
      "\n",
      "Val set: Average loss: 0.05879409\n",
      "\n",
      "| Epoch 171 |    50/  658 batches | lr 0.00006 | ms/batch 12.79 | loss 0.06216863\n",
      "| Epoch 171 |   100/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.05862816\n",
      "| Epoch 171 |   150/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.05564132\n",
      "| Epoch 171 |   200/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.05508018\n",
      "| Epoch 171 |   250/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.05880737\n",
      "| Epoch 171 |   300/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.05881442\n",
      "| Epoch 171 |   350/  658 batches | lr 0.00006 | ms/batch 12.50 | loss 0.05981425\n",
      "| Epoch 171 |   400/  658 batches | lr 0.00006 | ms/batch 14.18 | loss 0.05694892\n",
      "| Epoch 171 |   450/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.05339918\n",
      "| Epoch 171 |   500/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.05778572\n",
      "| Epoch 171 |   550/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.05662751\n",
      "| Epoch 171 |   600/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.05909615\n",
      "| Epoch 171 |   650/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.05630730\n",
      "\n",
      "Val set: Average loss: 0.05874218\n",
      "\n",
      "| Epoch 172 |    50/  658 batches | lr 0.00006 | ms/batch 12.85 | loss 0.06208676\n",
      "| Epoch 172 |   100/  658 batches | lr 0.00006 | ms/batch 14.03 | loss 0.05861839\n",
      "| Epoch 172 |   150/  658 batches | lr 0.00006 | ms/batch 12.70 | loss 0.05557463\n",
      "| Epoch 172 |   200/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.05521839\n",
      "| Epoch 172 |   250/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.05876366\n",
      "| Epoch 172 |   300/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.05879188\n",
      "| Epoch 172 |   350/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.05983598\n",
      "| Epoch 172 |   400/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.05683287\n",
      "| Epoch 172 |   450/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.05344949\n",
      "| Epoch 172 |   500/  658 batches | lr 0.00006 | ms/batch 14.21 | loss 0.05787594\n",
      "| Epoch 172 |   550/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.05662141\n",
      "| Epoch 172 |   600/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.05900529\n",
      "| Epoch 172 |   650/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.05638355\n",
      "\n",
      "Val set: Average loss: 0.05871607\n",
      "\n",
      "| Epoch 173 |    50/  658 batches | lr 0.00006 | ms/batch 12.80 | loss 0.06189956\n",
      "| Epoch 173 |   100/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.05863191\n",
      "| Epoch 173 |   150/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.05549415\n",
      "| Epoch 173 |   200/  658 batches | lr 0.00006 | ms/batch 14.27 | loss 0.05502183\n",
      "| Epoch 173 |   250/  658 batches | lr 0.00006 | ms/batch 14.36 | loss 0.05867717\n",
      "| Epoch 173 |   300/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.05871716\n",
      "| Epoch 173 |   350/  658 batches | lr 0.00006 | ms/batch 12.49 | loss 0.05975400\n",
      "| Epoch 173 |   400/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.05679453\n",
      "| Epoch 173 |   450/  658 batches | lr 0.00006 | ms/batch 12.58 | loss 0.05339108\n",
      "| Epoch 173 |   500/  658 batches | lr 0.00006 | ms/batch 14.13 | loss 0.05774448\n",
      "| Epoch 173 |   550/  658 batches | lr 0.00006 | ms/batch 14.21 | loss 0.05657228\n",
      "| Epoch 173 |   600/  658 batches | lr 0.00006 | ms/batch 12.48 | loss 0.05902607\n",
      "| Epoch 173 |   650/  658 batches | lr 0.00006 | ms/batch 12.47 | loss 0.05630811\n",
      "\n",
      "Val set: Average loss: 0.05872632\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 174 |    50/  658 batches | lr 0.00006 | ms/batch 12.68 | loss 0.06197587\n",
      "| Epoch 174 |   100/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.05850931\n",
      "| Epoch 174 |   150/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.05553917\n",
      "| Epoch 174 |   200/  658 batches | lr 0.00006 | ms/batch 14.12 | loss 0.05493087\n",
      "| Epoch 174 |   250/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.05864074\n",
      "| Epoch 174 |   300/  658 batches | lr 0.00006 | ms/batch 12.46 | loss 0.05878103\n",
      "| Epoch 174 |   350/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.05971682\n",
      "| Epoch 174 |   400/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.05666482\n",
      "| Epoch 174 |   450/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.05337097\n",
      "| Epoch 174 |   500/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.05778945\n",
      "| Epoch 174 |   550/  658 batches | lr 0.00006 | ms/batch 14.43 | loss 0.05658279\n",
      "| Epoch 174 |   600/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.05913352\n",
      "| Epoch 174 |   650/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.05624108\n",
      "\n",
      "Val set: Average loss: 0.05870905\n",
      "\n",
      "| Epoch 175 |    50/  658 batches | lr 0.00006 | ms/batch 12.79 | loss 0.06178386\n",
      "| Epoch 175 |   100/  658 batches | lr 0.00006 | ms/batch 14.34 | loss 0.05850197\n",
      "| Epoch 175 |   150/  658 batches | lr 0.00006 | ms/batch 12.68 | loss 0.05546228\n",
      "| Epoch 175 |   200/  658 batches | lr 0.00006 | ms/batch 14.50 | loss 0.05506927\n",
      "| Epoch 175 |   250/  658 batches | lr 0.00006 | ms/batch 14.70 | loss 0.05848094\n",
      "| Epoch 175 |   300/  658 batches | lr 0.00006 | ms/batch 12.67 | loss 0.05877868\n",
      "| Epoch 175 |   350/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.05969989\n",
      "| Epoch 175 |   400/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.05679233\n",
      "| Epoch 175 |   450/  658 batches | lr 0.00006 | ms/batch 12.74 | loss 0.05338069\n",
      "| Epoch 175 |   500/  658 batches | lr 0.00006 | ms/batch 14.43 | loss 0.05774895\n",
      "| Epoch 175 |   550/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.05656926\n",
      "| Epoch 175 |   600/  658 batches | lr 0.00006 | ms/batch 12.51 | loss 0.05911222\n",
      "| Epoch 175 |   650/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.05629291\n",
      "\n",
      "Val set: Average loss: 0.05863803\n",
      "\n",
      "| Epoch 176 |    50/  658 batches | lr 0.00006 | ms/batch 12.69 | loss 0.06181632\n",
      "| Epoch 176 |   100/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.05847018\n",
      "| Epoch 176 |   150/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.05542186\n",
      "| Epoch 176 |   200/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.05494378\n",
      "| Epoch 176 |   250/  658 batches | lr 0.00006 | ms/batch 14.45 | loss 0.05850757\n",
      "| Epoch 176 |   300/  658 batches | lr 0.00006 | ms/batch 12.62 | loss 0.05888416\n",
      "| Epoch 176 |   350/  658 batches | lr 0.00006 | ms/batch 12.93 | loss 0.05974042\n",
      "| Epoch 176 |   400/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.05702710\n",
      "| Epoch 176 |   450/  658 batches | lr 0.00006 | ms/batch 12.73 | loss 0.05336073\n",
      "| Epoch 176 |   500/  658 batches | lr 0.00006 | ms/batch 14.49 | loss 0.05773686\n",
      "| Epoch 176 |   550/  658 batches | lr 0.00006 | ms/batch 14.69 | loss 0.05637818\n",
      "| Epoch 176 |   600/  658 batches | lr 0.00006 | ms/batch 12.86 | loss 0.05901116\n",
      "| Epoch 176 |   650/  658 batches | lr 0.00006 | ms/batch 13.71 | loss 0.05614633\n",
      "\n",
      "Val set: Average loss: 0.05857418\n",
      "\n",
      "| Epoch 177 |    50/  658 batches | lr 0.00006 | ms/batch 15.87 | loss 0.06177947\n",
      "| Epoch 177 |   100/  658 batches | lr 0.00006 | ms/batch 19.59 | loss 0.05837695\n",
      "| Epoch 177 |   150/  658 batches | lr 0.00006 | ms/batch 16.06 | loss 0.05554643\n",
      "| Epoch 177 |   200/  658 batches | lr 0.00006 | ms/batch 19.46 | loss 0.05509503\n",
      "| Epoch 177 |   250/  658 batches | lr 0.00006 | ms/batch 17.39 | loss 0.05847447\n",
      "| Epoch 177 |   300/  658 batches | lr 0.00006 | ms/batch 18.08 | loss 0.05849858\n",
      "| Epoch 177 |   350/  658 batches | lr 0.00006 | ms/batch 15.42 | loss 0.05963347\n",
      "| Epoch 177 |   400/  658 batches | lr 0.00006 | ms/batch 16.86 | loss 0.05686044\n",
      "| Epoch 177 |   450/  658 batches | lr 0.00006 | ms/batch 15.81 | loss 0.05331569\n",
      "| Epoch 177 |   500/  658 batches | lr 0.00006 | ms/batch 19.70 | loss 0.05751572\n",
      "| Epoch 177 |   550/  658 batches | lr 0.00006 | ms/batch 17.59 | loss 0.05647342\n",
      "| Epoch 177 |   600/  658 batches | lr 0.00006 | ms/batch 15.77 | loss 0.05899138\n",
      "| Epoch 177 |   650/  658 batches | lr 0.00006 | ms/batch 16.43 | loss 0.05610256\n",
      "\n",
      "Val set: Average loss: 0.05863734\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 178 |    50/  658 batches | lr 0.00006 | ms/batch 16.80 | loss 0.06178061\n",
      "| Epoch 178 |   100/  658 batches | lr 0.00006 | ms/batch 18.10 | loss 0.05840232\n",
      "| Epoch 178 |   150/  658 batches | lr 0.00006 | ms/batch 15.81 | loss 0.05533117\n",
      "| Epoch 178 |   200/  658 batches | lr 0.00006 | ms/batch 17.73 | loss 0.05504085\n",
      "| Epoch 178 |   250/  658 batches | lr 0.00006 | ms/batch 16.40 | loss 0.05839617\n",
      "| Epoch 178 |   300/  658 batches | lr 0.00006 | ms/batch 13.65 | loss 0.05861937\n",
      "| Epoch 178 |   350/  658 batches | lr 0.00006 | ms/batch 13.54 | loss 0.05961181\n",
      "| Epoch 178 |   400/  658 batches | lr 0.00006 | ms/batch 14.82 | loss 0.05677230\n",
      "| Epoch 178 |   450/  658 batches | lr 0.00006 | ms/batch 13.88 | loss 0.05341481\n",
      "| Epoch 178 |   500/  658 batches | lr 0.00006 | ms/batch 17.42 | loss 0.05752791\n",
      "| Epoch 178 |   550/  658 batches | lr 0.00006 | ms/batch 17.93 | loss 0.05640716\n",
      "| Epoch 178 |   600/  658 batches | lr 0.00006 | ms/batch 15.75 | loss 0.05894768\n",
      "| Epoch 178 |   650/  658 batches | lr 0.00006 | ms/batch 14.24 | loss 0.05605575\n",
      "\n",
      "Val set: Average loss: 0.05851505\n",
      "\n",
      "| Epoch 179 |    50/  658 batches | lr 0.00006 | ms/batch 13.68 | loss 0.06171867\n",
      "| Epoch 179 |   100/  658 batches | lr 0.00006 | ms/batch 17.39 | loss 0.05840417\n",
      "| Epoch 179 |   150/  658 batches | lr 0.00006 | ms/batch 13.09 | loss 0.05538660\n",
      "| Epoch 179 |   200/  658 batches | lr 0.00006 | ms/batch 17.05 | loss 0.05494285\n",
      "| Epoch 179 |   250/  658 batches | lr 0.00006 | ms/batch 15.50 | loss 0.05838323\n",
      "| Epoch 179 |   300/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.05863746\n",
      "| Epoch 179 |   350/  658 batches | lr 0.00006 | ms/batch 13.64 | loss 0.05959506\n",
      "| Epoch 179 |   400/  658 batches | lr 0.00006 | ms/batch 15.23 | loss 0.05680631\n",
      "| Epoch 179 |   450/  658 batches | lr 0.00006 | ms/batch 16.61 | loss 0.05329799\n",
      "| Epoch 179 |   500/  658 batches | lr 0.00006 | ms/batch 16.55 | loss 0.05748800\n",
      "| Epoch 179 |   550/  658 batches | lr 0.00006 | ms/batch 15.07 | loss 0.05643920\n",
      "| Epoch 179 |   600/  658 batches | lr 0.00006 | ms/batch 13.27 | loss 0.05900735\n",
      "| Epoch 179 |   650/  658 batches | lr 0.00006 | ms/batch 13.47 | loss 0.05592048\n",
      "\n",
      "Val set: Average loss: 0.05847456\n",
      "\n",
      "| Epoch 180 |    50/  658 batches | lr 0.00006 | ms/batch 15.66 | loss 0.06166782\n",
      "| Epoch 180 |   100/  658 batches | lr 0.00006 | ms/batch 15.80 | loss 0.05832820\n",
      "| Epoch 180 |   150/  658 batches | lr 0.00006 | ms/batch 13.78 | loss 0.05521591\n",
      "| Epoch 180 |   200/  658 batches | lr 0.00006 | ms/batch 16.44 | loss 0.05508448\n",
      "| Epoch 180 |   250/  658 batches | lr 0.00006 | ms/batch 15.80 | loss 0.05839787\n",
      "| Epoch 180 |   300/  658 batches | lr 0.00006 | ms/batch 14.44 | loss 0.05877998\n",
      "| Epoch 180 |   350/  658 batches | lr 0.00006 | ms/batch 13.32 | loss 0.05970202\n",
      "| Epoch 180 |   400/  658 batches | lr 0.00006 | ms/batch 16.26 | loss 0.05713388\n",
      "| Epoch 180 |   450/  658 batches | lr 0.00006 | ms/batch 13.33 | loss 0.05315145\n",
      "| Epoch 180 |   500/  658 batches | lr 0.00006 | ms/batch 15.66 | loss 0.05749585\n",
      "| Epoch 180 |   550/  658 batches | lr 0.00006 | ms/batch 15.78 | loss 0.05631788\n",
      "| Epoch 180 |   600/  658 batches | lr 0.00006 | ms/batch 13.82 | loss 0.05888844\n",
      "| Epoch 180 |   650/  658 batches | lr 0.00006 | ms/batch 15.21 | loss 0.05589043\n",
      "\n",
      "Val set: Average loss: 0.05850524\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 181 |    50/  658 batches | lr 0.00006 | ms/batch 14.83 | loss 0.06155104\n",
      "| Epoch 181 |   100/  658 batches | lr 0.00006 | ms/batch 16.35 | loss 0.05822955\n",
      "| Epoch 181 |   150/  658 batches | lr 0.00006 | ms/batch 14.01 | loss 0.05550815\n",
      "| Epoch 181 |   200/  658 batches | lr 0.00006 | ms/batch 15.77 | loss 0.05483479\n",
      "| Epoch 181 |   250/  658 batches | lr 0.00006 | ms/batch 15.63 | loss 0.05834993\n",
      "| Epoch 181 |   300/  658 batches | lr 0.00006 | ms/batch 14.04 | loss 0.05857790\n",
      "| Epoch 181 |   350/  658 batches | lr 0.00006 | ms/batch 14.83 | loss 0.05948746\n",
      "| Epoch 181 |   400/  658 batches | lr 0.00006 | ms/batch 16.06 | loss 0.05683725\n",
      "| Epoch 181 |   450/  658 batches | lr 0.00006 | ms/batch 13.38 | loss 0.05340465\n",
      "| Epoch 181 |   500/  658 batches | lr 0.00006 | ms/batch 15.93 | loss 0.05746742\n",
      "| Epoch 181 |   550/  658 batches | lr 0.00006 | ms/batch 15.93 | loss 0.05622600\n",
      "| Epoch 181 |   600/  658 batches | lr 0.00006 | ms/batch 14.28 | loss 0.05889938\n",
      "| Epoch 181 |   650/  658 batches | lr 0.00006 | ms/batch 14.46 | loss 0.05591340\n",
      "\n",
      "Val set: Average loss: 0.05850844\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch 182 |    50/  658 batches | lr 0.00006 | ms/batch 14.47 | loss 0.06147680\n",
      "| Epoch 182 |   100/  658 batches | lr 0.00006 | ms/batch 16.44 | loss 0.05822055\n",
      "| Epoch 182 |   150/  658 batches | lr 0.00006 | ms/batch 13.91 | loss 0.05527505\n",
      "| Epoch 182 |   200/  658 batches | lr 0.00006 | ms/batch 15.71 | loss 0.05464950\n",
      "| Epoch 182 |   250/  658 batches | lr 0.00006 | ms/batch 15.90 | loss 0.05831186\n",
      "| Epoch 182 |   300/  658 batches | lr 0.00006 | ms/batch 13.84 | loss 0.05869104\n",
      "| Epoch 182 |   350/  658 batches | lr 0.00006 | ms/batch 13.61 | loss 0.05948141\n",
      "| Epoch 182 |   400/  658 batches | lr 0.00006 | ms/batch 16.10 | loss 0.05685553\n",
      "| Epoch 182 |   450/  658 batches | lr 0.00006 | ms/batch 13.56 | loss 0.05320076\n",
      "| Epoch 182 |   500/  658 batches | lr 0.00006 | ms/batch 16.23 | loss 0.05726663\n",
      "| Epoch 182 |   550/  658 batches | lr 0.00006 | ms/batch 16.02 | loss 0.05620278\n",
      "| Epoch 182 |   600/  658 batches | lr 0.00006 | ms/batch 13.60 | loss 0.05893897\n",
      "| Epoch 182 |   650/  658 batches | lr 0.00006 | ms/batch 14.41 | loss 0.05608021\n",
      "\n",
      "Val set: Average loss: 0.05849719\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch 183 |    50/  658 batches | lr 0.00006 | ms/batch 15.85 | loss 0.06142896\n",
      "| Epoch 183 |   100/  658 batches | lr 0.00006 | ms/batch 16.26 | loss 0.05814212\n",
      "| Epoch 183 |   150/  658 batches | lr 0.00006 | ms/batch 14.00 | loss 0.05508331\n",
      "| Epoch 183 |   200/  658 batches | lr 0.00006 | ms/batch 16.47 | loss 0.05460751\n",
      "| Epoch 183 |   250/  658 batches | lr 0.00006 | ms/batch 16.49 | loss 0.05820458\n",
      "| Epoch 183 |   300/  658 batches | lr 0.00006 | ms/batch 13.78 | loss 0.05842523\n",
      "| Epoch 183 |   350/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.05941911\n",
      "| Epoch 183 |   400/  658 batches | lr 0.00006 | ms/batch 17.15 | loss 0.05672843\n",
      "| Epoch 183 |   450/  658 batches | lr 0.00006 | ms/batch 13.42 | loss 0.05325152\n",
      "| Epoch 183 |   500/  658 batches | lr 0.00006 | ms/batch 16.48 | loss 0.05748466\n",
      "| Epoch 183 |   550/  658 batches | lr 0.00006 | ms/batch 16.92 | loss 0.05628009\n",
      "| Epoch 183 |   600/  658 batches | lr 0.00006 | ms/batch 14.70 | loss 0.05888874\n",
      "| Epoch 183 |   650/  658 batches | lr 0.00006 | ms/batch 15.53 | loss 0.05591318\n",
      "\n",
      "Val set: Average loss: 0.05842499\n",
      "\n",
      "| Epoch 184 |    50/  658 batches | lr 0.00006 | ms/batch 14.66 | loss 0.06134102\n",
      "| Epoch 184 |   100/  658 batches | lr 0.00006 | ms/batch 16.46 | loss 0.05817294\n",
      "| Epoch 184 |   150/  658 batches | lr 0.00006 | ms/batch 13.44 | loss 0.05515939\n",
      "| Epoch 184 |   200/  658 batches | lr 0.00006 | ms/batch 16.23 | loss 0.05476139\n",
      "| Epoch 184 |   250/  658 batches | lr 0.00006 | ms/batch 16.16 | loss 0.05820205\n",
      "| Epoch 184 |   300/  658 batches | lr 0.00006 | ms/batch 14.00 | loss 0.05834972\n",
      "| Epoch 184 |   350/  658 batches | lr 0.00006 | ms/batch 13.64 | loss 0.05936126\n",
      "| Epoch 184 |   400/  658 batches | lr 0.00006 | ms/batch 17.59 | loss 0.05667801\n",
      "| Epoch 184 |   450/  658 batches | lr 0.00006 | ms/batch 13.99 | loss 0.05322595\n",
      "| Epoch 184 |   500/  658 batches | lr 0.00006 | ms/batch 16.52 | loss 0.05720633\n",
      "| Epoch 184 |   550/  658 batches | lr 0.00006 | ms/batch 16.40 | loss 0.05621349\n",
      "| Epoch 184 |   600/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.05881867\n",
      "| Epoch 184 |   650/  658 batches | lr 0.00006 | ms/batch 14.11 | loss 0.05583564\n",
      "\n",
      "Val set: Average loss: 0.05853381\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 185 |    50/  658 batches | lr 0.00006 | ms/batch 14.94 | loss 0.06135878\n",
      "| Epoch 185 |   100/  658 batches | lr 0.00006 | ms/batch 16.44 | loss 0.05821426\n",
      "| Epoch 185 |   150/  658 batches | lr 0.00006 | ms/batch 15.82 | loss 0.05515260\n",
      "| Epoch 185 |   200/  658 batches | lr 0.00006 | ms/batch 16.17 | loss 0.05450229\n",
      "| Epoch 185 |   250/  658 batches | lr 0.00006 | ms/batch 16.16 | loss 0.05819850\n",
      "| Epoch 185 |   300/  658 batches | lr 0.00006 | ms/batch 14.55 | loss 0.05852608\n",
      "| Epoch 185 |   350/  658 batches | lr 0.00006 | ms/batch 16.09 | loss 0.05941465\n",
      "| Epoch 185 |   400/  658 batches | lr 0.00006 | ms/batch 15.83 | loss 0.05667058\n",
      "| Epoch 185 |   450/  658 batches | lr 0.00006 | ms/batch 14.50 | loss 0.05320665\n",
      "| Epoch 185 |   500/  658 batches | lr 0.00006 | ms/batch 17.49 | loss 0.05737760\n",
      "| Epoch 185 |   550/  658 batches | lr 0.00006 | ms/batch 16.04 | loss 0.05619319\n",
      "| Epoch 185 |   600/  658 batches | lr 0.00006 | ms/batch 16.96 | loss 0.05883216\n",
      "| Epoch 185 |   650/  658 batches | lr 0.00006 | ms/batch 15.26 | loss 0.05594052\n",
      "\n",
      "Val set: Average loss: 0.05840211\n",
      "\n",
      "| Epoch 186 |    50/  658 batches | lr 0.00006 | ms/batch 16.96 | loss 0.06124961\n",
      "| Epoch 186 |   100/  658 batches | lr 0.00006 | ms/batch 16.31 | loss 0.05799678\n",
      "| Epoch 186 |   150/  658 batches | lr 0.00006 | ms/batch 16.21 | loss 0.05510770\n",
      "| Epoch 186 |   200/  658 batches | lr 0.00006 | ms/batch 16.17 | loss 0.05463044\n",
      "| Epoch 186 |   250/  658 batches | lr 0.00006 | ms/batch 16.92 | loss 0.05810510\n",
      "| Epoch 186 |   300/  658 batches | lr 0.00006 | ms/batch 15.84 | loss 0.05856345\n",
      "| Epoch 186 |   350/  658 batches | lr 0.00006 | ms/batch 15.52 | loss 0.05949545\n",
      "| Epoch 186 |   400/  658 batches | lr 0.00006 | ms/batch 18.68 | loss 0.05698537\n",
      "| Epoch 186 |   450/  658 batches | lr 0.00006 | ms/batch 14.62 | loss 0.05303716\n",
      "| Epoch 186 |   500/  658 batches | lr 0.00006 | ms/batch 15.64 | loss 0.05735189\n",
      "| Epoch 186 |   550/  658 batches | lr 0.00006 | ms/batch 17.79 | loss 0.05602531\n",
      "| Epoch 186 |   600/  658 batches | lr 0.00006 | ms/batch 13.39 | loss 0.05883633\n",
      "| Epoch 186 |   650/  658 batches | lr 0.00006 | ms/batch 16.06 | loss 0.05574652\n",
      "\n",
      "Val set: Average loss: 0.05842053\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 187 |    50/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.06131798\n",
      "| Epoch 187 |   100/  658 batches | lr 0.00006 | ms/batch 15.30 | loss 0.05811730\n",
      "| Epoch 187 |   150/  658 batches | lr 0.00006 | ms/batch 15.75 | loss 0.05499239\n",
      "| Epoch 187 |   200/  658 batches | lr 0.00006 | ms/batch 16.41 | loss 0.05461725\n",
      "| Epoch 187 |   250/  658 batches | lr 0.00006 | ms/batch 16.24 | loss 0.05818731\n",
      "| Epoch 187 |   300/  658 batches | lr 0.00006 | ms/batch 13.28 | loss 0.05838888\n",
      "| Epoch 187 |   350/  658 batches | lr 0.00006 | ms/batch 14.47 | loss 0.05936975\n",
      "| Epoch 187 |   400/  658 batches | lr 0.00006 | ms/batch 16.72 | loss 0.05689638\n",
      "| Epoch 187 |   450/  658 batches | lr 0.00006 | ms/batch 14.40 | loss 0.05296907\n",
      "| Epoch 187 |   500/  658 batches | lr 0.00006 | ms/batch 14.97 | loss 0.05736085\n",
      "| Epoch 187 |   550/  658 batches | lr 0.00006 | ms/batch 14.95 | loss 0.05620870\n",
      "| Epoch 187 |   600/  658 batches | lr 0.00006 | ms/batch 14.62 | loss 0.05877624\n",
      "| Epoch 187 |   650/  658 batches | lr 0.00006 | ms/batch 15.69 | loss 0.05569197\n",
      "\n",
      "Val set: Average loss: 0.05838646\n",
      "\n",
      "| Epoch 188 |    50/  658 batches | lr 0.00006 | ms/batch 14.76 | loss 0.06132199\n",
      "| Epoch 188 |   100/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.05806361\n",
      "| Epoch 188 |   150/  658 batches | lr 0.00006 | ms/batch 14.31 | loss 0.05492424\n",
      "| Epoch 188 |   200/  658 batches | lr 0.00006 | ms/batch 15.35 | loss 0.05458285\n",
      "| Epoch 188 |   250/  658 batches | lr 0.00006 | ms/batch 14.65 | loss 0.05807829\n",
      "| Epoch 188 |   300/  658 batches | lr 0.00006 | ms/batch 13.01 | loss 0.05834165\n",
      "| Epoch 188 |   350/  658 batches | lr 0.00006 | ms/batch 14.41 | loss 0.05928015\n",
      "| Epoch 188 |   400/  658 batches | lr 0.00006 | ms/batch 15.64 | loss 0.05671510\n",
      "| Epoch 188 |   450/  658 batches | lr 0.00006 | ms/batch 13.42 | loss 0.05315032\n",
      "| Epoch 188 |   500/  658 batches | lr 0.00006 | ms/batch 16.30 | loss 0.05726570\n",
      "| Epoch 188 |   550/  658 batches | lr 0.00006 | ms/batch 18.39 | loss 0.05604967\n",
      "| Epoch 188 |   600/  658 batches | lr 0.00006 | ms/batch 15.28 | loss 0.05871743\n",
      "| Epoch 188 |   650/  658 batches | lr 0.00006 | ms/batch 14.93 | loss 0.05565796\n",
      "\n",
      "Val set: Average loss: 0.05849505\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 189 |    50/  658 batches | lr 0.00006 | ms/batch 14.52 | loss 0.06134524\n",
      "| Epoch 189 |   100/  658 batches | lr 0.00006 | ms/batch 16.31 | loss 0.05795024\n",
      "| Epoch 189 |   150/  658 batches | lr 0.00006 | ms/batch 14.40 | loss 0.05490229\n",
      "| Epoch 189 |   200/  658 batches | lr 0.00006 | ms/batch 15.44 | loss 0.05451924\n",
      "| Epoch 189 |   250/  658 batches | lr 0.00006 | ms/batch 16.12 | loss 0.05806949\n",
      "| Epoch 189 |   300/  658 batches | lr 0.00006 | ms/batch 15.71 | loss 0.05836421\n",
      "| Epoch 189 |   350/  658 batches | lr 0.00006 | ms/batch 15.81 | loss 0.05927228\n",
      "| Epoch 189 |   400/  658 batches | lr 0.00006 | ms/batch 16.76 | loss 0.05671480\n",
      "| Epoch 189 |   450/  658 batches | lr 0.00006 | ms/batch 14.10 | loss 0.05313208\n",
      "| Epoch 189 |   500/  658 batches | lr 0.00006 | ms/batch 14.66 | loss 0.05723614\n",
      "| Epoch 189 |   550/  658 batches | lr 0.00006 | ms/batch 17.14 | loss 0.05614999\n",
      "| Epoch 189 |   600/  658 batches | lr 0.00006 | ms/batch 16.97 | loss 0.05877738\n",
      "| Epoch 189 |   650/  658 batches | lr 0.00006 | ms/batch 12.77 | loss 0.05564881\n",
      "\n",
      "Val set: Average loss: 0.05844632\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch 190 |    50/  658 batches | lr 0.00006 | ms/batch 16.80 | loss 0.06125923\n",
      "| Epoch 190 |   100/  658 batches | lr 0.00006 | ms/batch 18.01 | loss 0.05793655\n",
      "| Epoch 190 |   150/  658 batches | lr 0.00006 | ms/batch 12.98 | loss 0.05486458\n",
      "| Epoch 190 |   200/  658 batches | lr 0.00006 | ms/batch 16.73 | loss 0.05445941\n",
      "| Epoch 190 |   250/  658 batches | lr 0.00006 | ms/batch 14.68 | loss 0.05802895\n",
      "| Epoch 190 |   300/  658 batches | lr 0.00006 | ms/batch 16.40 | loss 0.05828118\n",
      "| Epoch 190 |   350/  658 batches | lr 0.00006 | ms/batch 15.68 | loss 0.05922047\n",
      "| Epoch 190 |   400/  658 batches | lr 0.00006 | ms/batch 15.10 | loss 0.05672408\n",
      "| Epoch 190 |   450/  658 batches | lr 0.00006 | ms/batch 17.45 | loss 0.05308629\n",
      "| Epoch 190 |   500/  658 batches | lr 0.00006 | ms/batch 16.28 | loss 0.05732600\n",
      "| Epoch 190 |   550/  658 batches | lr 0.00006 | ms/batch 15.39 | loss 0.05618686\n",
      "| Epoch 190 |   600/  658 batches | lr 0.00006 | ms/batch 14.79 | loss 0.05876904\n",
      "| Epoch 190 |   650/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.05554593\n",
      "\n",
      "Val set: Average loss: 0.05843974\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch 191 |    50/  658 batches | lr 0.00006 | ms/batch 16.58 | loss 0.06129381\n",
      "| Epoch 191 |   100/  658 batches | lr 0.00006 | ms/batch 17.63 | loss 0.05792418\n",
      "| Epoch 191 |   150/  658 batches | lr 0.00006 | ms/batch 16.74 | loss 0.05495000\n",
      "| Epoch 191 |   200/  658 batches | lr 0.00006 | ms/batch 16.36 | loss 0.05434289\n",
      "| Epoch 191 |   250/  658 batches | lr 0.00006 | ms/batch 17.63 | loss 0.05799457\n",
      "| Epoch 191 |   300/  658 batches | lr 0.00006 | ms/batch 13.36 | loss 0.05829432\n",
      "| Epoch 191 |   350/  658 batches | lr 0.00006 | ms/batch 13.17 | loss 0.05919982\n",
      "| Epoch 191 |   400/  658 batches | lr 0.00006 | ms/batch 17.88 | loss 0.05660046\n",
      "| Epoch 191 |   450/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.05289753\n",
      "| Epoch 191 |   500/  658 batches | lr 0.00006 | ms/batch 14.92 | loss 0.05712584\n",
      "| Epoch 191 |   550/  658 batches | lr 0.00006 | ms/batch 15.80 | loss 0.05605241\n",
      "| Epoch 191 |   600/  658 batches | lr 0.00006 | ms/batch 14.52 | loss 0.05860592\n",
      "| Epoch 191 |   650/  658 batches | lr 0.00006 | ms/batch 14.77 | loss 0.05556296\n",
      "\n",
      "Val set: Average loss: 0.05831097\n",
      "\n",
      "| Epoch 192 |    50/  658 batches | lr 0.00006 | ms/batch 15.56 | loss 0.06110765\n",
      "| Epoch 192 |   100/  658 batches | lr 0.00006 | ms/batch 18.69 | loss 0.05786324\n",
      "| Epoch 192 |   150/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.05479250\n",
      "| Epoch 192 |   200/  658 batches | lr 0.00006 | ms/batch 14.87 | loss 0.05432166\n",
      "| Epoch 192 |   250/  658 batches | lr 0.00006 | ms/batch 16.73 | loss 0.05791937\n",
      "| Epoch 192 |   300/  658 batches | lr 0.00006 | ms/batch 14.53 | loss 0.05824523\n",
      "| Epoch 192 |   350/  658 batches | lr 0.00006 | ms/batch 14.48 | loss 0.05923079\n",
      "| Epoch 192 |   400/  658 batches | lr 0.00006 | ms/batch 14.59 | loss 0.05662597\n",
      "| Epoch 192 |   450/  658 batches | lr 0.00006 | ms/batch 14.55 | loss 0.05288712\n",
      "| Epoch 192 |   500/  658 batches | lr 0.00006 | ms/batch 19.29 | loss 0.05721526\n",
      "| Epoch 192 |   550/  658 batches | lr 0.00006 | ms/batch 19.88 | loss 0.05610834\n",
      "| Epoch 192 |   600/  658 batches | lr 0.00006 | ms/batch 17.67 | loss 0.05865349\n",
      "| Epoch 192 |   650/  658 batches | lr 0.00006 | ms/batch 16.16 | loss 0.05551274\n",
      "\n",
      "Val set: Average loss: 0.05833627\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 193 |    50/  658 batches | lr 0.00006 | ms/batch 13.57 | loss 0.06107463\n",
      "| Epoch 193 |   100/  658 batches | lr 0.00006 | ms/batch 14.63 | loss 0.05777699\n",
      "| Epoch 193 |   150/  658 batches | lr 0.00006 | ms/batch 14.62 | loss 0.05472703\n",
      "| Epoch 193 |   200/  658 batches | lr 0.00006 | ms/batch 16.01 | loss 0.05443857\n",
      "| Epoch 193 |   250/  658 batches | lr 0.00006 | ms/batch 16.41 | loss 0.05789240\n",
      "| Epoch 193 |   300/  658 batches | lr 0.00006 | ms/batch 21.52 | loss 0.05815093\n",
      "| Epoch 193 |   350/  658 batches | lr 0.00006 | ms/batch 22.40 | loss 0.05906407\n",
      "| Epoch 193 |   400/  658 batches | lr 0.00006 | ms/batch 17.22 | loss 0.05663132\n",
      "| Epoch 193 |   450/  658 batches | lr 0.00006 | ms/batch 15.78 | loss 0.05294912\n",
      "| Epoch 193 |   500/  658 batches | lr 0.00006 | ms/batch 15.07 | loss 0.05710259\n",
      "| Epoch 193 |   550/  658 batches | lr 0.00006 | ms/batch 14.71 | loss 0.05606224\n",
      "| Epoch 193 |   600/  658 batches | lr 0.00006 | ms/batch 14.64 | loss 0.05863287\n",
      "| Epoch 193 |   650/  658 batches | lr 0.00006 | ms/batch 15.73 | loss 0.05542898\n",
      "\n",
      "Val set: Average loss: 0.05836807\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch 194 |    50/  658 batches | lr 0.00006 | ms/batch 15.47 | loss 0.06124073\n",
      "| Epoch 194 |   100/  658 batches | lr 0.00006 | ms/batch 15.05 | loss 0.05778285\n",
      "| Epoch 194 |   150/  658 batches | lr 0.00006 | ms/batch 15.12 | loss 0.05489624\n",
      "| Epoch 194 |   200/  658 batches | lr 0.00006 | ms/batch 17.32 | loss 0.05430916\n",
      "| Epoch 194 |   250/  658 batches | lr 0.00006 | ms/batch 16.19 | loss 0.05787716\n",
      "| Epoch 194 |   300/  658 batches | lr 0.00006 | ms/batch 16.12 | loss 0.05814550\n",
      "| Epoch 194 |   350/  658 batches | lr 0.00006 | ms/batch 15.35 | loss 0.05911710\n",
      "| Epoch 194 |   400/  658 batches | lr 0.00006 | ms/batch 15.22 | loss 0.05657915\n",
      "| Epoch 194 |   450/  658 batches | lr 0.00006 | ms/batch 15.08 | loss 0.05300543\n",
      "| Epoch 194 |   500/  658 batches | lr 0.00006 | ms/batch 16.39 | loss 0.05707485\n",
      "| Epoch 194 |   550/  658 batches | lr 0.00006 | ms/batch 16.76 | loss 0.05608518\n",
      "| Epoch 194 |   600/  658 batches | lr 0.00006 | ms/batch 16.46 | loss 0.05855802\n",
      "| Epoch 194 |   650/  658 batches | lr 0.00006 | ms/batch 15.77 | loss 0.05545474\n",
      "\n",
      "Val set: Average loss: 0.05827901\n",
      "\n",
      "| Epoch 195 |    50/  658 batches | lr 0.00006 | ms/batch 16.38 | loss 0.06130921\n",
      "| Epoch 195 |   100/  658 batches | lr 0.00006 | ms/batch 14.67 | loss 0.05776378\n",
      "| Epoch 195 |   150/  658 batches | lr 0.00006 | ms/batch 14.49 | loss 0.05476754\n",
      "| Epoch 195 |   200/  658 batches | lr 0.00006 | ms/batch 16.98 | loss 0.05443333\n",
      "| Epoch 195 |   250/  658 batches | lr 0.00006 | ms/batch 18.69 | loss 0.05786818\n",
      "| Epoch 195 |   300/  658 batches | lr 0.00006 | ms/batch 12.91 | loss 0.05815513\n",
      "| Epoch 195 |   350/  658 batches | lr 0.00006 | ms/batch 13.12 | loss 0.05910760\n",
      "| Epoch 195 |   400/  658 batches | lr 0.00006 | ms/batch 16.17 | loss 0.05666658\n",
      "| Epoch 195 |   450/  658 batches | lr 0.00006 | ms/batch 14.88 | loss 0.05289568\n",
      "| Epoch 195 |   500/  658 batches | lr 0.00006 | ms/batch 17.76 | loss 0.05714693\n",
      "| Epoch 195 |   550/  658 batches | lr 0.00006 | ms/batch 15.36 | loss 0.05598945\n",
      "| Epoch 195 |   600/  658 batches | lr 0.00006 | ms/batch 14.87 | loss 0.05846761\n",
      "| Epoch 195 |   650/  658 batches | lr 0.00006 | ms/batch 13.62 | loss 0.05537228\n",
      "\n",
      "Val set: Average loss: 0.05840854\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 196 |    50/  658 batches | lr 0.00006 | ms/batch 22.72 | loss 0.06112864\n",
      "| Epoch 196 |   100/  658 batches | lr 0.00006 | ms/batch 18.53 | loss 0.05775265\n",
      "| Epoch 196 |   150/  658 batches | lr 0.00006 | ms/batch 16.81 | loss 0.05466091\n",
      "| Epoch 196 |   200/  658 batches | lr 0.00006 | ms/batch 16.78 | loss 0.05421292\n",
      "| Epoch 196 |   250/  658 batches | lr 0.00006 | ms/batch 18.89 | loss 0.05778758\n",
      "| Epoch 196 |   300/  658 batches | lr 0.00006 | ms/batch 16.47 | loss 0.05810016\n",
      "| Epoch 196 |   350/  658 batches | lr 0.00006 | ms/batch 21.10 | loss 0.05915748\n",
      "| Epoch 196 |   400/  658 batches | lr 0.00006 | ms/batch 19.84 | loss 0.05656490\n",
      "| Epoch 196 |   450/  658 batches | lr 0.00006 | ms/batch 14.52 | loss 0.05285301\n",
      "| Epoch 196 |   500/  658 batches | lr 0.00006 | ms/batch 18.04 | loss 0.05712091\n",
      "| Epoch 196 |   550/  658 batches | lr 0.00006 | ms/batch 19.63 | loss 0.05604206\n",
      "| Epoch 196 |   600/  658 batches | lr 0.00006 | ms/batch 19.53 | loss 0.05847133\n",
      "| Epoch 196 |   650/  658 batches | lr 0.00006 | ms/batch 15.84 | loss 0.05548110\n",
      "\n",
      "Val set: Average loss: 0.05838682\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch 197 |    50/  658 batches | lr 0.00006 | ms/batch 15.30 | loss 0.06130754\n",
      "| Epoch 197 |   100/  658 batches | lr 0.00006 | ms/batch 16.33 | loss 0.05763063\n",
      "| Epoch 197 |   150/  658 batches | lr 0.00006 | ms/batch 17.14 | loss 0.05531564\n",
      "| Epoch 197 |   200/  658 batches | lr 0.00006 | ms/batch 21.50 | loss 0.05454534\n",
      "| Epoch 197 |   250/  658 batches | lr 0.00006 | ms/batch 20.37 | loss 0.05785324\n",
      "| Epoch 197 |   300/  658 batches | lr 0.00006 | ms/batch 18.97 | loss 0.05796772\n",
      "| Epoch 197 |   350/  658 batches | lr 0.00006 | ms/batch 16.04 | loss 0.05900773\n",
      "| Epoch 197 |   400/  658 batches | lr 0.00006 | ms/batch 18.27 | loss 0.05651946\n",
      "| Epoch 197 |   450/  658 batches | lr 0.00006 | ms/batch 18.51 | loss 0.05277270\n",
      "| Epoch 197 |   500/  658 batches | lr 0.00006 | ms/batch 19.75 | loss 0.05701443\n",
      "| Epoch 197 |   550/  658 batches | lr 0.00006 | ms/batch 18.22 | loss 0.05596848\n",
      "| Epoch 197 |   600/  658 batches | lr 0.00006 | ms/batch 13.71 | loss 0.05813567\n",
      "| Epoch 197 |   650/  658 batches | lr 0.00006 | ms/batch 14.58 | loss 0.05543316\n",
      "\n",
      "Val set: Average loss: 0.05830305\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch 198 |    50/  658 batches | lr 0.00006 | ms/batch 15.23 | loss 0.06125944\n",
      "| Epoch 198 |   100/  658 batches | lr 0.00006 | ms/batch 14.99 | loss 0.05756941\n",
      "| Epoch 198 |   150/  658 batches | lr 0.00006 | ms/batch 14.87 | loss 0.05507470\n",
      "| Epoch 198 |   200/  658 batches | lr 0.00006 | ms/batch 14.89 | loss 0.05452556\n",
      "| Epoch 198 |   250/  658 batches | lr 0.00006 | ms/batch 14.60 | loss 0.05781104\n",
      "| Epoch 198 |   300/  658 batches | lr 0.00006 | ms/batch 14.51 | loss 0.05800240\n",
      "| Epoch 198 |   350/  658 batches | lr 0.00006 | ms/batch 14.62 | loss 0.05905949\n",
      "| Epoch 198 |   400/  658 batches | lr 0.00006 | ms/batch 16.18 | loss 0.05641809\n",
      "| Epoch 198 |   450/  658 batches | lr 0.00006 | ms/batch 15.45 | loss 0.05276223\n",
      "| Epoch 198 |   500/  658 batches | lr 0.00006 | ms/batch 18.34 | loss 0.05709713\n",
      "| Epoch 198 |   550/  658 batches | lr 0.00006 | ms/batch 14.54 | loss 0.05584099\n",
      "| Epoch 198 |   600/  658 batches | lr 0.00006 | ms/batch 12.72 | loss 0.05804553\n",
      "| Epoch 198 |   650/  658 batches | lr 0.00006 | ms/batch 15.49 | loss 0.05532102\n",
      "\n",
      "Val set: Average loss: 0.05839905\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch 199 |    50/  658 batches | lr 0.00006 | ms/batch 13.09 | loss 0.06100585\n",
      "| Epoch 199 |   100/  658 batches | lr 0.00006 | ms/batch 14.25 | loss 0.05749039\n",
      "| Epoch 199 |   150/  658 batches | lr 0.00006 | ms/batch 12.63 | loss 0.05464037\n",
      "| Epoch 199 |   200/  658 batches | lr 0.00006 | ms/batch 14.33 | loss 0.05424900\n",
      "| Epoch 199 |   250/  658 batches | lr 0.00006 | ms/batch 14.49 | loss 0.05773927\n",
      "| Epoch 199 |   300/  658 batches | lr 0.00006 | ms/batch 12.63 | loss 0.05806544\n",
      "| Epoch 199 |   350/  658 batches | lr 0.00006 | ms/batch 12.76 | loss 0.05902960\n",
      "| Epoch 199 |   400/  658 batches | lr 0.00006 | ms/batch 14.51 | loss 0.05643916\n",
      "| Epoch 199 |   450/  658 batches | lr 0.00006 | ms/batch 12.60 | loss 0.05289324\n",
      "| Epoch 199 |   500/  658 batches | lr 0.00006 | ms/batch 14.37 | loss 0.05693466\n",
      "| Epoch 199 |   550/  658 batches | lr 0.00006 | ms/batch 14.32 | loss 0.05590881\n",
      "| Epoch 199 |   600/  658 batches | lr 0.00006 | ms/batch 12.76 | loss 0.05833095\n",
      "| Epoch 199 |   650/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.05530135\n",
      "\n",
      "Val set: Average loss: 0.05822162\n",
      "\n",
      "| Epoch 200 |    50/  658 batches | lr 0.00006 | ms/batch 13.00 | loss 0.06108288\n",
      "| Epoch 200 |   100/  658 batches | lr 0.00006 | ms/batch 14.21 | loss 0.05740980\n",
      "| Epoch 200 |   150/  658 batches | lr 0.00006 | ms/batch 12.93 | loss 0.05484470\n",
      "| Epoch 200 |   200/  658 batches | lr 0.00006 | ms/batch 14.81 | loss 0.05417609\n",
      "| Epoch 200 |   250/  658 batches | lr 0.00006 | ms/batch 14.33 | loss 0.05768261\n",
      "| Epoch 200 |   300/  658 batches | lr 0.00006 | ms/batch 12.62 | loss 0.05783438\n",
      "| Epoch 200 |   350/  658 batches | lr 0.00006 | ms/batch 12.60 | loss 0.05893805\n",
      "| Epoch 200 |   400/  658 batches | lr 0.00006 | ms/batch 14.41 | loss 0.05639381\n",
      "| Epoch 200 |   450/  658 batches | lr 0.00006 | ms/batch 12.76 | loss 0.05258795\n",
      "| Epoch 200 |   500/  658 batches | lr 0.00006 | ms/batch 14.28 | loss 0.05686422\n",
      "| Epoch 200 |   550/  658 batches | lr 0.00006 | ms/batch 14.37 | loss 0.05563463\n",
      "| Epoch 200 |   600/  658 batches | lr 0.00006 | ms/batch 12.66 | loss 0.05811218\n",
      "| Epoch 200 |   650/  658 batches | lr 0.00006 | ms/batch 12.66 | loss 0.05530901\n",
      "\n",
      "Val set: Average loss: 0.05823121\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 201 |    50/  658 batches | lr 0.00006 | ms/batch 12.86 | loss 0.06109575\n",
      "| Epoch 201 |   100/  658 batches | lr 0.00006 | ms/batch 14.40 | loss 0.05743001\n",
      "| Epoch 201 |   150/  658 batches | lr 0.00006 | ms/batch 12.75 | loss 0.05472545\n",
      "| Epoch 201 |   200/  658 batches | lr 0.00006 | ms/batch 14.38 | loss 0.05412076\n",
      "| Epoch 201 |   250/  658 batches | lr 0.00006 | ms/batch 14.26 | loss 0.05758588\n",
      "| Epoch 201 |   300/  658 batches | lr 0.00006 | ms/batch 12.69 | loss 0.05774386\n",
      "| Epoch 201 |   350/  658 batches | lr 0.00006 | ms/batch 12.63 | loss 0.05886158\n",
      "| Epoch 201 |   400/  658 batches | lr 0.00006 | ms/batch 14.37 | loss 0.05632958\n",
      "| Epoch 201 |   450/  658 batches | lr 0.00006 | ms/batch 12.75 | loss 0.05266722\n",
      "| Epoch 201 |   500/  658 batches | lr 0.00006 | ms/batch 14.36 | loss 0.05726046\n",
      "| Epoch 201 |   550/  658 batches | lr 0.00006 | ms/batch 14.30 | loss 0.05595327\n",
      "| Epoch 201 |   600/  658 batches | lr 0.00006 | ms/batch 12.60 | loss 0.05834146\n",
      "| Epoch 201 |   650/  658 batches | lr 0.00006 | ms/batch 12.59 | loss 0.05531494\n",
      "\n",
      "Val set: Average loss: 0.05824952\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch 202 |    50/  658 batches | lr 0.00006 | ms/batch 12.89 | loss 0.06103974\n",
      "| Epoch 202 |   100/  658 batches | lr 0.00006 | ms/batch 14.29 | loss 0.05761720\n",
      "| Epoch 202 |   150/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.05470333\n",
      "| Epoch 202 |   200/  658 batches | lr 0.00006 | ms/batch 14.32 | loss 0.05403692\n",
      "| Epoch 202 |   250/  658 batches | lr 0.00006 | ms/batch 14.31 | loss 0.05763245\n",
      "| Epoch 202 |   300/  658 batches | lr 0.00006 | ms/batch 12.67 | loss 0.05782442\n",
      "| Epoch 202 |   350/  658 batches | lr 0.00006 | ms/batch 12.69 | loss 0.05891680\n",
      "| Epoch 202 |   400/  658 batches | lr 0.00006 | ms/batch 14.28 | loss 0.05639639\n",
      "| Epoch 202 |   450/  658 batches | lr 0.00006 | ms/batch 12.64 | loss 0.05263914\n",
      "| Epoch 202 |   500/  658 batches | lr 0.00006 | ms/batch 14.45 | loss 0.05708854\n",
      "| Epoch 202 |   550/  658 batches | lr 0.00006 | ms/batch 14.36 | loss 0.05583712\n",
      "| Epoch 202 |   600/  658 batches | lr 0.00006 | ms/batch 12.66 | loss 0.05817025\n",
      "| Epoch 202 |   650/  658 batches | lr 0.00006 | ms/batch 12.81 | loss 0.05520832\n",
      "\n",
      "Val set: Average loss: 0.05816638\n",
      "\n",
      "| Epoch 203 |    50/  658 batches | lr 0.00006 | ms/batch 12.99 | loss 0.06096197\n",
      "| Epoch 203 |   100/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.05742763\n",
      "| Epoch 203 |   150/  658 batches | lr 0.00006 | ms/batch 12.77 | loss 0.05468621\n",
      "| Epoch 203 |   200/  658 batches | lr 0.00006 | ms/batch 14.39 | loss 0.05405786\n",
      "| Epoch 203 |   250/  658 batches | lr 0.00006 | ms/batch 14.22 | loss 0.05757942\n",
      "| Epoch 203 |   300/  658 batches | lr 0.00006 | ms/batch 12.59 | loss 0.05782098\n",
      "| Epoch 203 |   350/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.05883388\n",
      "| Epoch 203 |   400/  658 batches | lr 0.00006 | ms/batch 14.27 | loss 0.05634758\n",
      "| Epoch 203 |   450/  658 batches | lr 0.00006 | ms/batch 12.71 | loss 0.05281642\n",
      "| Epoch 203 |   500/  658 batches | lr 0.00006 | ms/batch 14.34 | loss 0.05679567\n",
      "| Epoch 203 |   550/  658 batches | lr 0.00006 | ms/batch 14.36 | loss 0.05572447\n",
      "| Epoch 203 |   600/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.05812373\n",
      "| Epoch 203 |   650/  658 batches | lr 0.00006 | ms/batch 12.64 | loss 0.05524716\n",
      "\n",
      "Val set: Average loss: 0.05827742\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 204 |    50/  658 batches | lr 0.00006 | ms/batch 12.85 | loss 0.06090682\n",
      "| Epoch 204 |   100/  658 batches | lr 0.00006 | ms/batch 14.32 | loss 0.05736994\n",
      "| Epoch 204 |   150/  658 batches | lr 0.00006 | ms/batch 12.76 | loss 0.05447322\n",
      "| Epoch 204 |   200/  658 batches | lr 0.00006 | ms/batch 14.41 | loss 0.05400544\n",
      "| Epoch 204 |   250/  658 batches | lr 0.00006 | ms/batch 14.29 | loss 0.05756406\n",
      "| Epoch 204 |   300/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05769011\n",
      "| Epoch 204 |   350/  658 batches | lr 0.00006 | ms/batch 12.67 | loss 0.05875598\n",
      "| Epoch 204 |   400/  658 batches | lr 0.00006 | ms/batch 14.34 | loss 0.05631740\n",
      "| Epoch 204 |   450/  658 batches | lr 0.00006 | ms/batch 12.62 | loss 0.05265425\n",
      "| Epoch 204 |   500/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.05706375\n",
      "| Epoch 204 |   550/  658 batches | lr 0.00006 | ms/batch 14.31 | loss 0.05568822\n",
      "| Epoch 204 |   600/  658 batches | lr 0.00006 | ms/batch 12.68 | loss 0.05813968\n",
      "| Epoch 204 |   650/  658 batches | lr 0.00006 | ms/batch 13.08 | loss 0.05511697\n",
      "\n",
      "Val set: Average loss: 0.05818682\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch 205 |    50/  658 batches | lr 0.00006 | ms/batch 12.84 | loss 0.06095824\n",
      "| Epoch 205 |   100/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.05732133\n",
      "| Epoch 205 |   150/  658 batches | lr 0.00006 | ms/batch 12.77 | loss 0.05452040\n",
      "| Epoch 205 |   200/  658 batches | lr 0.00006 | ms/batch 14.35 | loss 0.05414921\n",
      "| Epoch 205 |   250/  658 batches | lr 0.00006 | ms/batch 14.34 | loss 0.05747420\n",
      "| Epoch 205 |   300/  658 batches | lr 0.00006 | ms/batch 12.77 | loss 0.05774635\n",
      "| Epoch 205 |   350/  658 batches | lr 0.00006 | ms/batch 12.63 | loss 0.05877362\n",
      "| Epoch 205 |   400/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.05619694\n",
      "| Epoch 205 |   450/  658 batches | lr 0.00006 | ms/batch 12.69 | loss 0.05244084\n",
      "| Epoch 205 |   500/  658 batches | lr 0.00006 | ms/batch 14.44 | loss 0.05694333\n",
      "| Epoch 205 |   550/  658 batches | lr 0.00006 | ms/batch 14.31 | loss 0.05560649\n",
      "| Epoch 205 |   600/  658 batches | lr 0.00006 | ms/batch 12.60 | loss 0.05813118\n",
      "| Epoch 205 |   650/  658 batches | lr 0.00006 | ms/batch 12.67 | loss 0.05510494\n",
      "\n",
      "Val set: Average loss: 0.05840424\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch 206 |    50/  658 batches | lr 0.00006 | ms/batch 12.79 | loss 0.06073856\n",
      "| Epoch 206 |   100/  658 batches | lr 0.00006 | ms/batch 14.25 | loss 0.05735600\n",
      "| Epoch 206 |   150/  658 batches | lr 0.00006 | ms/batch 12.78 | loss 0.05441787\n",
      "| Epoch 206 |   200/  658 batches | lr 0.00006 | ms/batch 14.35 | loss 0.05404150\n",
      "| Epoch 206 |   250/  658 batches | lr 0.00006 | ms/batch 14.32 | loss 0.05746710\n",
      "| Epoch 206 |   300/  658 batches | lr 0.00006 | ms/batch 12.63 | loss 0.05764057\n",
      "| Epoch 206 |   350/  658 batches | lr 0.00006 | ms/batch 12.74 | loss 0.05867368\n",
      "| Epoch 206 |   400/  658 batches | lr 0.00006 | ms/batch 14.33 | loss 0.05621797\n",
      "| Epoch 206 |   450/  658 batches | lr 0.00006 | ms/batch 12.63 | loss 0.05263978\n",
      "| Epoch 206 |   500/  658 batches | lr 0.00006 | ms/batch 14.26 | loss 0.05717667\n",
      "| Epoch 206 |   550/  658 batches | lr 0.00006 | ms/batch 14.29 | loss 0.05560445\n",
      "| Epoch 206 |   600/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.05800498\n",
      "| Epoch 206 |   650/  658 batches | lr 0.00006 | ms/batch 12.63 | loss 0.05508878\n",
      "\n",
      "Val set: Average loss: 0.05802622\n",
      "\n",
      "| Epoch 207 |    50/  658 batches | lr 0.00006 | ms/batch 12.87 | loss 0.06079120\n",
      "| Epoch 207 |   100/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.05716710\n",
      "| Epoch 207 |   150/  658 batches | lr 0.00006 | ms/batch 12.78 | loss 0.05441807\n",
      "| Epoch 207 |   200/  658 batches | lr 0.00006 | ms/batch 14.33 | loss 0.05406203\n",
      "| Epoch 207 |   250/  658 batches | lr 0.00006 | ms/batch 14.43 | loss 0.05742926\n",
      "| Epoch 207 |   300/  658 batches | lr 0.00006 | ms/batch 12.81 | loss 0.05764529\n",
      "| Epoch 207 |   350/  658 batches | lr 0.00006 | ms/batch 12.58 | loss 0.05876524\n",
      "| Epoch 207 |   400/  658 batches | lr 0.00006 | ms/batch 14.36 | loss 0.05633152\n",
      "| Epoch 207 |   450/  658 batches | lr 0.00006 | ms/batch 12.90 | loss 0.05252144\n",
      "| Epoch 207 |   500/  658 batches | lr 0.00006 | ms/batch 14.46 | loss 0.05686042\n",
      "| Epoch 207 |   550/  658 batches | lr 0.00006 | ms/batch 14.35 | loss 0.05551955\n",
      "| Epoch 207 |   600/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.05787182\n",
      "| Epoch 207 |   650/  658 batches | lr 0.00006 | ms/batch 12.62 | loss 0.05507732\n",
      "\n",
      "Val set: Average loss: 0.05819840\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 208 |    50/  658 batches | lr 0.00006 | ms/batch 13.01 | loss 0.06075810\n",
      "| Epoch 208 |   100/  658 batches | lr 0.00006 | ms/batch 14.30 | loss 0.05713168\n",
      "| Epoch 208 |   150/  658 batches | lr 0.00006 | ms/batch 12.68 | loss 0.05440419\n",
      "| Epoch 208 |   200/  658 batches | lr 0.00006 | ms/batch 14.34 | loss 0.05392358\n",
      "| Epoch 208 |   250/  658 batches | lr 0.00006 | ms/batch 14.34 | loss 0.05740775\n",
      "| Epoch 208 |   300/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.05761547\n",
      "| Epoch 208 |   350/  658 batches | lr 0.00006 | ms/batch 12.58 | loss 0.05873799\n",
      "| Epoch 208 |   400/  658 batches | lr 0.00006 | ms/batch 14.30 | loss 0.05630746\n",
      "| Epoch 208 |   450/  658 batches | lr 0.00006 | ms/batch 12.66 | loss 0.05247804\n",
      "| Epoch 208 |   500/  658 batches | lr 0.00006 | ms/batch 14.36 | loss 0.05688373\n",
      "| Epoch 208 |   550/  658 batches | lr 0.00006 | ms/batch 14.27 | loss 0.05552176\n",
      "| Epoch 208 |   600/  658 batches | lr 0.00006 | ms/batch 12.67 | loss 0.05789477\n",
      "| Epoch 208 |   650/  658 batches | lr 0.00006 | ms/batch 12.72 | loss 0.05513103\n",
      "\n",
      "Val set: Average loss: 0.05801662\n",
      "\n",
      "| Epoch 209 |    50/  658 batches | lr 0.00006 | ms/batch 12.81 | loss 0.06077324\n",
      "| Epoch 209 |   100/  658 batches | lr 0.00006 | ms/batch 14.78 | loss 0.05715180\n",
      "| Epoch 209 |   150/  658 batches | lr 0.00006 | ms/batch 15.46 | loss 0.05436514\n",
      "| Epoch 209 |   200/  658 batches | lr 0.00006 | ms/batch 15.38 | loss 0.05389258\n",
      "| Epoch 209 |   250/  658 batches | lr 0.00006 | ms/batch 14.89 | loss 0.05736173\n",
      "| Epoch 209 |   300/  658 batches | lr 0.00006 | ms/batch 12.90 | loss 0.05756313\n",
      "| Epoch 209 |   350/  658 batches | lr 0.00006 | ms/batch 12.97 | loss 0.05861852\n",
      "| Epoch 209 |   400/  658 batches | lr 0.00006 | ms/batch 14.63 | loss 0.05612292\n",
      "| Epoch 209 |   450/  658 batches | lr 0.00006 | ms/batch 13.45 | loss 0.05229303\n",
      "| Epoch 209 |   500/  658 batches | lr 0.00006 | ms/batch 14.79 | loss 0.05705208\n",
      "| Epoch 209 |   550/  658 batches | lr 0.00006 | ms/batch 14.85 | loss 0.05552890\n",
      "| Epoch 209 |   600/  658 batches | lr 0.00006 | ms/batch 13.12 | loss 0.05790750\n",
      "| Epoch 209 |   650/  658 batches | lr 0.00006 | ms/batch 12.92 | loss 0.05507279\n",
      "\n",
      "Val set: Average loss: 0.05801639\n",
      "\n",
      "| Epoch 210 |    50/  658 batches | lr 0.00006 | ms/batch 12.82 | loss 0.06079378\n",
      "| Epoch 210 |   100/  658 batches | lr 0.00006 | ms/batch 14.46 | loss 0.05711010\n",
      "| Epoch 210 |   150/  658 batches | lr 0.00006 | ms/batch 12.64 | loss 0.05434119\n",
      "| Epoch 210 |   200/  658 batches | lr 0.00006 | ms/batch 14.40 | loss 0.05388648\n",
      "| Epoch 210 |   250/  658 batches | lr 0.00006 | ms/batch 14.35 | loss 0.05731371\n",
      "| Epoch 210 |   300/  658 batches | lr 0.00006 | ms/batch 12.68 | loss 0.05753617\n",
      "| Epoch 210 |   350/  658 batches | lr 0.00006 | ms/batch 12.63 | loss 0.05850044\n",
      "| Epoch 210 |   400/  658 batches | lr 0.00006 | ms/batch 14.31 | loss 0.05601634\n",
      "| Epoch 210 |   450/  658 batches | lr 0.00006 | ms/batch 12.62 | loss 0.05239755\n",
      "| Epoch 210 |   500/  658 batches | lr 0.00006 | ms/batch 14.52 | loss 0.05707379\n",
      "| Epoch 210 |   550/  658 batches | lr 0.00006 | ms/batch 14.37 | loss 0.05549116\n",
      "| Epoch 210 |   600/  658 batches | lr 0.00006 | ms/batch 12.63 | loss 0.05775143\n",
      "| Epoch 210 |   650/  658 batches | lr 0.00006 | ms/batch 12.75 | loss 0.05503328\n",
      "\n",
      "Val set: Average loss: 0.05800704\n",
      "\n",
      "| Epoch 211 |    50/  658 batches | lr 0.00006 | ms/batch 12.86 | loss 0.06068206\n",
      "| Epoch 211 |   100/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.05701045\n",
      "| Epoch 211 |   150/  658 batches | lr 0.00006 | ms/batch 12.84 | loss 0.05449594\n",
      "| Epoch 211 |   200/  658 batches | lr 0.00006 | ms/batch 14.37 | loss 0.05383089\n",
      "| Epoch 211 |   250/  658 batches | lr 0.00006 | ms/batch 14.34 | loss 0.05732171\n",
      "| Epoch 211 |   300/  658 batches | lr 0.00006 | ms/batch 12.65 | loss 0.05730327\n",
      "| Epoch 211 |   350/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.05851631\n",
      "| Epoch 211 |   400/  658 batches | lr 0.00006 | ms/batch 14.28 | loss 0.05606964\n",
      "| Epoch 211 |   450/  658 batches | lr 0.00006 | ms/batch 12.70 | loss 0.05220689\n",
      "| Epoch 211 |   500/  658 batches | lr 0.00006 | ms/batch 14.47 | loss 0.05705879\n",
      "| Epoch 211 |   550/  658 batches | lr 0.00006 | ms/batch 14.40 | loss 0.05539659\n",
      "| Epoch 211 |   600/  658 batches | lr 0.00006 | ms/batch 12.73 | loss 0.05773894\n",
      "| Epoch 211 |   650/  658 batches | lr 0.00006 | ms/batch 12.63 | loss 0.05488589\n",
      "\n",
      "Val set: Average loss: 0.05799228\n",
      "\n",
      "| Epoch 212 |    50/  658 batches | lr 0.00006 | ms/batch 12.91 | loss 0.06058952\n",
      "| Epoch 212 |   100/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.05696024\n",
      "| Epoch 212 |   150/  658 batches | lr 0.00006 | ms/batch 12.70 | loss 0.05443062\n",
      "| Epoch 212 |   200/  658 batches | lr 0.00006 | ms/batch 14.41 | loss 0.05379758\n",
      "| Epoch 212 |   250/  658 batches | lr 0.00006 | ms/batch 14.32 | loss 0.05730688\n",
      "| Epoch 212 |   300/  658 batches | lr 0.00006 | ms/batch 12.66 | loss 0.05735192\n",
      "| Epoch 212 |   350/  658 batches | lr 0.00006 | ms/batch 12.62 | loss 0.05851070\n",
      "| Epoch 212 |   400/  658 batches | lr 0.00006 | ms/batch 15.11 | loss 0.05608071\n",
      "| Epoch 212 |   450/  658 batches | lr 0.00006 | ms/batch 12.69 | loss 0.05220168\n",
      "| Epoch 212 |   500/  658 batches | lr 0.00006 | ms/batch 14.39 | loss 0.05716238\n",
      "| Epoch 212 |   550/  658 batches | lr 0.00006 | ms/batch 14.35 | loss 0.05543672\n",
      "| Epoch 212 |   600/  658 batches | lr 0.00006 | ms/batch 12.63 | loss 0.05763263\n",
      "| Epoch 212 |   650/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.05492405\n",
      "\n",
      "Val set: Average loss: 0.05830070\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 213 |    50/  658 batches | lr 0.00006 | ms/batch 12.83 | loss 0.06062446\n",
      "| Epoch 213 |   100/  658 batches | lr 0.00006 | ms/batch 14.25 | loss 0.05723342\n",
      "| Epoch 213 |   150/  658 batches | lr 0.00006 | ms/batch 12.67 | loss 0.05405976\n",
      "| Epoch 213 |   200/  658 batches | lr 0.00006 | ms/batch 14.42 | loss 0.05380743\n",
      "| Epoch 213 |   250/  658 batches | lr 0.00006 | ms/batch 14.38 | loss 0.05725190\n",
      "| Epoch 213 |   300/  658 batches | lr 0.00006 | ms/batch 12.67 | loss 0.05745262\n",
      "| Epoch 213 |   350/  658 batches | lr 0.00006 | ms/batch 12.62 | loss 0.05858077\n",
      "| Epoch 213 |   400/  658 batches | lr 0.00006 | ms/batch 14.22 | loss 0.05617134\n",
      "| Epoch 213 |   450/  658 batches | lr 0.00006 | ms/batch 12.79 | loss 0.05218799\n",
      "| Epoch 213 |   500/  658 batches | lr 0.00006 | ms/batch 14.33 | loss 0.05715384\n",
      "| Epoch 213 |   550/  658 batches | lr 0.00006 | ms/batch 14.40 | loss 0.05560364\n",
      "| Epoch 213 |   600/  658 batches | lr 0.00006 | ms/batch 12.63 | loss 0.05761924\n",
      "| Epoch 213 |   650/  658 batches | lr 0.00006 | ms/batch 12.64 | loss 0.05485207\n",
      "\n",
      "Val set: Average loss: 0.05804006\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch 214 |    50/  658 batches | lr 0.00006 | ms/batch 12.88 | loss 0.06050316\n",
      "| Epoch 214 |   100/  658 batches | lr 0.00006 | ms/batch 14.29 | loss 0.05693846\n",
      "| Epoch 214 |   150/  658 batches | lr 0.00006 | ms/batch 12.77 | loss 0.05408501\n",
      "| Epoch 214 |   200/  658 batches | lr 0.00006 | ms/batch 14.35 | loss 0.05383482\n",
      "| Epoch 214 |   250/  658 batches | lr 0.00006 | ms/batch 14.57 | loss 0.05720687\n",
      "| Epoch 214 |   300/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.05724742\n",
      "| Epoch 214 |   350/  658 batches | lr 0.00006 | ms/batch 12.64 | loss 0.05846406\n",
      "| Epoch 214 |   400/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.05607345\n",
      "| Epoch 214 |   450/  658 batches | lr 0.00006 | ms/batch 12.94 | loss 0.05217558\n",
      "| Epoch 214 |   500/  658 batches | lr 0.00006 | ms/batch 14.42 | loss 0.05703769\n",
      "| Epoch 214 |   550/  658 batches | lr 0.00006 | ms/batch 14.22 | loss 0.05537073\n",
      "| Epoch 214 |   600/  658 batches | lr 0.00006 | ms/batch 12.67 | loss 0.05769305\n",
      "| Epoch 214 |   650/  658 batches | lr 0.00006 | ms/batch 12.68 | loss 0.05487336\n",
      "\n",
      "Val set: Average loss: 0.05800529\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch 215 |    50/  658 batches | lr 0.00006 | ms/batch 12.94 | loss 0.06044383\n",
      "| Epoch 215 |   100/  658 batches | lr 0.00006 | ms/batch 14.40 | loss 0.05688205\n",
      "| Epoch 215 |   150/  658 batches | lr 0.00006 | ms/batch 12.82 | loss 0.05406037\n",
      "| Epoch 215 |   200/  658 batches | lr 0.00006 | ms/batch 14.30 | loss 0.05373977\n",
      "| Epoch 215 |   250/  658 batches | lr 0.00006 | ms/batch 14.24 | loss 0.05719325\n",
      "| Epoch 215 |   300/  658 batches | lr 0.00006 | ms/batch 12.66 | loss 0.05732700\n",
      "| Epoch 215 |   350/  658 batches | lr 0.00006 | ms/batch 12.70 | loss 0.05843880\n",
      "| Epoch 215 |   400/  658 batches | lr 0.00006 | ms/batch 14.27 | loss 0.05594461\n",
      "| Epoch 215 |   450/  658 batches | lr 0.00006 | ms/batch 12.63 | loss 0.05212705\n",
      "| Epoch 215 |   500/  658 batches | lr 0.00006 | ms/batch 14.45 | loss 0.05703967\n",
      "| Epoch 215 |   550/  658 batches | lr 0.00006 | ms/batch 15.01 | loss 0.05536558\n",
      "| Epoch 215 |   600/  658 batches | lr 0.00006 | ms/batch 12.72 | loss 0.05769793\n",
      "| Epoch 215 |   650/  658 batches | lr 0.00006 | ms/batch 12.60 | loss 0.05482785\n",
      "\n",
      "Val set: Average loss: 0.05814846\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch 216 |    50/  658 batches | lr 0.00006 | ms/batch 12.80 | loss 0.06039730\n",
      "| Epoch 216 |   100/  658 batches | lr 0.00006 | ms/batch 14.34 | loss 0.05708159\n",
      "| Epoch 216 |   150/  658 batches | lr 0.00006 | ms/batch 12.74 | loss 0.05426895\n",
      "| Epoch 216 |   200/  658 batches | lr 0.00006 | ms/batch 14.31 | loss 0.05360958\n",
      "| Epoch 216 |   250/  658 batches | lr 0.00006 | ms/batch 14.40 | loss 0.05723292\n",
      "| Epoch 216 |   300/  658 batches | lr 0.00006 | ms/batch 12.74 | loss 0.05727870\n",
      "| Epoch 216 |   350/  658 batches | lr 0.00006 | ms/batch 12.71 | loss 0.05847318\n",
      "| Epoch 216 |   400/  658 batches | lr 0.00006 | ms/batch 14.28 | loss 0.05592249\n",
      "| Epoch 216 |   450/  658 batches | lr 0.00006 | ms/batch 12.68 | loss 0.05218583\n",
      "| Epoch 216 |   500/  658 batches | lr 0.00006 | ms/batch 14.36 | loss 0.05691190\n",
      "| Epoch 216 |   550/  658 batches | lr 0.00006 | ms/batch 14.41 | loss 0.05547695\n",
      "| Epoch 216 |   600/  658 batches | lr 0.00006 | ms/batch 12.65 | loss 0.05777946\n",
      "| Epoch 216 |   650/  658 batches | lr 0.00006 | ms/batch 12.67 | loss 0.05479347\n",
      "\n",
      "Val set: Average loss: 0.05796400\n",
      "\n",
      "| Epoch 217 |    50/  658 batches | lr 0.00006 | ms/batch 12.91 | loss 0.06053090\n",
      "| Epoch 217 |   100/  658 batches | lr 0.00006 | ms/batch 14.27 | loss 0.05686259\n",
      "| Epoch 217 |   150/  658 batches | lr 0.00006 | ms/batch 12.74 | loss 0.05395985\n",
      "| Epoch 217 |   200/  658 batches | lr 0.00006 | ms/batch 14.41 | loss 0.05367330\n",
      "| Epoch 217 |   250/  658 batches | lr 0.00006 | ms/batch 14.33 | loss 0.05719767\n",
      "| Epoch 217 |   300/  658 batches | lr 0.00006 | ms/batch 12.65 | loss 0.05721307\n",
      "| Epoch 217 |   350/  658 batches | lr 0.00006 | ms/batch 12.80 | loss 0.05839532\n",
      "| Epoch 217 |   400/  658 batches | lr 0.00006 | ms/batch 14.39 | loss 0.05592881\n",
      "| Epoch 217 |   450/  658 batches | lr 0.00006 | ms/batch 12.76 | loss 0.05211430\n",
      "| Epoch 217 |   500/  658 batches | lr 0.00006 | ms/batch 14.28 | loss 0.05694737\n",
      "| Epoch 217 |   550/  658 batches | lr 0.00006 | ms/batch 14.33 | loss 0.05541446\n",
      "| Epoch 217 |   600/  658 batches | lr 0.00006 | ms/batch 12.68 | loss 0.05791403\n",
      "| Epoch 217 |   650/  658 batches | lr 0.00006 | ms/batch 12.65 | loss 0.05465967\n",
      "\n",
      "Val set: Average loss: 0.05842023\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 218 |    50/  658 batches | lr 0.00006 | ms/batch 12.97 | loss 0.06039986\n",
      "| Epoch 218 |   100/  658 batches | lr 0.00006 | ms/batch 14.28 | loss 0.05713274\n",
      "| Epoch 218 |   150/  658 batches | lr 0.00006 | ms/batch 12.76 | loss 0.05383456\n",
      "| Epoch 218 |   200/  658 batches | lr 0.00006 | ms/batch 14.33 | loss 0.05357196\n",
      "| Epoch 218 |   250/  658 batches | lr 0.00006 | ms/batch 14.31 | loss 0.05723626\n",
      "| Epoch 218 |   300/  658 batches | lr 0.00006 | ms/batch 12.80 | loss 0.05717216\n",
      "| Epoch 218 |   350/  658 batches | lr 0.00006 | ms/batch 12.69 | loss 0.05837776\n",
      "| Epoch 218 |   400/  658 batches | lr 0.00006 | ms/batch 14.45 | loss 0.05594524\n",
      "| Epoch 218 |   450/  658 batches | lr 0.00006 | ms/batch 12.75 | loss 0.05200672\n",
      "| Epoch 218 |   500/  658 batches | lr 0.00006 | ms/batch 14.38 | loss 0.05733402\n",
      "| Epoch 218 |   550/  658 batches | lr 0.00006 | ms/batch 14.35 | loss 0.05604425\n",
      "| Epoch 218 |   600/  658 batches | lr 0.00006 | ms/batch 12.67 | loss 0.05726196\n",
      "| Epoch 218 |   650/  658 batches | lr 0.00006 | ms/batch 12.80 | loss 0.05491421\n",
      "\n",
      "Val set: Average loss: 0.05811749\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch 219 |    50/  658 batches | lr 0.00006 | ms/batch 12.95 | loss 0.06064852\n",
      "| Epoch 219 |   100/  658 batches | lr 0.00006 | ms/batch 14.28 | loss 0.05677650\n",
      "| Epoch 219 |   150/  658 batches | lr 0.00006 | ms/batch 12.71 | loss 0.05447869\n",
      "| Epoch 219 |   200/  658 batches | lr 0.00006 | ms/batch 14.36 | loss 0.05374921\n",
      "| Epoch 219 |   250/  658 batches | lr 0.00006 | ms/batch 14.41 | loss 0.05716287\n",
      "| Epoch 219 |   300/  658 batches | lr 0.00006 | ms/batch 12.67 | loss 0.05682773\n",
      "| Epoch 219 |   350/  658 batches | lr 0.00006 | ms/batch 12.67 | loss 0.05825897\n",
      "| Epoch 219 |   400/  658 batches | lr 0.00006 | ms/batch 14.34 | loss 0.05579985\n",
      "| Epoch 219 |   450/  658 batches | lr 0.00006 | ms/batch 12.81 | loss 0.05199173\n",
      "| Epoch 219 |   500/  658 batches | lr 0.00006 | ms/batch 14.34 | loss 0.05743259\n",
      "| Epoch 219 |   550/  658 batches | lr 0.00006 | ms/batch 14.35 | loss 0.05547429\n",
      "| Epoch 219 |   600/  658 batches | lr 0.00006 | ms/batch 12.66 | loss 0.05733031\n",
      "| Epoch 219 |   650/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.05467898\n",
      "\n",
      "Val set: Average loss: 0.05808528\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch 220 |    50/  658 batches | lr 0.00006 | ms/batch 12.96 | loss 0.06042744\n",
      "| Epoch 220 |   100/  658 batches | lr 0.00006 | ms/batch 14.29 | loss 0.05679746\n",
      "| Epoch 220 |   150/  658 batches | lr 0.00006 | ms/batch 12.71 | loss 0.05412731\n",
      "| Epoch 220 |   200/  658 batches | lr 0.00006 | ms/batch 14.40 | loss 0.05359019\n",
      "| Epoch 220 |   250/  658 batches | lr 0.00006 | ms/batch 14.26 | loss 0.05711887\n",
      "| Epoch 220 |   300/  658 batches | lr 0.00006 | ms/batch 12.73 | loss 0.05712454\n",
      "| Epoch 220 |   350/  658 batches | lr 0.00006 | ms/batch 12.63 | loss 0.05841522\n",
      "| Epoch 220 |   400/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.05584925\n",
      "| Epoch 220 |   450/  658 batches | lr 0.00006 | ms/batch 12.75 | loss 0.05187005\n",
      "| Epoch 220 |   500/  658 batches | lr 0.00006 | ms/batch 14.50 | loss 0.05690965\n",
      "| Epoch 220 |   550/  658 batches | lr 0.00006 | ms/batch 14.34 | loss 0.05536509\n",
      "| Epoch 220 |   600/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.05726366\n",
      "| Epoch 220 |   650/  658 batches | lr 0.00006 | ms/batch 12.58 | loss 0.05452463\n",
      "\n",
      "Val set: Average loss: 0.05794526\n",
      "\n",
      "| Epoch 221 |    50/  658 batches | lr 0.00006 | ms/batch 12.94 | loss 0.06032758\n",
      "| Epoch 221 |   100/  658 batches | lr 0.00006 | ms/batch 14.19 | loss 0.05662744\n",
      "| Epoch 221 |   150/  658 batches | lr 0.00006 | ms/batch 12.76 | loss 0.05390695\n",
      "| Epoch 221 |   200/  658 batches | lr 0.00006 | ms/batch 14.44 | loss 0.05353835\n",
      "| Epoch 221 |   250/  658 batches | lr 0.00006 | ms/batch 14.35 | loss 0.05707215\n",
      "| Epoch 221 |   300/  658 batches | lr 0.00006 | ms/batch 12.58 | loss 0.05711279\n",
      "| Epoch 221 |   350/  658 batches | lr 0.00006 | ms/batch 12.62 | loss 0.05830641\n",
      "| Epoch 221 |   400/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.05571782\n",
      "| Epoch 221 |   450/  658 batches | lr 0.00006 | ms/batch 12.63 | loss 0.05182198\n",
      "| Epoch 221 |   500/  658 batches | lr 0.00006 | ms/batch 14.35 | loss 0.05693921\n",
      "| Epoch 221 |   550/  658 batches | lr 0.00006 | ms/batch 14.37 | loss 0.05520996\n",
      "| Epoch 221 |   600/  658 batches | lr 0.00006 | ms/batch 12.64 | loss 0.05754959\n",
      "| Epoch 221 |   650/  658 batches | lr 0.00006 | ms/batch 12.70 | loss 0.05456962\n",
      "\n",
      "Val set: Average loss: 0.05819665\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 222 |    50/  658 batches | lr 0.00006 | ms/batch 12.99 | loss 0.06023986\n",
      "| Epoch 222 |   100/  658 batches | lr 0.00006 | ms/batch 14.61 | loss 0.05675731\n",
      "| Epoch 222 |   150/  658 batches | lr 0.00006 | ms/batch 12.89 | loss 0.05378287\n",
      "| Epoch 222 |   200/  658 batches | lr 0.00006 | ms/batch 14.34 | loss 0.05351051\n",
      "| Epoch 222 |   250/  658 batches | lr 0.00006 | ms/batch 14.37 | loss 0.05701813\n",
      "| Epoch 222 |   300/  658 batches | lr 0.00006 | ms/batch 12.52 | loss 0.05713663\n",
      "| Epoch 222 |   350/  658 batches | lr 0.00006 | ms/batch 12.62 | loss 0.05830370\n",
      "| Epoch 222 |   400/  658 batches | lr 0.00006 | ms/batch 14.32 | loss 0.05581808\n",
      "| Epoch 222 |   450/  658 batches | lr 0.00006 | ms/batch 12.66 | loss 0.05198071\n",
      "| Epoch 222 |   500/  658 batches | lr 0.00006 | ms/batch 14.53 | loss 0.05699514\n",
      "| Epoch 222 |   550/  658 batches | lr 0.00006 | ms/batch 14.41 | loss 0.05546892\n",
      "| Epoch 222 |   600/  658 batches | lr 0.00006 | ms/batch 12.60 | loss 0.05717427\n",
      "| Epoch 222 |   650/  658 batches | lr 0.00006 | ms/batch 12.63 | loss 0.05447941\n",
      "\n",
      "Val set: Average loss: 0.05820337\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch 223 |    50/  658 batches | lr 0.00006 | ms/batch 12.88 | loss 0.06026257\n",
      "| Epoch 223 |   100/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.05673297\n",
      "| Epoch 223 |   150/  658 batches | lr 0.00006 | ms/batch 12.77 | loss 0.05369178\n",
      "| Epoch 223 |   200/  658 batches | lr 0.00006 | ms/batch 14.39 | loss 0.05334817\n",
      "| Epoch 223 |   250/  658 batches | lr 0.00006 | ms/batch 14.40 | loss 0.05694817\n",
      "| Epoch 223 |   300/  658 batches | lr 0.00006 | ms/batch 12.66 | loss 0.05696813\n",
      "| Epoch 223 |   350/  658 batches | lr 0.00006 | ms/batch 12.69 | loss 0.05821584\n",
      "| Epoch 223 |   400/  658 batches | lr 0.00006 | ms/batch 14.22 | loss 0.05575256\n",
      "| Epoch 223 |   450/  658 batches | lr 0.00006 | ms/batch 12.78 | loss 0.05198889\n",
      "| Epoch 223 |   500/  658 batches | lr 0.00006 | ms/batch 14.46 | loss 0.05683820\n",
      "| Epoch 223 |   550/  658 batches | lr 0.00006 | ms/batch 14.29 | loss 0.05510470\n",
      "| Epoch 223 |   600/  658 batches | lr 0.00006 | ms/batch 12.70 | loss 0.05723870\n",
      "| Epoch 223 |   650/  658 batches | lr 0.00006 | ms/batch 12.67 | loss 0.05449106\n",
      "\n",
      "Val set: Average loss: 0.05808710\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch 224 |    50/  658 batches | lr 0.00006 | ms/batch 12.92 | loss 0.06019371\n",
      "| Epoch 224 |   100/  658 batches | lr 0.00006 | ms/batch 14.25 | loss 0.05664249\n",
      "| Epoch 224 |   150/  658 batches | lr 0.00006 | ms/batch 12.83 | loss 0.05364045\n",
      "| Epoch 224 |   200/  658 batches | lr 0.00006 | ms/batch 14.36 | loss 0.05333644\n",
      "| Epoch 224 |   250/  658 batches | lr 0.00006 | ms/batch 14.37 | loss 0.05695305\n",
      "| Epoch 224 |   300/  658 batches | lr 0.00006 | ms/batch 12.77 | loss 0.05632014\n",
      "| Epoch 224 |   350/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.05810731\n",
      "| Epoch 224 |   400/  658 batches | lr 0.00006 | ms/batch 14.33 | loss 0.05563951\n",
      "| Epoch 224 |   450/  658 batches | lr 0.00006 | ms/batch 12.70 | loss 0.05182741\n",
      "| Epoch 224 |   500/  658 batches | lr 0.00006 | ms/batch 14.37 | loss 0.05668649\n",
      "| Epoch 224 |   550/  658 batches | lr 0.00006 | ms/batch 14.32 | loss 0.05539705\n",
      "| Epoch 224 |   600/  658 batches | lr 0.00006 | ms/batch 12.69 | loss 0.05717480\n",
      "| Epoch 224 |   650/  658 batches | lr 0.00006 | ms/batch 12.64 | loss 0.05454822\n",
      "\n",
      "Val set: Average loss: 0.05799834\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch 225 |    50/  658 batches | lr 0.00006 | ms/batch 12.91 | loss 0.06009957\n",
      "| Epoch 225 |   100/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.05653571\n",
      "| Epoch 225 |   150/  658 batches | lr 0.00006 | ms/batch 12.67 | loss 0.05356731\n",
      "| Epoch 225 |   200/  658 batches | lr 0.00006 | ms/batch 14.35 | loss 0.05333181\n",
      "| Epoch 225 |   250/  658 batches | lr 0.00006 | ms/batch 14.58 | loss 0.05686715\n",
      "| Epoch 225 |   300/  658 batches | lr 0.00006 | ms/batch 13.28 | loss 0.05615221\n",
      "| Epoch 225 |   350/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.05807594\n",
      "| Epoch 225 |   400/  658 batches | lr 0.00006 | ms/batch 14.27 | loss 0.05556556\n",
      "| Epoch 225 |   450/  658 batches | lr 0.00006 | ms/batch 12.71 | loss 0.05164444\n",
      "| Epoch 225 |   500/  658 batches | lr 0.00006 | ms/batch 14.34 | loss 0.05670759\n",
      "| Epoch 225 |   550/  658 batches | lr 0.00006 | ms/batch 14.41 | loss 0.05541956\n",
      "| Epoch 225 |   600/  658 batches | lr 0.00006 | ms/batch 12.64 | loss 0.05715631\n",
      "| Epoch 225 |   650/  658 batches | lr 0.00006 | ms/batch 12.58 | loss 0.05445488\n",
      "\n",
      "Val set: Average loss: 0.05791035\n",
      "\n",
      "| Epoch 226 |    50/  658 batches | lr 0.00006 | ms/batch 12.89 | loss 0.06008561\n",
      "| Epoch 226 |   100/  658 batches | lr 0.00006 | ms/batch 14.34 | loss 0.05646050\n",
      "| Epoch 226 |   150/  658 batches | lr 0.00006 | ms/batch 12.75 | loss 0.05358608\n",
      "| Epoch 226 |   200/  658 batches | lr 0.00006 | ms/batch 14.35 | loss 0.05316231\n",
      "| Epoch 226 |   250/  658 batches | lr 0.00006 | ms/batch 14.24 | loss 0.05681137\n",
      "| Epoch 226 |   300/  658 batches | lr 0.00006 | ms/batch 12.67 | loss 0.05673012\n",
      "| Epoch 226 |   350/  658 batches | lr 0.00006 | ms/batch 12.70 | loss 0.05828821\n",
      "| Epoch 226 |   400/  658 batches | lr 0.00006 | ms/batch 14.33 | loss 0.05561080\n",
      "| Epoch 226 |   450/  658 batches | lr 0.00006 | ms/batch 12.75 | loss 0.05153030\n",
      "| Epoch 226 |   500/  658 batches | lr 0.00006 | ms/batch 14.26 | loss 0.05701369\n",
      "| Epoch 226 |   550/  658 batches | lr 0.00006 | ms/batch 14.42 | loss 0.05509060\n",
      "| Epoch 226 |   600/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.05722444\n",
      "| Epoch 226 |   650/  658 batches | lr 0.00006 | ms/batch 12.76 | loss 0.05454120\n",
      "\n",
      "Val set: Average loss: 0.05816399\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 227 |    50/  658 batches | lr 0.00006 | ms/batch 12.99 | loss 0.05980533\n",
      "| Epoch 227 |   100/  658 batches | lr 0.00006 | ms/batch 14.31 | loss 0.05672747\n",
      "| Epoch 227 |   150/  658 batches | lr 0.00006 | ms/batch 12.78 | loss 0.05356921\n",
      "| Epoch 227 |   200/  658 batches | lr 0.00006 | ms/batch 14.39 | loss 0.05330041\n",
      "| Epoch 227 |   250/  658 batches | lr 0.00006 | ms/batch 14.32 | loss 0.05679947\n",
      "| Epoch 227 |   300/  658 batches | lr 0.00006 | ms/batch 12.63 | loss 0.05642563\n",
      "| Epoch 227 |   350/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.05802393\n",
      "| Epoch 227 |   400/  658 batches | lr 0.00006 | ms/batch 14.27 | loss 0.05564640\n",
      "| Epoch 227 |   450/  658 batches | lr 0.00006 | ms/batch 12.74 | loss 0.05163199\n",
      "| Epoch 227 |   500/  658 batches | lr 0.00006 | ms/batch 14.30 | loss 0.05670363\n",
      "| Epoch 227 |   550/  658 batches | lr 0.00006 | ms/batch 14.36 | loss 0.05514943\n",
      "| Epoch 227 |   600/  658 batches | lr 0.00006 | ms/batch 12.65 | loss 0.05730589\n",
      "| Epoch 227 |   650/  658 batches | lr 0.00006 | ms/batch 12.60 | loss 0.05442600\n",
      "\n",
      "Val set: Average loss: 0.05830030\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch 228 |    50/  658 batches | lr 0.00006 | ms/batch 13.06 | loss 0.05996887\n",
      "| Epoch 228 |   100/  658 batches | lr 0.00006 | ms/batch 14.26 | loss 0.05660881\n",
      "| Epoch 228 |   150/  658 batches | lr 0.00006 | ms/batch 12.75 | loss 0.05352073\n",
      "| Epoch 228 |   200/  658 batches | lr 0.00006 | ms/batch 14.45 | loss 0.05314226\n",
      "| Epoch 228 |   250/  658 batches | lr 0.00006 | ms/batch 14.30 | loss 0.05677344\n",
      "| Epoch 228 |   300/  658 batches | lr 0.00006 | ms/batch 12.78 | loss 0.05683193\n",
      "| Epoch 228 |   350/  658 batches | lr 0.00006 | ms/batch 12.78 | loss 0.05806912\n",
      "| Epoch 228 |   400/  658 batches | lr 0.00006 | ms/batch 14.71 | loss 0.05554925\n",
      "| Epoch 228 |   450/  658 batches | lr 0.00006 | ms/batch 12.90 | loss 0.05172524\n",
      "| Epoch 228 |   500/  658 batches | lr 0.00006 | ms/batch 14.43 | loss 0.05685535\n",
      "| Epoch 228 |   550/  658 batches | lr 0.00006 | ms/batch 14.25 | loss 0.05540432\n",
      "| Epoch 228 |   600/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.05705958\n",
      "| Epoch 228 |   650/  658 batches | lr 0.00006 | ms/batch 12.59 | loss 0.05431625\n",
      "\n",
      "Val set: Average loss: 0.05804988\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch 229 |    50/  658 batches | lr 0.00006 | ms/batch 12.93 | loss 0.05990337\n",
      "| Epoch 229 |   100/  658 batches | lr 0.00006 | ms/batch 14.42 | loss 0.05641572\n",
      "| Epoch 229 |   150/  658 batches | lr 0.00006 | ms/batch 12.69 | loss 0.05353265\n",
      "| Epoch 229 |   200/  658 batches | lr 0.00006 | ms/batch 14.46 | loss 0.05307938\n",
      "| Epoch 229 |   250/  658 batches | lr 0.00006 | ms/batch 14.33 | loss 0.05673720\n",
      "| Epoch 229 |   300/  658 batches | lr 0.00006 | ms/batch 12.68 | loss 0.05665605\n",
      "| Epoch 229 |   350/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.05810003\n",
      "| Epoch 229 |   400/  658 batches | lr 0.00006 | ms/batch 14.22 | loss 0.05557275\n",
      "| Epoch 229 |   450/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.05146378\n",
      "| Epoch 229 |   500/  658 batches | lr 0.00006 | ms/batch 14.46 | loss 0.05656841\n",
      "| Epoch 229 |   550/  658 batches | lr 0.00006 | ms/batch 14.32 | loss 0.05513739\n",
      "| Epoch 229 |   600/  658 batches | lr 0.00006 | ms/batch 12.62 | loss 0.05699058\n",
      "| Epoch 229 |   650/  658 batches | lr 0.00006 | ms/batch 12.64 | loss 0.05435079\n",
      "\n",
      "Val set: Average loss: 0.05784242\n",
      "\n",
      "| Epoch 230 |    50/  658 batches | lr 0.00006 | ms/batch 12.83 | loss 0.05994876\n",
      "| Epoch 230 |   100/  658 batches | lr 0.00006 | ms/batch 14.25 | loss 0.05640272\n",
      "| Epoch 230 |   150/  658 batches | lr 0.00006 | ms/batch 12.87 | loss 0.05341195\n",
      "| Epoch 230 |   200/  658 batches | lr 0.00006 | ms/batch 14.33 | loss 0.05321362\n",
      "| Epoch 230 |   250/  658 batches | lr 0.00006 | ms/batch 14.27 | loss 0.05677219\n",
      "| Epoch 230 |   300/  658 batches | lr 0.00006 | ms/batch 12.67 | loss 0.05656084\n",
      "| Epoch 230 |   350/  658 batches | lr 0.00006 | ms/batch 12.64 | loss 0.05798583\n",
      "| Epoch 230 |   400/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.05543015\n",
      "| Epoch 230 |   450/  658 batches | lr 0.00006 | ms/batch 12.69 | loss 0.05135955\n",
      "| Epoch 230 |   500/  658 batches | lr 0.00006 | ms/batch 14.30 | loss 0.05663290\n",
      "| Epoch 230 |   550/  658 batches | lr 0.00006 | ms/batch 14.35 | loss 0.05484998\n",
      "| Epoch 230 |   600/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.05706191\n",
      "| Epoch 230 |   650/  658 batches | lr 0.00006 | ms/batch 12.58 | loss 0.05434316\n",
      "\n",
      "Val set: Average loss: 0.05787501\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 231 |    50/  658 batches | lr 0.00006 | ms/batch 12.92 | loss 0.05991643\n",
      "| Epoch 231 |   100/  658 batches | lr 0.00006 | ms/batch 14.32 | loss 0.05643817\n",
      "| Epoch 231 |   150/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.05332444\n",
      "| Epoch 231 |   200/  658 batches | lr 0.00006 | ms/batch 14.37 | loss 0.05320070\n",
      "| Epoch 231 |   250/  658 batches | lr 0.00006 | ms/batch 14.25 | loss 0.05671465\n",
      "| Epoch 231 |   300/  658 batches | lr 0.00006 | ms/batch 12.67 | loss 0.05599736\n",
      "| Epoch 231 |   350/  658 batches | lr 0.00006 | ms/batch 12.58 | loss 0.05789361\n",
      "| Epoch 231 |   400/  658 batches | lr 0.00006 | ms/batch 14.29 | loss 0.05549953\n",
      "| Epoch 231 |   450/  658 batches | lr 0.00006 | ms/batch 12.64 | loss 0.05160284\n",
      "| Epoch 231 |   500/  658 batches | lr 0.00006 | ms/batch 14.50 | loss 0.05660531\n",
      "| Epoch 231 |   550/  658 batches | lr 0.00006 | ms/batch 14.79 | loss 0.05497645\n",
      "| Epoch 231 |   600/  658 batches | lr 0.00006 | ms/batch 12.66 | loss 0.05730318\n",
      "| Epoch 231 |   650/  658 batches | lr 0.00006 | ms/batch 12.62 | loss 0.05431566\n",
      "\n",
      "Val set: Average loss: 0.05793149\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch 232 |    50/  658 batches | lr 0.00006 | ms/batch 12.93 | loss 0.05987692\n",
      "| Epoch 232 |   100/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.05641202\n",
      "| Epoch 232 |   150/  658 batches | lr 0.00006 | ms/batch 12.70 | loss 0.05333374\n",
      "| Epoch 232 |   200/  658 batches | lr 0.00006 | ms/batch 14.44 | loss 0.05302785\n",
      "| Epoch 232 |   250/  658 batches | lr 0.00006 | ms/batch 14.33 | loss 0.05670001\n",
      "| Epoch 232 |   300/  658 batches | lr 0.00006 | ms/batch 12.70 | loss 0.05645776\n",
      "| Epoch 232 |   350/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.05795197\n",
      "| Epoch 232 |   400/  658 batches | lr 0.00006 | ms/batch 14.21 | loss 0.05531752\n",
      "| Epoch 232 |   450/  658 batches | lr 0.00006 | ms/batch 12.65 | loss 0.05128236\n",
      "| Epoch 232 |   500/  658 batches | lr 0.00006 | ms/batch 14.38 | loss 0.05642821\n",
      "| Epoch 232 |   550/  658 batches | lr 0.00006 | ms/batch 14.31 | loss 0.05493595\n",
      "| Epoch 232 |   600/  658 batches | lr 0.00006 | ms/batch 12.68 | loss 0.05734355\n",
      "| Epoch 232 |   650/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.05417327\n",
      "\n",
      "Val set: Average loss: 0.05804270\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch 233 |    50/  658 batches | lr 0.00006 | ms/batch 12.86 | loss 0.05967236\n",
      "| Epoch 233 |   100/  658 batches | lr 0.00006 | ms/batch 14.18 | loss 0.05659026\n",
      "| Epoch 233 |   150/  658 batches | lr 0.00006 | ms/batch 12.66 | loss 0.05335694\n",
      "| Epoch 233 |   200/  658 batches | lr 0.00006 | ms/batch 14.36 | loss 0.05302927\n",
      "| Epoch 233 |   250/  658 batches | lr 0.00006 | ms/batch 14.33 | loss 0.05673768\n",
      "| Epoch 233 |   300/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.05656003\n",
      "| Epoch 233 |   350/  658 batches | lr 0.00006 | ms/batch 12.63 | loss 0.05780516\n",
      "| Epoch 233 |   400/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.05518570\n",
      "| Epoch 233 |   450/  658 batches | lr 0.00006 | ms/batch 12.59 | loss 0.05129368\n",
      "| Epoch 233 |   500/  658 batches | lr 0.00006 | ms/batch 14.31 | loss 0.05679131\n",
      "| Epoch 233 |   550/  658 batches | lr 0.00006 | ms/batch 14.25 | loss 0.05486757\n",
      "| Epoch 233 |   600/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.05735292\n",
      "| Epoch 233 |   650/  658 batches | lr 0.00006 | ms/batch 12.60 | loss 0.05420446\n",
      "\n",
      "Val set: Average loss: 0.05805261\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch 234 |    50/  658 batches | lr 0.00006 | ms/batch 12.89 | loss 0.05966682\n",
      "| Epoch 234 |   100/  658 batches | lr 0.00006 | ms/batch 14.33 | loss 0.05650240\n",
      "| Epoch 234 |   150/  658 batches | lr 0.00006 | ms/batch 12.76 | loss 0.05321354\n",
      "| Epoch 234 |   200/  658 batches | lr 0.00006 | ms/batch 14.36 | loss 0.05291250\n",
      "| Epoch 234 |   250/  658 batches | lr 0.00006 | ms/batch 14.25 | loss 0.05673290\n",
      "| Epoch 234 |   300/  658 batches | lr 0.00006 | ms/batch 12.77 | loss 0.05596596\n",
      "| Epoch 234 |   350/  658 batches | lr 0.00006 | ms/batch 12.68 | loss 0.05780152\n",
      "| Epoch 234 |   400/  658 batches | lr 0.00006 | ms/batch 14.25 | loss 0.05526102\n",
      "| Epoch 234 |   450/  658 batches | lr 0.00006 | ms/batch 12.69 | loss 0.05152591\n",
      "| Epoch 234 |   500/  658 batches | lr 0.00006 | ms/batch 14.43 | loss 0.05647661\n",
      "| Epoch 234 |   550/  658 batches | lr 0.00006 | ms/batch 14.48 | loss 0.05494952\n",
      "| Epoch 234 |   600/  658 batches | lr 0.00006 | ms/batch 12.77 | loss 0.05681094\n",
      "| Epoch 234 |   650/  658 batches | lr 0.00006 | ms/batch 12.91 | loss 0.05418235\n",
      "\n",
      "Val set: Average loss: 0.05813187\n",
      "\n",
      "EarlyStopping counter: 5 out of 20\n",
      "| Epoch 235 |    50/  658 batches | lr 0.00006 | ms/batch 13.04 | loss 0.05964408\n",
      "| Epoch 235 |   100/  658 batches | lr 0.00006 | ms/batch 14.26 | loss 0.05645912\n",
      "| Epoch 235 |   150/  658 batches | lr 0.00006 | ms/batch 12.71 | loss 0.05319466\n",
      "| Epoch 235 |   200/  658 batches | lr 0.00006 | ms/batch 15.20 | loss 0.05299785\n",
      "| Epoch 235 |   250/  658 batches | lr 0.00006 | ms/batch 14.41 | loss 0.05658437\n",
      "| Epoch 235 |   300/  658 batches | lr 0.00006 | ms/batch 13.05 | loss 0.05636139\n",
      "| Epoch 235 |   350/  658 batches | lr 0.00006 | ms/batch 13.05 | loss 0.05782124\n",
      "| Epoch 235 |   400/  658 batches | lr 0.00006 | ms/batch 14.58 | loss 0.05514502\n",
      "| Epoch 235 |   450/  658 batches | lr 0.00006 | ms/batch 12.73 | loss 0.05122614\n",
      "| Epoch 235 |   500/  658 batches | lr 0.00006 | ms/batch 14.98 | loss 0.05667063\n",
      "| Epoch 235 |   550/  658 batches | lr 0.00006 | ms/batch 14.54 | loss 0.05489152\n",
      "| Epoch 235 |   600/  658 batches | lr 0.00006 | ms/batch 12.82 | loss 0.05712244\n",
      "| Epoch 235 |   650/  658 batches | lr 0.00006 | ms/batch 12.83 | loss 0.05435046\n",
      "\n",
      "Val set: Average loss: 0.05796393\n",
      "\n",
      "EarlyStopping counter: 6 out of 20\n",
      "| Epoch 236 |    50/  658 batches | lr 0.00006 | ms/batch 13.28 | loss 0.05972379\n",
      "| Epoch 236 |   100/  658 batches | lr 0.00006 | ms/batch 15.29 | loss 0.05625897\n",
      "| Epoch 236 |   150/  658 batches | lr 0.00006 | ms/batch 12.84 | loss 0.05328438\n",
      "| Epoch 236 |   200/  658 batches | lr 0.00006 | ms/batch 15.08 | loss 0.05305842\n",
      "| Epoch 236 |   250/  658 batches | lr 0.00006 | ms/batch 14.48 | loss 0.05665934\n",
      "| Epoch 236 |   300/  658 batches | lr 0.00006 | ms/batch 13.33 | loss 0.05597935\n",
      "| Epoch 236 |   350/  658 batches | lr 0.00006 | ms/batch 13.12 | loss 0.05776922\n",
      "| Epoch 236 |   400/  658 batches | lr 0.00006 | ms/batch 15.10 | loss 0.05527373\n",
      "| Epoch 236 |   450/  658 batches | lr 0.00006 | ms/batch 12.91 | loss 0.05138030\n",
      "| Epoch 236 |   500/  658 batches | lr 0.00006 | ms/batch 15.02 | loss 0.05636947\n",
      "| Epoch 236 |   550/  658 batches | lr 0.00006 | ms/batch 14.37 | loss 0.05488155\n",
      "| Epoch 236 |   600/  658 batches | lr 0.00006 | ms/batch 13.96 | loss 0.05698841\n",
      "| Epoch 236 |   650/  658 batches | lr 0.00006 | ms/batch 12.85 | loss 0.05436078\n",
      "\n",
      "Val set: Average loss: 0.05800753\n",
      "\n",
      "EarlyStopping counter: 7 out of 20\n",
      "| Epoch 237 |    50/  658 batches | lr 0.00006 | ms/batch 13.13 | loss 0.05969451\n",
      "| Epoch 237 |   100/  658 batches | lr 0.00006 | ms/batch 14.99 | loss 0.05624585\n",
      "| Epoch 237 |   150/  658 batches | lr 0.00006 | ms/batch 12.73 | loss 0.05325149\n",
      "| Epoch 237 |   200/  658 batches | lr 0.00006 | ms/batch 14.94 | loss 0.05301688\n",
      "| Epoch 237 |   250/  658 batches | lr 0.00006 | ms/batch 14.49 | loss 0.05660570\n",
      "| Epoch 237 |   300/  658 batches | lr 0.00006 | ms/batch 13.02 | loss 0.05628326\n",
      "| Epoch 237 |   350/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.05781001\n",
      "| Epoch 237 |   400/  658 batches | lr 0.00006 | ms/batch 14.65 | loss 0.05514408\n",
      "| Epoch 237 |   450/  658 batches | lr 0.00006 | ms/batch 12.74 | loss 0.05114164\n",
      "| Epoch 237 |   500/  658 batches | lr 0.00006 | ms/batch 15.28 | loss 0.05627926\n",
      "| Epoch 237 |   550/  658 batches | lr 0.00006 | ms/batch 14.68 | loss 0.05460852\n",
      "| Epoch 237 |   600/  658 batches | lr 0.00006 | ms/batch 13.23 | loss 0.05706759\n",
      "| Epoch 237 |   650/  658 batches | lr 0.00006 | ms/batch 12.79 | loss 0.05405869\n",
      "\n",
      "Val set: Average loss: 0.05799694\n",
      "\n",
      "EarlyStopping counter: 8 out of 20\n",
      "| Epoch 238 |    50/  658 batches | lr 0.00006 | ms/batch 13.28 | loss 0.05956611\n",
      "| Epoch 238 |   100/  658 batches | lr 0.00006 | ms/batch 14.85 | loss 0.05628781\n",
      "| Epoch 238 |   150/  658 batches | lr 0.00006 | ms/batch 12.75 | loss 0.05321732\n",
      "| Epoch 238 |   200/  658 batches | lr 0.00006 | ms/batch 14.81 | loss 0.05282964\n",
      "| Epoch 238 |   250/  658 batches | lr 0.00006 | ms/batch 14.51 | loss 0.05653466\n",
      "| Epoch 238 |   300/  658 batches | lr 0.00006 | ms/batch 12.76 | loss 0.05630265\n",
      "| Epoch 238 |   350/  658 batches | lr 0.00006 | ms/batch 12.70 | loss 0.05762783\n",
      "| Epoch 238 |   400/  658 batches | lr 0.00006 | ms/batch 15.23 | loss 0.05521149\n",
      "| Epoch 238 |   450/  658 batches | lr 0.00006 | ms/batch 12.82 | loss 0.05118217\n",
      "| Epoch 238 |   500/  658 batches | lr 0.00006 | ms/batch 15.08 | loss 0.05659818\n",
      "| Epoch 238 |   550/  658 batches | lr 0.00006 | ms/batch 14.41 | loss 0.05474327\n",
      "| Epoch 238 |   600/  658 batches | lr 0.00006 | ms/batch 12.88 | loss 0.05707564\n",
      "| Epoch 238 |   650/  658 batches | lr 0.00006 | ms/batch 12.67 | loss 0.05408888\n",
      "\n",
      "Val set: Average loss: 0.05792328\n",
      "\n",
      "EarlyStopping counter: 9 out of 20\n",
      "| Epoch 239 |    50/  658 batches | lr 0.00006 | ms/batch 13.32 | loss 0.05970327\n",
      "| Epoch 239 |   100/  658 batches | lr 0.00006 | ms/batch 14.56 | loss 0.05617736\n",
      "| Epoch 239 |   150/  658 batches | lr 0.00006 | ms/batch 12.87 | loss 0.05304307\n",
      "| Epoch 239 |   200/  658 batches | lr 0.00006 | ms/batch 15.13 | loss 0.05292486\n",
      "| Epoch 239 |   250/  658 batches | lr 0.00006 | ms/batch 14.53 | loss 0.05658223\n",
      "| Epoch 239 |   300/  658 batches | lr 0.00006 | ms/batch 13.03 | loss 0.05582175\n",
      "| Epoch 239 |   350/  658 batches | lr 0.00006 | ms/batch 12.59 | loss 0.05765072\n",
      "| Epoch 239 |   400/  658 batches | lr 0.00006 | ms/batch 15.03 | loss 0.05508692\n",
      "| Epoch 239 |   450/  658 batches | lr 0.00006 | ms/batch 12.88 | loss 0.05148523\n",
      "| Epoch 239 |   500/  658 batches | lr 0.00006 | ms/batch 14.84 | loss 0.05656635\n",
      "| Epoch 239 |   550/  658 batches | lr 0.00006 | ms/batch 14.44 | loss 0.05497940\n",
      "| Epoch 239 |   600/  658 batches | lr 0.00006 | ms/batch 13.47 | loss 0.05701686\n",
      "| Epoch 239 |   650/  658 batches | lr 0.00006 | ms/batch 12.77 | loss 0.05424782\n",
      "\n",
      "Val set: Average loss: 0.05800272\n",
      "\n",
      "EarlyStopping counter: 10 out of 20\n",
      "| Epoch 240 |    50/  658 batches | lr 0.00006 | ms/batch 13.34 | loss 0.05982752\n",
      "| Epoch 240 |   100/  658 batches | lr 0.00006 | ms/batch 15.04 | loss 0.05624998\n",
      "| Epoch 240 |   150/  658 batches | lr 0.00006 | ms/batch 12.92 | loss 0.05325220\n",
      "| Epoch 240 |   200/  658 batches | lr 0.00006 | ms/batch 15.03 | loss 0.05270937\n",
      "| Epoch 240 |   250/  658 batches | lr 0.00006 | ms/batch 14.42 | loss 0.05624005\n",
      "| Epoch 240 |   300/  658 batches | lr 0.00006 | ms/batch 13.30 | loss 0.05637841\n",
      "| Epoch 240 |   350/  658 batches | lr 0.00006 | ms/batch 12.87 | loss 0.05767051\n",
      "| Epoch 240 |   400/  658 batches | lr 0.00006 | ms/batch 14.88 | loss 0.05503537\n",
      "| Epoch 240 |   450/  658 batches | lr 0.00006 | ms/batch 12.89 | loss 0.05109952\n",
      "| Epoch 240 |   500/  658 batches | lr 0.00006 | ms/batch 14.87 | loss 0.05628357\n",
      "| Epoch 240 |   550/  658 batches | lr 0.00006 | ms/batch 14.47 | loss 0.05472952\n",
      "| Epoch 240 |   600/  658 batches | lr 0.00006 | ms/batch 13.25 | loss 0.05678555\n",
      "| Epoch 240 |   650/  658 batches | lr 0.00006 | ms/batch 12.88 | loss 0.05429252\n",
      "\n",
      "Val set: Average loss: 0.05799560\n",
      "\n",
      "EarlyStopping counter: 11 out of 20\n",
      "| Epoch 241 |    50/  658 batches | lr 0.00006 | ms/batch 13.29 | loss 0.05984411\n",
      "| Epoch 241 |   100/  658 batches | lr 0.00006 | ms/batch 15.15 | loss 0.05628782\n",
      "| Epoch 241 |   150/  658 batches | lr 0.00006 | ms/batch 12.84 | loss 0.05324788\n",
      "| Epoch 241 |   200/  658 batches | lr 0.00006 | ms/batch 14.94 | loss 0.05266482\n",
      "| Epoch 241 |   250/  658 batches | lr 0.00006 | ms/batch 14.51 | loss 0.05638921\n",
      "| Epoch 241 |   300/  658 batches | lr 0.00006 | ms/batch 13.22 | loss 0.05575425\n",
      "| Epoch 241 |   350/  658 batches | lr 0.00006 | ms/batch 12.91 | loss 0.05761875\n",
      "| Epoch 241 |   400/  658 batches | lr 0.00006 | ms/batch 14.92 | loss 0.05510407\n",
      "| Epoch 241 |   450/  658 batches | lr 0.00006 | ms/batch 13.02 | loss 0.05165522\n",
      "| Epoch 241 |   500/  658 batches | lr 0.00006 | ms/batch 15.00 | loss 0.05627300\n",
      "| Epoch 241 |   550/  658 batches | lr 0.00006 | ms/batch 14.55 | loss 0.05483462\n",
      "| Epoch 241 |   600/  658 batches | lr 0.00006 | ms/batch 12.75 | loss 0.05684609\n",
      "| Epoch 241 |   650/  658 batches | lr 0.00006 | ms/batch 12.60 | loss 0.05400573\n",
      "\n",
      "Val set: Average loss: 0.05786213\n",
      "\n",
      "EarlyStopping counter: 12 out of 20\n",
      "| Epoch 242 |    50/  658 batches | lr 0.00006 | ms/batch 13.29 | loss 0.05943927\n",
      "| Epoch 242 |   100/  658 batches | lr 0.00006 | ms/batch 15.03 | loss 0.05618910\n",
      "| Epoch 242 |   150/  658 batches | lr 0.00006 | ms/batch 12.99 | loss 0.05316674\n",
      "| Epoch 242 |   200/  658 batches | lr 0.00006 | ms/batch 15.09 | loss 0.05263183\n",
      "| Epoch 242 |   250/  658 batches | lr 0.00006 | ms/batch 14.73 | loss 0.05632487\n",
      "| Epoch 242 |   300/  658 batches | lr 0.00006 | ms/batch 13.44 | loss 0.05627506\n",
      "| Epoch 242 |   350/  658 batches | lr 0.00006 | ms/batch 12.84 | loss 0.05749612\n",
      "| Epoch 242 |   400/  658 batches | lr 0.00006 | ms/batch 14.94 | loss 0.05493809\n",
      "| Epoch 242 |   450/  658 batches | lr 0.00006 | ms/batch 12.98 | loss 0.05108785\n",
      "| Epoch 242 |   500/  658 batches | lr 0.00006 | ms/batch 14.92 | loss 0.05678572\n",
      "| Epoch 242 |   550/  658 batches | lr 0.00006 | ms/batch 14.91 | loss 0.05524195\n",
      "| Epoch 242 |   600/  658 batches | lr 0.00006 | ms/batch 14.32 | loss 0.05680775\n",
      "| Epoch 242 |   650/  658 batches | lr 0.00006 | ms/batch 13.09 | loss 0.05410976\n",
      "\n",
      "Val set: Average loss: 0.05799811\n",
      "\n",
      "EarlyStopping counter: 13 out of 20\n",
      "| Epoch 243 |    50/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.05971601\n",
      "| Epoch 243 |   100/  658 batches | lr 0.00006 | ms/batch 16.48 | loss 0.05603292\n",
      "| Epoch 243 |   150/  658 batches | lr 0.00006 | ms/batch 15.25 | loss 0.05334370\n",
      "| Epoch 243 |   200/  658 batches | lr 0.00006 | ms/batch 15.65 | loss 0.05266661\n",
      "| Epoch 243 |   250/  658 batches | lr 0.00006 | ms/batch 16.82 | loss 0.05630278\n",
      "| Epoch 243 |   300/  658 batches | lr 0.00006 | ms/batch 14.14 | loss 0.05576625\n",
      "| Epoch 243 |   350/  658 batches | lr 0.00006 | ms/batch 13.52 | loss 0.05755878\n",
      "| Epoch 243 |   400/  658 batches | lr 0.00006 | ms/batch 17.16 | loss 0.05503612\n",
      "| Epoch 243 |   450/  658 batches | lr 0.00006 | ms/batch 14.07 | loss 0.05144313\n",
      "| Epoch 243 |   500/  658 batches | lr 0.00006 | ms/batch 16.76 | loss 0.05648403\n",
      "| Epoch 243 |   550/  658 batches | lr 0.00006 | ms/batch 17.93 | loss 0.05470845\n",
      "| Epoch 243 |   600/  658 batches | lr 0.00006 | ms/batch 14.32 | loss 0.05688307\n",
      "| Epoch 243 |   650/  658 batches | lr 0.00006 | ms/batch 15.65 | loss 0.05412552\n",
      "\n",
      "Val set: Average loss: 0.05794000\n",
      "\n",
      "EarlyStopping counter: 14 out of 20\n",
      "| Epoch 244 |    50/  658 batches | lr 0.00006 | ms/batch 15.37 | loss 0.05959070\n",
      "| Epoch 244 |   100/  658 batches | lr 0.00006 | ms/batch 17.17 | loss 0.05614225\n",
      "| Epoch 244 |   150/  658 batches | lr 0.00006 | ms/batch 16.00 | loss 0.05298498\n",
      "| Epoch 244 |   200/  658 batches | lr 0.00006 | ms/batch 16.51 | loss 0.05263430\n",
      "| Epoch 244 |   250/  658 batches | lr 0.00006 | ms/batch 18.65 | loss 0.05629786\n",
      "| Epoch 244 |   300/  658 batches | lr 0.00006 | ms/batch 13.28 | loss 0.05623179\n",
      "| Epoch 244 |   350/  658 batches | lr 0.00006 | ms/batch 18.19 | loss 0.05742891\n",
      "| Epoch 244 |   400/  658 batches | lr 0.00006 | ms/batch 15.84 | loss 0.05491421\n",
      "| Epoch 244 |   450/  658 batches | lr 0.00006 | ms/batch 14.26 | loss 0.05113899\n",
      "| Epoch 244 |   500/  658 batches | lr 0.00006 | ms/batch 16.14 | loss 0.05700124\n",
      "| Epoch 244 |   550/  658 batches | lr 0.00006 | ms/batch 17.13 | loss 0.05498212\n",
      "| Epoch 244 |   600/  658 batches | lr 0.00006 | ms/batch 14.88 | loss 0.05687106\n",
      "| Epoch 244 |   650/  658 batches | lr 0.00006 | ms/batch 15.87 | loss 0.05403695\n",
      "\n",
      "Val set: Average loss: 0.05802181\n",
      "\n",
      "EarlyStopping counter: 15 out of 20\n",
      "| Epoch 245 |    50/  658 batches | lr 0.00006 | ms/batch 15.84 | loss 0.05956470\n",
      "| Epoch 245 |   100/  658 batches | lr 0.00006 | ms/batch 17.03 | loss 0.05589024\n",
      "| Epoch 245 |   150/  658 batches | lr 0.00006 | ms/batch 15.43 | loss 0.05338113\n",
      "| Epoch 245 |   200/  658 batches | lr 0.00006 | ms/batch 17.08 | loss 0.05257537\n",
      "| Epoch 245 |   250/  658 batches | lr 0.00006 | ms/batch 17.47 | loss 0.05630088\n",
      "| Epoch 245 |   300/  658 batches | lr 0.00006 | ms/batch 16.39 | loss 0.05570124\n",
      "| Epoch 245 |   350/  658 batches | lr 0.00006 | ms/batch 13.62 | loss 0.05742619\n",
      "| Epoch 245 |   400/  658 batches | lr 0.00006 | ms/batch 17.02 | loss 0.05496854\n",
      "| Epoch 245 |   450/  658 batches | lr 0.00006 | ms/batch 15.59 | loss 0.05121577\n",
      "| Epoch 245 |   500/  658 batches | lr 0.00006 | ms/batch 16.72 | loss 0.05656604\n",
      "| Epoch 245 |   550/  658 batches | lr 0.00006 | ms/batch 19.32 | loss 0.05460959\n",
      "| Epoch 245 |   600/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.05647477\n",
      "| Epoch 245 |   650/  658 batches | lr 0.00006 | ms/batch 15.84 | loss 0.05404518\n",
      "\n",
      "Val set: Average loss: 0.05782517\n",
      "\n",
      "| Epoch 246 |    50/  658 batches | lr 0.00006 | ms/batch 17.33 | loss 0.05951910\n",
      "| Epoch 246 |   100/  658 batches | lr 0.00006 | ms/batch 18.26 | loss 0.05599160\n",
      "| Epoch 246 |   150/  658 batches | lr 0.00006 | ms/batch 15.74 | loss 0.05304212\n",
      "| Epoch 246 |   200/  658 batches | lr 0.00006 | ms/batch 17.21 | loss 0.05280990\n",
      "| Epoch 246 |   250/  658 batches | lr 0.00006 | ms/batch 16.99 | loss 0.05628581\n",
      "| Epoch 246 |   300/  658 batches | lr 0.00006 | ms/batch 15.37 | loss 0.05563753\n",
      "| Epoch 246 |   350/  658 batches | lr 0.00006 | ms/batch 14.99 | loss 0.05752844\n",
      "| Epoch 246 |   400/  658 batches | lr 0.00006 | ms/batch 17.83 | loss 0.05502285\n",
      "| Epoch 246 |   450/  658 batches | lr 0.00006 | ms/batch 15.61 | loss 0.05123956\n",
      "| Epoch 246 |   500/  658 batches | lr 0.00006 | ms/batch 20.04 | loss 0.05651183\n",
      "| Epoch 246 |   550/  658 batches | lr 0.00006 | ms/batch 16.06 | loss 0.05462383\n",
      "| Epoch 246 |   600/  658 batches | lr 0.00006 | ms/batch 15.16 | loss 0.05642765\n",
      "| Epoch 246 |   650/  658 batches | lr 0.00006 | ms/batch 16.14 | loss 0.05411393\n",
      "\n",
      "Val set: Average loss: 0.05785345\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 247 |    50/  658 batches | lr 0.00006 | ms/batch 15.18 | loss 0.05984227\n",
      "| Epoch 247 |   100/  658 batches | lr 0.00006 | ms/batch 18.01 | loss 0.05603036\n",
      "| Epoch 247 |   150/  658 batches | lr 0.00006 | ms/batch 15.35 | loss 0.05317579\n",
      "| Epoch 247 |   200/  658 batches | lr 0.00006 | ms/batch 17.05 | loss 0.05236697\n",
      "| Epoch 247 |   250/  658 batches | lr 0.00006 | ms/batch 17.93 | loss 0.05609328\n",
      "| Epoch 247 |   300/  658 batches | lr 0.00006 | ms/batch 16.38 | loss 0.05606651\n",
      "| Epoch 247 |   350/  658 batches | lr 0.00006 | ms/batch 14.77 | loss 0.05746571\n",
      "| Epoch 247 |   400/  658 batches | lr 0.00006 | ms/batch 15.84 | loss 0.05486960\n",
      "| Epoch 247 |   450/  658 batches | lr 0.00006 | ms/batch 15.60 | loss 0.05100454\n",
      "| Epoch 247 |   500/  658 batches | lr 0.00006 | ms/batch 16.90 | loss 0.05660343\n",
      "| Epoch 247 |   550/  658 batches | lr 0.00006 | ms/batch 17.88 | loss 0.05476667\n",
      "| Epoch 247 |   600/  658 batches | lr 0.00006 | ms/batch 16.00 | loss 0.05640943\n",
      "| Epoch 247 |   650/  658 batches | lr 0.00006 | ms/batch 13.62 | loss 0.05367961\n",
      "\n",
      "Val set: Average loss: 0.05788229\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch 248 |    50/  658 batches | lr 0.00006 | ms/batch 13.97 | loss 0.05925445\n",
      "| Epoch 248 |   100/  658 batches | lr 0.00006 | ms/batch 16.66 | loss 0.05583201\n",
      "| Epoch 248 |   150/  658 batches | lr 0.00006 | ms/batch 16.36 | loss 0.05296804\n",
      "| Epoch 248 |   200/  658 batches | lr 0.00006 | ms/batch 17.69 | loss 0.05242256\n",
      "| Epoch 248 |   250/  658 batches | lr 0.00006 | ms/batch 17.26 | loss 0.05614587\n",
      "| Epoch 248 |   300/  658 batches | lr 0.00006 | ms/batch 15.15 | loss 0.05554090\n",
      "| Epoch 248 |   350/  658 batches | lr 0.00006 | ms/batch 14.39 | loss 0.05727920\n",
      "| Epoch 248 |   400/  658 batches | lr 0.00006 | ms/batch 14.77 | loss 0.05494066\n",
      "| Epoch 248 |   450/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.05129981\n",
      "| Epoch 248 |   500/  658 batches | lr 0.00006 | ms/batch 14.97 | loss 0.05615828\n",
      "| Epoch 248 |   550/  658 batches | lr 0.00006 | ms/batch 15.42 | loss 0.05476953\n",
      "| Epoch 248 |   600/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.05635601\n",
      "| Epoch 248 |   650/  658 batches | lr 0.00006 | ms/batch 14.74 | loss 0.05403310\n",
      "\n",
      "Val set: Average loss: 0.05788689\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch 249 |    50/  658 batches | lr 0.00006 | ms/batch 13.47 | loss 0.05945279\n",
      "| Epoch 249 |   100/  658 batches | lr 0.00006 | ms/batch 15.04 | loss 0.05586246\n",
      "| Epoch 249 |   150/  658 batches | lr 0.00006 | ms/batch 12.90 | loss 0.05300065\n",
      "| Epoch 249 |   200/  658 batches | lr 0.00006 | ms/batch 14.92 | loss 0.05236010\n",
      "| Epoch 249 |   250/  658 batches | lr 0.00006 | ms/batch 15.35 | loss 0.05607113\n",
      "| Epoch 249 |   300/  658 batches | lr 0.00006 | ms/batch 13.95 | loss 0.05601923\n",
      "| Epoch 249 |   350/  658 batches | lr 0.00006 | ms/batch 12.82 | loss 0.05733543\n",
      "| Epoch 249 |   400/  658 batches | lr 0.00006 | ms/batch 14.66 | loss 0.05481837\n",
      "| Epoch 249 |   450/  658 batches | lr 0.00006 | ms/batch 12.78 | loss 0.05105792\n",
      "| Epoch 249 |   500/  658 batches | lr 0.00006 | ms/batch 14.53 | loss 0.05634032\n",
      "| Epoch 249 |   550/  658 batches | lr 0.00006 | ms/batch 14.40 | loss 0.05452536\n",
      "| Epoch 249 |   600/  658 batches | lr 0.00006 | ms/batch 13.00 | loss 0.05636086\n",
      "| Epoch 249 |   650/  658 batches | lr 0.00006 | ms/batch 12.80 | loss 0.05396711\n",
      "\n",
      "Val set: Average loss: 0.05790263\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch 250 |    50/  658 batches | lr 0.00006 | ms/batch 12.94 | loss 0.05933788\n",
      "| Epoch 250 |   100/  658 batches | lr 0.00006 | ms/batch 14.48 | loss 0.05592407\n",
      "| Epoch 250 |   150/  658 batches | lr 0.00006 | ms/batch 14.31 | loss 0.05305126\n",
      "| Epoch 250 |   200/  658 batches | lr 0.00006 | ms/batch 16.26 | loss 0.05254447\n",
      "| Epoch 250 |   250/  658 batches | lr 0.00006 | ms/batch 14.52 | loss 0.05602638\n",
      "| Epoch 250 |   300/  658 batches | lr 0.00006 | ms/batch 12.69 | loss 0.05550142\n",
      "| Epoch 250 |   350/  658 batches | lr 0.00006 | ms/batch 12.86 | loss 0.05732671\n",
      "| Epoch 250 |   400/  658 batches | lr 0.00006 | ms/batch 14.33 | loss 0.05498313\n",
      "| Epoch 250 |   450/  658 batches | lr 0.00006 | ms/batch 12.76 | loss 0.05099089\n",
      "| Epoch 250 |   500/  658 batches | lr 0.00006 | ms/batch 14.28 | loss 0.05676194\n",
      "| Epoch 250 |   550/  658 batches | lr 0.00006 | ms/batch 14.31 | loss 0.05460121\n",
      "| Epoch 250 |   600/  658 batches | lr 0.00006 | ms/batch 12.73 | loss 0.05639246\n",
      "| Epoch 250 |   650/  658 batches | lr 0.00006 | ms/batch 12.72 | loss 0.05401514\n",
      "\n",
      "Val set: Average loss: 0.05779992\n",
      "\n",
      "| Epoch 251 |    50/  658 batches | lr 0.00006 | ms/batch 12.90 | loss 0.05969692\n",
      "| Epoch 251 |   100/  658 batches | lr 0.00006 | ms/batch 14.37 | loss 0.05588827\n",
      "| Epoch 251 |   150/  658 batches | lr 0.00006 | ms/batch 12.67 | loss 0.05351233\n",
      "| Epoch 251 |   200/  658 batches | lr 0.00006 | ms/batch 14.34 | loss 0.05239957\n",
      "| Epoch 251 |   250/  658 batches | lr 0.00006 | ms/batch 14.39 | loss 0.05601475\n",
      "| Epoch 251 |   300/  658 batches | lr 0.00006 | ms/batch 12.72 | loss 0.05595582\n",
      "| Epoch 251 |   350/  658 batches | lr 0.00006 | ms/batch 12.80 | loss 0.05717822\n",
      "| Epoch 251 |   400/  658 batches | lr 0.00006 | ms/batch 14.20 | loss 0.05476663\n",
      "| Epoch 251 |   450/  658 batches | lr 0.00006 | ms/batch 12.74 | loss 0.05110405\n",
      "| Epoch 251 |   500/  658 batches | lr 0.00006 | ms/batch 14.36 | loss 0.05634698\n",
      "| Epoch 251 |   550/  658 batches | lr 0.00006 | ms/batch 14.40 | loss 0.05518323\n",
      "| Epoch 251 |   600/  658 batches | lr 0.00006 | ms/batch 12.56 | loss 0.05642819\n",
      "| Epoch 251 |   650/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.05385805\n",
      "\n",
      "Val set: Average loss: 0.05781376\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 252 |    50/  658 batches | lr 0.00006 | ms/batch 12.95 | loss 0.05957282\n",
      "| Epoch 252 |   100/  658 batches | lr 0.00006 | ms/batch 14.36 | loss 0.05579221\n",
      "| Epoch 252 |   150/  658 batches | lr 0.00006 | ms/batch 12.69 | loss 0.05388067\n",
      "| Epoch 252 |   200/  658 batches | lr 0.00006 | ms/batch 14.37 | loss 0.05274798\n",
      "| Epoch 252 |   250/  658 batches | lr 0.00006 | ms/batch 14.46 | loss 0.05614507\n",
      "| Epoch 252 |   300/  658 batches | lr 0.00006 | ms/batch 12.68 | loss 0.05603780\n",
      "| Epoch 252 |   350/  658 batches | lr 0.00006 | ms/batch 12.53 | loss 0.05715763\n",
      "| Epoch 252 |   400/  658 batches | lr 0.00006 | ms/batch 14.42 | loss 0.05472495\n",
      "| Epoch 252 |   450/  658 batches | lr 0.00006 | ms/batch 12.71 | loss 0.05110449\n",
      "| Epoch 252 |   500/  658 batches | lr 0.00006 | ms/batch 15.01 | loss 0.05643315\n",
      "| Epoch 252 |   550/  658 batches | lr 0.00006 | ms/batch 14.38 | loss 0.05467515\n",
      "| Epoch 252 |   600/  658 batches | lr 0.00006 | ms/batch 12.62 | loss 0.05621354\n",
      "| Epoch 252 |   650/  658 batches | lr 0.00006 | ms/batch 12.69 | loss 0.05379864\n",
      "\n",
      "Val set: Average loss: 0.05777828\n",
      "\n",
      "| Epoch 253 |    50/  658 batches | lr 0.00006 | ms/batch 13.11 | loss 0.05933589\n",
      "| Epoch 253 |   100/  658 batches | lr 0.00006 | ms/batch 14.34 | loss 0.05570031\n",
      "| Epoch 253 |   150/  658 batches | lr 0.00006 | ms/batch 12.75 | loss 0.05317206\n",
      "| Epoch 253 |   200/  658 batches | lr 0.00006 | ms/batch 14.34 | loss 0.05237853\n",
      "| Epoch 253 |   250/  658 batches | lr 0.00006 | ms/batch 14.48 | loss 0.05600295\n",
      "| Epoch 253 |   300/  658 batches | lr 0.00006 | ms/batch 12.75 | loss 0.05551956\n",
      "| Epoch 253 |   350/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.05713268\n",
      "| Epoch 253 |   400/  658 batches | lr 0.00006 | ms/batch 14.40 | loss 0.05478922\n",
      "| Epoch 253 |   450/  658 batches | lr 0.00006 | ms/batch 12.79 | loss 0.05124638\n",
      "| Epoch 253 |   500/  658 batches | lr 0.00006 | ms/batch 14.31 | loss 0.05630066\n",
      "| Epoch 253 |   550/  658 batches | lr 0.00006 | ms/batch 14.45 | loss 0.05459699\n",
      "| Epoch 253 |   600/  658 batches | lr 0.00006 | ms/batch 12.71 | loss 0.05635069\n",
      "| Epoch 253 |   650/  658 batches | lr 0.00006 | ms/batch 12.83 | loss 0.05385851\n",
      "\n",
      "Val set: Average loss: 0.05779439\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 254 |    50/  658 batches | lr 0.00006 | ms/batch 13.04 | loss 0.05936415\n",
      "| Epoch 254 |   100/  658 batches | lr 0.00006 | ms/batch 14.79 | loss 0.05568542\n",
      "| Epoch 254 |   150/  658 batches | lr 0.00006 | ms/batch 12.73 | loss 0.05365098\n",
      "| Epoch 254 |   200/  658 batches | lr 0.00006 | ms/batch 14.27 | loss 0.05258043\n",
      "| Epoch 254 |   250/  658 batches | lr 0.00006 | ms/batch 14.30 | loss 0.05591345\n",
      "| Epoch 254 |   300/  658 batches | lr 0.00006 | ms/batch 12.78 | loss 0.05555732\n",
      "| Epoch 254 |   350/  658 batches | lr 0.00006 | ms/batch 12.57 | loss 0.05725064\n",
      "| Epoch 254 |   400/  658 batches | lr 0.00006 | ms/batch 14.29 | loss 0.05492496\n",
      "| Epoch 254 |   450/  658 batches | lr 0.00006 | ms/batch 13.12 | loss 0.05076121\n",
      "| Epoch 254 |   500/  658 batches | lr 0.00006 | ms/batch 14.37 | loss 0.05636625\n",
      "| Epoch 254 |   550/  658 batches | lr 0.00006 | ms/batch 14.39 | loss 0.05464063\n",
      "| Epoch 254 |   600/  658 batches | lr 0.00006 | ms/batch 12.66 | loss 0.05622729\n",
      "| Epoch 254 |   650/  658 batches | lr 0.00006 | ms/batch 12.72 | loss 0.05401185\n",
      "\n",
      "Val set: Average loss: 0.05768287\n",
      "\n",
      "| Epoch 255 |    50/  658 batches | lr 0.00006 | ms/batch 13.01 | loss 0.05952602\n",
      "| Epoch 255 |   100/  658 batches | lr 0.00006 | ms/batch 14.35 | loss 0.05574394\n",
      "| Epoch 255 |   150/  658 batches | lr 0.00006 | ms/batch 13.17 | loss 0.05336834\n",
      "| Epoch 255 |   200/  658 batches | lr 0.00006 | ms/batch 15.28 | loss 0.05252151\n",
      "| Epoch 255 |   250/  658 batches | lr 0.00006 | ms/batch 14.39 | loss 0.05587011\n",
      "| Epoch 255 |   300/  658 batches | lr 0.00006 | ms/batch 12.73 | loss 0.05540694\n",
      "| Epoch 255 |   350/  658 batches | lr 0.00006 | ms/batch 12.78 | loss 0.05725600\n",
      "| Epoch 255 |   400/  658 batches | lr 0.00006 | ms/batch 14.29 | loss 0.05477666\n",
      "| Epoch 255 |   450/  658 batches | lr 0.00006 | ms/batch 12.80 | loss 0.05075936\n",
      "| Epoch 255 |   500/  658 batches | lr 0.00006 | ms/batch 14.43 | loss 0.05637401\n",
      "| Epoch 255 |   550/  658 batches | lr 0.00006 | ms/batch 14.49 | loss 0.05442574\n",
      "| Epoch 255 |   600/  658 batches | lr 0.00006 | ms/batch 12.72 | loss 0.05603890\n",
      "| Epoch 255 |   650/  658 batches | lr 0.00006 | ms/batch 12.70 | loss 0.05379017\n",
      "\n",
      "Val set: Average loss: 0.05772609\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 256 |    50/  658 batches | lr 0.00006 | ms/batch 12.86 | loss 0.05920768\n",
      "| Epoch 256 |   100/  658 batches | lr 0.00006 | ms/batch 14.31 | loss 0.05563982\n",
      "| Epoch 256 |   150/  658 batches | lr 0.00006 | ms/batch 12.85 | loss 0.05343671\n",
      "| Epoch 256 |   200/  658 batches | lr 0.00006 | ms/batch 14.53 | loss 0.05263760\n",
      "| Epoch 256 |   250/  658 batches | lr 0.00006 | ms/batch 14.48 | loss 0.05585718\n",
      "| Epoch 256 |   300/  658 batches | lr 0.00006 | ms/batch 12.78 | loss 0.05534605\n",
      "| Epoch 256 |   350/  658 batches | lr 0.00006 | ms/batch 12.76 | loss 0.05721457\n",
      "| Epoch 256 |   400/  658 batches | lr 0.00006 | ms/batch 14.33 | loss 0.05471453\n",
      "| Epoch 256 |   450/  658 batches | lr 0.00006 | ms/batch 12.75 | loss 0.05126182\n",
      "| Epoch 256 |   500/  658 batches | lr 0.00006 | ms/batch 14.64 | loss 0.05618337\n",
      "| Epoch 256 |   550/  658 batches | lr 0.00006 | ms/batch 14.44 | loss 0.05449917\n",
      "| Epoch 256 |   600/  658 batches | lr 0.00006 | ms/batch 12.83 | loss 0.05597719\n",
      "| Epoch 256 |   650/  658 batches | lr 0.00006 | ms/batch 12.70 | loss 0.05380169\n",
      "\n",
      "Val set: Average loss: 0.05765781\n",
      "\n",
      "| Epoch 257 |    50/  658 batches | lr 0.00006 | ms/batch 13.01 | loss 0.05922143\n",
      "| Epoch 257 |   100/  658 batches | lr 0.00006 | ms/batch 14.25 | loss 0.05560443\n",
      "| Epoch 257 |   150/  658 batches | lr 0.00006 | ms/batch 12.80 | loss 0.05307525\n",
      "| Epoch 257 |   200/  658 batches | lr 0.00006 | ms/batch 14.58 | loss 0.05219194\n",
      "| Epoch 257 |   250/  658 batches | lr 0.00006 | ms/batch 14.50 | loss 0.05573919\n",
      "| Epoch 257 |   300/  658 batches | lr 0.00006 | ms/batch 12.95 | loss 0.05526359\n",
      "| Epoch 257 |   350/  658 batches | lr 0.00006 | ms/batch 12.71 | loss 0.05714311\n",
      "| Epoch 257 |   400/  658 batches | lr 0.00006 | ms/batch 14.40 | loss 0.05462168\n",
      "| Epoch 257 |   450/  658 batches | lr 0.00006 | ms/batch 12.87 | loss 0.05118930\n",
      "| Epoch 257 |   500/  658 batches | lr 0.00006 | ms/batch 14.87 | loss 0.05597229\n",
      "| Epoch 257 |   550/  658 batches | lr 0.00006 | ms/batch 14.55 | loss 0.05441711\n",
      "| Epoch 257 |   600/  658 batches | lr 0.00006 | ms/batch 12.70 | loss 0.05598842\n",
      "| Epoch 257 |   650/  658 batches | lr 0.00006 | ms/batch 13.09 | loss 0.05381797\n",
      "\n",
      "Val set: Average loss: 0.05778563\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 258 |    50/  658 batches | lr 0.00006 | ms/batch 12.95 | loss 0.05923186\n",
      "| Epoch 258 |   100/  658 batches | lr 0.00006 | ms/batch 14.59 | loss 0.05550231\n",
      "| Epoch 258 |   150/  658 batches | lr 0.00006 | ms/batch 13.29 | loss 0.05312775\n",
      "| Epoch 258 |   200/  658 batches | lr 0.00006 | ms/batch 14.86 | loss 0.05235047\n",
      "| Epoch 258 |   250/  658 batches | lr 0.00006 | ms/batch 15.19 | loss 0.05570248\n",
      "| Epoch 258 |   300/  658 batches | lr 0.00006 | ms/batch 12.74 | loss 0.05528637\n",
      "| Epoch 258 |   350/  658 batches | lr 0.00006 | ms/batch 12.68 | loss 0.05714553\n",
      "| Epoch 258 |   400/  658 batches | lr 0.00006 | ms/batch 14.38 | loss 0.05471754\n",
      "| Epoch 258 |   450/  658 batches | lr 0.00006 | ms/batch 13.06 | loss 0.05108948\n",
      "| Epoch 258 |   500/  658 batches | lr 0.00006 | ms/batch 15.03 | loss 0.05608172\n",
      "| Epoch 258 |   550/  658 batches | lr 0.00006 | ms/batch 14.42 | loss 0.05436524\n",
      "| Epoch 258 |   600/  658 batches | lr 0.00006 | ms/batch 12.80 | loss 0.05591679\n",
      "| Epoch 258 |   650/  658 batches | lr 0.00006 | ms/batch 12.71 | loss 0.05371327\n",
      "\n",
      "Val set: Average loss: 0.05773095\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch 259 |    50/  658 batches | lr 0.00006 | ms/batch 13.01 | loss 0.05919151\n",
      "| Epoch 259 |   100/  658 batches | lr 0.00006 | ms/batch 14.34 | loss 0.05550315\n",
      "| Epoch 259 |   150/  658 batches | lr 0.00006 | ms/batch 12.72 | loss 0.05312532\n",
      "| Epoch 259 |   200/  658 batches | lr 0.00006 | ms/batch 14.39 | loss 0.05236063\n",
      "| Epoch 259 |   250/  658 batches | lr 0.00006 | ms/batch 14.40 | loss 0.05566056\n",
      "| Epoch 259 |   300/  658 batches | lr 0.00006 | ms/batch 12.67 | loss 0.05553903\n",
      "| Epoch 259 |   350/  658 batches | lr 0.00006 | ms/batch 12.90 | loss 0.05718383\n",
      "| Epoch 259 |   400/  658 batches | lr 0.00006 | ms/batch 15.19 | loss 0.05434237\n",
      "| Epoch 259 |   450/  658 batches | lr 0.00006 | ms/batch 12.72 | loss 0.05048281\n",
      "| Epoch 259 |   500/  658 batches | lr 0.00006 | ms/batch 14.40 | loss 0.05646201\n",
      "| Epoch 259 |   550/  658 batches | lr 0.00006 | ms/batch 14.40 | loss 0.05435740\n",
      "| Epoch 259 |   600/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05605927\n",
      "| Epoch 259 |   650/  658 batches | lr 0.00006 | ms/batch 12.60 | loss 0.05371786\n",
      "\n",
      "Val set: Average loss: 0.05770771\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch 260 |    50/  658 batches | lr 0.00006 | ms/batch 13.11 | loss 0.05904849\n",
      "| Epoch 260 |   100/  658 batches | lr 0.00006 | ms/batch 14.41 | loss 0.05549707\n",
      "| Epoch 260 |   150/  658 batches | lr 0.00006 | ms/batch 12.75 | loss 0.05321671\n",
      "| Epoch 260 |   200/  658 batches | lr 0.00006 | ms/batch 14.51 | loss 0.05239850\n",
      "| Epoch 260 |   250/  658 batches | lr 0.00006 | ms/batch 14.47 | loss 0.05566489\n",
      "| Epoch 260 |   300/  658 batches | lr 0.00006 | ms/batch 13.03 | loss 0.05524551\n",
      "| Epoch 260 |   350/  658 batches | lr 0.00006 | ms/batch 13.41 | loss 0.05708108\n",
      "| Epoch 260 |   400/  658 batches | lr 0.00006 | ms/batch 14.26 | loss 0.05451735\n",
      "| Epoch 260 |   450/  658 batches | lr 0.00006 | ms/batch 12.74 | loss 0.05114936\n",
      "| Epoch 260 |   500/  658 batches | lr 0.00006 | ms/batch 14.29 | loss 0.05618686\n",
      "| Epoch 260 |   550/  658 batches | lr 0.00006 | ms/batch 14.27 | loss 0.05428157\n",
      "| Epoch 260 |   600/  658 batches | lr 0.00006 | ms/batch 12.74 | loss 0.05600078\n",
      "| Epoch 260 |   650/  658 batches | lr 0.00006 | ms/batch 13.24 | loss 0.05355345\n",
      "\n",
      "Val set: Average loss: 0.05760122\n",
      "\n",
      "| Epoch 261 |    50/  658 batches | lr 0.00006 | ms/batch 12.99 | loss 0.05912452\n",
      "| Epoch 261 |   100/  658 batches | lr 0.00006 | ms/batch 14.46 | loss 0.05558756\n",
      "| Epoch 261 |   150/  658 batches | lr 0.00006 | ms/batch 12.80 | loss 0.05319917\n",
      "| Epoch 261 |   200/  658 batches | lr 0.00006 | ms/batch 14.46 | loss 0.05257625\n",
      "| Epoch 261 |   250/  658 batches | lr 0.00006 | ms/batch 14.30 | loss 0.05564028\n",
      "| Epoch 261 |   300/  658 batches | lr 0.00006 | ms/batch 12.79 | loss 0.05525008\n",
      "| Epoch 261 |   350/  658 batches | lr 0.00006 | ms/batch 12.93 | loss 0.05697365\n",
      "| Epoch 261 |   400/  658 batches | lr 0.00006 | ms/batch 15.02 | loss 0.05441677\n",
      "| Epoch 261 |   450/  658 batches | lr 0.00006 | ms/batch 12.77 | loss 0.05076665\n",
      "| Epoch 261 |   500/  658 batches | lr 0.00006 | ms/batch 14.46 | loss 0.05625172\n",
      "| Epoch 261 |   550/  658 batches | lr 0.00006 | ms/batch 14.40 | loss 0.05430043\n",
      "| Epoch 261 |   600/  658 batches | lr 0.00006 | ms/batch 12.85 | loss 0.05585857\n",
      "| Epoch 261 |   650/  658 batches | lr 0.00006 | ms/batch 13.13 | loss 0.05368747\n",
      "\n",
      "Val set: Average loss: 0.05780938\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 262 |    50/  658 batches | lr 0.00006 | ms/batch 12.91 | loss 0.05885017\n",
      "| Epoch 262 |   100/  658 batches | lr 0.00006 | ms/batch 14.17 | loss 0.05554633\n",
      "| Epoch 262 |   150/  658 batches | lr 0.00006 | ms/batch 13.09 | loss 0.05300980\n",
      "| Epoch 262 |   200/  658 batches | lr 0.00006 | ms/batch 15.12 | loss 0.05226788\n",
      "| Epoch 262 |   250/  658 batches | lr 0.00006 | ms/batch 14.34 | loss 0.05556334\n",
      "| Epoch 262 |   300/  658 batches | lr 0.00006 | ms/batch 12.98 | loss 0.05516816\n",
      "| Epoch 262 |   350/  658 batches | lr 0.00006 | ms/batch 13.97 | loss 0.05697061\n",
      "| Epoch 262 |   400/  658 batches | lr 0.00006 | ms/batch 14.27 | loss 0.05445970\n",
      "| Epoch 262 |   450/  658 batches | lr 0.00006 | ms/batch 12.79 | loss 0.05106334\n",
      "| Epoch 262 |   500/  658 batches | lr 0.00006 | ms/batch 14.41 | loss 0.05608889\n",
      "| Epoch 262 |   550/  658 batches | lr 0.00006 | ms/batch 14.64 | loss 0.05443554\n",
      "| Epoch 262 |   600/  658 batches | lr 0.00006 | ms/batch 13.23 | loss 0.05598450\n",
      "| Epoch 262 |   650/  658 batches | lr 0.00006 | ms/batch 12.66 | loss 0.05358246\n",
      "\n",
      "Val set: Average loss: 0.05765080\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch 263 |    50/  658 batches | lr 0.00006 | ms/batch 12.96 | loss 0.05899718\n",
      "| Epoch 263 |   100/  658 batches | lr 0.00006 | ms/batch 14.21 | loss 0.05531769\n",
      "| Epoch 263 |   150/  658 batches | lr 0.00006 | ms/batch 12.95 | loss 0.05308563\n",
      "| Epoch 263 |   200/  658 batches | lr 0.00006 | ms/batch 15.54 | loss 0.05233028\n",
      "| Epoch 263 |   250/  658 batches | lr 0.00006 | ms/batch 14.56 | loss 0.05553422\n",
      "| Epoch 263 |   300/  658 batches | lr 0.00006 | ms/batch 13.43 | loss 0.05510837\n",
      "| Epoch 263 |   350/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.05694274\n",
      "| Epoch 263 |   400/  658 batches | lr 0.00006 | ms/batch 14.34 | loss 0.05448711\n",
      "| Epoch 263 |   450/  658 batches | lr 0.00006 | ms/batch 12.78 | loss 0.05086855\n",
      "| Epoch 263 |   500/  658 batches | lr 0.00006 | ms/batch 15.47 | loss 0.05597488\n",
      "| Epoch 263 |   550/  658 batches | lr 0.00006 | ms/batch 14.80 | loss 0.05446849\n",
      "| Epoch 263 |   600/  658 batches | lr 0.00006 | ms/batch 12.75 | loss 0.05588933\n",
      "| Epoch 263 |   650/  658 batches | lr 0.00006 | ms/batch 13.38 | loss 0.05356636\n",
      "\n",
      "Val set: Average loss: 0.05753355\n",
      "\n",
      "| Epoch 264 |    50/  658 batches | lr 0.00006 | ms/batch 13.22 | loss 0.05890373\n",
      "| Epoch 264 |   100/  658 batches | lr 0.00006 | ms/batch 14.64 | loss 0.05530517\n",
      "| Epoch 264 |   150/  658 batches | lr 0.00006 | ms/batch 12.66 | loss 0.05325147\n",
      "| Epoch 264 |   200/  658 batches | lr 0.00006 | ms/batch 14.39 | loss 0.05249439\n",
      "| Epoch 264 |   250/  658 batches | lr 0.00006 | ms/batch 14.23 | loss 0.05557874\n",
      "| Epoch 264 |   300/  658 batches | lr 0.00006 | ms/batch 13.06 | loss 0.05506965\n",
      "| Epoch 264 |   350/  658 batches | lr 0.00006 | ms/batch 15.30 | loss 0.05678372\n",
      "| Epoch 264 |   400/  658 batches | lr 0.00006 | ms/batch 14.41 | loss 0.05443552\n",
      "| Epoch 264 |   450/  658 batches | lr 0.00006 | ms/batch 12.63 | loss 0.05084469\n",
      "| Epoch 264 |   500/  658 batches | lr 0.00006 | ms/batch 14.69 | loss 0.05595341\n",
      "| Epoch 264 |   550/  658 batches | lr 0.00006 | ms/batch 15.25 | loss 0.05443864\n",
      "| Epoch 264 |   600/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05593021\n",
      "| Epoch 264 |   650/  658 batches | lr 0.00006 | ms/batch 12.59 | loss 0.05360619\n",
      "\n",
      "Val set: Average loss: 0.05755277\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 265 |    50/  658 batches | lr 0.00006 | ms/batch 13.05 | loss 0.05902507\n",
      "| Epoch 265 |   100/  658 batches | lr 0.00006 | ms/batch 14.42 | loss 0.05522439\n",
      "| Epoch 265 |   150/  658 batches | lr 0.00006 | ms/batch 12.76 | loss 0.05322787\n",
      "| Epoch 265 |   200/  658 batches | lr 0.00006 | ms/batch 14.34 | loss 0.05243196\n",
      "| Epoch 265 |   250/  658 batches | lr 0.00006 | ms/batch 14.44 | loss 0.05561575\n",
      "| Epoch 265 |   300/  658 batches | lr 0.00006 | ms/batch 13.08 | loss 0.05513899\n",
      "| Epoch 265 |   350/  658 batches | lr 0.00006 | ms/batch 12.60 | loss 0.05677399\n",
      "| Epoch 265 |   400/  658 batches | lr 0.00006 | ms/batch 14.44 | loss 0.05435062\n",
      "| Epoch 265 |   450/  658 batches | lr 0.00006 | ms/batch 12.75 | loss 0.05092223\n",
      "| Epoch 265 |   500/  658 batches | lr 0.00006 | ms/batch 14.71 | loss 0.05614772\n",
      "| Epoch 265 |   550/  658 batches | lr 0.00006 | ms/batch 15.11 | loss 0.05441145\n",
      "| Epoch 265 |   600/  658 batches | lr 0.00006 | ms/batch 12.66 | loss 0.05582471\n",
      "| Epoch 265 |   650/  658 batches | lr 0.00006 | ms/batch 12.61 | loss 0.05349189\n",
      "\n",
      "Val set: Average loss: 0.05763435\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch 266 |    50/  658 batches | lr 0.00006 | ms/batch 13.15 | loss 0.05890662\n",
      "| Epoch 266 |   100/  658 batches | lr 0.00006 | ms/batch 14.94 | loss 0.05521028\n",
      "| Epoch 266 |   150/  658 batches | lr 0.00006 | ms/batch 12.63 | loss 0.05306099\n",
      "| Epoch 266 |   200/  658 batches | lr 0.00006 | ms/batch 14.25 | loss 0.05235792\n",
      "| Epoch 266 |   250/  658 batches | lr 0.00006 | ms/batch 14.42 | loss 0.05552771\n",
      "| Epoch 266 |   300/  658 batches | lr 0.00006 | ms/batch 12.76 | loss 0.05482784\n",
      "| Epoch 266 |   350/  658 batches | lr 0.00006 | ms/batch 12.62 | loss 0.05666869\n",
      "| Epoch 266 |   400/  658 batches | lr 0.00006 | ms/batch 14.74 | loss 0.05424380\n",
      "| Epoch 266 |   450/  658 batches | lr 0.00006 | ms/batch 13.77 | loss 0.05080215\n",
      "| Epoch 266 |   500/  658 batches | lr 0.00006 | ms/batch 14.27 | loss 0.05607267\n",
      "| Epoch 266 |   550/  658 batches | lr 0.00006 | ms/batch 14.44 | loss 0.05432575\n",
      "| Epoch 266 |   600/  658 batches | lr 0.00006 | ms/batch 12.66 | loss 0.05616604\n",
      "| Epoch 266 |   650/  658 batches | lr 0.00006 | ms/batch 12.67 | loss 0.05350354\n",
      "\n",
      "Val set: Average loss: 0.05756145\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch 267 |    50/  658 batches | lr 0.00006 | ms/batch 13.19 | loss 0.05892382\n",
      "| Epoch 267 |   100/  658 batches | lr 0.00006 | ms/batch 14.33 | loss 0.05517571\n",
      "| Epoch 267 |   150/  658 batches | lr 0.00006 | ms/batch 12.73 | loss 0.05290325\n",
      "| Epoch 267 |   200/  658 batches | lr 0.00006 | ms/batch 14.41 | loss 0.05184611\n",
      "| Epoch 267 |   250/  658 batches | lr 0.00006 | ms/batch 14.41 | loss 0.05550382\n",
      "| Epoch 267 |   300/  658 batches | lr 0.00006 | ms/batch 12.80 | loss 0.05491896\n",
      "| Epoch 267 |   350/  658 batches | lr 0.00006 | ms/batch 14.50 | loss 0.05658117\n",
      "| Epoch 267 |   400/  658 batches | lr 0.00006 | ms/batch 14.36 | loss 0.05430658\n",
      "| Epoch 267 |   450/  658 batches | lr 0.00006 | ms/batch 12.93 | loss 0.05075602\n",
      "| Epoch 267 |   500/  658 batches | lr 0.00006 | ms/batch 14.51 | loss 0.05591583\n",
      "| Epoch 267 |   550/  658 batches | lr 0.00006 | ms/batch 14.40 | loss 0.05413512\n",
      "| Epoch 267 |   600/  658 batches | lr 0.00006 | ms/batch 12.64 | loss 0.05601662\n",
      "| Epoch 267 |   650/  658 batches | lr 0.00006 | ms/batch 13.02 | loss 0.05355039\n",
      "\n",
      "Val set: Average loss: 0.05773451\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch 268 |    50/  658 batches | lr 0.00006 | ms/batch 12.90 | loss 0.05875227\n",
      "| Epoch 268 |   100/  658 batches | lr 0.00006 | ms/batch 14.38 | loss 0.05511398\n",
      "| Epoch 268 |   150/  658 batches | lr 0.00006 | ms/batch 12.81 | loss 0.05285423\n",
      "| Epoch 268 |   200/  658 batches | lr 0.00006 | ms/batch 14.30 | loss 0.05205591\n",
      "| Epoch 268 |   250/  658 batches | lr 0.00006 | ms/batch 14.33 | loss 0.05544889\n",
      "| Epoch 268 |   300/  658 batches | lr 0.00006 | ms/batch 12.89 | loss 0.05499866\n",
      "| Epoch 268 |   350/  658 batches | lr 0.00006 | ms/batch 13.55 | loss 0.05656045\n",
      "| Epoch 268 |   400/  658 batches | lr 0.00006 | ms/batch 14.47 | loss 0.05423749\n",
      "| Epoch 268 |   450/  658 batches | lr 0.00006 | ms/batch 12.94 | loss 0.05094336\n",
      "| Epoch 268 |   500/  658 batches | lr 0.00006 | ms/batch 14.55 | loss 0.05591508\n",
      "| Epoch 268 |   550/  658 batches | lr 0.00006 | ms/batch 14.54 | loss 0.05452930\n",
      "| Epoch 268 |   600/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05579789\n",
      "| Epoch 268 |   650/  658 batches | lr 0.00006 | ms/batch 12.58 | loss 0.05370539\n",
      "\n",
      "Val set: Average loss: 0.05758853\n",
      "\n",
      "EarlyStopping counter: 5 out of 20\n",
      "| Epoch 269 |    50/  658 batches | lr 0.00006 | ms/batch 13.11 | loss 0.05855679\n",
      "| Epoch 269 |   100/  658 batches | lr 0.00006 | ms/batch 14.40 | loss 0.05519331\n",
      "| Epoch 269 |   150/  658 batches | lr 0.00006 | ms/batch 12.68 | loss 0.05280887\n",
      "| Epoch 269 |   200/  658 batches | lr 0.00006 | ms/batch 14.28 | loss 0.05185757\n",
      "| Epoch 269 |   250/  658 batches | lr 0.00006 | ms/batch 14.42 | loss 0.05531844\n",
      "| Epoch 269 |   300/  658 batches | lr 0.00006 | ms/batch 13.00 | loss 0.05487693\n",
      "| Epoch 269 |   350/  658 batches | lr 0.00006 | ms/batch 12.65 | loss 0.05675847\n",
      "| Epoch 269 |   400/  658 batches | lr 0.00006 | ms/batch 14.70 | loss 0.05429052\n",
      "| Epoch 269 |   450/  658 batches | lr 0.00006 | ms/batch 13.20 | loss 0.05099984\n",
      "| Epoch 269 |   500/  658 batches | lr 0.00006 | ms/batch 14.27 | loss 0.05589934\n",
      "| Epoch 269 |   550/  658 batches | lr 0.00006 | ms/batch 14.50 | loss 0.05414648\n",
      "| Epoch 269 |   600/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.05585329\n",
      "| Epoch 269 |   650/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05341910\n",
      "\n",
      "Val set: Average loss: 0.05779746\n",
      "\n",
      "EarlyStopping counter: 6 out of 20\n",
      "| Epoch 270 |    50/  658 batches | lr 0.00006 | ms/batch 13.03 | loss 0.05850021\n",
      "| Epoch 270 |   100/  658 batches | lr 0.00006 | ms/batch 14.39 | loss 0.05519583\n",
      "| Epoch 270 |   150/  658 batches | lr 0.00006 | ms/batch 12.99 | loss 0.05299051\n",
      "| Epoch 270 |   200/  658 batches | lr 0.00006 | ms/batch 15.07 | loss 0.05209523\n",
      "| Epoch 270 |   250/  658 batches | lr 0.00006 | ms/batch 14.37 | loss 0.05529363\n",
      "| Epoch 270 |   300/  658 batches | lr 0.00006 | ms/batch 12.76 | loss 0.05473353\n",
      "| Epoch 270 |   350/  658 batches | lr 0.00006 | ms/batch 12.59 | loss 0.05651074\n",
      "| Epoch 270 |   400/  658 batches | lr 0.00006 | ms/batch 14.21 | loss 0.05411146\n",
      "| Epoch 270 |   450/  658 batches | lr 0.00006 | ms/batch 12.78 | loss 0.05051594\n",
      "| Epoch 270 |   500/  658 batches | lr 0.00006 | ms/batch 14.36 | loss 0.05594454\n",
      "| Epoch 270 |   550/  658 batches | lr 0.00006 | ms/batch 14.49 | loss 0.05445393\n",
      "| Epoch 270 |   600/  658 batches | lr 0.00006 | ms/batch 12.65 | loss 0.05571002\n",
      "| Epoch 270 |   650/  658 batches | lr 0.00006 | ms/batch 12.97 | loss 0.05337967\n",
      "\n",
      "Val set: Average loss: 0.05760563\n",
      "\n",
      "EarlyStopping counter: 7 out of 20\n",
      "| Epoch 271 |    50/  658 batches | lr 0.00006 | ms/batch 12.97 | loss 0.05883201\n",
      "| Epoch 271 |   100/  658 batches | lr 0.00006 | ms/batch 14.22 | loss 0.05515987\n",
      "| Epoch 271 |   150/  658 batches | lr 0.00006 | ms/batch 12.62 | loss 0.05282999\n",
      "| Epoch 271 |   200/  658 batches | lr 0.00006 | ms/batch 14.42 | loss 0.05204711\n",
      "| Epoch 271 |   250/  658 batches | lr 0.00006 | ms/batch 14.36 | loss 0.05526538\n",
      "| Epoch 271 |   300/  658 batches | lr 0.00006 | ms/batch 12.71 | loss 0.05476900\n",
      "| Epoch 271 |   350/  658 batches | lr 0.00006 | ms/batch 12.62 | loss 0.05649030\n",
      "| Epoch 271 |   400/  658 batches | lr 0.00006 | ms/batch 14.26 | loss 0.05409298\n",
      "| Epoch 271 |   450/  658 batches | lr 0.00006 | ms/batch 12.71 | loss 0.05046019\n",
      "| Epoch 271 |   500/  658 batches | lr 0.00006 | ms/batch 14.57 | loss 0.05587261\n",
      "| Epoch 271 |   550/  658 batches | lr 0.00006 | ms/batch 15.37 | loss 0.05443475\n",
      "| Epoch 271 |   600/  658 batches | lr 0.00006 | ms/batch 12.96 | loss 0.05631851\n",
      "| Epoch 271 |   650/  658 batches | lr 0.00006 | ms/batch 12.83 | loss 0.05364800\n",
      "\n",
      "Val set: Average loss: 0.05758207\n",
      "\n",
      "EarlyStopping counter: 8 out of 20\n",
      "| Epoch 272 |    50/  658 batches | lr 0.00006 | ms/batch 12.80 | loss 0.05864464\n",
      "| Epoch 272 |   100/  658 batches | lr 0.00006 | ms/batch 14.82 | loss 0.05508153\n",
      "| Epoch 272 |   150/  658 batches | lr 0.00006 | ms/batch 13.69 | loss 0.05293035\n",
      "| Epoch 272 |   200/  658 batches | lr 0.00006 | ms/batch 15.34 | loss 0.05210822\n",
      "| Epoch 272 |   250/  658 batches | lr 0.00006 | ms/batch 14.39 | loss 0.05532326\n",
      "| Epoch 272 |   300/  658 batches | lr 0.00006 | ms/batch 12.77 | loss 0.05486180\n",
      "| Epoch 272 |   350/  658 batches | lr 0.00006 | ms/batch 12.62 | loss 0.05672122\n",
      "| Epoch 272 |   400/  658 batches | lr 0.00006 | ms/batch 14.51 | loss 0.05423180\n",
      "| Epoch 272 |   450/  658 batches | lr 0.00006 | ms/batch 13.49 | loss 0.05051497\n",
      "| Epoch 272 |   500/  658 batches | lr 0.00006 | ms/batch 14.48 | loss 0.05569414\n",
      "| Epoch 272 |   550/  658 batches | lr 0.00006 | ms/batch 14.27 | loss 0.05420024\n",
      "| Epoch 272 |   600/  658 batches | lr 0.00006 | ms/batch 12.63 | loss 0.05583852\n",
      "| Epoch 272 |   650/  658 batches | lr 0.00006 | ms/batch 12.75 | loss 0.05346291\n",
      "\n",
      "Val set: Average loss: 0.05762395\n",
      "\n",
      "EarlyStopping counter: 9 out of 20\n",
      "| Epoch 273 |    50/  658 batches | lr 0.00006 | ms/batch 12.95 | loss 0.05844281\n",
      "| Epoch 273 |   100/  658 batches | lr 0.00006 | ms/batch 14.30 | loss 0.05494864\n",
      "| Epoch 273 |   150/  658 batches | lr 0.00006 | ms/batch 12.74 | loss 0.05289704\n",
      "| Epoch 273 |   200/  658 batches | lr 0.00006 | ms/batch 14.49 | loss 0.05195761\n",
      "| Epoch 273 |   250/  658 batches | lr 0.00006 | ms/batch 14.34 | loss 0.05518215\n",
      "| Epoch 273 |   300/  658 batches | lr 0.00006 | ms/batch 12.80 | loss 0.05477827\n",
      "| Epoch 273 |   350/  658 batches | lr 0.00006 | ms/batch 12.90 | loss 0.05643657\n",
      "| Epoch 273 |   400/  658 batches | lr 0.00006 | ms/batch 14.40 | loss 0.05397959\n",
      "| Epoch 273 |   450/  658 batches | lr 0.00006 | ms/batch 12.59 | loss 0.05045079\n",
      "| Epoch 273 |   500/  658 batches | lr 0.00006 | ms/batch 14.41 | loss 0.05573263\n",
      "| Epoch 273 |   550/  658 batches | lr 0.00006 | ms/batch 14.31 | loss 0.05453339\n",
      "| Epoch 273 |   600/  658 batches | lr 0.00006 | ms/batch 12.55 | loss 0.05588298\n",
      "| Epoch 273 |   650/  658 batches | lr 0.00006 | ms/batch 12.72 | loss 0.05357911\n",
      "\n",
      "Val set: Average loss: 0.05766942\n",
      "\n",
      "EarlyStopping counter: 10 out of 20\n",
      "| Epoch 274 |    50/  658 batches | lr 0.00006 | ms/batch 12.96 | loss 0.05866232\n",
      "| Epoch 274 |   100/  658 batches | lr 0.00006 | ms/batch 14.38 | loss 0.05504262\n",
      "| Epoch 274 |   150/  658 batches | lr 0.00006 | ms/batch 12.70 | loss 0.05269249\n",
      "| Epoch 274 |   200/  658 batches | lr 0.00006 | ms/batch 14.35 | loss 0.05196585\n",
      "| Epoch 274 |   250/  658 batches | lr 0.00006 | ms/batch 14.65 | loss 0.05524338\n",
      "| Epoch 274 |   300/  658 batches | lr 0.00006 | ms/batch 13.52 | loss 0.05466654\n",
      "| Epoch 274 |   350/  658 batches | lr 0.00006 | ms/batch 12.81 | loss 0.05665831\n",
      "| Epoch 274 |   400/  658 batches | lr 0.00006 | ms/batch 14.35 | loss 0.05408489\n",
      "| Epoch 274 |   450/  658 batches | lr 0.00006 | ms/batch 12.60 | loss 0.05018882\n",
      "| Epoch 274 |   500/  658 batches | lr 0.00006 | ms/batch 14.28 | loss 0.05558403\n",
      "| Epoch 274 |   550/  658 batches | lr 0.00006 | ms/batch 14.40 | loss 0.05420254\n",
      "| Epoch 274 |   600/  658 batches | lr 0.00006 | ms/batch 12.54 | loss 0.05564899\n",
      "| Epoch 274 |   650/  658 batches | lr 0.00006 | ms/batch 12.59 | loss 0.05341118\n",
      "\n",
      "Val set: Average loss: 0.05775550\n",
      "\n",
      "EarlyStopping counter: 11 out of 20\n",
      "| Epoch 275 |    50/  658 batches | lr 0.00006 | ms/batch 13.05 | loss 0.05842340\n",
      "| Epoch 275 |   100/  658 batches | lr 0.00006 | ms/batch 14.26 | loss 0.05502067\n",
      "| Epoch 275 |   150/  658 batches | lr 0.00006 | ms/batch 12.67 | loss 0.05266013\n",
      "| Epoch 275 |   200/  658 batches | lr 0.00006 | ms/batch 14.32 | loss 0.05181843\n",
      "| Epoch 275 |   250/  658 batches | lr 0.00006 | ms/batch 14.98 | loss 0.05516357\n",
      "| Epoch 275 |   300/  658 batches | lr 0.00006 | ms/batch 13.36 | loss 0.05462395\n",
      "| Epoch 275 |   350/  658 batches | lr 0.00006 | ms/batch 12.84 | loss 0.05639106\n",
      "| Epoch 275 |   400/  658 batches | lr 0.00006 | ms/batch 14.34 | loss 0.05404079\n",
      "| Epoch 275 |   450/  658 batches | lr 0.00006 | ms/batch 12.72 | loss 0.05065262\n",
      "| Epoch 275 |   500/  658 batches | lr 0.00006 | ms/batch 14.43 | loss 0.05561395\n",
      "| Epoch 275 |   550/  658 batches | lr 0.00006 | ms/batch 14.37 | loss 0.05441702\n",
      "| Epoch 275 |   600/  658 batches | lr 0.00006 | ms/batch 12.80 | loss 0.05580052\n",
      "| Epoch 275 |   650/  658 batches | lr 0.00006 | ms/batch 13.26 | loss 0.05330159\n",
      "\n",
      "Val set: Average loss: 0.05775048\n",
      "\n",
      "EarlyStopping counter: 12 out of 20\n",
      "| Epoch 276 |    50/  658 batches | lr 0.00006 | ms/batch 13.27 | loss 0.05865442\n",
      "| Epoch 276 |   100/  658 batches | lr 0.00006 | ms/batch 14.57 | loss 0.05491576\n",
      "| Epoch 276 |   150/  658 batches | lr 0.00006 | ms/batch 13.24 | loss 0.05271366\n",
      "| Epoch 276 |   200/  658 batches | lr 0.00006 | ms/batch 15.39 | loss 0.05221242\n",
      "| Epoch 276 |   250/  658 batches | lr 0.00006 | ms/batch 15.29 | loss 0.05511100\n",
      "| Epoch 276 |   300/  658 batches | lr 0.00006 | ms/batch 15.37 | loss 0.05453436\n",
      "| Epoch 276 |   350/  658 batches | lr 0.00006 | ms/batch 13.98 | loss 0.05640045\n",
      "| Epoch 276 |   400/  658 batches | lr 0.00006 | ms/batch 16.41 | loss 0.05402875\n",
      "| Epoch 276 |   450/  658 batches | lr 0.00006 | ms/batch 14.25 | loss 0.05063551\n",
      "| Epoch 276 |   500/  658 batches | lr 0.00006 | ms/batch 15.98 | loss 0.05570788\n",
      "| Epoch 276 |   550/  658 batches | lr 0.00006 | ms/batch 15.28 | loss 0.05419407\n",
      "| Epoch 276 |   600/  658 batches | lr 0.00006 | ms/batch 13.23 | loss 0.05571750\n",
      "| Epoch 276 |   650/  658 batches | lr 0.00006 | ms/batch 13.71 | loss 0.05322503\n",
      "\n",
      "Val set: Average loss: 0.05784264\n",
      "\n",
      "EarlyStopping counter: 13 out of 20\n",
      "| Epoch 277 |    50/  658 batches | lr 0.00006 | ms/batch 13.63 | loss 0.05830168\n",
      "| Epoch 277 |   100/  658 batches | lr 0.00006 | ms/batch 14.88 | loss 0.05488115\n",
      "| Epoch 277 |   150/  658 batches | lr 0.00006 | ms/batch 13.62 | loss 0.05271264\n",
      "| Epoch 277 |   200/  658 batches | lr 0.00006 | ms/batch 15.37 | loss 0.05192447\n",
      "| Epoch 277 |   250/  658 batches | lr 0.00006 | ms/batch 16.33 | loss 0.05509151\n",
      "| Epoch 277 |   300/  658 batches | lr 0.00006 | ms/batch 14.60 | loss 0.05458542\n",
      "| Epoch 277 |   350/  658 batches | lr 0.00006 | ms/batch 13.64 | loss 0.05649496\n",
      "| Epoch 277 |   400/  658 batches | lr 0.00006 | ms/batch 14.93 | loss 0.05392230\n",
      "| Epoch 277 |   450/  658 batches | lr 0.00006 | ms/batch 14.09 | loss 0.05034350\n",
      "| Epoch 277 |   500/  658 batches | lr 0.00006 | ms/batch 17.42 | loss 0.05558313\n",
      "| Epoch 277 |   550/  658 batches | lr 0.00006 | ms/batch 16.74 | loss 0.05391325\n",
      "| Epoch 277 |   600/  658 batches | lr 0.00006 | ms/batch 14.36 | loss 0.05559319\n",
      "| Epoch 277 |   650/  658 batches | lr 0.00006 | ms/batch 13.64 | loss 0.05308389\n",
      "\n",
      "Val set: Average loss: 0.05763550\n",
      "\n",
      "EarlyStopping counter: 14 out of 20\n",
      "| Epoch 278 |    50/  658 batches | lr 0.00006 | ms/batch 14.33 | loss 0.05839664\n",
      "| Epoch 278 |   100/  658 batches | lr 0.00006 | ms/batch 14.88 | loss 0.05485806\n",
      "| Epoch 278 |   150/  658 batches | lr 0.00006 | ms/batch 13.16 | loss 0.05257095\n",
      "| Epoch 278 |   200/  658 batches | lr 0.00006 | ms/batch 15.19 | loss 0.05182068\n",
      "| Epoch 278 |   250/  658 batches | lr 0.00006 | ms/batch 15.92 | loss 0.05498733\n",
      "| Epoch 278 |   300/  658 batches | lr 0.00006 | ms/batch 13.96 | loss 0.05459956\n",
      "| Epoch 278 |   350/  658 batches | lr 0.00006 | ms/batch 14.62 | loss 0.05641211\n",
      "| Epoch 278 |   400/  658 batches | lr 0.00006 | ms/batch 15.51 | loss 0.05397245\n",
      "| Epoch 278 |   450/  658 batches | lr 0.00006 | ms/batch 13.52 | loss 0.05051261\n",
      "| Epoch 278 |   500/  658 batches | lr 0.00006 | ms/batch 14.55 | loss 0.05565920\n",
      "| Epoch 278 |   550/  658 batches | lr 0.00006 | ms/batch 16.79 | loss 0.05423386\n",
      "| Epoch 278 |   600/  658 batches | lr 0.00006 | ms/batch 15.17 | loss 0.05548466\n",
      "| Epoch 278 |   650/  658 batches | lr 0.00006 | ms/batch 18.15 | loss 0.05313018\n",
      "\n",
      "Val set: Average loss: 0.05772143\n",
      "\n",
      "EarlyStopping counter: 15 out of 20\n",
      "| Epoch 279 |    50/  658 batches | lr 0.00006 | ms/batch 13.53 | loss 0.05822821\n",
      "| Epoch 279 |   100/  658 batches | lr 0.00006 | ms/batch 16.46 | loss 0.05492737\n",
      "| Epoch 279 |   150/  658 batches | lr 0.00006 | ms/batch 14.57 | loss 0.05269251\n",
      "| Epoch 279 |   200/  658 batches | lr 0.00006 | ms/batch 14.86 | loss 0.05183373\n",
      "| Epoch 279 |   250/  658 batches | lr 0.00006 | ms/batch 16.53 | loss 0.05500058\n",
      "| Epoch 279 |   300/  658 batches | lr 0.00006 | ms/batch 13.92 | loss 0.05453346\n",
      "| Epoch 279 |   350/  658 batches | lr 0.00006 | ms/batch 13.67 | loss 0.05638662\n",
      "| Epoch 279 |   400/  658 batches | lr 0.00006 | ms/batch 15.46 | loss 0.05393162\n",
      "| Epoch 279 |   450/  658 batches | lr 0.00006 | ms/batch 17.00 | loss 0.05048283\n",
      "| Epoch 279 |   500/  658 batches | lr 0.00006 | ms/batch 16.55 | loss 0.05554909\n",
      "| Epoch 279 |   550/  658 batches | lr 0.00006 | ms/batch 14.87 | loss 0.05378729\n",
      "| Epoch 279 |   600/  658 batches | lr 0.00006 | ms/batch 15.00 | loss 0.05574839\n",
      "| Epoch 279 |   650/  658 batches | lr 0.00006 | ms/batch 16.13 | loss 0.05313295\n",
      "\n",
      "Val set: Average loss: 0.05762017\n",
      "\n",
      "EarlyStopping counter: 16 out of 20\n",
      "| Epoch 280 |    50/  658 batches | lr 0.00006 | ms/batch 15.50 | loss 0.05831502\n",
      "| Epoch 280 |   100/  658 batches | lr 0.00006 | ms/batch 16.16 | loss 0.05484729\n",
      "| Epoch 280 |   150/  658 batches | lr 0.00006 | ms/batch 15.88 | loss 0.05258903\n",
      "| Epoch 280 |   200/  658 batches | lr 0.00006 | ms/batch 18.80 | loss 0.05177122\n",
      "| Epoch 280 |   250/  658 batches | lr 0.00006 | ms/batch 18.50 | loss 0.05498418\n",
      "| Epoch 280 |   300/  658 batches | lr 0.00006 | ms/batch 13.10 | loss 0.05438075\n",
      "| Epoch 280 |   350/  658 batches | lr 0.00006 | ms/batch 13.04 | loss 0.05619104\n",
      "| Epoch 280 |   400/  658 batches | lr 0.00006 | ms/batch 14.69 | loss 0.05407601\n",
      "| Epoch 280 |   450/  658 batches | lr 0.00006 | ms/batch 12.83 | loss 0.04998117\n",
      "| Epoch 280 |   500/  658 batches | lr 0.00006 | ms/batch 14.39 | loss 0.05539288\n",
      "| Epoch 280 |   550/  658 batches | lr 0.00006 | ms/batch 14.93 | loss 0.05385880\n",
      "| Epoch 280 |   600/  658 batches | lr 0.00006 | ms/batch 13.04 | loss 0.05587874\n",
      "| Epoch 280 |   650/  658 batches | lr 0.00006 | ms/batch 13.20 | loss 0.05317834\n",
      "\n",
      "Val set: Average loss: 0.05767053\n",
      "\n",
      "EarlyStopping counter: 17 out of 20\n",
      "| Epoch 281 |    50/  658 batches | lr 0.00006 | ms/batch 13.29 | loss 0.05835566\n",
      "| Epoch 281 |   100/  658 batches | lr 0.00006 | ms/batch 15.31 | loss 0.05481459\n",
      "| Epoch 281 |   150/  658 batches | lr 0.00006 | ms/batch 12.87 | loss 0.05239660\n",
      "| Epoch 281 |   200/  658 batches | lr 0.00006 | ms/batch 15.05 | loss 0.05172219\n",
      "| Epoch 281 |   250/  658 batches | lr 0.00006 | ms/batch 14.79 | loss 0.05504461\n",
      "| Epoch 281 |   300/  658 batches | lr 0.00006 | ms/batch 12.72 | loss 0.05446122\n",
      "| Epoch 281 |   350/  658 batches | lr 0.00006 | ms/batch 13.24 | loss 0.05645296\n",
      "| Epoch 281 |   400/  658 batches | lr 0.00006 | ms/batch 14.91 | loss 0.05397779\n",
      "| Epoch 281 |   450/  658 batches | lr 0.00006 | ms/batch 12.85 | loss 0.05045975\n",
      "| Epoch 281 |   500/  658 batches | lr 0.00006 | ms/batch 14.63 | loss 0.05557379\n",
      "| Epoch 281 |   550/  658 batches | lr 0.00006 | ms/batch 14.47 | loss 0.05360587\n",
      "| Epoch 281 |   600/  658 batches | lr 0.00006 | ms/batch 12.75 | loss 0.05574561\n",
      "| Epoch 281 |   650/  658 batches | lr 0.00006 | ms/batch 12.83 | loss 0.05312119\n",
      "\n",
      "Val set: Average loss: 0.05783559\n",
      "\n",
      "EarlyStopping counter: 18 out of 20\n",
      "| Epoch 282 |    50/  658 batches | lr 0.00006 | ms/batch 13.01 | loss 0.05834866\n",
      "| Epoch 282 |   100/  658 batches | lr 0.00006 | ms/batch 14.34 | loss 0.05480265\n",
      "| Epoch 282 |   150/  658 batches | lr 0.00006 | ms/batch 12.75 | loss 0.05228563\n",
      "| Epoch 282 |   200/  658 batches | lr 0.00006 | ms/batch 14.54 | loss 0.05173778\n",
      "| Epoch 282 |   250/  658 batches | lr 0.00006 | ms/batch 14.44 | loss 0.05494712\n",
      "| Epoch 282 |   300/  658 batches | lr 0.00006 | ms/batch 12.86 | loss 0.05441376\n",
      "| Epoch 282 |   350/  658 batches | lr 0.00006 | ms/batch 12.99 | loss 0.05617466\n",
      "| Epoch 282 |   400/  658 batches | lr 0.00006 | ms/batch 14.41 | loss 0.05399926\n",
      "| Epoch 282 |   450/  658 batches | lr 0.00006 | ms/batch 13.24 | loss 0.05019766\n",
      "| Epoch 282 |   500/  658 batches | lr 0.00006 | ms/batch 16.16 | loss 0.05542289\n",
      "| Epoch 282 |   550/  658 batches | lr 0.00006 | ms/batch 15.25 | loss 0.05385302\n",
      "| Epoch 282 |   600/  658 batches | lr 0.00006 | ms/batch 13.12 | loss 0.05576697\n",
      "| Epoch 282 |   650/  658 batches | lr 0.00006 | ms/batch 12.76 | loss 0.05310633\n",
      "\n",
      "Val set: Average loss: 0.05786243\n",
      "\n",
      "EarlyStopping counter: 19 out of 20\n",
      "| Epoch 283 |    50/  658 batches | lr 0.00006 | ms/batch 12.85 | loss 0.05806603\n",
      "| Epoch 283 |   100/  658 batches | lr 0.00006 | ms/batch 14.38 | loss 0.05486272\n",
      "| Epoch 283 |   150/  658 batches | lr 0.00006 | ms/batch 12.79 | loss 0.05235057\n",
      "| Epoch 283 |   200/  658 batches | lr 0.00006 | ms/batch 14.42 | loss 0.05164814\n",
      "| Epoch 283 |   250/  658 batches | lr 0.00006 | ms/batch 14.56 | loss 0.05499854\n",
      "| Epoch 283 |   300/  658 batches | lr 0.00006 | ms/batch 12.80 | loss 0.05439343\n",
      "| Epoch 283 |   350/  658 batches | lr 0.00006 | ms/batch 13.09 | loss 0.05623809\n",
      "| Epoch 283 |   400/  658 batches | lr 0.00006 | ms/batch 14.82 | loss 0.05394251\n",
      "| Epoch 283 |   450/  658 batches | lr 0.00006 | ms/batch 13.27 | loss 0.05036380\n",
      "| Epoch 283 |   500/  658 batches | lr 0.00006 | ms/batch 14.51 | loss 0.05558276\n",
      "| Epoch 283 |   550/  658 batches | lr 0.00006 | ms/batch 14.40 | loss 0.05359304\n",
      "| Epoch 283 |   600/  658 batches | lr 0.00006 | ms/batch 13.90 | loss 0.05568317\n",
      "| Epoch 283 |   650/  658 batches | lr 0.00006 | ms/batch 13.01 | loss 0.05297030\n",
      "\n",
      "Val set: Average loss: 0.05784665\n",
      "\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Stopping at Epoch: 283\n"
     ]
    }
   ],
   "source": [
    "load = False\n",
    "save_model_path = '../models/final_real_data_model_cleaned.chkpt'\n",
    "val_err_df_path = '../results/val_final_real_data_model_cleaned.csv'\n",
    "\n",
    "if not load:\n",
    "  train_losses, val_losses = train(\n",
    "      epochs,\n",
    "      batch_size,\n",
    "      model,\n",
    "      optimizer,\n",
    "      loss_fn,\n",
    "      X_train,\n",
    "      y_train,\n",
    "      X_val,\n",
    "      y_val)\n",
    "  val_err_df = pd.DataFrame({\n",
    "      'Training': train_losses,\n",
    "      'Validation': val_losses})\n",
    "  val_err_df.to_csv(val_err_df_path)\n",
    "  torch.save(model.state_dict(), save_model_path)\n",
    "else:\n",
    "  model = Net(input_size, output_size, hidden_size, num_layers, act_fn)\n",
    "  model.load_state_dict(torch.load(save_model_path, map_location=device))\n",
    "  model = model.to(device)\n",
    "  val_err_df = pd.read_csv(val_err_df_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1650894219921,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "KkenWSRYvDpl",
    "outputId": "37746aa5-0b46-4a80-d14d-397868e89361",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_err_df[1:].plot(xlabel='epoch', ylabel='MSE')\n",
    "plt.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FlG5Ky25vDpm",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1650894219922,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "TBZ4eHAdvDpn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_size = 30\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_out = model(X_test[0:test_size].to(device))\n",
    "\n",
    "test_out = output_sc.inverse_transform(test_out.cpu().detach().numpy())\n",
    "real_out = output_sc.inverse_transform(y_test[0:test_size].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1650894219926,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "wK1WeGIZvDpo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['strike', 'close', 'hv_21', 'moneyness', 'tau', 'r',\n",
    "       'call', 'put']\n",
    "test_options = pd.DataFrame(input_sc.inverse_transform(X_test[0:test_size].detach().cpu().numpy()), columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 68,
     "status": "ok",
     "timestamp": 1650894220542,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "_dvE5LGXvDpq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         strike        close     hv_21  moneyness       tau         r  \\\n0    724.942017  1078.057373  0.601565   0.672724  0.291270  0.005249   \n1    119.779816   186.636154  1.620926   0.643852  0.010965  0.010750   \n2    970.000977   952.522156  0.653796   1.018581  0.120999  0.008331   \n3   2159.910889  2146.113281  0.751449   0.993920  0.002666  0.010322   \n4   3176.765381  2890.473389  0.405984   0.910914  0.099046  0.008408   \n5    102.653839   169.737167  0.838465   0.604154  1.063380  0.010719   \n6    104.794586   197.499741  0.826699   1.882022  0.181236  0.009094   \n7   1559.966797  2518.695557  0.633307   1.614246  0.716814  0.008331   \n8    719.991516   193.073837  0.660636   0.267920  1.639517  0.011406   \n9    249.830109   199.511520  1.524059   0.797834  0.387449  0.008408   \n10   129.948334   195.890305  0.824784   0.663701  0.387449  0.011924   \n11  1119.909668  1057.134888  0.610801   1.059783  2.214584  0.006981   \n12   334.924774   169.737167  0.726566   0.505509  0.530279  0.009071   \n13  3200.313477  2434.200684  0.594725   0.761143  0.543932  0.011406   \n14    64.120392   709.498657  0.834498  11.086348  0.079770  0.010322   \n15   399.682343   156.459396  0.277649   2.554791  0.140275  0.008232   \n16   294.785797   290.041779  0.417067   0.983093  0.871156  0.008331   \n17   174.904022    90.875229  0.547864   0.519945  0.085124  0.008812   \n18   140.116913   149.216965  0.464679   1.066400  0.066116  0.010437   \n19   182.396637   156.459396  0.277649   1.165044  0.005343  0.008232   \n20  3150.006104  2327.978516  0.671394   1.353462  0.714271  0.008530   \n21    38.966648   176.174850  0.742180   0.219800  0.354452  0.009094   \n22  1579.768677  2486.507080  0.643534   0.636033  0.123676  0.008812   \n23   569.871704   876.476685  0.712405   0.650468  0.392870  0.008331   \n24   390.048981   169.737167  0.838465   2.296751  0.409469  0.010719   \n25    95.161224   191.062057  0.837918   2.013749  0.348830  0.009880   \n26  3255.972900  2763.328613  0.360834   1.177976  0.044163  0.008232   \n27  2979.816650  2151.746338  0.751449   1.384739  0.030241  0.010673   \n28   639.981140   172.955978  1.544856   0.270326  0.030241  0.009071   \n29   394.865692   724.486450  0.807613   0.545809  0.684018  0.010750   \n\n        call       put   Prediction         Real  \n0   0.000239  0.999761    13.695415    20.074718  \n1   0.000239  0.999761   -11.851948    -0.095158  \n2   0.000239  0.999761   117.253822   152.008652  \n3   0.999798  0.000202    33.196011    21.010876  \n4   0.999798  0.000202    65.812744    53.350750  \n5   0.000239  0.999761     2.352215    12.840801  \n6   0.999798  0.000202    92.213051    97.350006  \n7   0.999798  0.000202  1477.562988  1360.902954  \n8   0.999798  0.000202    -5.173756     1.266521  \n9   0.999798  0.000202    13.408627     9.436596  \n10  0.000239  0.999761    -4.091434     4.500515  \n11  0.000239  0.999761   365.674835   374.026154  \n12  0.999798  0.000202     0.241360     1.777157  \n13  0.999798  0.000202    51.504452    78.456711  \n14  0.999798  0.000202   949.060181   995.292175  \n15  0.000239  0.999761    56.851192    51.223125  \n16  0.999798  0.000202    30.297482    28.244793  \n17  0.999798  0.000202     3.242138    -0.095158  \n18  0.999798  0.000202    18.272655    11.308910  \n19  0.000239  0.999761    18.848461    23.819332  \n20  0.000239  0.999761   805.792603   707.977905  \n21  0.000239  0.999761    -6.836338     0.075054  \n22  0.000239  0.999761     2.528118     6.032406  \n23  0.000239  0.999761    24.414364    29.010738  \n24  0.000239  0.999761   169.125793   132.030258  \n25  0.999798  0.000202   119.540657   108.243439  \n26  0.000239  0.999761   387.560852   359.983826  \n27  0.000239  0.999761   758.068726   803.976318  \n28  0.999798  0.000202    -2.701969    -0.095158  \n29  0.000239  0.999761    23.815548    31.393673  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>strike</th>\n      <th>close</th>\n      <th>hv_21</th>\n      <th>moneyness</th>\n      <th>tau</th>\n      <th>r</th>\n      <th>call</th>\n      <th>put</th>\n      <th>Prediction</th>\n      <th>Real</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>724.942017</td>\n      <td>1078.057373</td>\n      <td>0.601565</td>\n      <td>0.672724</td>\n      <td>0.291270</td>\n      <td>0.005249</td>\n      <td>0.000239</td>\n      <td>0.999761</td>\n      <td>13.695415</td>\n      <td>20.074718</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>119.779816</td>\n      <td>186.636154</td>\n      <td>1.620926</td>\n      <td>0.643852</td>\n      <td>0.010965</td>\n      <td>0.010750</td>\n      <td>0.000239</td>\n      <td>0.999761</td>\n      <td>-11.851948</td>\n      <td>-0.095158</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>970.000977</td>\n      <td>952.522156</td>\n      <td>0.653796</td>\n      <td>1.018581</td>\n      <td>0.120999</td>\n      <td>0.008331</td>\n      <td>0.000239</td>\n      <td>0.999761</td>\n      <td>117.253822</td>\n      <td>152.008652</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2159.910889</td>\n      <td>2146.113281</td>\n      <td>0.751449</td>\n      <td>0.993920</td>\n      <td>0.002666</td>\n      <td>0.010322</td>\n      <td>0.999798</td>\n      <td>0.000202</td>\n      <td>33.196011</td>\n      <td>21.010876</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3176.765381</td>\n      <td>2890.473389</td>\n      <td>0.405984</td>\n      <td>0.910914</td>\n      <td>0.099046</td>\n      <td>0.008408</td>\n      <td>0.999798</td>\n      <td>0.000202</td>\n      <td>65.812744</td>\n      <td>53.350750</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>102.653839</td>\n      <td>169.737167</td>\n      <td>0.838465</td>\n      <td>0.604154</td>\n      <td>1.063380</td>\n      <td>0.010719</td>\n      <td>0.000239</td>\n      <td>0.999761</td>\n      <td>2.352215</td>\n      <td>12.840801</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>104.794586</td>\n      <td>197.499741</td>\n      <td>0.826699</td>\n      <td>1.882022</td>\n      <td>0.181236</td>\n      <td>0.009094</td>\n      <td>0.999798</td>\n      <td>0.000202</td>\n      <td>92.213051</td>\n      <td>97.350006</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1559.966797</td>\n      <td>2518.695557</td>\n      <td>0.633307</td>\n      <td>1.614246</td>\n      <td>0.716814</td>\n      <td>0.008331</td>\n      <td>0.999798</td>\n      <td>0.000202</td>\n      <td>1477.562988</td>\n      <td>1360.902954</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>719.991516</td>\n      <td>193.073837</td>\n      <td>0.660636</td>\n      <td>0.267920</td>\n      <td>1.639517</td>\n      <td>0.011406</td>\n      <td>0.999798</td>\n      <td>0.000202</td>\n      <td>-5.173756</td>\n      <td>1.266521</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>249.830109</td>\n      <td>199.511520</td>\n      <td>1.524059</td>\n      <td>0.797834</td>\n      <td>0.387449</td>\n      <td>0.008408</td>\n      <td>0.999798</td>\n      <td>0.000202</td>\n      <td>13.408627</td>\n      <td>9.436596</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>129.948334</td>\n      <td>195.890305</td>\n      <td>0.824784</td>\n      <td>0.663701</td>\n      <td>0.387449</td>\n      <td>0.011924</td>\n      <td>0.000239</td>\n      <td>0.999761</td>\n      <td>-4.091434</td>\n      <td>4.500515</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1119.909668</td>\n      <td>1057.134888</td>\n      <td>0.610801</td>\n      <td>1.059783</td>\n      <td>2.214584</td>\n      <td>0.006981</td>\n      <td>0.000239</td>\n      <td>0.999761</td>\n      <td>365.674835</td>\n      <td>374.026154</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>334.924774</td>\n      <td>169.737167</td>\n      <td>0.726566</td>\n      <td>0.505509</td>\n      <td>0.530279</td>\n      <td>0.009071</td>\n      <td>0.999798</td>\n      <td>0.000202</td>\n      <td>0.241360</td>\n      <td>1.777157</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>3200.313477</td>\n      <td>2434.200684</td>\n      <td>0.594725</td>\n      <td>0.761143</td>\n      <td>0.543932</td>\n      <td>0.011406</td>\n      <td>0.999798</td>\n      <td>0.000202</td>\n      <td>51.504452</td>\n      <td>78.456711</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>64.120392</td>\n      <td>709.498657</td>\n      <td>0.834498</td>\n      <td>11.086348</td>\n      <td>0.079770</td>\n      <td>0.010322</td>\n      <td>0.999798</td>\n      <td>0.000202</td>\n      <td>949.060181</td>\n      <td>995.292175</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>399.682343</td>\n      <td>156.459396</td>\n      <td>0.277649</td>\n      <td>2.554791</td>\n      <td>0.140275</td>\n      <td>0.008232</td>\n      <td>0.000239</td>\n      <td>0.999761</td>\n      <td>56.851192</td>\n      <td>51.223125</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>294.785797</td>\n      <td>290.041779</td>\n      <td>0.417067</td>\n      <td>0.983093</td>\n      <td>0.871156</td>\n      <td>0.008331</td>\n      <td>0.999798</td>\n      <td>0.000202</td>\n      <td>30.297482</td>\n      <td>28.244793</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>174.904022</td>\n      <td>90.875229</td>\n      <td>0.547864</td>\n      <td>0.519945</td>\n      <td>0.085124</td>\n      <td>0.008812</td>\n      <td>0.999798</td>\n      <td>0.000202</td>\n      <td>3.242138</td>\n      <td>-0.095158</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>140.116913</td>\n      <td>149.216965</td>\n      <td>0.464679</td>\n      <td>1.066400</td>\n      <td>0.066116</td>\n      <td>0.010437</td>\n      <td>0.999798</td>\n      <td>0.000202</td>\n      <td>18.272655</td>\n      <td>11.308910</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>182.396637</td>\n      <td>156.459396</td>\n      <td>0.277649</td>\n      <td>1.165044</td>\n      <td>0.005343</td>\n      <td>0.008232</td>\n      <td>0.000239</td>\n      <td>0.999761</td>\n      <td>18.848461</td>\n      <td>23.819332</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>3150.006104</td>\n      <td>2327.978516</td>\n      <td>0.671394</td>\n      <td>1.353462</td>\n      <td>0.714271</td>\n      <td>0.008530</td>\n      <td>0.000239</td>\n      <td>0.999761</td>\n      <td>805.792603</td>\n      <td>707.977905</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>38.966648</td>\n      <td>176.174850</td>\n      <td>0.742180</td>\n      <td>0.219800</td>\n      <td>0.354452</td>\n      <td>0.009094</td>\n      <td>0.000239</td>\n      <td>0.999761</td>\n      <td>-6.836338</td>\n      <td>0.075054</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>1579.768677</td>\n      <td>2486.507080</td>\n      <td>0.643534</td>\n      <td>0.636033</td>\n      <td>0.123676</td>\n      <td>0.008812</td>\n      <td>0.000239</td>\n      <td>0.999761</td>\n      <td>2.528118</td>\n      <td>6.032406</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>569.871704</td>\n      <td>876.476685</td>\n      <td>0.712405</td>\n      <td>0.650468</td>\n      <td>0.392870</td>\n      <td>0.008331</td>\n      <td>0.000239</td>\n      <td>0.999761</td>\n      <td>24.414364</td>\n      <td>29.010738</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>390.048981</td>\n      <td>169.737167</td>\n      <td>0.838465</td>\n      <td>2.296751</td>\n      <td>0.409469</td>\n      <td>0.010719</td>\n      <td>0.000239</td>\n      <td>0.999761</td>\n      <td>169.125793</td>\n      <td>132.030258</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>95.161224</td>\n      <td>191.062057</td>\n      <td>0.837918</td>\n      <td>2.013749</td>\n      <td>0.348830</td>\n      <td>0.009880</td>\n      <td>0.999798</td>\n      <td>0.000202</td>\n      <td>119.540657</td>\n      <td>108.243439</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>3255.972900</td>\n      <td>2763.328613</td>\n      <td>0.360834</td>\n      <td>1.177976</td>\n      <td>0.044163</td>\n      <td>0.008232</td>\n      <td>0.000239</td>\n      <td>0.999761</td>\n      <td>387.560852</td>\n      <td>359.983826</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>2979.816650</td>\n      <td>2151.746338</td>\n      <td>0.751449</td>\n      <td>1.384739</td>\n      <td>0.030241</td>\n      <td>0.010673</td>\n      <td>0.000239</td>\n      <td>0.999761</td>\n      <td>758.068726</td>\n      <td>803.976318</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>639.981140</td>\n      <td>172.955978</td>\n      <td>1.544856</td>\n      <td>0.270326</td>\n      <td>0.030241</td>\n      <td>0.009071</td>\n      <td>0.999798</td>\n      <td>0.000202</td>\n      <td>-2.701969</td>\n      <td>-0.095158</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>394.865692</td>\n      <td>724.486450</td>\n      <td>0.807613</td>\n      <td>0.545809</td>\n      <td>0.684018</td>\n      <td>0.010750</td>\n      <td>0.000239</td>\n      <td>0.999761</td>\n      <td>23.815548</td>\n      <td>31.393673</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_options['Prediction'] = test_out\n",
    "test_options['Real'] = real_out\n",
    "test_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 67,
     "status": "ok",
     "timestamp": 1650894220545,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "TNw5-1jgvDpr",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_options['Abs Error'] = np.abs(test_options.Prediction - test_options.Real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 990
    },
    "executionInfo": {
     "elapsed": 65,
     "status": "ok",
     "timestamp": 1650894220546,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "lAC6AdeVvDpr",
    "outputId": "78bd13cc-c5a0-4746-f402-9e84d8b78696",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         strike        close     hv_21  moneyness       tau         r  \\\n12   334.924774   169.737167  0.726566   0.505509  0.530279  0.009071   \n16   294.785797   290.041779  0.417067   0.983093  0.871156  0.008331   \n28   639.981140   172.955978  1.544856   0.270326  0.030241  0.009071   \n17   174.904022    90.875229  0.547864   0.519945  0.085124  0.008812   \n22  1579.768677  2486.507080  0.643534   0.636033  0.123676  0.008812   \n9    249.830109   199.511520  1.524059   0.797834  0.387449  0.008408   \n23   569.871704   876.476685  0.712405   0.650468  0.392870  0.008331   \n19   182.396637   156.459396  0.277649   1.165044  0.005343  0.008232   \n6    104.794586   197.499741  0.826699   1.882022  0.181236  0.009094   \n15   399.682343   156.459396  0.277649   2.554791  0.140275  0.008232   \n0    724.942017  1078.057373  0.601565   0.672724  0.291270  0.005249   \n8    719.991516   193.073837  0.660636   0.267920  1.639517  0.011406   \n21    38.966648   176.174850  0.742180   0.219800  0.354452  0.009094   \n18   140.116913   149.216965  0.464679   1.066400  0.066116  0.010437   \n29   394.865692   724.486450  0.807613   0.545809  0.684018  0.010750   \n11  1119.909668  1057.134888  0.610801   1.059783  2.214584  0.006981   \n10   129.948334   195.890305  0.824784   0.663701  0.387449  0.011924   \n5    102.653839   169.737167  0.838465   0.604154  1.063380  0.010719   \n25    95.161224   191.062057  0.837918   2.013749  0.348830  0.009880   \n1    119.779816   186.636154  1.620926   0.643852  0.010965  0.010750   \n3   2159.910889  2146.113281  0.751449   0.993920  0.002666  0.010322   \n4   3176.765381  2890.473389  0.405984   0.910914  0.099046  0.008408   \n13  3200.313477  2434.200684  0.594725   0.761143  0.543932  0.011406   \n26  3255.972900  2763.328613  0.360834   1.177976  0.044163  0.008232   \n2    970.000977   952.522156  0.653796   1.018581  0.120999  0.008331   \n24   390.048981   169.737167  0.838465   2.296751  0.409469  0.010719   \n27  2979.816650  2151.746338  0.751449   1.384739  0.030241  0.010673   \n14    64.120392   709.498657  0.834498  11.086348  0.079770  0.010322   \n20  3150.006104  2327.978516  0.671394   1.353462  0.714271  0.008530   \n7   1559.966797  2518.695557  0.633307   1.614246  0.716814  0.008331   \n\n        call       put   Prediction         Real   Abs Error  \n12  0.999798  0.000202     0.241360     1.777157    1.535797  \n16  0.999798  0.000202    30.297482    28.244793    2.052689  \n28  0.999798  0.000202    -2.701969    -0.095158    2.606812  \n17  0.999798  0.000202     3.242138    -0.095158    3.337296  \n22  0.000239  0.999761     2.528118     6.032406    3.504288  \n9   0.999798  0.000202    13.408627     9.436596    3.972031  \n23  0.000239  0.999761    24.414364    29.010738    4.596375  \n19  0.000239  0.999761    18.848461    23.819332    4.970871  \n6   0.999798  0.000202    92.213051    97.350006    5.136955  \n15  0.000239  0.999761    56.851192    51.223125    5.628067  \n0   0.000239  0.999761    13.695415    20.074718    6.379303  \n8   0.999798  0.000202    -5.173756     1.266521    6.440277  \n21  0.000239  0.999761    -6.836338     0.075054    6.911392  \n18  0.999798  0.000202    18.272655    11.308910    6.963745  \n29  0.000239  0.999761    23.815548    31.393673    7.578125  \n11  0.000239  0.999761   365.674835   374.026154    8.351318  \n10  0.000239  0.999761    -4.091434     4.500515    8.591949  \n5   0.000239  0.999761     2.352215    12.840801   10.488586  \n25  0.999798  0.000202   119.540657   108.243439   11.297218  \n1   0.000239  0.999761   -11.851948    -0.095158   11.756790  \n3   0.999798  0.000202    33.196011    21.010876   12.185135  \n4   0.999798  0.000202    65.812744    53.350750   12.461994  \n13  0.999798  0.000202    51.504452    78.456711   26.952259  \n26  0.000239  0.999761   387.560852   359.983826   27.577026  \n2   0.000239  0.999761   117.253822   152.008652   34.754829  \n24  0.000239  0.999761   169.125793   132.030258   37.095535  \n27  0.000239  0.999761   758.068726   803.976318   45.907593  \n14  0.999798  0.000202   949.060181   995.292175   46.231995  \n20  0.000239  0.999761   805.792603   707.977905   97.814697  \n7   0.999798  0.000202  1477.562988  1360.902954  116.660034  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>strike</th>\n      <th>close</th>\n      <th>hv_21</th>\n      <th>moneyness</th>\n      <th>tau</th>\n      <th>r</th>\n      <th>call</th>\n      <th>put</th>\n      <th>Prediction</th>\n      <th>Real</th>\n      <th>Abs Error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12</th>\n      <td>334.924774</td>\n      <td>169.737167</td>\n      <td>0.726566</td>\n      <td>0.505509</td>\n      <td>0.530279</td>\n      <td>0.009071</td>\n      <td>0.999798</td>\n      <td>0.000202</td>\n      <td>0.241360</td>\n      <td>1.777157</td>\n      <td>1.535797</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>294.785797</td>\n      <td>290.041779</td>\n      <td>0.417067</td>\n      <td>0.983093</td>\n      <td>0.871156</td>\n      <td>0.008331</td>\n      <td>0.999798</td>\n      <td>0.000202</td>\n      <td>30.297482</td>\n      <td>28.244793</td>\n      <td>2.052689</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>639.981140</td>\n      <td>172.955978</td>\n      <td>1.544856</td>\n      <td>0.270326</td>\n      <td>0.030241</td>\n      <td>0.009071</td>\n      <td>0.999798</td>\n      <td>0.000202</td>\n      <td>-2.701969</td>\n      <td>-0.095158</td>\n      <td>2.606812</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>174.904022</td>\n      <td>90.875229</td>\n      <td>0.547864</td>\n      <td>0.519945</td>\n      <td>0.085124</td>\n      <td>0.008812</td>\n      <td>0.999798</td>\n      <td>0.000202</td>\n      <td>3.242138</td>\n      <td>-0.095158</td>\n      <td>3.337296</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>1579.768677</td>\n      <td>2486.507080</td>\n      <td>0.643534</td>\n      <td>0.636033</td>\n      <td>0.123676</td>\n      <td>0.008812</td>\n      <td>0.000239</td>\n      <td>0.999761</td>\n      <td>2.528118</td>\n      <td>6.032406</td>\n      <td>3.504288</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>249.830109</td>\n      <td>199.511520</td>\n      <td>1.524059</td>\n      <td>0.797834</td>\n      <td>0.387449</td>\n      <td>0.008408</td>\n      <td>0.999798</td>\n      <td>0.000202</td>\n      <td>13.408627</td>\n      <td>9.436596</td>\n      <td>3.972031</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>569.871704</td>\n      <td>876.476685</td>\n      <td>0.712405</td>\n      <td>0.650468</td>\n      <td>0.392870</td>\n      <td>0.008331</td>\n      <td>0.000239</td>\n      <td>0.999761</td>\n      <td>24.414364</td>\n      <td>29.010738</td>\n      <td>4.596375</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>182.396637</td>\n      <td>156.459396</td>\n      <td>0.277649</td>\n      <td>1.165044</td>\n      <td>0.005343</td>\n      <td>0.008232</td>\n      <td>0.000239</td>\n      <td>0.999761</td>\n      <td>18.848461</td>\n      <td>23.819332</td>\n      <td>4.970871</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>104.794586</td>\n      <td>197.499741</td>\n      <td>0.826699</td>\n      <td>1.882022</td>\n      <td>0.181236</td>\n      <td>0.009094</td>\n      <td>0.999798</td>\n      <td>0.000202</td>\n      <td>92.213051</td>\n      <td>97.350006</td>\n      <td>5.136955</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>399.682343</td>\n      <td>156.459396</td>\n      <td>0.277649</td>\n      <td>2.554791</td>\n      <td>0.140275</td>\n      <td>0.008232</td>\n      <td>0.000239</td>\n      <td>0.999761</td>\n      <td>56.851192</td>\n      <td>51.223125</td>\n      <td>5.628067</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>724.942017</td>\n      <td>1078.057373</td>\n      <td>0.601565</td>\n      <td>0.672724</td>\n      <td>0.291270</td>\n      <td>0.005249</td>\n      <td>0.000239</td>\n      <td>0.999761</td>\n      <td>13.695415</td>\n      <td>20.074718</td>\n      <td>6.379303</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>719.991516</td>\n      <td>193.073837</td>\n      <td>0.660636</td>\n      <td>0.267920</td>\n      <td>1.639517</td>\n      <td>0.011406</td>\n      <td>0.999798</td>\n      <td>0.000202</td>\n      <td>-5.173756</td>\n      <td>1.266521</td>\n      <td>6.440277</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>38.966648</td>\n      <td>176.174850</td>\n      <td>0.742180</td>\n      <td>0.219800</td>\n      <td>0.354452</td>\n      <td>0.009094</td>\n      <td>0.000239</td>\n      <td>0.999761</td>\n      <td>-6.836338</td>\n      <td>0.075054</td>\n      <td>6.911392</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>140.116913</td>\n      <td>149.216965</td>\n      <td>0.464679</td>\n      <td>1.066400</td>\n      <td>0.066116</td>\n      <td>0.010437</td>\n      <td>0.999798</td>\n      <td>0.000202</td>\n      <td>18.272655</td>\n      <td>11.308910</td>\n      <td>6.963745</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>394.865692</td>\n      <td>724.486450</td>\n      <td>0.807613</td>\n      <td>0.545809</td>\n      <td>0.684018</td>\n      <td>0.010750</td>\n      <td>0.000239</td>\n      <td>0.999761</td>\n      <td>23.815548</td>\n      <td>31.393673</td>\n      <td>7.578125</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1119.909668</td>\n      <td>1057.134888</td>\n      <td>0.610801</td>\n      <td>1.059783</td>\n      <td>2.214584</td>\n      <td>0.006981</td>\n      <td>0.000239</td>\n      <td>0.999761</td>\n      <td>365.674835</td>\n      <td>374.026154</td>\n      <td>8.351318</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>129.948334</td>\n      <td>195.890305</td>\n      <td>0.824784</td>\n      <td>0.663701</td>\n      <td>0.387449</td>\n      <td>0.011924</td>\n      <td>0.000239</td>\n      <td>0.999761</td>\n      <td>-4.091434</td>\n      <td>4.500515</td>\n      <td>8.591949</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>102.653839</td>\n      <td>169.737167</td>\n      <td>0.838465</td>\n      <td>0.604154</td>\n      <td>1.063380</td>\n      <td>0.010719</td>\n      <td>0.000239</td>\n      <td>0.999761</td>\n      <td>2.352215</td>\n      <td>12.840801</td>\n      <td>10.488586</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>95.161224</td>\n      <td>191.062057</td>\n      <td>0.837918</td>\n      <td>2.013749</td>\n      <td>0.348830</td>\n      <td>0.009880</td>\n      <td>0.999798</td>\n      <td>0.000202</td>\n      <td>119.540657</td>\n      <td>108.243439</td>\n      <td>11.297218</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>119.779816</td>\n      <td>186.636154</td>\n      <td>1.620926</td>\n      <td>0.643852</td>\n      <td>0.010965</td>\n      <td>0.010750</td>\n      <td>0.000239</td>\n      <td>0.999761</td>\n      <td>-11.851948</td>\n      <td>-0.095158</td>\n      <td>11.756790</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2159.910889</td>\n      <td>2146.113281</td>\n      <td>0.751449</td>\n      <td>0.993920</td>\n      <td>0.002666</td>\n      <td>0.010322</td>\n      <td>0.999798</td>\n      <td>0.000202</td>\n      <td>33.196011</td>\n      <td>21.010876</td>\n      <td>12.185135</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3176.765381</td>\n      <td>2890.473389</td>\n      <td>0.405984</td>\n      <td>0.910914</td>\n      <td>0.099046</td>\n      <td>0.008408</td>\n      <td>0.999798</td>\n      <td>0.000202</td>\n      <td>65.812744</td>\n      <td>53.350750</td>\n      <td>12.461994</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>3200.313477</td>\n      <td>2434.200684</td>\n      <td>0.594725</td>\n      <td>0.761143</td>\n      <td>0.543932</td>\n      <td>0.011406</td>\n      <td>0.999798</td>\n      <td>0.000202</td>\n      <td>51.504452</td>\n      <td>78.456711</td>\n      <td>26.952259</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>3255.972900</td>\n      <td>2763.328613</td>\n      <td>0.360834</td>\n      <td>1.177976</td>\n      <td>0.044163</td>\n      <td>0.008232</td>\n      <td>0.000239</td>\n      <td>0.999761</td>\n      <td>387.560852</td>\n      <td>359.983826</td>\n      <td>27.577026</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>970.000977</td>\n      <td>952.522156</td>\n      <td>0.653796</td>\n      <td>1.018581</td>\n      <td>0.120999</td>\n      <td>0.008331</td>\n      <td>0.000239</td>\n      <td>0.999761</td>\n      <td>117.253822</td>\n      <td>152.008652</td>\n      <td>34.754829</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>390.048981</td>\n      <td>169.737167</td>\n      <td>0.838465</td>\n      <td>2.296751</td>\n      <td>0.409469</td>\n      <td>0.010719</td>\n      <td>0.000239</td>\n      <td>0.999761</td>\n      <td>169.125793</td>\n      <td>132.030258</td>\n      <td>37.095535</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>2979.816650</td>\n      <td>2151.746338</td>\n      <td>0.751449</td>\n      <td>1.384739</td>\n      <td>0.030241</td>\n      <td>0.010673</td>\n      <td>0.000239</td>\n      <td>0.999761</td>\n      <td>758.068726</td>\n      <td>803.976318</td>\n      <td>45.907593</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>64.120392</td>\n      <td>709.498657</td>\n      <td>0.834498</td>\n      <td>11.086348</td>\n      <td>0.079770</td>\n      <td>0.010322</td>\n      <td>0.999798</td>\n      <td>0.000202</td>\n      <td>949.060181</td>\n      <td>995.292175</td>\n      <td>46.231995</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>3150.006104</td>\n      <td>2327.978516</td>\n      <td>0.671394</td>\n      <td>1.353462</td>\n      <td>0.714271</td>\n      <td>0.008530</td>\n      <td>0.000239</td>\n      <td>0.999761</td>\n      <td>805.792603</td>\n      <td>707.977905</td>\n      <td>97.814697</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1559.966797</td>\n      <td>2518.695557</td>\n      <td>0.633307</td>\n      <td>1.614246</td>\n      <td>0.716814</td>\n      <td>0.008331</td>\n      <td>0.999798</td>\n      <td>0.000202</td>\n      <td>1477.562988</td>\n      <td>1360.902954</td>\n      <td>116.660034</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_options.sort_values('Abs Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fDJ-hkrSAqVh",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### MSE on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def get_mse(model, X, y, batch_size):\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for batch, batch_labels in DataLoader(OptDataset(X, y), batch_size=batch_size):\n",
    "            out = model(batch.to(device))\n",
    "            loss = loss_fn(out, batch_labels.to(device))\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    losses = np.array(losses)\n",
    "    return losses"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 276,
     "status": "ok",
     "timestamp": 1650895213041,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "GG64Xp3vAib-",
    "outputId": "f846ee65-029d-4a76-b006-d65e4ac07a48",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE on the train set is:  0.055784855015281486\n",
      "The MSE on the val set is:  0.05784665452069547\n",
      "The MSE on the test set is:  0.06300446296851318\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "print('The MSE on the train set is: ', get_mse(model, X_train, y_train, batch_size).mean())\n",
    "print('The MSE on the val set is: ', get_mse(model, X_val, y_val, batch_size).mean())\n",
    "print('The MSE on the test set is: ', get_mse(model, X_test, y_test, batch_size).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCLf2KQJAvoE",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### MAE on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def get_mae(model, X, y, batch_size):\n",
    "    mae_loss = nn.L1Loss()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for batch, batch_labels in DataLoader(OptDataset(X, y), batch_size=batch_size):\n",
    "            out = model(batch.to(device))\n",
    "            loss = mae_loss(out, batch_labels.to(device))\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    losses = np.array(losses)\n",
    "    return losses"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1650895213494,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "mZohsEyLAu7S",
    "outputId": "4d6bfba3-5751-478d-d53e-73751702414e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAE on the train set is:  0.08593935257893928\n",
      "The MAE on the val set is:  0.08775011225637183\n",
      "The MAE on the test set is:  0.0903486671397485\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "print('The MAE on the train set is: ', get_mae(model, X_train, y_train, batch_size).mean())\n",
    "print('The MAE on the val set is: ', get_mae(model, X_val, y_val, batch_size).mean())\n",
    "print('The MAE on the test set is: ', get_mae(model, X_test, y_test, batch_size).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmsZ4aPaA1SJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### RSME on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE on the train set is:  0.23468705471699283\n",
      "The RMSE on the val set is:  0.2386931611242923\n",
      "The RMSE on the test set is:  0.24977507467035934\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "print('The RMSE on the train set is: ', np.sqrt(get_mse(model, X_train, y_train, batch_size)).mean())\n",
    "print('The RMSE on the val set is: ', np.sqrt(get_mse(model, X_val, y_val, batch_size)).mean())\n",
    "print('The RMSE on the test set is: ', np.sqrt(get_mse(model, X_test, y_test, batch_size)).mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8Jxp0L4A5zb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### MAPE on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "def get_mape(model, X, y, batch_size):\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for batch, batch_labels in DataLoader(OptDataset(X, y), batch_size=batch_size):\n",
    "            out = model(batch.to(device))\n",
    "            loss = MAPELoss(out, batch_labels.to(device)).detach().cpu().item()\n",
    "            losses.append(loss)\n",
    "\n",
    "    return np.array(losses)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 335,
     "status": "ok",
     "timestamp": 1650895213818,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "fHghkyflA79o",
    "outputId": "37838323-11f0-4eb9-d7d7-50303bf4e9ce",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAPE on the train set is:  0.524604383369166\n",
      "The MAPE on the val set is:  0.4246139897998557\n",
      "The MAPE on the test set is:  0.6576548123575119\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "print('The MAPE on the train set is: ', get_mape(model, X_train, y_train, batch_size).mean())\n",
    "print('The MAPE on the val set is: ', get_mape(model, X_val, y_val, batch_size).mean())\n",
    "print('The MAPE on the test set is: ', get_mape(model, X_test, y_test, batch_size).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLLLqkX6BEle",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1650895213820,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "sf8FmLxxBGcu",
    "outputId": "764313a9-78fc-46ca-dd08-9fb8834e4374",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the R^2 score is:  0.9516276514431621\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(X_test[0:batch_size].to(device)).squeeze().cpu().detach().numpy()\n",
    "\n",
    "y_true = y_test[0:batch_size].cpu().squeeze().detach().numpy()\n",
    "\n",
    "r2 = r2_score(y_pred=out, y_true=y_true)\n",
    "\n",
    "print('the R^2 score is: ', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "executionInfo": {
     "elapsed": 744,
     "status": "ok",
     "timestamp": 1650895214553,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "awvWu7WxBIHB",
    "outputId": "1b3dccd3-90ef-47d5-9895-267fdf93020c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 648x432 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(9, 6))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "ax.scatter(\n",
    "    y=output_sc.inverse_transform(out.reshape(-1, 1)),\n",
    "    x=output_sc.inverse_transform(y_true.squeeze().reshape(-1, 1))\n",
    ")\n",
    "ax.set_xlabel('Actual Value')\n",
    "ax.set_ylabel('Predicted Value')\n",
    "\n",
    "ax.text(20, 80, f'$R^2$ = {np.round(r2, 6)}', fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Model-Testing-Heston.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}