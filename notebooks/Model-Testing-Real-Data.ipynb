{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ju-WUaXnY5cr",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Models Testing on Heston data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 824,
     "status": "ok",
     "timestamp": 1650891681415,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "hH3-v8y-AuXg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1650891681417,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "QXEzFQ3iAyj_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set seeds\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1650891681418,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "gsH02HCWA0gC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "options_path = '../data/real_options.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1650891681421,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "jT4n95T6A4S6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 3413,
     "status": "ok",
     "timestamp": 1650891684820,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "7H8lEQPCA5IS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "options_df = pd.read_csv(options_path, index_col=0)\n",
    "options_df = reduce_mem_usage(options_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1650891684821,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "9TKRgvuOA8pC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "options_df = shuffle(options_df, random_state=0)\n",
    "options_df = options_df.reset_index()\n",
    "options_df['r'] = options_df['r'] / 100\n",
    "options_df = options_df.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1650891684822,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "3HXliAsq132p",
    "outputId": "09bc2eb1-d20d-4471-ed50-5fa0eba727fb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         strike    lastPrice  impliedVolatility  type     close     hv_21  \\\n0        116.25    48.500000           0.524902  call   162.875  0.253662   \n1        340.00     0.399902           0.589355  call   195.375  0.650391   \n2        270.00     0.070007           0.460938   put   289.750  0.372314   \n3        175.00     8.851562           0.283691   put   170.375  0.258057   \n4       1500.00  1459.000000           0.000010  call  2490.000  0.645020   \n...         ...          ...                ...   ...       ...       ...   \n217542   310.00   123.000000           0.596680   put   197.875  0.581055   \n217543   220.00    32.562500           0.015640  call   209.875  1.515625   \n217544   305.00    33.562500           0.295410   put   289.750  0.372314   \n217545  2476.00    61.750000           0.625000  call  1091.000  0.590332   \n217546   165.00     5.300781           0.856934   put   195.375  0.650391   \n\n           hv_42     hv_63  moneyness       tau         r  \n0       0.292236  0.306396   1.401367  0.145630  0.008430  \n1       0.690918  0.687988   0.574707  0.203247  0.009201  \n2       0.355225  0.351807   0.931641  0.002747  0.008408  \n3       0.292725  0.302979   1.027344  0.120850  0.007851  \n4       0.556152  0.573242   1.660156  0.472412  0.009201  \n...          ...       ...        ...       ...       ...  \n217542  0.671387  0.687988   1.566406  0.137329  0.008408  \n217543  1.135742  1.008789   0.954102  0.741699  0.008430  \n217544  0.355225  0.351807   1.052734  0.387451  0.008408  \n217545  0.614746  0.659180   0.440674  1.200195  0.006832  \n217546  0.690918  0.687988   0.844727  0.068665  0.009201  \n\n[217547 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>strike</th>\n      <th>lastPrice</th>\n      <th>impliedVolatility</th>\n      <th>type</th>\n      <th>close</th>\n      <th>hv_21</th>\n      <th>hv_42</th>\n      <th>hv_63</th>\n      <th>moneyness</th>\n      <th>tau</th>\n      <th>r</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>116.25</td>\n      <td>48.500000</td>\n      <td>0.524902</td>\n      <td>call</td>\n      <td>162.875</td>\n      <td>0.253662</td>\n      <td>0.292236</td>\n      <td>0.306396</td>\n      <td>1.401367</td>\n      <td>0.145630</td>\n      <td>0.008430</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>340.00</td>\n      <td>0.399902</td>\n      <td>0.589355</td>\n      <td>call</td>\n      <td>195.375</td>\n      <td>0.650391</td>\n      <td>0.690918</td>\n      <td>0.687988</td>\n      <td>0.574707</td>\n      <td>0.203247</td>\n      <td>0.009201</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>270.00</td>\n      <td>0.070007</td>\n      <td>0.460938</td>\n      <td>put</td>\n      <td>289.750</td>\n      <td>0.372314</td>\n      <td>0.355225</td>\n      <td>0.351807</td>\n      <td>0.931641</td>\n      <td>0.002747</td>\n      <td>0.008408</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>175.00</td>\n      <td>8.851562</td>\n      <td>0.283691</td>\n      <td>put</td>\n      <td>170.375</td>\n      <td>0.258057</td>\n      <td>0.292725</td>\n      <td>0.302979</td>\n      <td>1.027344</td>\n      <td>0.120850</td>\n      <td>0.007851</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1500.00</td>\n      <td>1459.000000</td>\n      <td>0.000010</td>\n      <td>call</td>\n      <td>2490.000</td>\n      <td>0.645020</td>\n      <td>0.556152</td>\n      <td>0.573242</td>\n      <td>1.660156</td>\n      <td>0.472412</td>\n      <td>0.009201</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>217542</th>\n      <td>310.00</td>\n      <td>123.000000</td>\n      <td>0.596680</td>\n      <td>put</td>\n      <td>197.875</td>\n      <td>0.581055</td>\n      <td>0.671387</td>\n      <td>0.687988</td>\n      <td>1.566406</td>\n      <td>0.137329</td>\n      <td>0.008408</td>\n    </tr>\n    <tr>\n      <th>217543</th>\n      <td>220.00</td>\n      <td>32.562500</td>\n      <td>0.015640</td>\n      <td>call</td>\n      <td>209.875</td>\n      <td>1.515625</td>\n      <td>1.135742</td>\n      <td>1.008789</td>\n      <td>0.954102</td>\n      <td>0.741699</td>\n      <td>0.008430</td>\n    </tr>\n    <tr>\n      <th>217544</th>\n      <td>305.00</td>\n      <td>33.562500</td>\n      <td>0.295410</td>\n      <td>put</td>\n      <td>289.750</td>\n      <td>0.372314</td>\n      <td>0.355225</td>\n      <td>0.351807</td>\n      <td>1.052734</td>\n      <td>0.387451</td>\n      <td>0.008408</td>\n    </tr>\n    <tr>\n      <th>217545</th>\n      <td>2476.00</td>\n      <td>61.750000</td>\n      <td>0.625000</td>\n      <td>call</td>\n      <td>1091.000</td>\n      <td>0.590332</td>\n      <td>0.614746</td>\n      <td>0.659180</td>\n      <td>0.440674</td>\n      <td>1.200195</td>\n      <td>0.006832</td>\n    </tr>\n    <tr>\n      <th>217546</th>\n      <td>165.00</td>\n      <td>5.300781</td>\n      <td>0.856934</td>\n      <td>put</td>\n      <td>195.375</td>\n      <td>0.650391</td>\n      <td>0.690918</td>\n      <td>0.687988</td>\n      <td>0.844727</td>\n      <td>0.068665</td>\n      <td>0.009201</td>\n    </tr>\n  </tbody>\n</table>\n<p>217547 rows Ã— 11 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pn28_RUMBAFH",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 515,
     "status": "ok",
     "timestamp": 1650891685322,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "32oPe6XUBCTF",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "options_df = pd.get_dummies(options_df, prefix='', prefix_sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 1032,
     "status": "ok",
     "timestamp": 1650891686346,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "_Tlc7k7xBDPV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_sc = StandardScaler()\n",
    "output_sc = StandardScaler()\n",
    "input_data = input_sc.fit_transform(options_df.drop(['lastPrice', 'impliedVolatility', 'hv_42', 'hv_63'], axis=1))\n",
    "output_data = output_sc.fit_transform(options_df['lastPrice'].values.reshape(-1, 1))\n",
    "\n",
    "train_size = 0.8\n",
    "val_size = 0.1\n",
    "\n",
    "last_train_idx = int(np.round(len(input_data) * train_size))\n",
    "last_val_idx = last_train_idx + int(np.round(len(input_data) * val_size))\n",
    "\n",
    "X_train = input_data[0:last_train_idx]\n",
    "X_val = input_data[last_train_idx:last_val_idx]\n",
    "X_test = input_data[last_val_idx:]\n",
    "\n",
    "y_train = output_data[0:last_train_idx]\n",
    "y_val = output_data[last_train_idx:last_val_idx]\n",
    "y_test = output_data[last_val_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1650891686347,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "7nEEoQGvvDpL",
    "outputId": "88b4d863-d037-439b-e625-5ebb52ad41ef",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['strike', 'close', 'hv_21', 'moneyness', 'tau', 'r', 'call', 'put'], dtype='object')"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cols = options_df.drop(['lastPrice', 'impliedVolatility', 'hv_42', 'hv_63'], axis=1).columns\n",
    "df_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1650891686349,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "IwMVtvfABIhR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train = Variable(torch.Tensor(X_train))\n",
    "X_val = Variable(torch.Tensor(X_val))\n",
    "X_test = Variable(torch.Tensor(X_test))\n",
    "\n",
    "y_train = Variable(torch.Tensor(y_train))\n",
    "y_val = Variable(torch.Tensor(y_val))\n",
    "y_test = Variable(torch.Tensor(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ra2l5P1nBVCz",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1650891686350,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "xTLMLFoSBWDy",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "CUDA = torch.cuda.is_available()\n",
    "device = 'cuda:0' if CUDA else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1650891686352,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "CQ9Gl3bUBWsj",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "\n",
    "  def __init__(self, module):\n",
    "    super(ResBlock, self).__init__()\n",
    "    self.module = module\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.module(x) + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1650891686353,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "YL3SicQPBYq0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class HiddenLayer(nn.Module):\n",
    "\n",
    "  def __init__(self, layer_size, act_fn):\n",
    "      super(HiddenLayer, self).__init__()\n",
    "      \n",
    "      if act_fn == 'ReLU':\n",
    "        self.layer = nn.Sequential(\n",
    "          nn.Linear(layer_size, layer_size),\n",
    "          nn.ReLU())\n",
    "      elif act_fn == 'LeakyReLU':\n",
    "        self.layer = nn.Sequential(\n",
    "          nn.Linear(layer_size, layer_size),\n",
    "          nn.LeakyReLU())\n",
    "      elif act_fn == 'ELU':\n",
    "        self.layer = nn.Sequential(\n",
    "          nn.Linear(layer_size, layer_size),\n",
    "          nn.ELU())\n",
    "    \n",
    "  def forward(self, x):\n",
    "    return self.layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 455,
     "status": "ok",
     "timestamp": 1650891686792,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "lHUFGf9xBawS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "  def __init__(self, input_size, output_size, hidden_size, num_layers, act_fn):\n",
    "    super(Net, self).__init__()\n",
    "    self.input_size = input_size\n",
    "    self.output_size = output_size\n",
    "    self.hidden_size = hidden_size\n",
    "\n",
    "    if act_fn == 'ReLU':\n",
    "      self.initial_layer = nn.Sequential(\n",
    "          nn.Linear(self.input_size, self.hidden_size),\n",
    "          nn.ReLU())\n",
    "    elif act_fn == 'LeakyReLU':\n",
    "      self.initial_layer = nn.Sequential(\n",
    "          nn.Linear(self.input_size, self.hidden_size),\n",
    "          nn.LeakyReLU())\n",
    "    elif act_fn == 'ELU':\n",
    "      self.initial_layer = nn.Sequential(\n",
    "          nn.Linear(self.input_size, self.hidden_size),\n",
    "          nn.ELU())\n",
    "\n",
    "    self.hidden_layers_list = []\n",
    "\n",
    "    for i in range(num_layers // 2):\n",
    "      self.hidden_layers_list.append(\n",
    "          ResBlock(\n",
    "            nn.Sequential(\n",
    "                HiddenLayer(self.hidden_size, act_fn),\n",
    "                HiddenLayer(self.hidden_size, act_fn)\n",
    "            )\n",
    "        )\n",
    "      )\n",
    "\n",
    "    self.hidden_layers = nn.Sequential(*self.hidden_layers_list)\n",
    "\n",
    "    self.net = nn.Sequential(\n",
    "        self.initial_layer,\n",
    "        self.hidden_layers,\n",
    "        nn.Linear(self.hidden_size, self.output_size)\n",
    "    )\n",
    "  \n",
    "  def forward(self, x):\n",
    "    return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1650891686793,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "zcq_lQrHBdH8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def init_weights(m, init_m: str):\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def init_uniform(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "      torch.nn.init.uniform_(m.weight)\n",
    "      m.bias.data.fill_(0.01)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def init_normal(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "      torch.nn.init.normal_(m.weight)\n",
    "      m.bias.data.fill_(0.01)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def init_xuniform(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "      torch.nn.init.xavier_uniform_(m.weight)\n",
    "      m.bias.data.fill_(0.01)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def init_xnormal(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "      torch.nn.init.xavier_normal_(m.weight)\n",
    "      m.bias.data.fill_(0.01)\n",
    "\n",
    "  if init_m == 'uniform':\n",
    "    m.apply(init_uniform)\n",
    "  elif init_m == 'normal':\n",
    "    m.apply(init_normal)\n",
    "  elif init_m == 'xaiver uniform':\n",
    "    m.apply(init_xuniform)\n",
    "  elif init_m == 'xavier normal':\n",
    "    m.apply(init_xnormal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vuCpyycNCKEZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1650891686794,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "YbCOnCSNCL25",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_size = 8\n",
    "output_size = 1\n",
    "num_layers = 8\n",
    "hidden_size = 800\n",
    "batch_size = 1213\n",
    "epochs = 2000\n",
    "lr = 0.00068\n",
    "init_method = 'xaiver uniform'\n",
    "act_fn = 'ReLU'\n",
    "\n",
    "model = Net(input_size, output_size, hidden_size, num_layers, act_fn)\n",
    "init_weights(model, init_method)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 7351,
     "status": "ok",
     "timestamp": 1650891694138,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "QqZbxrppvDpZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "X_train = X_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "\n",
    "X_val = X_val.to(device)\n",
    "y_val = y_val.to(device)\n",
    "\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1650891694142,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "Q-9T0GArCMgp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class OptDataset(Dataset):\n",
    "\n",
    "  def __init__(self, X, y):\n",
    "    self.X = X\n",
    "    self.y = y\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.X[idx], self.y[idx]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6-hCH2ivDpb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Losses Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1650891694144,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "mVaO8TruHW4M",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def MAPELoss(output, target):\n",
    "  return torch.mean(torch.abs((target - output) / target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1650891694149,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "tVLW5dHhvDpe",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, loss_fn, X_val, y_val):\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    out = model(X_val)\n",
    "    loss = loss_fn(out, y_val)\n",
    "    print('\\nVal set: Average loss: {:.8f}\\n'.format(\n",
    "            loss.item()))\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68eF5_EovDpf",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Early Stopping class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1650891694150,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "n2So2ffSvDpg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Code took form: https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, \n",
    "                 patience=10, \n",
    "                 verbose=False, \n",
    "                 delta=0, \n",
    "                 path='../models/final_heston_model.chkpt',\n",
    "                 trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score > self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dL_xmnKXvDph",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1650891694152,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "DrBBTGKJvDph",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    epochs,\n",
    "    batch_size,\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val\n",
    "):\n",
    "\n",
    "  training_losses = []\n",
    "  validation_losses = []\n",
    "\n",
    "  early_stopping = EarlyStopping(patience=20)\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "    i = 0\n",
    "\n",
    "    for batch, batch_labels in DataLoader(OptDataset(X_train, y_train), batch_size=batch_size):\n",
    "      out = model(batch.to(device))\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      loss = loss_fn(out, batch_labels.to(device))\n",
    "      epoch_losses.append(loss.item())\n",
    "      total_loss += loss.item()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      if i > 0 and i % 50 == 0:\n",
    "        avg_loss = total_loss / 50\n",
    "        elapsed = time.time() - start_time\n",
    "        print('| Epoch {:3d} | {:5d}/{:5d} batches | lr {:2.5f} | ms/batch {:5.2f} | '\n",
    "                  'loss {:5.8f}'.format(\n",
    "              epoch, i, len(X_train) // batch_size+1, lr, elapsed * 1000 / 50,\n",
    "              avg_loss))\n",
    "        start_time = time.time()\n",
    "        total_loss = 0\n",
    "\n",
    "      i += 1\n",
    "\n",
    "    training_losses.append(np.array(epoch_losses).mean())\n",
    "    val_loss = evaluate(model, loss_fn, X_val, y_val)\n",
    "    validation_losses.append(val_loss)\n",
    "\n",
    "    early_stopping(val_loss, model)\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(f\"Stopping at Epoch: {epoch}\")\n",
    "        break\n",
    "\n",
    "  return training_losses, validation_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2525796,
     "status": "ok",
     "timestamp": 1650894219916,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "hBETWoCfvDpj",
    "outputId": "30acf99f-3a1e-4d87-d1ff-13068ebe4cd4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch   0 |    50/  144 batches | lr 0.00068 | ms/batch 44.85 | loss 0.87298324\n",
      "| Epoch   0 |   100/  144 batches | lr 0.00068 | ms/batch 38.34 | loss 0.14754409\n",
      "\n",
      "Val set: Average loss: 0.13159057\n",
      "\n",
      "| Epoch   1 |    50/  144 batches | lr 0.00068 | ms/batch 38.33 | loss 0.12356914\n",
      "| Epoch   1 |   100/  144 batches | lr 0.00068 | ms/batch 36.78 | loss 0.12312661\n",
      "\n",
      "Val set: Average loss: 0.11905827\n",
      "\n",
      "| Epoch   2 |    50/  144 batches | lr 0.00068 | ms/batch 39.21 | loss 0.10457141\n",
      "| Epoch   2 |   100/  144 batches | lr 0.00068 | ms/batch 36.55 | loss 0.09978281\n",
      "\n",
      "Val set: Average loss: 0.12044018\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch   3 |    50/  144 batches | lr 0.00068 | ms/batch 37.10 | loss 0.09624446\n",
      "| Epoch   3 |   100/  144 batches | lr 0.00068 | ms/batch 35.25 | loss 0.09342015\n",
      "\n",
      "Val set: Average loss: 0.10429933\n",
      "\n",
      "| Epoch   4 |    50/  144 batches | lr 0.00068 | ms/batch 37.40 | loss 0.09009929\n",
      "| Epoch   4 |   100/  144 batches | lr 0.00068 | ms/batch 35.24 | loss 0.08759400\n",
      "\n",
      "Val set: Average loss: 0.09247221\n",
      "\n",
      "| Epoch   5 |    50/  144 batches | lr 0.00068 | ms/batch 37.33 | loss 0.08944242\n",
      "| Epoch   5 |   100/  144 batches | lr 0.00068 | ms/batch 35.24 | loss 0.08102284\n",
      "\n",
      "Val set: Average loss: 0.09462140\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch   6 |    50/  144 batches | lr 0.00068 | ms/batch 37.60 | loss 0.08348236\n",
      "| Epoch   6 |   100/  144 batches | lr 0.00068 | ms/batch 35.50 | loss 0.07756901\n",
      "\n",
      "Val set: Average loss: 0.08557500\n",
      "\n",
      "| Epoch   7 |    50/  144 batches | lr 0.00068 | ms/batch 37.69 | loss 0.07726005\n",
      "| Epoch   7 |   100/  144 batches | lr 0.00068 | ms/batch 35.06 | loss 0.07476407\n",
      "\n",
      "Val set: Average loss: 0.07657830\n",
      "\n",
      "| Epoch   8 |    50/  144 batches | lr 0.00068 | ms/batch 37.34 | loss 0.07761004\n",
      "| Epoch   8 |   100/  144 batches | lr 0.00068 | ms/batch 35.45 | loss 0.07553780\n",
      "\n",
      "Val set: Average loss: 0.07329920\n",
      "\n",
      "| Epoch   9 |    50/  144 batches | lr 0.00068 | ms/batch 37.50 | loss 0.07340407\n",
      "| Epoch   9 |   100/  144 batches | lr 0.00068 | ms/batch 35.24 | loss 0.07367106\n",
      "\n",
      "Val set: Average loss: 0.07201111\n",
      "\n",
      "| Epoch  10 |    50/  144 batches | lr 0.00068 | ms/batch 37.74 | loss 0.07256002\n",
      "| Epoch  10 |   100/  144 batches | lr 0.00068 | ms/batch 35.32 | loss 0.07355105\n",
      "\n",
      "Val set: Average loss: 0.07320505\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  11 |    50/  144 batches | lr 0.00068 | ms/batch 37.52 | loss 0.07280458\n",
      "| Epoch  11 |   100/  144 batches | lr 0.00068 | ms/batch 35.13 | loss 0.07147946\n",
      "\n",
      "Val set: Average loss: 0.07086962\n",
      "\n",
      "| Epoch  12 |    50/  144 batches | lr 0.00068 | ms/batch 37.54 | loss 0.07122710\n",
      "| Epoch  12 |   100/  144 batches | lr 0.00068 | ms/batch 35.39 | loss 0.07122871\n",
      "\n",
      "Val set: Average loss: 0.06973351\n",
      "\n",
      "| Epoch  13 |    50/  144 batches | lr 0.00068 | ms/batch 37.54 | loss 0.07074969\n",
      "| Epoch  13 |   100/  144 batches | lr 0.00068 | ms/batch 35.30 | loss 0.07112076\n",
      "\n",
      "Val set: Average loss: 0.07043895\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  14 |    50/  144 batches | lr 0.00068 | ms/batch 37.13 | loss 0.07288927\n",
      "| Epoch  14 |   100/  144 batches | lr 0.00068 | ms/batch 35.29 | loss 0.07109493\n",
      "\n",
      "Val set: Average loss: 0.06967653\n",
      "\n",
      "| Epoch  15 |    50/  144 batches | lr 0.00068 | ms/batch 37.52 | loss 0.06993667\n",
      "| Epoch  15 |   100/  144 batches | lr 0.00068 | ms/batch 35.51 | loss 0.06937931\n",
      "\n",
      "Val set: Average loss: 0.06990115\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  16 |    50/  144 batches | lr 0.00068 | ms/batch 37.44 | loss 0.06944525\n",
      "| Epoch  16 |   100/  144 batches | lr 0.00068 | ms/batch 35.09 | loss 0.06892568\n",
      "\n",
      "Val set: Average loss: 0.07099446\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  17 |    50/  144 batches | lr 0.00068 | ms/batch 37.70 | loss 0.06954757\n",
      "| Epoch  17 |   100/  144 batches | lr 0.00068 | ms/batch 35.20 | loss 0.06898340\n",
      "\n",
      "Val set: Average loss: 0.07046299\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  18 |    50/  144 batches | lr 0.00068 | ms/batch 37.51 | loss 0.06997460\n",
      "| Epoch  18 |   100/  144 batches | lr 0.00068 | ms/batch 35.39 | loss 0.07121326\n",
      "\n",
      "Val set: Average loss: 0.07533932\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch  19 |    50/  144 batches | lr 0.00068 | ms/batch 37.44 | loss 0.07156411\n",
      "| Epoch  19 |   100/  144 batches | lr 0.00068 | ms/batch 35.35 | loss 0.06971452\n",
      "\n",
      "Val set: Average loss: 0.07031710\n",
      "\n",
      "EarlyStopping counter: 5 out of 20\n",
      "| Epoch  20 |    50/  144 batches | lr 0.00068 | ms/batch 37.71 | loss 0.07076394\n",
      "| Epoch  20 |   100/  144 batches | lr 0.00068 | ms/batch 35.62 | loss 0.06902576\n",
      "\n",
      "Val set: Average loss: 0.06903801\n",
      "\n",
      "| Epoch  21 |    50/  144 batches | lr 0.00068 | ms/batch 37.69 | loss 0.06925658\n",
      "| Epoch  21 |   100/  144 batches | lr 0.00068 | ms/batch 35.37 | loss 0.07004859\n",
      "\n",
      "Val set: Average loss: 0.07017698\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  22 |    50/  144 batches | lr 0.00068 | ms/batch 37.48 | loss 0.06859488\n",
      "| Epoch  22 |   100/  144 batches | lr 0.00068 | ms/batch 35.33 | loss 0.06741646\n",
      "\n",
      "Val set: Average loss: 0.06831868\n",
      "\n",
      "| Epoch  23 |    50/  144 batches | lr 0.00068 | ms/batch 37.52 | loss 0.06853971\n",
      "| Epoch  23 |   100/  144 batches | lr 0.00068 | ms/batch 35.63 | loss 0.06780036\n",
      "\n",
      "Val set: Average loss: 0.07135446\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  24 |    50/  144 batches | lr 0.00068 | ms/batch 37.50 | loss 0.06759825\n",
      "| Epoch  24 |   100/  144 batches | lr 0.00068 | ms/batch 35.45 | loss 0.06698630\n",
      "\n",
      "Val set: Average loss: 0.07000585\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  25 |    50/  144 batches | lr 0.00068 | ms/batch 37.97 | loss 0.06725941\n",
      "| Epoch  25 |   100/  144 batches | lr 0.00068 | ms/batch 35.40 | loss 0.06717135\n",
      "\n",
      "Val set: Average loss: 0.07540052\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  26 |    50/  144 batches | lr 0.00068 | ms/batch 37.69 | loss 0.06754114\n",
      "| Epoch  26 |   100/  144 batches | lr 0.00068 | ms/batch 35.22 | loss 0.06698293\n",
      "\n",
      "Val set: Average loss: 0.06738387\n",
      "\n",
      "| Epoch  27 |    50/  144 batches | lr 0.00068 | ms/batch 37.73 | loss 0.06839231\n",
      "| Epoch  27 |   100/  144 batches | lr 0.00068 | ms/batch 35.43 | loss 0.06721818\n",
      "\n",
      "Val set: Average loss: 0.07035816\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  28 |    50/  144 batches | lr 0.00068 | ms/batch 37.58 | loss 0.06674810\n",
      "| Epoch  28 |   100/  144 batches | lr 0.00068 | ms/batch 35.48 | loss 0.06667607\n",
      "\n",
      "Val set: Average loss: 0.06901985\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  29 |    50/  144 batches | lr 0.00068 | ms/batch 37.64 | loss 0.06946624\n",
      "| Epoch  29 |   100/  144 batches | lr 0.00068 | ms/batch 35.63 | loss 0.06609663\n",
      "\n",
      "Val set: Average loss: 0.06716269\n",
      "\n",
      "| Epoch  30 |    50/  144 batches | lr 0.00068 | ms/batch 37.49 | loss 0.06689853\n",
      "| Epoch  30 |   100/  144 batches | lr 0.00068 | ms/batch 35.24 | loss 0.06737370\n",
      "\n",
      "Val set: Average loss: 0.06765082\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  31 |    50/  144 batches | lr 0.00068 | ms/batch 37.55 | loss 0.06691085\n",
      "| Epoch  31 |   100/  144 batches | lr 0.00068 | ms/batch 35.33 | loss 0.06643952\n",
      "\n",
      "Val set: Average loss: 0.06865697\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  32 |    50/  144 batches | lr 0.00068 | ms/batch 37.46 | loss 0.06662949\n",
      "| Epoch  32 |   100/  144 batches | lr 0.00068 | ms/batch 35.28 | loss 0.06694558\n",
      "\n",
      "Val set: Average loss: 0.06809928\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  33 |    50/  144 batches | lr 0.00068 | ms/batch 37.42 | loss 0.06629409\n",
      "| Epoch  33 |   100/  144 batches | lr 0.00068 | ms/batch 35.23 | loss 0.06679625\n",
      "\n",
      "Val set: Average loss: 0.06787339\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch  34 |    50/  144 batches | lr 0.00068 | ms/batch 37.48 | loss 0.06693408\n",
      "| Epoch  34 |   100/  144 batches | lr 0.00068 | ms/batch 35.33 | loss 0.06584114\n",
      "\n",
      "Val set: Average loss: 0.06822936\n",
      "\n",
      "EarlyStopping counter: 5 out of 20\n",
      "| Epoch  35 |    50/  144 batches | lr 0.00068 | ms/batch 37.54 | loss 0.06755898\n",
      "| Epoch  35 |   100/  144 batches | lr 0.00068 | ms/batch 35.32 | loss 0.06682951\n",
      "\n",
      "Val set: Average loss: 0.06805950\n",
      "\n",
      "EarlyStopping counter: 6 out of 20\n",
      "| Epoch  36 |    50/  144 batches | lr 0.00068 | ms/batch 37.63 | loss 0.06973487\n",
      "| Epoch  36 |   100/  144 batches | lr 0.00068 | ms/batch 35.26 | loss 0.06632023\n",
      "\n",
      "Val set: Average loss: 0.06759419\n",
      "\n",
      "EarlyStopping counter: 7 out of 20\n",
      "| Epoch  37 |    50/  144 batches | lr 0.00068 | ms/batch 38.61 | loss 0.06675567\n",
      "| Epoch  37 |   100/  144 batches | lr 0.00068 | ms/batch 35.24 | loss 0.06561901\n",
      "\n",
      "Val set: Average loss: 0.06846189\n",
      "\n",
      "EarlyStopping counter: 8 out of 20\n",
      "| Epoch  38 |    50/  144 batches | lr 0.00068 | ms/batch 37.51 | loss 0.06550228\n",
      "| Epoch  38 |   100/  144 batches | lr 0.00068 | ms/batch 35.31 | loss 0.06594507\n",
      "\n",
      "Val set: Average loss: 0.07029772\n",
      "\n",
      "EarlyStopping counter: 9 out of 20\n",
      "| Epoch  39 |    50/  144 batches | lr 0.00068 | ms/batch 37.45 | loss 0.06687260\n",
      "| Epoch  39 |   100/  144 batches | lr 0.00068 | ms/batch 35.24 | loss 0.06505762\n",
      "\n",
      "Val set: Average loss: 0.06684720\n",
      "\n",
      "| Epoch  40 |    50/  144 batches | lr 0.00068 | ms/batch 38.08 | loss 0.06473820\n",
      "| Epoch  40 |   100/  144 batches | lr 0.00068 | ms/batch 35.43 | loss 0.06469123\n",
      "\n",
      "Val set: Average loss: 0.06697990\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  41 |    50/  144 batches | lr 0.00068 | ms/batch 37.48 | loss 0.06811446\n",
      "| Epoch  41 |   100/  144 batches | lr 0.00068 | ms/batch 35.48 | loss 0.06607793\n",
      "\n",
      "Val set: Average loss: 0.06625701\n",
      "\n",
      "| Epoch  42 |    50/  144 batches | lr 0.00068 | ms/batch 37.55 | loss 0.06545617\n",
      "| Epoch  42 |   100/  144 batches | lr 0.00068 | ms/batch 35.41 | loss 0.06563091\n",
      "\n",
      "Val set: Average loss: 0.06880093\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  43 |    50/  144 batches | lr 0.00068 | ms/batch 37.56 | loss 0.06626701\n",
      "| Epoch  43 |   100/  144 batches | lr 0.00068 | ms/batch 35.37 | loss 0.06377905\n",
      "\n",
      "Val set: Average loss: 0.06800777\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  44 |    50/  144 batches | lr 0.00068 | ms/batch 37.41 | loss 0.06703130\n",
      "| Epoch  44 |   100/  144 batches | lr 0.00068 | ms/batch 35.31 | loss 0.06560379\n",
      "\n",
      "Val set: Average loss: 0.06630762\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  45 |    50/  144 batches | lr 0.00068 | ms/batch 37.41 | loss 0.06478309\n",
      "| Epoch  45 |   100/  144 batches | lr 0.00068 | ms/batch 35.26 | loss 0.06394725\n",
      "\n",
      "Val set: Average loss: 0.06639412\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch  46 |    50/  144 batches | lr 0.00068 | ms/batch 37.63 | loss 0.06453741\n",
      "| Epoch  46 |   100/  144 batches | lr 0.00068 | ms/batch 35.39 | loss 0.06355978\n",
      "\n",
      "Val set: Average loss: 0.07339988\n",
      "\n",
      "EarlyStopping counter: 5 out of 20\n",
      "| Epoch  47 |    50/  144 batches | lr 0.00068 | ms/batch 37.54 | loss 0.06725218\n",
      "| Epoch  47 |   100/  144 batches | lr 0.00068 | ms/batch 35.34 | loss 0.06434265\n",
      "\n",
      "Val set: Average loss: 0.06674698\n",
      "\n",
      "EarlyStopping counter: 6 out of 20\n",
      "| Epoch  48 |    50/  144 batches | lr 0.00068 | ms/batch 37.52 | loss 0.06391312\n",
      "| Epoch  48 |   100/  144 batches | lr 0.00068 | ms/batch 35.25 | loss 0.06467343\n",
      "\n",
      "Val set: Average loss: 0.06862879\n",
      "\n",
      "EarlyStopping counter: 7 out of 20\n",
      "| Epoch  49 |    50/  144 batches | lr 0.00068 | ms/batch 37.49 | loss 0.06462865\n",
      "| Epoch  49 |   100/  144 batches | lr 0.00068 | ms/batch 35.49 | loss 0.06332338\n",
      "\n",
      "Val set: Average loss: 0.06506750\n",
      "\n",
      "| Epoch  50 |    50/  144 batches | lr 0.00068 | ms/batch 37.47 | loss 0.06400213\n",
      "| Epoch  50 |   100/  144 batches | lr 0.00068 | ms/batch 35.38 | loss 0.06305961\n",
      "\n",
      "Val set: Average loss: 0.06570608\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  51 |    50/  144 batches | lr 0.00068 | ms/batch 37.54 | loss 0.06514581\n",
      "| Epoch  51 |   100/  144 batches | lr 0.00068 | ms/batch 35.34 | loss 0.06273469\n",
      "\n",
      "Val set: Average loss: 0.06593402\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  52 |    50/  144 batches | lr 0.00068 | ms/batch 37.51 | loss 0.06497542\n",
      "| Epoch  52 |   100/  144 batches | lr 0.00068 | ms/batch 35.54 | loss 0.06406636\n",
      "\n",
      "Val set: Average loss: 0.06544749\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  53 |    50/  144 batches | lr 0.00068 | ms/batch 37.65 | loss 0.06557966\n",
      "| Epoch  53 |   100/  144 batches | lr 0.00068 | ms/batch 35.51 | loss 0.06319888\n",
      "\n",
      "Val set: Average loss: 0.06485682\n",
      "\n",
      "| Epoch  54 |    50/  144 batches | lr 0.00068 | ms/batch 37.60 | loss 0.06626539\n",
      "| Epoch  54 |   100/  144 batches | lr 0.00068 | ms/batch 35.41 | loss 0.06333159\n",
      "\n",
      "Val set: Average loss: 0.06610369\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  55 |    50/  144 batches | lr 0.00068 | ms/batch 37.68 | loss 0.06342542\n",
      "| Epoch  55 |   100/  144 batches | lr 0.00068 | ms/batch 35.27 | loss 0.06288528\n",
      "\n",
      "Val set: Average loss: 0.06462368\n",
      "\n",
      "| Epoch  56 |    50/  144 batches | lr 0.00068 | ms/batch 37.86 | loss 0.06350601\n",
      "| Epoch  56 |   100/  144 batches | lr 0.00068 | ms/batch 35.49 | loss 0.06419824\n",
      "\n",
      "Val set: Average loss: 0.06486589\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  57 |    50/  144 batches | lr 0.00068 | ms/batch 37.67 | loss 0.06292802\n",
      "| Epoch  57 |   100/  144 batches | lr 0.00068 | ms/batch 35.47 | loss 0.06266405\n",
      "\n",
      "Val set: Average loss: 0.06429224\n",
      "\n",
      "| Epoch  58 |    50/  144 batches | lr 0.00068 | ms/batch 37.68 | loss 0.06506558\n",
      "| Epoch  58 |   100/  144 batches | lr 0.00068 | ms/batch 35.75 | loss 0.06400936\n",
      "\n",
      "Val set: Average loss: 0.06506149\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  59 |    50/  144 batches | lr 0.00068 | ms/batch 37.62 | loss 0.06357096\n",
      "| Epoch  59 |   100/  144 batches | lr 0.00068 | ms/batch 35.63 | loss 0.06277429\n",
      "\n",
      "Val set: Average loss: 0.06506751\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  60 |    50/  144 batches | lr 0.00068 | ms/batch 37.89 | loss 0.07119627\n",
      "| Epoch  60 |   100/  144 batches | lr 0.00068 | ms/batch 35.66 | loss 0.06309437\n",
      "\n",
      "Val set: Average loss: 0.06573600\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  61 |    50/  144 batches | lr 0.00068 | ms/batch 37.83 | loss 0.06286363\n",
      "| Epoch  61 |   100/  144 batches | lr 0.00068 | ms/batch 35.73 | loss 0.06198078\n",
      "\n",
      "Val set: Average loss: 0.06447906\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch  62 |    50/  144 batches | lr 0.00068 | ms/batch 37.70 | loss 0.06535631\n",
      "| Epoch  62 |   100/  144 batches | lr 0.00068 | ms/batch 35.57 | loss 0.06188759\n",
      "\n",
      "Val set: Average loss: 0.06562301\n",
      "\n",
      "EarlyStopping counter: 5 out of 20\n",
      "| Epoch  63 |    50/  144 batches | lr 0.00068 | ms/batch 37.71 | loss 0.06312038\n",
      "| Epoch  63 |   100/  144 batches | lr 0.00068 | ms/batch 35.58 | loss 0.06184458\n",
      "\n",
      "Val set: Average loss: 0.06335165\n",
      "\n",
      "| Epoch  64 |    50/  144 batches | lr 0.00068 | ms/batch 37.62 | loss 0.06276338\n",
      "| Epoch  64 |   100/  144 batches | lr 0.00068 | ms/batch 35.65 | loss 0.06186151\n",
      "\n",
      "Val set: Average loss: 0.06433111\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  65 |    50/  144 batches | lr 0.00068 | ms/batch 37.83 | loss 0.06469124\n",
      "| Epoch  65 |   100/  144 batches | lr 0.00068 | ms/batch 35.48 | loss 0.06167569\n",
      "\n",
      "Val set: Average loss: 0.06368441\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  66 |    50/  144 batches | lr 0.00068 | ms/batch 37.81 | loss 0.06513054\n",
      "| Epoch  66 |   100/  144 batches | lr 0.00068 | ms/batch 35.47 | loss 0.06232502\n",
      "\n",
      "Val set: Average loss: 0.06534481\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  67 |    50/  144 batches | lr 0.00068 | ms/batch 37.68 | loss 0.06260587\n",
      "| Epoch  67 |   100/  144 batches | lr 0.00068 | ms/batch 35.75 | loss 0.06164917\n",
      "\n",
      "Val set: Average loss: 0.06431611\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch  68 |    50/  144 batches | lr 0.00068 | ms/batch 37.73 | loss 0.06244852\n",
      "| Epoch  68 |   100/  144 batches | lr 0.00068 | ms/batch 35.67 | loss 0.06194457\n",
      "\n",
      "Val set: Average loss: 0.06387553\n",
      "\n",
      "EarlyStopping counter: 5 out of 20\n",
      "| Epoch  69 |    50/  144 batches | lr 0.00068 | ms/batch 37.70 | loss 0.06244522\n",
      "| Epoch  69 |   100/  144 batches | lr 0.00068 | ms/batch 35.57 | loss 0.06156542\n",
      "\n",
      "Val set: Average loss: 0.06337725\n",
      "\n",
      "EarlyStopping counter: 6 out of 20\n",
      "| Epoch  70 |    50/  144 batches | lr 0.00068 | ms/batch 37.86 | loss 0.06253839\n",
      "| Epoch  70 |   100/  144 batches | lr 0.00068 | ms/batch 35.58 | loss 0.06239406\n",
      "\n",
      "Val set: Average loss: 0.06534606\n",
      "\n",
      "EarlyStopping counter: 7 out of 20\n",
      "| Epoch  71 |    50/  144 batches | lr 0.00068 | ms/batch 37.71 | loss 0.06312656\n",
      "| Epoch  71 |   100/  144 batches | lr 0.00068 | ms/batch 35.53 | loss 0.06263961\n",
      "\n",
      "Val set: Average loss: 0.06308193\n",
      "\n",
      "| Epoch  72 |    50/  144 batches | lr 0.00068 | ms/batch 37.61 | loss 0.06221170\n",
      "| Epoch  72 |   100/  144 batches | lr 0.00068 | ms/batch 35.66 | loss 0.06192244\n",
      "\n",
      "Val set: Average loss: 0.06339024\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  73 |    50/  144 batches | lr 0.00068 | ms/batch 37.80 | loss 0.06308365\n",
      "| Epoch  73 |   100/  144 batches | lr 0.00068 | ms/batch 35.64 | loss 0.06171410\n",
      "\n",
      "Val set: Average loss: 0.07100169\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  74 |    50/  144 batches | lr 0.00068 | ms/batch 37.51 | loss 0.06402451\n",
      "| Epoch  74 |   100/  144 batches | lr 0.00068 | ms/batch 35.78 | loss 0.06187474\n",
      "\n",
      "Val set: Average loss: 0.06426052\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  75 |    50/  144 batches | lr 0.00068 | ms/batch 37.61 | loss 0.06220901\n",
      "| Epoch  75 |   100/  144 batches | lr 0.00068 | ms/batch 35.52 | loss 0.06107204\n",
      "\n",
      "Val set: Average loss: 0.06417173\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch  76 |    50/  144 batches | lr 0.00068 | ms/batch 37.76 | loss 0.06251359\n",
      "| Epoch  76 |   100/  144 batches | lr 0.00068 | ms/batch 35.84 | loss 0.06141559\n",
      "\n",
      "Val set: Average loss: 0.06462998\n",
      "\n",
      "EarlyStopping counter: 5 out of 20\n",
      "| Epoch  77 |    50/  144 batches | lr 0.00068 | ms/batch 37.70 | loss 0.06136847\n",
      "| Epoch  77 |   100/  144 batches | lr 0.00068 | ms/batch 35.39 | loss 0.06155948\n",
      "\n",
      "Val set: Average loss: 0.06340248\n",
      "\n",
      "EarlyStopping counter: 6 out of 20\n",
      "| Epoch  78 |    50/  144 batches | lr 0.00068 | ms/batch 37.80 | loss 0.06421171\n",
      "| Epoch  78 |   100/  144 batches | lr 0.00068 | ms/batch 35.43 | loss 0.06175414\n",
      "\n",
      "Val set: Average loss: 0.06215353\n",
      "\n",
      "| Epoch  79 |    50/  144 batches | lr 0.00068 | ms/batch 37.30 | loss 0.06272673\n",
      "| Epoch  79 |   100/  144 batches | lr 0.00068 | ms/batch 35.39 | loss 0.06208507\n",
      "\n",
      "Val set: Average loss: 0.06511066\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  80 |    50/  144 batches | lr 0.00068 | ms/batch 37.69 | loss 0.06180609\n",
      "| Epoch  80 |   100/  144 batches | lr 0.00068 | ms/batch 35.55 | loss 0.06088915\n",
      "\n",
      "Val set: Average loss: 0.06273447\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  81 |    50/  144 batches | lr 0.00068 | ms/batch 37.61 | loss 0.06104362\n",
      "| Epoch  81 |   100/  144 batches | lr 0.00068 | ms/batch 35.51 | loss 0.06112181\n",
      "\n",
      "Val set: Average loss: 0.06405656\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  82 |    50/  144 batches | lr 0.00068 | ms/batch 37.71 | loss 0.06166566\n",
      "| Epoch  82 |   100/  144 batches | lr 0.00068 | ms/batch 35.63 | loss 0.06149171\n",
      "\n",
      "Val set: Average loss: 0.06345230\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch  83 |    50/  144 batches | lr 0.00068 | ms/batch 37.82 | loss 0.06163965\n",
      "| Epoch  83 |   100/  144 batches | lr 0.00068 | ms/batch 35.52 | loss 0.06116742\n",
      "\n",
      "Val set: Average loss: 0.06235336\n",
      "\n",
      "EarlyStopping counter: 5 out of 20\n",
      "| Epoch  84 |    50/  144 batches | lr 0.00068 | ms/batch 37.80 | loss 0.06111065\n",
      "| Epoch  84 |   100/  144 batches | lr 0.00068 | ms/batch 35.89 | loss 0.06106015\n",
      "\n",
      "Val set: Average loss: 0.06291085\n",
      "\n",
      "EarlyStopping counter: 6 out of 20\n",
      "| Epoch  85 |    50/  144 batches | lr 0.00068 | ms/batch 37.72 | loss 0.06128525\n",
      "| Epoch  85 |   100/  144 batches | lr 0.00068 | ms/batch 35.35 | loss 0.06020506\n",
      "\n",
      "Val set: Average loss: 0.06270840\n",
      "\n",
      "EarlyStopping counter: 7 out of 20\n",
      "| Epoch  86 |    50/  144 batches | lr 0.00068 | ms/batch 37.48 | loss 0.06249681\n",
      "| Epoch  86 |   100/  144 batches | lr 0.00068 | ms/batch 35.54 | loss 0.06058191\n",
      "\n",
      "Val set: Average loss: 0.06595424\n",
      "\n",
      "EarlyStopping counter: 8 out of 20\n",
      "| Epoch  87 |    50/  144 batches | lr 0.00068 | ms/batch 37.71 | loss 0.06101794\n",
      "| Epoch  87 |   100/  144 batches | lr 0.00068 | ms/batch 35.47 | loss 0.06112023\n",
      "\n",
      "Val set: Average loss: 0.06441177\n",
      "\n",
      "EarlyStopping counter: 9 out of 20\n",
      "| Epoch  88 |    50/  144 batches | lr 0.00068 | ms/batch 37.51 | loss 0.06054518\n",
      "| Epoch  88 |   100/  144 batches | lr 0.00068 | ms/batch 35.33 | loss 0.06070545\n",
      "\n",
      "Val set: Average loss: 0.06401104\n",
      "\n",
      "EarlyStopping counter: 10 out of 20\n",
      "| Epoch  89 |    50/  144 batches | lr 0.00068 | ms/batch 37.60 | loss 0.06335354\n",
      "| Epoch  89 |   100/  144 batches | lr 0.00068 | ms/batch 35.54 | loss 0.06049480\n",
      "\n",
      "Val set: Average loss: 0.06512687\n",
      "\n",
      "EarlyStopping counter: 11 out of 20\n",
      "| Epoch  90 |    50/  144 batches | lr 0.00068 | ms/batch 37.76 | loss 0.06175071\n",
      "| Epoch  90 |   100/  144 batches | lr 0.00068 | ms/batch 35.50 | loss 0.06069874\n",
      "\n",
      "Val set: Average loss: 0.06212160\n",
      "\n",
      "| Epoch  91 |    50/  144 batches | lr 0.00068 | ms/batch 37.53 | loss 0.06241165\n",
      "| Epoch  91 |   100/  144 batches | lr 0.00068 | ms/batch 35.28 | loss 0.06203940\n",
      "\n",
      "Val set: Average loss: 0.06478883\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  92 |    50/  144 batches | lr 0.00068 | ms/batch 37.57 | loss 0.06091679\n",
      "| Epoch  92 |   100/  144 batches | lr 0.00068 | ms/batch 35.37 | loss 0.06071365\n",
      "\n",
      "Val set: Average loss: 0.06216129\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  93 |    50/  144 batches | lr 0.00068 | ms/batch 37.51 | loss 0.06214109\n",
      "| Epoch  93 |   100/  144 batches | lr 0.00068 | ms/batch 35.29 | loss 0.05999360\n",
      "\n",
      "Val set: Average loss: 0.06115171\n",
      "\n",
      "| Epoch  94 |    50/  144 batches | lr 0.00068 | ms/batch 37.36 | loss 0.06044402\n",
      "| Epoch  94 |   100/  144 batches | lr 0.00068 | ms/batch 34.85 | loss 0.05965932\n",
      "\n",
      "Val set: Average loss: 0.06255245\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  95 |    50/  144 batches | lr 0.00068 | ms/batch 36.79 | loss 0.06123862\n",
      "| Epoch  95 |   100/  144 batches | lr 0.00068 | ms/batch 34.68 | loss 0.06028883\n",
      "\n",
      "Val set: Average loss: 0.06427760\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  96 |    50/  144 batches | lr 0.00068 | ms/batch 37.00 | loss 0.06485156\n",
      "| Epoch  96 |   100/  144 batches | lr 0.00068 | ms/batch 35.09 | loss 0.06083852\n",
      "\n",
      "Val set: Average loss: 0.06178074\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  97 |    50/  144 batches | lr 0.00068 | ms/batch 37.32 | loss 0.06171875\n",
      "| Epoch  97 |   100/  144 batches | lr 0.00068 | ms/batch 35.28 | loss 0.06083506\n",
      "\n",
      "Val set: Average loss: 0.06172768\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch  98 |    50/  144 batches | lr 0.00068 | ms/batch 37.52 | loss 0.06019837\n",
      "| Epoch  98 |   100/  144 batches | lr 0.00068 | ms/batch 35.29 | loss 0.06183290\n",
      "\n",
      "Val set: Average loss: 0.06161094\n",
      "\n",
      "EarlyStopping counter: 5 out of 20\n",
      "| Epoch  99 |    50/  144 batches | lr 0.00068 | ms/batch 37.43 | loss 0.05999883\n",
      "| Epoch  99 |   100/  144 batches | lr 0.00068 | ms/batch 35.31 | loss 0.06085216\n",
      "\n",
      "Val set: Average loss: 0.06089796\n",
      "\n",
      "| Epoch 100 |    50/  144 batches | lr 0.00068 | ms/batch 37.40 | loss 0.06007418\n",
      "| Epoch 100 |   100/  144 batches | lr 0.00068 | ms/batch 35.47 | loss 0.06087767\n",
      "\n",
      "Val set: Average loss: 0.06337312\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 101 |    50/  144 batches | lr 0.00068 | ms/batch 37.72 | loss 0.06134822\n",
      "| Epoch 101 |   100/  144 batches | lr 0.00068 | ms/batch 35.33 | loss 0.06015352\n",
      "\n",
      "Val set: Average loss: 0.06107377\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch 102 |    50/  144 batches | lr 0.00068 | ms/batch 37.61 | loss 0.05998054\n",
      "| Epoch 102 |   100/  144 batches | lr 0.00068 | ms/batch 35.38 | loss 0.05989857\n",
      "\n",
      "Val set: Average loss: 0.06263883\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch 103 |    50/  144 batches | lr 0.00068 | ms/batch 37.44 | loss 0.05950654\n",
      "| Epoch 103 |   100/  144 batches | lr 0.00068 | ms/batch 35.28 | loss 0.05939923\n",
      "\n",
      "Val set: Average loss: 0.06191678\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch 104 |    50/  144 batches | lr 0.00068 | ms/batch 37.47 | loss 0.06537422\n",
      "| Epoch 104 |   100/  144 batches | lr 0.00068 | ms/batch 35.43 | loss 0.06064603\n",
      "\n",
      "Val set: Average loss: 0.06124495\n",
      "\n",
      "EarlyStopping counter: 5 out of 20\n",
      "| Epoch 105 |    50/  144 batches | lr 0.00068 | ms/batch 37.59 | loss 0.05931784\n",
      "| Epoch 105 |   100/  144 batches | lr 0.00068 | ms/batch 35.26 | loss 0.06118395\n",
      "\n",
      "Val set: Average loss: 0.06230834\n",
      "\n",
      "EarlyStopping counter: 6 out of 20\n",
      "| Epoch 106 |    50/  144 batches | lr 0.00068 | ms/batch 37.31 | loss 0.06173094\n",
      "| Epoch 106 |   100/  144 batches | lr 0.00068 | ms/batch 35.29 | loss 0.06036403\n",
      "\n",
      "Val set: Average loss: 0.06153259\n",
      "\n",
      "EarlyStopping counter: 7 out of 20\n",
      "| Epoch 107 |    50/  144 batches | lr 0.00068 | ms/batch 37.27 | loss 0.06127913\n",
      "| Epoch 107 |   100/  144 batches | lr 0.00068 | ms/batch 35.24 | loss 0.05938571\n",
      "\n",
      "Val set: Average loss: 0.06065099\n",
      "\n",
      "| Epoch 108 |    50/  144 batches | lr 0.00068 | ms/batch 37.40 | loss 0.06078317\n",
      "| Epoch 108 |   100/  144 batches | lr 0.00068 | ms/batch 35.29 | loss 0.06002448\n",
      "\n",
      "Val set: Average loss: 0.06363651\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 109 |    50/  144 batches | lr 0.00068 | ms/batch 37.38 | loss 0.05964887\n",
      "| Epoch 109 |   100/  144 batches | lr 0.00068 | ms/batch 35.37 | loss 0.05942642\n",
      "\n",
      "Val set: Average loss: 0.06092651\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch 110 |    50/  144 batches | lr 0.00068 | ms/batch 37.47 | loss 0.05885095\n",
      "| Epoch 110 |   100/  144 batches | lr 0.00068 | ms/batch 35.36 | loss 0.05964352\n",
      "\n",
      "Val set: Average loss: 0.06315015\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch 111 |    50/  144 batches | lr 0.00068 | ms/batch 37.53 | loss 0.05978757\n",
      "| Epoch 111 |   100/  144 batches | lr 0.00068 | ms/batch 35.15 | loss 0.06016843\n",
      "\n",
      "Val set: Average loss: 0.06109094\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch 112 |    50/  144 batches | lr 0.00068 | ms/batch 37.65 | loss 0.05919468\n",
      "| Epoch 112 |   100/  144 batches | lr 0.00068 | ms/batch 35.17 | loss 0.06016897\n",
      "\n",
      "Val set: Average loss: 0.06076401\n",
      "\n",
      "EarlyStopping counter: 5 out of 20\n",
      "| Epoch 113 |    50/  144 batches | lr 0.00068 | ms/batch 37.28 | loss 0.06244664\n",
      "| Epoch 113 |   100/  144 batches | lr 0.00068 | ms/batch 35.42 | loss 0.05910937\n",
      "\n",
      "Val set: Average loss: 0.06228304\n",
      "\n",
      "EarlyStopping counter: 6 out of 20\n",
      "| Epoch 114 |    50/  144 batches | lr 0.00068 | ms/batch 37.22 | loss 0.05894701\n",
      "| Epoch 114 |   100/  144 batches | lr 0.00068 | ms/batch 35.40 | loss 0.05924676\n",
      "\n",
      "Val set: Average loss: 0.06251069\n",
      "\n",
      "EarlyStopping counter: 7 out of 20\n",
      "| Epoch 115 |    50/  144 batches | lr 0.00068 | ms/batch 37.31 | loss 0.05972277\n",
      "| Epoch 115 |   100/  144 batches | lr 0.00068 | ms/batch 35.45 | loss 0.05961005\n",
      "\n",
      "Val set: Average loss: 0.06368946\n",
      "\n",
      "EarlyStopping counter: 8 out of 20\n",
      "| Epoch 116 |    50/  144 batches | lr 0.00068 | ms/batch 37.48 | loss 0.06021512\n",
      "| Epoch 116 |   100/  144 batches | lr 0.00068 | ms/batch 34.96 | loss 0.06016001\n",
      "\n",
      "Val set: Average loss: 0.06234121\n",
      "\n",
      "EarlyStopping counter: 9 out of 20\n",
      "| Epoch 117 |    50/  144 batches | lr 0.00068 | ms/batch 37.47 | loss 0.05935742\n",
      "| Epoch 117 |   100/  144 batches | lr 0.00068 | ms/batch 35.24 | loss 0.06035342\n",
      "\n",
      "Val set: Average loss: 0.06161048\n",
      "\n",
      "EarlyStopping counter: 10 out of 20\n",
      "| Epoch 118 |    50/  144 batches | lr 0.00068 | ms/batch 37.48 | loss 0.05980838\n",
      "| Epoch 118 |   100/  144 batches | lr 0.00068 | ms/batch 35.29 | loss 0.05970503\n",
      "\n",
      "Val set: Average loss: 0.06201515\n",
      "\n",
      "EarlyStopping counter: 11 out of 20\n",
      "| Epoch 119 |    50/  144 batches | lr 0.00068 | ms/batch 37.55 | loss 0.05852146\n",
      "| Epoch 119 |   100/  144 batches | lr 0.00068 | ms/batch 35.21 | loss 0.05892615\n",
      "\n",
      "Val set: Average loss: 0.06017641\n",
      "\n",
      "| Epoch 120 |    50/  144 batches | lr 0.00068 | ms/batch 37.33 | loss 0.06016242\n",
      "| Epoch 120 |   100/  144 batches | lr 0.00068 | ms/batch 35.23 | loss 0.05968726\n",
      "\n",
      "Val set: Average loss: 0.06072778\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 121 |    50/  144 batches | lr 0.00068 | ms/batch 37.43 | loss 0.05917884\n",
      "| Epoch 121 |   100/  144 batches | lr 0.00068 | ms/batch 35.28 | loss 0.05966170\n",
      "\n",
      "Val set: Average loss: 0.06242830\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch 122 |    50/  144 batches | lr 0.00068 | ms/batch 37.32 | loss 0.05947316\n",
      "| Epoch 122 |   100/  144 batches | lr 0.00068 | ms/batch 35.16 | loss 0.05964100\n",
      "\n",
      "Val set: Average loss: 0.06197103\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch 123 |    50/  144 batches | lr 0.00068 | ms/batch 37.55 | loss 0.06019879\n",
      "| Epoch 123 |   100/  144 batches | lr 0.00068 | ms/batch 35.34 | loss 0.06054814\n",
      "\n",
      "Val set: Average loss: 0.06152672\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch 124 |    50/  144 batches | lr 0.00068 | ms/batch 37.33 | loss 0.05964252\n",
      "| Epoch 124 |   100/  144 batches | lr 0.00068 | ms/batch 35.28 | loss 0.05893138\n",
      "\n",
      "Val set: Average loss: 0.06166440\n",
      "\n",
      "EarlyStopping counter: 5 out of 20\n",
      "| Epoch 125 |    50/  144 batches | lr 0.00068 | ms/batch 37.40 | loss 0.05915944\n",
      "| Epoch 125 |   100/  144 batches | lr 0.00068 | ms/batch 35.10 | loss 0.05944464\n",
      "\n",
      "Val set: Average loss: 0.06120963\n",
      "\n",
      "EarlyStopping counter: 6 out of 20\n",
      "| Epoch 126 |    50/  144 batches | lr 0.00068 | ms/batch 37.22 | loss 0.06049412\n",
      "| Epoch 126 |   100/  144 batches | lr 0.00068 | ms/batch 35.17 | loss 0.05991922\n",
      "\n",
      "Val set: Average loss: 0.06019197\n",
      "\n",
      "EarlyStopping counter: 7 out of 20\n",
      "| Epoch 127 |    50/  144 batches | lr 0.00068 | ms/batch 37.39 | loss 0.05949183\n",
      "| Epoch 127 |   100/  144 batches | lr 0.00068 | ms/batch 35.05 | loss 0.05907568\n",
      "\n",
      "Val set: Average loss: 0.06221382\n",
      "\n",
      "EarlyStopping counter: 8 out of 20\n",
      "| Epoch 128 |    50/  144 batches | lr 0.00068 | ms/batch 37.36 | loss 0.05961210\n",
      "| Epoch 128 |   100/  144 batches | lr 0.00068 | ms/batch 35.17 | loss 0.05928809\n",
      "\n",
      "Val set: Average loss: 0.06010105\n",
      "\n",
      "| Epoch 129 |    50/  144 batches | lr 0.00068 | ms/batch 37.35 | loss 0.06090421\n",
      "| Epoch 129 |   100/  144 batches | lr 0.00068 | ms/batch 35.06 | loss 0.06043715\n",
      "\n",
      "Val set: Average loss: 0.06078241\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 130 |    50/  144 batches | lr 0.00068 | ms/batch 37.20 | loss 0.05834764\n",
      "| Epoch 130 |   100/  144 batches | lr 0.00068 | ms/batch 35.13 | loss 0.05916605\n",
      "\n",
      "Val set: Average loss: 0.06086947\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch 131 |    50/  144 batches | lr 0.00068 | ms/batch 37.23 | loss 0.05868915\n",
      "| Epoch 131 |   100/  144 batches | lr 0.00068 | ms/batch 35.34 | loss 0.05848449\n",
      "\n",
      "Val set: Average loss: 0.06001879\n",
      "\n",
      "| Epoch 132 |    50/  144 batches | lr 0.00068 | ms/batch 37.16 | loss 0.05884267\n",
      "| Epoch 132 |   100/  144 batches | lr 0.00068 | ms/batch 35.35 | loss 0.05889678\n",
      "\n",
      "Val set: Average loss: 0.06047311\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 133 |    50/  144 batches | lr 0.00068 | ms/batch 37.42 | loss 0.05886526\n",
      "| Epoch 133 |   100/  144 batches | lr 0.00068 | ms/batch 35.07 | loss 0.05922583\n",
      "\n",
      "Val set: Average loss: 0.06192198\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch 134 |    50/  144 batches | lr 0.00068 | ms/batch 37.13 | loss 0.05797596\n",
      "| Epoch 134 |   100/  144 batches | lr 0.00068 | ms/batch 35.12 | loss 0.05921334\n",
      "\n",
      "Val set: Average loss: 0.06164079\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch 135 |    50/  144 batches | lr 0.00068 | ms/batch 37.22 | loss 0.05985489\n",
      "| Epoch 135 |   100/  144 batches | lr 0.00068 | ms/batch 35.21 | loss 0.06016187\n",
      "\n",
      "Val set: Average loss: 0.06083927\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch 136 |    50/  144 batches | lr 0.00068 | ms/batch 37.32 | loss 0.06020125\n",
      "| Epoch 136 |   100/  144 batches | lr 0.00068 | ms/batch 35.05 | loss 0.05854701\n",
      "\n",
      "Val set: Average loss: 0.06065302\n",
      "\n",
      "EarlyStopping counter: 5 out of 20\n",
      "| Epoch 137 |    50/  144 batches | lr 0.00068 | ms/batch 37.52 | loss 0.05884216\n",
      "| Epoch 137 |   100/  144 batches | lr 0.00068 | ms/batch 35.27 | loss 0.05814251\n",
      "\n",
      "Val set: Average loss: 0.06063984\n",
      "\n",
      "EarlyStopping counter: 6 out of 20\n",
      "| Epoch 138 |    50/  144 batches | lr 0.00068 | ms/batch 37.54 | loss 0.05881326\n",
      "| Epoch 138 |   100/  144 batches | lr 0.00068 | ms/batch 35.14 | loss 0.05855731\n",
      "\n",
      "Val set: Average loss: 0.05979365\n",
      "\n",
      "| Epoch 139 |    50/  144 batches | lr 0.00068 | ms/batch 37.07 | loss 0.05929953\n",
      "| Epoch 139 |   100/  144 batches | lr 0.00068 | ms/batch 35.11 | loss 0.06038274\n",
      "\n",
      "Val set: Average loss: 0.06094642\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 140 |    50/  144 batches | lr 0.00068 | ms/batch 37.16 | loss 0.05977971\n",
      "| Epoch 140 |   100/  144 batches | lr 0.00068 | ms/batch 35.13 | loss 0.05947654\n",
      "\n",
      "Val set: Average loss: 0.05983793\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch 141 |    50/  144 batches | lr 0.00068 | ms/batch 37.34 | loss 0.05992525\n",
      "| Epoch 141 |   100/  144 batches | lr 0.00068 | ms/batch 34.97 | loss 0.05973994\n",
      "\n",
      "Val set: Average loss: 0.06010037\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch 142 |    50/  144 batches | lr 0.00068 | ms/batch 37.30 | loss 0.05892063\n",
      "| Epoch 142 |   100/  144 batches | lr 0.00068 | ms/batch 35.14 | loss 0.05884994\n",
      "\n",
      "Val set: Average loss: 0.06053546\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch 143 |    50/  144 batches | lr 0.00068 | ms/batch 37.29 | loss 0.05856795\n",
      "| Epoch 143 |   100/  144 batches | lr 0.00068 | ms/batch 35.02 | loss 0.05952679\n",
      "\n",
      "Val set: Average loss: 0.06071606\n",
      "\n",
      "EarlyStopping counter: 5 out of 20\n",
      "| Epoch 144 |    50/  144 batches | lr 0.00068 | ms/batch 37.33 | loss 0.05915153\n",
      "| Epoch 144 |   100/  144 batches | lr 0.00068 | ms/batch 35.21 | loss 0.05945829\n",
      "\n",
      "Val set: Average loss: 0.06010377\n",
      "\n",
      "EarlyStopping counter: 6 out of 20\n",
      "| Epoch 145 |    50/  144 batches | lr 0.00068 | ms/batch 37.38 | loss 0.05937668\n",
      "| Epoch 145 |   100/  144 batches | lr 0.00068 | ms/batch 35.06 | loss 0.05803110\n",
      "\n",
      "Val set: Average loss: 0.06153073\n",
      "\n",
      "EarlyStopping counter: 7 out of 20\n",
      "| Epoch 146 |    50/  144 batches | lr 0.00068 | ms/batch 37.29 | loss 0.05901124\n",
      "| Epoch 146 |   100/  144 batches | lr 0.00068 | ms/batch 35.08 | loss 0.05946152\n",
      "\n",
      "Val set: Average loss: 0.06044188\n",
      "\n",
      "EarlyStopping counter: 8 out of 20\n",
      "| Epoch 147 |    50/  144 batches | lr 0.00068 | ms/batch 37.39 | loss 0.05915154\n",
      "| Epoch 147 |   100/  144 batches | lr 0.00068 | ms/batch 35.18 | loss 0.05885443\n",
      "\n",
      "Val set: Average loss: 0.06021680\n",
      "\n",
      "EarlyStopping counter: 9 out of 20\n",
      "| Epoch 148 |    50/  144 batches | lr 0.00068 | ms/batch 37.29 | loss 0.05921803\n",
      "| Epoch 148 |   100/  144 batches | lr 0.00068 | ms/batch 34.98 | loss 0.05855024\n",
      "\n",
      "Val set: Average loss: 0.06133535\n",
      "\n",
      "EarlyStopping counter: 10 out of 20\n",
      "| Epoch 149 |    50/  144 batches | lr 0.00068 | ms/batch 37.20 | loss 0.05835456\n",
      "| Epoch 149 |   100/  144 batches | lr 0.00068 | ms/batch 35.10 | loss 0.05877747\n",
      "\n",
      "Val set: Average loss: 0.06078627\n",
      "\n",
      "EarlyStopping counter: 11 out of 20\n",
      "| Epoch 150 |    50/  144 batches | lr 0.00068 | ms/batch 37.23 | loss 0.06128977\n",
      "| Epoch 150 |   100/  144 batches | lr 0.00068 | ms/batch 35.09 | loss 0.06003251\n",
      "\n",
      "Val set: Average loss: 0.06029952\n",
      "\n",
      "EarlyStopping counter: 12 out of 20\n",
      "| Epoch 151 |    50/  144 batches | lr 0.00068 | ms/batch 37.17 | loss 0.06219017\n",
      "| Epoch 151 |   100/  144 batches | lr 0.00068 | ms/batch 35.07 | loss 0.05915713\n",
      "\n",
      "Val set: Average loss: 0.06100406\n",
      "\n",
      "EarlyStopping counter: 13 out of 20\n",
      "| Epoch 152 |    50/  144 batches | lr 0.00068 | ms/batch 37.28 | loss 0.05826718\n",
      "| Epoch 152 |   100/  144 batches | lr 0.00068 | ms/batch 35.02 | loss 0.05916165\n",
      "\n",
      "Val set: Average loss: 0.06068515\n",
      "\n",
      "EarlyStopping counter: 14 out of 20\n",
      "| Epoch 153 |    50/  144 batches | lr 0.00068 | ms/batch 37.36 | loss 0.05831488\n",
      "| Epoch 153 |   100/  144 batches | lr 0.00068 | ms/batch 35.21 | loss 0.05857308\n",
      "\n",
      "Val set: Average loss: 0.06072171\n",
      "\n",
      "EarlyStopping counter: 15 out of 20\n",
      "| Epoch 154 |    50/  144 batches | lr 0.00068 | ms/batch 37.28 | loss 0.05980414\n",
      "| Epoch 154 |   100/  144 batches | lr 0.00068 | ms/batch 34.97 | loss 0.05835638\n",
      "\n",
      "Val set: Average loss: 0.06065664\n",
      "\n",
      "EarlyStopping counter: 16 out of 20\n",
      "| Epoch 155 |    50/  144 batches | lr 0.00068 | ms/batch 37.28 | loss 0.05991576\n",
      "| Epoch 155 |   100/  144 batches | lr 0.00068 | ms/batch 35.13 | loss 0.05970047\n",
      "\n",
      "Val set: Average loss: 0.05967659\n",
      "\n",
      "| Epoch 156 |    50/  144 batches | lr 0.00068 | ms/batch 37.23 | loss 0.05775600\n",
      "| Epoch 156 |   100/  144 batches | lr 0.00068 | ms/batch 35.07 | loss 0.05824698\n",
      "\n",
      "Val set: Average loss: 0.06298858\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 157 |    50/  144 batches | lr 0.00068 | ms/batch 37.28 | loss 0.05905299\n",
      "| Epoch 157 |   100/  144 batches | lr 0.00068 | ms/batch 35.07 | loss 0.05876167\n",
      "\n",
      "Val set: Average loss: 0.06300142\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch 158 |    50/  144 batches | lr 0.00068 | ms/batch 37.38 | loss 0.05725005\n",
      "| Epoch 158 |   100/  144 batches | lr 0.00068 | ms/batch 35.12 | loss 0.05808091\n",
      "\n",
      "Val set: Average loss: 0.06294879\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch 159 |    50/  144 batches | lr 0.00068 | ms/batch 37.15 | loss 0.05884080\n",
      "| Epoch 159 |   100/  144 batches | lr 0.00068 | ms/batch 35.08 | loss 0.05847336\n",
      "\n",
      "Val set: Average loss: 0.06017606\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch 160 |    50/  144 batches | lr 0.00068 | ms/batch 37.58 | loss 0.05852781\n",
      "| Epoch 160 |   100/  144 batches | lr 0.00068 | ms/batch 34.95 | loss 0.05928634\n",
      "\n",
      "Val set: Average loss: 0.06181426\n",
      "\n",
      "EarlyStopping counter: 5 out of 20\n",
      "| Epoch 161 |    50/  144 batches | lr 0.00068 | ms/batch 37.18 | loss 0.05942974\n",
      "| Epoch 161 |   100/  144 batches | lr 0.00068 | ms/batch 35.08 | loss 0.05911342\n",
      "\n",
      "Val set: Average loss: 0.06179237\n",
      "\n",
      "EarlyStopping counter: 6 out of 20\n",
      "| Epoch 162 |    50/  144 batches | lr 0.00068 | ms/batch 37.27 | loss 0.05858583\n",
      "| Epoch 162 |   100/  144 batches | lr 0.00068 | ms/batch 35.11 | loss 0.05868262\n",
      "\n",
      "Val set: Average loss: 0.06297223\n",
      "\n",
      "EarlyStopping counter: 7 out of 20\n",
      "| Epoch 163 |    50/  144 batches | lr 0.00068 | ms/batch 37.21 | loss 0.05838671\n",
      "| Epoch 163 |   100/  144 batches | lr 0.00068 | ms/batch 35.06 | loss 0.05726882\n",
      "\n",
      "Val set: Average loss: 0.06026869\n",
      "\n",
      "EarlyStopping counter: 8 out of 20\n",
      "| Epoch 164 |    50/  144 batches | lr 0.00068 | ms/batch 37.16 | loss 0.05763514\n",
      "| Epoch 164 |   100/  144 batches | lr 0.00068 | ms/batch 35.02 | loss 0.05803977\n",
      "\n",
      "Val set: Average loss: 0.05994255\n",
      "\n",
      "EarlyStopping counter: 9 out of 20\n",
      "| Epoch 165 |    50/  144 batches | lr 0.00068 | ms/batch 37.27 | loss 0.05893666\n",
      "| Epoch 165 |   100/  144 batches | lr 0.00068 | ms/batch 35.06 | loss 0.05939125\n",
      "\n",
      "Val set: Average loss: 0.06140525\n",
      "\n",
      "EarlyStopping counter: 10 out of 20\n",
      "| Epoch 166 |    50/  144 batches | lr 0.00068 | ms/batch 37.24 | loss 0.05825814\n",
      "| Epoch 166 |   100/  144 batches | lr 0.00068 | ms/batch 35.07 | loss 0.05828035\n",
      "\n",
      "Val set: Average loss: 0.06077552\n",
      "\n",
      "EarlyStopping counter: 11 out of 20\n",
      "| Epoch 167 |    50/  144 batches | lr 0.00068 | ms/batch 37.20 | loss 0.05980950\n",
      "| Epoch 167 |   100/  144 batches | lr 0.00068 | ms/batch 35.29 | loss 0.05839086\n",
      "\n",
      "Val set: Average loss: 0.05983639\n",
      "\n",
      "EarlyStopping counter: 12 out of 20\n",
      "| Epoch 168 |    50/  144 batches | lr 0.00068 | ms/batch 37.36 | loss 0.06093701\n",
      "| Epoch 168 |   100/  144 batches | lr 0.00068 | ms/batch 34.98 | loss 0.05833371\n",
      "\n",
      "Val set: Average loss: 0.06079131\n",
      "\n",
      "EarlyStopping counter: 13 out of 20\n",
      "| Epoch 169 |    50/  144 batches | lr 0.00068 | ms/batch 37.37 | loss 0.05805949\n",
      "| Epoch 169 |   100/  144 batches | lr 0.00068 | ms/batch 35.02 | loss 0.05791591\n",
      "\n",
      "Val set: Average loss: 0.06084584\n",
      "\n",
      "EarlyStopping counter: 14 out of 20\n",
      "| Epoch 170 |    50/  144 batches | lr 0.00068 | ms/batch 37.24 | loss 0.05805117\n",
      "| Epoch 170 |   100/  144 batches | lr 0.00068 | ms/batch 35.12 | loss 0.05850686\n",
      "\n",
      "Val set: Average loss: 0.06065683\n",
      "\n",
      "EarlyStopping counter: 15 out of 20\n",
      "| Epoch 171 |    50/  144 batches | lr 0.00068 | ms/batch 37.18 | loss 0.05948102\n",
      "| Epoch 171 |   100/  144 batches | lr 0.00068 | ms/batch 35.05 | loss 0.05813689\n",
      "\n",
      "Val set: Average loss: 0.06138283\n",
      "\n",
      "EarlyStopping counter: 16 out of 20\n",
      "| Epoch 172 |    50/  144 batches | lr 0.00068 | ms/batch 37.29 | loss 0.05735248\n",
      "| Epoch 172 |   100/  144 batches | lr 0.00068 | ms/batch 35.01 | loss 0.05762326\n",
      "\n",
      "Val set: Average loss: 0.06012547\n",
      "\n",
      "EarlyStopping counter: 17 out of 20\n",
      "| Epoch 173 |    50/  144 batches | lr 0.00068 | ms/batch 37.19 | loss 0.05784224\n",
      "| Epoch 173 |   100/  144 batches | lr 0.00068 | ms/batch 35.09 | loss 0.05805215\n",
      "\n",
      "Val set: Average loss: 0.06052293\n",
      "\n",
      "EarlyStopping counter: 18 out of 20\n",
      "| Epoch 174 |    50/  144 batches | lr 0.00068 | ms/batch 37.27 | loss 0.05747848\n",
      "| Epoch 174 |   100/  144 batches | lr 0.00068 | ms/batch 35.14 | loss 0.05776850\n",
      "\n",
      "Val set: Average loss: 0.06049920\n",
      "\n",
      "EarlyStopping counter: 19 out of 20\n",
      "| Epoch 175 |    50/  144 batches | lr 0.00068 | ms/batch 37.24 | loss 0.05737780\n",
      "| Epoch 175 |   100/  144 batches | lr 0.00068 | ms/batch 35.11 | loss 0.05818333\n",
      "\n",
      "Val set: Average loss: 0.06125000\n",
      "\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Stopping at Epoch: 175\n"
     ]
    }
   ],
   "source": [
    "load = False\n",
    "save_model_path = '../models/final_real_data_model.chkpt'\n",
    "val_err_df_path = '../results/val_final_real_data_model.csv'\n",
    "\n",
    "if not load:\n",
    "  train_losses, val_losses = train(\n",
    "      epochs,\n",
    "      batch_size,\n",
    "      model,\n",
    "      optimizer,\n",
    "      loss_fn,\n",
    "      X_train,\n",
    "      y_train,\n",
    "      X_val,\n",
    "      y_val)\n",
    "  val_err_df = pd.DataFrame({\n",
    "      'Training': train_losses,\n",
    "      'Validation': val_losses})\n",
    "  val_err_df.to_csv(val_err_df_path)\n",
    "  torch.save(model.state_dict(), save_model_path)\n",
    "else:\n",
    "  model = Net(input_size, output_size, hidden_size, num_layers, act_fn)\n",
    "  model.load_state_dict(torch.load(save_model_path, map_location=device))\n",
    "  model = model.to(device)\n",
    "  val_err_df = pd.read_csv(val_err_df_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1650894219921,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "KkenWSRYvDpl",
    "outputId": "37746aa5-0b46-4a80-d14d-397868e89361",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABJa0lEQVR4nO3dd3xUVfr48c+TSTLpCQkJJaFLByEQioCIiwUsIAgKVtQVu2tZXXv9+tt11bXrqmsXRcUGigVRREWR0DsEDBBqSEJ6z/n9ce6kMRDADAnmeb9evHLnzL13ztyEeeac55xzxRiDUkopVZtfQ1dAKaVU46QBQimllFcaIJRSSnmlAUIppZRXGiCUUkp55d/QFagvzZs3N+3bt2/oaiil1DFl8eLFe40xsd6e+9MEiPbt25OcnNzQ1VBKqWOKiGw50HPaxaSUUsorDRBKKaW80gChlFLKqz9NDkIp9edSWlpKWloaRUVFDV2VP4WgoCASEhIICAg45GM0QCilGqW0tDTCw8Np3749ItLQ1TmmGWPIyMggLS2NDh06HPJx2sWklGqUioqKiImJ0eBQD0SEmJiYw26N+TRAiMgoEVkvIikicoeX54eLyBIRKRORCdXK+4rILyKyWkRWiMj5vqynUqpx0uBQf47kWvosQIiIC3geGA30ACaLSI9au20FpgDv1iovAC4xxvQERgFPiUiUr+oKQHEeLHkLdPlzpZQCfNuCGAikGGM2G2NKgOnA2Oo7GGNSjTErgIpa5RuMMRud7R3AHsDrTL9688tzMPMGSF/n05dRSh0bMjIy6Nu3L3379qVly5bEx8dXPi4pKTnoscnJydx44411vsaQIUPqq7o+4cskdTywrdrjNGDQ4Z5ERAYCgcCmeqrX/srLYPGbdrukwGcvo5Q6dsTExLBs2TIAHnjgAcLCwvj73/9e+XxZWRn+/t4/QpOSkkhKSqrzNRYsWFAvdfWVRp2kFpFWwNvAZcaYCi/PTxWRZBFJTk9PP/IX2vgN5O6w22WFR34epdSf2pQpU7j66qsZNGgQt99+O7/99hsnnHACiYmJDBkyhPXr1wMwb948zjrrLMAGl8svv5wRI0bQsWNHnnnmmcrzhYWFVe4/YsQIJkyYQLdu3bjwwgvx3O1z9uzZdOvWjf79+3PjjTdWnvdo8GULYjvQptrjBKfskIhIBPAFcLcx5ldv+xhjXgZeBkhKSjry5MHi1wEBDJTqmGulGpsHZ61mzY6cej1nj9YR3H92z8M+Li0tjQULFuByucjJyeHHH3/E39+fb7/9lrvuuouPPvpov2PWrVvH999/T25uLl27duWaa67Zbz7C0qVLWb16Na1bt2bo0KH8/PPPJCUlcdVVVzF//nw6dOjA5MmTj/j9HglfBohFQGcR6YANDJOACw7lQBEJBD4B3jLGzPBdFSFrewqRG+ewM+4k4vfM0xaEUuqgJk6ciMvlAiA7O5tLL72UjRs3IiKUlpZ6PebMM8/E7XbjdruJi4tj9+7dJCQk1Nhn4MCBlWV9+/YlNTWVsLAwOnbsWDl3YfLkybz88ss+fHc1+SxAGGPKROR64GvABbxmjFktIg8BycaYmSIyABsImgFni8iDzsil84DhQIyITHFOOcUYs6y+6+kX0ZprSv7G2ITuNkBoC0KpRudIvun7SmhoaOX2vffey8knn8wnn3xCamoqI0aM8HqM2+2u3Ha5XJSVlR3RPkebT2dSG2NmA7Nrld1XbXsRtuup9nHvAO/4sm4e7iA3X1cMZGhghC0o0wChlDo02dnZxMfHA/DGG2/U+/m7du3K5s2bSU1NpX379rz//vv1/hoH06iT1EdDoMtegoJypz9QA4RS6hDdfvvt3HnnnSQmJvrkG39wcDAvvPACo0aNon///oSHhxMZGVnvr3MgYv4kE8OSkpLMkd4wqMvdX3LNkDhuXvQXOPVhGFr3+GWllG+tXbuW7t27N3Q1GlxeXh5hYWEYY7juuuvo3LkzN9988xGdy9s1FZHFxhivY3KbfAsCwO3vR562IJRSjdArr7xC37596dmzJ9nZ2Vx11VVH7bV1NVfAHeBHUbmAuKBURzEppRqPm2+++YhbDH+UtiAAt7+L4rIKCAjWFoRSSjk0QACB/n42QPgHaYBQSimHBghsDqK4tNy2IHQehFJKARogACdAVLYgNAehlFKgAQLw5CDKISBIWxBKKQBOPvlkvv766xplTz31FNdcc43X/UeMGIFnqP0ZZ5zBvn379tvngQce4PHHHz/o63766aesWbOm8vF9993Ht99+e5i1rx8aILCjmErKKsA/WFsQSinArns0ffr0GmXTp08/pAXzZs+eTVRU1BG9bu0A8dBDD3HKKacc0bn+KA0QVO9icmsLQikFwIQJE/jiiy8qbw6UmprKjh07eO+990hKSqJnz57cf//9Xo9t3749e/fuBeCRRx6hS5cuDBs2rHI5cLDzGwYMGECfPn0499xzKSgoYMGCBcycOZPbbruNvn37smnTJqZMmcKMGXbN0rlz55KYmEjv3r25/PLLKS4urny9+++/n379+tG7d2/WraufG5/pPAhqDXMtzm3o6iilavvyDti1sn7P2bI3jP7XAZ+Ojo5m4MCBfPnll4wdO5bp06dz3nnncddddxEdHU15eTkjR45kxYoVHH/88V7PsXjxYqZPn86yZcsoKyujX79+9O/fH4Dx48dz5ZVXAnDPPffw6quvcsMNNzBmzBjOOussJkyYUONcRUVFTJkyhblz59KlSxcuueQSXnzxRW666SYAmjdvzpIlS3jhhRd4/PHH+d///veHL5G2IPAMcy3XYa5KqRqqdzN5upc++OAD+vXrR2JiIqtXr67RHVTbjz/+yLhx4wgJCSEiIoIxY8ZUPrdq1SpOPPFEevfuzbRp01i9evVB67J+/Xo6dOhAly5dALj00kuZP39+5fPjx48HoH///qSmph7pW65BWxB4hrk6LQidSa1U43OQb/q+NHbsWG6++WaWLFlCQUEB0dHRPP744yxatIhmzZoxZcoUioqO7EvllClT+PTTT+nTpw9vvPEG8+bN+0N19SwXXp9LhWsLgtrDXLUFoZSywsLCOPnkk7n88suZPHkyOTk5hIaGEhkZye7du/nyyy8Pevzw4cP59NNPKSwsJDc3l1mzZlU+l5ubS6tWrSgtLWXatGmV5eHh4eTm7t/V3bVrV1JTU0lJSQHg7bff5qSTTqqnd+qdBgjAHeAZ5qoT5ZRSNU2ePJnly5czefJk+vTpQ2JiIt26deOCCy5g6NChBz22X79+nH/++fTp04fRo0czYMCAyucefvhhBg0axNChQ+nWrVtl+aRJk3jsscdITExk06ZNleVBQUG8/vrrTJw4kd69e+Pn58fVV19d/2+4Gl3uG3jim/U8/30Km05eiCx8Ee5Nr+faKaUOly73Xf90ue8j4Pb3o8JAhX8QlJdARUVDV0kppRqcBgjsMFeAMj/nnrCah1BKKQ0QYIe5ggYIpRqbP0sXeGNwJNdSAwS2iwmgVJwAoUNdlWpwQUFBZGRkaJCoB8YYMjIyCAoKOqzjdB4Edi0mgBJtQSjVaCQkJJCWlkZ6ug4aqQ9BQUEkJCQc1jEaIKjKQZRKoC3QAKFUgwsICKBDhw4NXY0mzaddTCIySkTWi0iKiNzh5fnhIrJERMpEZEKt574SkX0i8rkv6whVXUzFJsAW6FwIpZTyXYAQERfwPDAa6AFMFpEetXbbCkwB3vVyiseAi31Vv+o8LYiqLibNQSillC9bEAOBFGPMZmNMCTAdGFt9B2NMqjFmBbDfxANjzFzgqCyt6slBFBuni0lbEEop5dMAEQ9sq/Y4zSmrNyIyVUSSRST5jySyPF1MRThdTNqCUEqpY3uYqzHmZWNMkjEmKTY29ojPE1gZILQFoZRSHr4MENuBNtUeJzhljY4nB1HoSVLrKCallPJpgFgEdBaRDiISCEwCZvrw9Y6Yp4upsEKHuSqllIfPAoQxpgy4HvgaWAt8YIxZLSIPicgYABEZICJpwETgJRGpvKWSiPwIfAiMFJE0ETndV3X1BIiCymGumoNQSimfTpQzxswGZtcqu6/a9iJs15O3Y0/0Zd2qcwc4XUwV2sWklFIex3SSur5UjmKqEPDz1xaEUkqhAQIAfz/BT3BuOxqsLQillEIDBAAiQqDnvtQBel9qpZQCDRCV3P4uikvLbQtC50EopZQGCA93jRaE5iCUUkoDhMMd4AQIf7e2IJRSCg0Qldz+LorLnC4mbUEopZQGCA+3vx8lni4mbUEopZQGCI/KHIQOc1VKKUADRKVAfz+KS3WYq1JKeWiAcNTIQehMaqWU0gDh4daJckopVYMGCIc7wOUEiFAoKWjo6iilVIPTAOFw+/vZmdSBoVCSB8Y0dJWUUqpBaYBwVHYxBYYCRvMQSqkmTwOEw+3vsvMgAkNtQUl+w1ZIKaUamAYIR+VqroFhtqAkr2ErpJRSDUwDhMPt70dJeQUVASG2QFsQSqkmTgOEwx1gL0WZvwYIpZQCDRCV3P72vtQlfp4AoV1MSqmmTQOEw3Nf6mK/IFugLQilVBOnAcJRFSC0i0kppcDHAUJERonIehFJEZE7vDw/XESWiEiZiEyo9dylIrLR+XepL+sJdiY1QLF4WhDaxaSUatp8FiBExAU8D4wGegCTRaRHrd22AlOAd2sdGw3cDwwCBgL3i0gzX9UVIDzIH4Cscg0QSikFvm1BDARSjDGbjTElwHRgbPUdjDGpxpgVQEWtY08H5hhjMo0xWcAcYJQP60p0SCAAmUUC4qddTEqpJs+XASIe2FbtcZpTVm/HishUEUkWkeT09PQjrihAdKgTIApL7WQ5DRBKqSbumE5SG2NeNsYkGWOSYmNj/9C5mjkBIiu/pGrBPqWUasJ8GSC2A22qPU5wynx97BEJDXQR6PIjs8ATILQFoZRq2nwZIBYBnUWkg4gEApOAmYd47NfAaSLSzElOn+aU+YyI0Cw0oFoLQgOEUqpp81mAMMaUAddjP9jXAh8YY1aLyEMiMgZARAaISBowEXhJRFY7x2YCD2ODzCLgIafMp5qFBJKZrzkIpZQC8PflyY0xs4HZtcruq7a9CNt95O3Y14DXfFm/2qJDA8kqKIGIUMj/Y0lvpZQ61h3TSer61iw0ULuYlFLKoQGimuiQwKokdbGOYlJKNW0aIKppFhpIdmEpFQHaglBKKQ0Q1USHBGAMFEmwnQdhTENXSSmlGowGiGo8k+UKCQJTDmXFDVwjpZRqOBogqvEst5Fr9J4QSimlAaKaZs6CfbkVblugy20opZowDRDVeFoQ2eX2p7YglFJNmQaIajwtiKwyDRBKKaUBoprgQBfBAS4ySwJsgXYxKaWaMA0QtUSHBpJe6qxAUpIHS6dBfkbDVkoppRqABohamoUGkF7kBIitv8Jn18KqGQ1bKaWUagAaIGppFhLIrmInQKz/0v4szGq4CimlVAPRAFFLdGgguwtd9kHmJvuzKKfhKqSUUg1EA0QtzcPcbM2tVViU3SB1UUqphqQBopaEZsEUlBpMQEhVYdG+BquPUko1FA0QtbRpZgNDmb8TIJp30RaEUqpJ0gBRS5toGxhK/EKgZW+I7qgBQinVJGmAqCWhWTAAya0vhBF3gjtCA4RSqknSAFFLqNuf6NBAvgo+E7qdCUGRUKyjmJRSTY8GCC/aNAsmLavAPgiKtC0IvXmQUqqJOWiAEJGLqm0PrfXc9b6qVENLiA4hLavQPgiKBFOh6zIppZqculoQt1TbfrbWc5fXc10ajYRmwWzPKqSiwtgAAZqHUEo1OXUFCDnAtrfH+x8sMkpE1otIiojc4eV5t4i87zy/UETaO+WBIvK6iKwUkeUiMqKu16pPbZqFUFJewZ7cYg0QSqkmq64AYQ6w7e1xDSLiAp4HRgM9gMki0qPWblcAWcaY44AngUed8isBjDG9gVOBJ0TkqOVLPENdt2UVQFCELdTlNpRSTUxdH7rdRGSFiKystu153LWOYwcCKcaYzcaYEmA6MLbWPmOBN53tGcBIERFsQPkOwBizB9gHJB3qm/qj2jhDXbdlFmgLQinVZPnX8Xz3P3DueGBbtcdpwKAD7WOMKRORbCAGWA6MEZH3gDZAf+fnb9UPFpGpwFSAtm3b/oGq1tQ6ygaItKxCaBdlCzVAKKWamIMGCGPMluqPRSQGGA5sNcYs9mG9XsMGp2RgC7AAKPdSv5eBlwGSkpLqbRxqUICLFhFupwURbws1QCilmpi6hrl+LiK9nO1WwCrs6KW3ReSmOs69Hfut3yPBKfO6j4j4A5FAhjGmzBhzszGmrzFmLBAFbDikd1RPOjQPZVN6np1JDRoglFJNTl05iA7GmFXO9mXAHGPM2diuorqGuS4COotIBxEJBCYBM2vtMxO41NmeAHxnjDEiEiIioQAicipQZoxZc2hvqX50bRHOxt15GFcA+Afriq5KqSanrhxEabXtkcArAMaYXBGpONiBTk7heuBrwAW8ZoxZLSIPAcnGmJnAq9jWSAqQiQ0iAHHA185rbAcuPsz39Yd1bhFObnEZO7OLaK3LbSilmqC6AsQ2EbkBm2DuB3wFICLBQEBdJzfGzAZm1yq7r9p2ETDRy3Gp1D1Kyqe6tgwHYP3uXBsgtItJKdXE1NXFdAXQE5gCnG+M2eeUDwZe9121Gl6XOBsgNuzKrVqPSSmlmpC6RjHtAa72Uv498L2vKtUYRIYE0CLCzYbdeTZAFOxt6CoppdRRddAAISK1k8o1GGPG1G91GpcuLcLZsDsXWkVC5qaGro5SSh1VdeUgTsBOZHsPWMghrL/0Z9KlRTjTFm7BtI9AtItJKdXE1BUgWmLXQpoMXAB8AbxnjFnt64o1Bl1ahFFUWkEOIUQW5dh7QkiTipFKqSbsoElqY0y5MeYrY8yl2MR0CjDvz3wviOq6tLCJ6t0lbqgohdLCBq6RUkodPXW1IBARN3AmthXRHngG+MS31WocOsaGAbC7JIguYEcyBYY0aJ2UUupoqStJ/RbQCzuX4cFqs6qbhIggf9z+fqSXBtmComyIaNWwlVJKqaOkrhbERUA+8DfgRqnqfxfAGGMifFi3BicixEW4bRcT6FwIpVSTUtc8iKN2k57GKi48iB1FgfaBBgilVBPS5ANAXWLD3KQVOgFC12NSSjUhGiDqEBfhJjXfaWjpiq5KqSZEA0Qd4sLd2sWklGqSNEDUIS48iGICMS63BgilVJOiAaIOsRF2BFNZQJgGCKVUk6IBog6xYTZAlPiHa4BQSjUpGiDqEOe0IApcYVCko5iUUk2HBog6xIS68RPII1RbEEqpJkUDRB1cfkLzMDc5JkQDhFKqSdEAcQjiItxkVmiAUEo1LRogDkFsmJuMUh3mqpRqWjRAHIK48CB2lwZBeTGUFjV0dZRS6qjwaYAQkVEisl5EUkTkDi/Pu0Xkfef5hSLS3ikPEJE3RWSliKwVkTt9Wc+6xEW42V3srOiq6zEppZoInwUIEXEBzwOjgR7AZBHpUWu3K4AsY8xxwJPAo075RMBtjOkN9Aeu8gSPhhAX7mafcW4UpN1MSqkmwpctiIFAijFmszGmBJgOjK21z1jgTWd7BjBS7E0nDBAqIv5AMFACNNhX9xYRQeSgAUIp1bT4MkDEA9uqPU5zyrzuY4wpA7KBGGywyAd2AluBx40xmbVfQESmikiyiCSnp6fX/ztwdIwNJceE2ge6oqtSqolorEnqgUA50BroANwqIh1r72SMedkYk2SMSYqNjfVZZdpEh5Av2oJQSjUtvgwQ24E21R4nOGVe93G6kyKBDOAC4CtjTKkxZg/wM5Dkw7oelNvfRWhEjH2gy20opZoIXwaIRUBnEekgIoHAJGBmrX1mApc62xOA74wxBtut9BcAEQkFBgPrfFjXOsU0d1oo2oJQSjURPgsQTk7heuBrYC3wgTFmtYg8JCJjnN1eBWJEJAW4BfAMhX0eCBOR1dhA87oxZoWv6noo4mNjKDUujAYIpVQT4e/LkxtjZgOza5XdV227CDuktfZxed7KG1LHuDByCCE4N9Mznkkppf7UGmuSutHp0DyUXBNCQXZGQ1dFKaWOCg0Qh6hD81ByCKEkP6uhq6KUUkeFBohD1DoymDxCKS/UHIRSqmnQAHGI/PyE8sAI/HQtJqVUE6EB4jBIcCTu0hxyikobuipKKeVzGiAOQ2ybrjQni3H/+Zrl2/Y1dHWUUsqnNEAchq69BwCQUL6Nx79Z38C1UUop39IAcTjiugMwttU+lm/bR0WFObqvv28rVJQf3ddUSjVZGiAOR7P24B9Ez8Cd5BSV8XtG/pGfa+tCeLQD5B3iKrT5e+GZfrD6kyN/TaWUOgwaIA6Hnwtiu5JQmgrwx/IQaYugMBP2HmJXVdYWqCi1rQillDoKNEAcrtjuhOzbSGig648FiBxnYducHYe2f66zX6FO1FNKHR0aIA5XXDckdweDWrtYlvYHJs1lp9X8WZfcXfanBgil1FGiAeJwxdnbap8cncnaHTkUlx1h0tgTGA65BbHT/tQAoZQ6SjRAHK7YbgD0C9pBSXkFX63axZ6cosM/T2UXU+17KB1of0+A2Hf4r6WUUkdAA8ThimwDgWF0qNiKn8At0xdz87+fP7x8RFkx5O2224caIDwtiMZ0T+y0xfD8YL3LnlJ/UhogDpefH7QZRMimr/j8usF8NWAZ0/wf4uMvPj/0c3i6lfyDIfswA0Rj6mJKWwTpayFzc0PXRCnlAxogjsTAKyF3Bz32fk3nzW8DELBtAYu3ZB7a8Z5WQ3w/KNgLpYfQRdUYA0SBc2+Mgr0NWw+llE9ogDgSnU+HZh3g81sgfw/GP5hhgRv4z5wNh3a8p9XQZqD9mVtHorqkwN4LOzAMSgsOLaAcDZ4Aka8BQqk/Iw0QR8LPDwZOhbJCiO+P9BrPYP+NLEhJ59fNh3DHuRxnBFObQc7jOgKEp/XgLPXRaPIQnpaDBgil/pQ0QBypxIug7Qkw8n5oewJBpfsYELaX/8zZgDF2jabcolK+W7e78nGl7DQIbgYxx9nHdQYIZw6EJ0A0lpFMBU6XWv4hLheilDqm+Dd0BY5ZQRFw+Vd2O2MTADd13ssFSzOZtyGdfm2bcclrv7F82z6mTx3M4I4xVcdmb4fIBIho7Tw+wGS5Xatg7wYwFfZxXE/7s7HkITwtB81BKPWnpAGiPkR3hNA4BrnWEx/Vn8teX0RUSAD5xWX4+wnfrdtjA8T2JeCOsEnqyDYUSRD+gZFk7fidWG/nnf9vWPs5DLrKPq5sQTSSAFGZgziEbrXGaN0X0GkkBAQ1dE2UapR82sUkIqNEZL2IpIjIHV6ed4vI+87zC0WkvVN+oYgsq/avQkT6+rKuf4gItBuCK/VHPrlqAHeO7kb3lhH896L+nNAphrlrd9sP0TfOgpdHQEYKe/ya0+/hOWwsimDZqtU8OWfD/suH71oJphySX4eAUIhqa8sbQ4AwplqAOAa7mDI2wfQLdHVcpQ7CZwFCRFzA88BooAcwWUR61NrtCiDLGHMc8CTwKIAxZpoxpq8xpi9wMfC7MWaZr+paL/peAHm7iEv9jKtOaMV77WYxMjqDk7vGsSk9n+y5j9mkdmgMlBXxc7qboAAXsfEd6R6ay9NzN/LQ52uqzlecB5m/A2KPC28JIdH2ucIs2LfNLhleH4yBrNTDO6Zonw1ecGx2MXmCWt6uhq2HUo2YL1sQA4EUY8xmY0wJMB0YW2ufscCbzvYMYKSISK19JjvHNm6dT4NWfWD+4zDzBvjlOXj/Qk7pFEIs+whd9jr0nghXfEtRj/N4eVcXxifG07xNV+LLtzN1YHM+WrCGnJdGw7bfYM8awEC/i+35I1pDYDiInw0Qcx+Et8ZUJYr/iOXT4ZnEw1tK3PO6ITHH5iimygT7MVh3pY4SXwaIeGBbtcdpTpnXfYwxZUA2EFNrn/OB97y9gIhMFZFkEUlOT2/gbg4RGH47ZP0Oq2ZArwmQlUrbb67k/ZBHkYoSKk68HcJiebvlnawtT+D8AW3g+ElIaT63xiVzQ9h3ROxcQEXy67Z7CWDYLRDTGWK72uG1QVH22/vO5VBWBEvf+eN1X/OZTYR7XvNQeD5YY7tBSR6UFv7xehxNhU6AKDhG8ydKHQWNepiriAwCCowxq7w9b4x52RiTZIxJio31muY9urqeAe1PhOMnwfhXYMSd8PsPRAYHcFPJtVz06V5mLt/BtIVbSGwbRecW4ZDQHxIG4k5+icv8ZgNQsvZL2LUC3JH2LnZTv4fT/599jeBmdlhsRop9nPwqVFQceZ1LCmDz93Y7/TDus+35YI3tan8ea9/EtQWhVJ18GSC2A22qPU5wyrzuIyL+QCRQ/SvdJA7QemiU/Pzg0lkw/iW7Pfw2uHEZ0bcuYti4q1i6dR83vreU1IwCLj2hfdVxg6+BfVsIKNnHJ+6xBJVk2eRpi562ZeIOJ7/cxSWv/Ua+KwK2LLDf+HuOt7mDTXOPvM6b59mWCBxZgGjuBIhjLQ/hSfQfa/VW6ijy5TDXRUBnEemADQSTgAtq7TMTuBT4BZgAfGecWWUi4gecB5zowzrWv+opFBGI7oAA5w9oy8juLcjML6F5mJvo0MCq/bqPgah2ENuVooS/U/bdLPyLsqFlr8pdvli5k/kb0kmLddPVM5P65Lsh9SdY8hZ0PrXqfMZARTm4DuHXu362bam07O399qcFmTZHMfBKcAVUK/d0MR2jLQhPF9OxOkRXqaPAZy0IJ6dwPfA1sBb4wBizWkQeEpExzm6vAjEikgLcAlQfCjsc2GaM+dMsFdo8zE2XFuE1gwPYD/Kp82DiG5wxoDuLcT50W1QFiI8W28l0qfnOse5IiOkE3c6ETd/ZJcQ9vrgFnj4e9m48eIUqKmDD13DcSBuM0jfY4FLdsmnw9Z3ww79rlhdkgH9Q1dDb/L3w9jiY/9ghXIlGQGeBK1Unn+YgjDGzjTFdjDGdjDGPOGX3GWNmOttFxpiJxpjjjDEDqwcDY8w8Y8xgX9avUQmJhsBQIkMC2BF3MgDPrQvh7V9S2ZKRz8LfM+nYPJSdJc6krpa9bQul62ibJE790ZbvWGbnTeTsgDfOtI+NgdWfwvsXwc/PVI1WWvw65O+BnudA8y5Qmr//rO60Rfbnj4/XHFZbkAkhzSHUyf1sX2wD1abvfXBxfMDTxVRWCCX5DVsXpRqpRp2kbqo6nXEjD7pv5bVNkdz72Wom/vcXRODRCceTTRgA+dHdeXNBKv9vbSwl4mbhV9PYsjcP5txrE9lXfGPzFC+fBM/2gw8vtbmLOffC84Ng0f9gzv3Q4STbxeXcKW+/bqa0ZLt6bWQbO3zX08LI32uDmjscXIGw8kNbfjh5jIZUfbLhsdY9ptRRogGiETq+Qyvuv/M+Ft97Kg+c3YOM/BKGHdecAe2j8Q+1k+WeWBHI/TNX83byHn7leBLS5/PJyw/A7/Pt6Kk2A+HahXDqQxAaZ3/eugFuXGqT31/ciqkog7Ofsi0RTy6h+gd89na7LEinv8CJt9rg4RkKW5ABoc3tsaGxVSvMFuytn7kZvuZpAYEmqpU6AF2LqRETEaYM7cCwzrFEhdgEcav4drAZVtORWdcPo1d8BLJkN8y6kZtKXiE5cCCde1xEJNhZ20P/Zv95RHfk1+FvseG9fyBxfbg4uqMtD20OwdE1A8T2ZPszYYAdbvv5zXbORKvj7YdqdAf7fEiMDSTNu9ogsncjtB3k68vzxxRmQut+sHWvJqqVOgANEMeA4+LCKrd7n3Ihj34ayCMTzue4uHBb2HU0fNuMLa1GceG6M2n+/K/87ZTOlJUb4sLdDGgfTWRIAFn5Jfzvp83894fN+PtdQMnvFZywJ7fqPLHdYOMceG00dB1Nac5uAlxum+/wD4T2w2DNp/CXe5xv4M6cxlDnm/iQ62031N4NjTtAlBTYob3NO8PWBdqCUOoANEAcYzq3juEf115dszAsDm7bRDs/F+9vs3Mtbp+xosYuoYEuSisMJWUVjO3bmltP7crpT83nhXmb+M95fe1O7YZA2m/g54I597LPRGKadSPO3xk51WOsHSG1czkU51R10YS3hqBI6H0efPF3GyAaM0/+oXkX+1NHMinllQaIPws/FwB920Txzc3DSc3IJyIogG2ZBSzemsXe3BIAJg1sQ5cWtsVwwaC2vLEglSuGdaBn60jbMhhxB1SUkfnMCGJz1/FmVgKnZRfSKjIYup8NX9wK74y3rxnqtCD+crddkjwgyN4Eqa7htQDlpTXnVRxNnjkQUW3A5dYktVIHoEnqP6GgABfdWkbQOiqYQR1juHbEcdx3dg/uO7tHZXAAmDq8IxFB/ox57mfu+2wVmQXOh3ZAMI9G3MVG2jGnIokHZq4GoCIklo9DzmODu6dNWvc4x54oorXNS4DttvG0IEqLYPn7sOTtmvMrVn0E/2p3SIsDzlicRnJqPSe9PUn04GjbPVbf6zFlb4cfHoPysvo9r1JHmQaIJqxFRBDf3nISFwxsy7SFWznpse9559ctFJaU8+mWQN7t/x5DRo7h69W7mbNmN7NX7eSWzLFMyLqeouF3Vy0/Xl3zLnb5jw1fw3+6wydTYeb1MOtG22owBuY/YedcLDv4Kiplhbk0n3kRm2Y+agtyd8HPT/+xtaegqgUREu2b1WhXTIfv/88uY6LUMUwDRBMXE+bm4XN68fVNJ9InIYp7Pl3FQ5+vprisgpHdWnDliR3p2iKc+z9bxdPfbiTM7U9OURnfr9tDem4x/2/2Wq56O5n7P1tFXnGZDRCm3N6MJ7wlXPwpnPh3uxzIh1Mg5VvYs9ouXb5s2oE/7CsqKPxwKiNkKWdlvglFOfDtAzDnvqrRVdVlbLKjrLytKpuxyXaNldlutsocRGULop4DxJ619ueKxr9KvVIHowFCAXBcXDivTkmid3wk7/22jTC3PwM7RBPg8uP/je/FjuwiNu7J4+FzehIb7ubDxWlcO20xr//8Oyl78nj71y2MefYntvo5K7qHtYSLPoZOJ8PIe2H0v2Hd5/D+xRDWAkb9E/ZtsaOIcnfZkUVAfspPZD41DPNsP8I3z+aDspMIpZDSOQ/Big/suVN/2v8N/PoiJL9mf9aW/JqdGLjNmQle2cXUzCba62pB/PgEfHDJoV9MT4BY+zkU59rtjE3wWGc7WVGpY4QGCFXJ7e/ihQv7ERHkz8nd4gj0t38e/dtFc82ITgzqEM2YPvGM7dOa79btYVFqFo9P7MPcW0fw7pWDySkq5fKvCikbfB1c9BFEtKo6+aCr4C/32qUtBk6FXufaVsRHV9quqFdPsx+iH0yhMGsHWRHd+Cb+em4vm8rCim4ELH4F/PwhIgG2/Fyz4hXldn4GwE9P7T9RL+Vb+9NzXGEWBITYpHpobM0cxMZvIbPW8l9rZ9l/Rdl1X8TyUpuDaTPYvte1n9vy+Y/bZU083U7zH4cZV9R9PqUakAYIVUOb6BC+ufkkHhnXq0b5P0Z1Y/rUwbj8hHP7JyACkwa0YWxf22IY3DGGxyf2IWVvES8EXAZx3SqPzS8u46bpS3m6eAxm6jzeCRjPqBeSKex9oZ2P0O9SO8HuhcEEluzjypJbeanF/bxcdiYtIoJ4rWy0PVG/i6HL6XZNqPIyWP8l7Fxhv5Xn74GT7oCSXJj3z6qK79sG6evstqflUZBpu5fAjsQqybMTBGffBtPOtUHLk1QvL4Xda+yyJZ51qQ4mczOUl0DSZXaF3oX/tetUrXjfPr/LubXJqo/tnBJvXWI5O+3CiUo1MB3mqvbTMjLIa7nnbrDdW0Uw95aTaBcTWuP5EV3jOLN3K577PoVtmQX4u/zo28Z2WS3btg+AeRujWLp1BwDv9LuKK//hJKC7jMLMuIx/l09ijWlP4Zrd7M4pYkL/BD5MHsCstndw9slX2QUBk1+FlR/AZ9fZVkibAbZFMPRGGyh+e9l+sI9+tKr10GmkbUGUFdsWREgz1u7MoWtkO/st6fmBdr/4/jbHsW0htB1sh+yWOyvlbv0V2g2DHx6FPpMhtsv+F2mPc1/xuB62xfTp1fDKSLvybUKSXaqkJB/S19qgs3PF/pMKP7sW9qbAzYdxhz+lfEBbEOqIdIwNw+VX+/bhcN/ZPejeMpyfUvYye+VO/vHRStbszOGli/tzy6ldWLp1H6N7taRPQiQfLt6GMYZtmQXkthvJuktX8UrRKfRtE8Xve/MpKCmnd3wknVtE8n7FX+yoo/bD7AvNuskuFBgQBCnfkhF/Mpe8s5q8kf+CoTfZlWrfOsfeeCmyDSRdblsr25dAYSb5rkhGP/0jb+b0g7/OhTHPwoUf2Rs+BUXBgmft63jWngpuZgPEyg/gp//AW2O9D9Pds9beN7x5Fzh+Ilwxxy6lPvxWu6ZV9la7XpZxkvO1E+4FmbD5B7tf7ZV168OetYe3Vtb2JVVBVjU52oJQ9apFRBCfXW8/xI0xpOzJI8TtT3xUMKf3bMnYvq1JaBbC+4u2cdcnK3lzQSr/+modveMjObO3zVncdUZ3znvpFwB6J0TSpUU4P2xIZ1tmAV+szOeq6E5I5iY49UFoM4jyDy/j3rRBzM9L54tVuzn/1Aft8iCfXmO7e/pfZmeJA6TMgZyd7Aq0ixNO+20bU4YORxKSqt7EgCvgx//YnMiuFfbbf++JdiRWQaZdl6owywagq3+EwGotqT1rILqTDVwA8f3gaqdra6PzQbv4TfszKNJ2P1W3frYdBQaw7TeITPB+odd/aV/HWyvmQCoq4PXRdsLjmGfr3r+8zI48K8iAW9ZCUMShv5b6U9AWhPIZEaFzi3Dio4Iry9rFhOLyE87q04qgAD8emLUGlwiLUrN4Yd4mWkcGMbBDND1bR+D29+O42DC6tggnPbeYi15dyL++XMfy8OHQ8ngY8FdM60RujH2dbwo60yLCzYfJzrfu3hNsorx5F+h7gW19xPW0I5KytzKvtBt+Ail78liUmlWz4gOn2gmDv75oA0RcD9tyKSuyQ3SH3gTnvQ2Zm+zoKLBdWhUV9ht6XHfvF8Rzh8CNX0NkW7vUeu0AsXaWbfH4Bx0451FWDB9cCnMfPLxfyL5UG9i2OefdvhimX1jzZlPVrf7EjjQryavKoaiadq20+aSVMyBlrs15eVNear9wHGM0QKgGEREUwPh+CcSGu5l1wzC6tQxnT24xAzvY5PHfT+vK7aO64e/yo0tLO/t7e1YhPVpFcOHvo9gz+RtwBfDxku18sXInt5zWhSlDOpC8JYvf9zo3AOowHK5fZJc+B5s47ngyRRfP5tH0oVwwqC3hQf68u3BLzcqFt7TrSi19x95wqWVvOyoJ7J38jj8POp4Ex51iR03tXA5P94WnetskdVwP7286rIUdNWUqID7R5juyUquG2Rbl2BxLj7HQOtG2ILzZucLmRbb+YpPpxkDeIawn5eku27seivNg6TQ79Njb0Ftj4Kcn7QKOrfrAolf3v9tgU1dRDq+NghmXwUdX2CVonkuyv8fa5j4ELwyueR+SY4AGCNVgHhrTk5/+cTIdY8O47yz7oTrkOLsA4Mnd4rhimF1O/Pj4SGJCA3n4nF68eFE/SssNt320koWbM7h/5moGto/mquGdGN8vHj+Bx79ezyNfrOHHjVUfmmlZBVyzoR8Xl97JnLwOlJRXMKpnK8YlxjN71S5S9uTWrNyQ6+0w1eIc1tCe8tA4m+geekNVl9KIu+ys7Ff+YveN6w7iqsqT1CZSdRvZ+P42aQ22nx9gw1e2S6z72Tao7VxulyupLc0JHAUZdvTVov/BE11gwzc19yvcV/OxZwSVqbAtI8+ors217gKYuRlm/922lobdDAOutEn1g83hKC+DhS8d+Bv0n1FWqm1djbwfrvvNzvUpK7K/t+oKMm2ALS+xXziOIRogVIPxd/nh9reLDA45rjlzbh7O+MT4/fZrFhpI8j2nMHlgW9rFhHLH6G78nLKX81/+FQGeOK8PLj+hRUQQI7rG8cXKnbzy4+9c9voivlm9ixfnbeLU/8xn3vp0FmzK4NYPlxMU4EdS+2ZcdVInIoICuOTV39iVXfVhXBzdhd9c/QC45xdh4n8XUDz5Qxh+W1XFEvpDt7NsUvvSWXDRDLg3HTqceOA33bI3ANtDurOktJ1NaHs+8Je8ZYfGJgy0/ypKyd+yeP9zbFsIgc4S8Ft+tseZCvjor5CxiaLScsq3/AqPdbK3mPXYtdLePApsMPLcPXDTd1X7pG+A5wfb29YeP8nOV+l1rk3Sz7nPzkYvK7YfjtVt+BK+vB1eHgGpteap1PbzM/DlPw6+z7HAM2Kt40n2hls9nUUsdy6rud9vr9ilZQB2LDlq1asPmqRWjUbnagsJ1uYZYgtw+bAOjOrVkncXbmVAh2jaRIdUPvf4xD6kZuTTPiaUS15byNS37QfsaT1acP+YnvycspfbZ6xgRNdYggJcxEcF88ZlAzj/pV846bHvaRkZxJBOMbj8hKUF5/J6p+ZM7HEmd87cyBPfbOCuM2rlFya8DhWlVa0K2X9kl0dBSRkh3c/GpC3i2nmwMWs1yzsMIyD5deh2pr2v+Mj7wM+PvLhEwoB1n/yL/qdOtncBjOthJwtu+w26jLItgCVv2tbA4Gth+XuY6RcyvuA+XvR7lHYVZTZP0X6YTZbvWmk/zLb8Aslv2Ep1PRPWf2G7qMJiYdk7UFEGNySD52ZSrgA46yl729qZ18Pu1bbl8rdlVUn0NZ/ZIBIcBW+NsUOMk65w5pxEVa42jDF2bkh+uv3mHRjCAWVtgTfPrrqjYVSbA+/bEPY482uaO3djDIu1Ezl3LLWPf3rS5h3WzrK/r70bqlqLxwhtQahjUuuoYP5+eldO6hJbozw6NJB+bZsRHRrIW5cP4rykBP53SRIvX5JEfFQw5yW14Y3LBvDgmJ6Vx/SKj+S9qYO5aHA7erSK4OMl23nn16107jOUuL9+yOQhXbhwUFtenr+ZT5dup6LCkFdcxuod2ZSKf41RTKXlFRgvffWLUjPp+9Ac3twWx4/D3mb57lIKSsr5MPIKuxbUtPNs91TfCwGYvqaYXyu60z9/vh2N9dJwO+N803eQuxPaDLIjs3Yut62QoTfZYLV3PY/l3kG73GWUj7jbLnny0RV2yGxOmm3BtO4Lxdl2Dsmwm2wFf//B9qmv+AA6n1oVHDx6ngODrrbJ6uxtNiiu/9J500Ww/ivbNfbXufYD/Ytb4Ylu8FhH2wWXvd3um77e3n2wvMTmUA5myZt2KPHSd2z/fX1MHizMsi2t2i2g0sLDz7Gkr4WotuCuuqEXrfvabqTMzXbtsLWz7ICDk/5h72DoCR5gXy8t2Saw66z3vgMvCVNW7LP8kLYg1J9WdGgg/57QZ7/yEV3j9is7PiGK4xOiAMjIK+bbtbsZ3btqqZB7zuzBsm37uOn9ZTz+zXr25BZTUlZBuNufE7s05/SeLVmUmsn7i7YRHOCiVWQwhaXldI4L4//G9eIfH62gpKyC/zd7LZ1iw4gNd9OrdQSPrtzHxB4TCFgzw3ZXhbektLyC139OJar5Y2zbncFlvQO4uWeh7cKZbgMIbQba1srqj6HjCAhvAeEtWNr1Fvqte5xtFbFsiruAQWcNJPjdsZgPL0PABoiKMpucbneCzYUERdm5DiHRNviM+idenfqwTVp3HQ1vnGkDxMArbdAqybXJ9eAomDwdfn7KflDGdrOjwV4eAZd/VdWdJS677MhxI72/VnkZLHvXBqvRj9rJhp9MtfNK/sh9RJZOg5Uf2i65Ca/ZsqIceH4QtOgB578DAc6ou4py+8HrOsDH5J51EFurRdm6r722nqHMV/9ogwjYVtyqGZC72/6+NnwN751vJ12e8+KBW58FmfDySeAKtLkOT2vM4/NbbC7s/GngV7/f+TVAKFVLTJib8we0rVEWHOji0+uG8vmKHXy8ZDun9WhJz9YRJG/JZM6aPcxeuYsAlzAuMR63v4tdOUW4/f2Ys2Y3Jz8+j6LSCp6Y2If/+2INa3bmcNvpXRl6XHPOef5nHi05jzujl+MacgMAs1fuZPu+Qh4c05Nv1+7mv0u3E902iU59/83QX65EAkKgRS9MYCiIC0m8uLKeb5oz+cEvnSUcR8yKdF4rCGFU2clckOYkolv0rnpT7YfZD5uuZ8Dyd+0wzaBI6DLa+4XxD7QjwcB2mSx8yX64rvnMBpkOJ9nn/Fy2S8ij17nw6qnwzT225RDT2Y7o+v0HOzR41QzbEqoos0HIP7CqpTT637Y1c/bT8MHFdsXeYTdDTKeadZv7sN3/nBf2r7dn5FBQlM3XiJ8dmnri321Q+O1lyN1hj39vEkx6F/wC4O1xkLHRdvu1PcEmpEPjbN1NhX2u8yk1X6t1ov258L82jxRV7e+otc1psWMpdB0FS9+2XYbL37P3VBl5n31+0/e2dVWUA+2H2haUZ1Lm+i+h+1lV51w+3XYLDr+93oMD+DhAiMgo4GnABfzPGPOvWs+7gbeA/kAGcL4xJtV57njgJSACqAAGGGO8DOlQ6ugIcPkxLjGBcYlVk9fO7Z/Aw2MrWLZtH62igmvM+QBYujWLq99ZzLjEFpzbP4FmoQG89MNmLhrUjsiQAK4Y1oFXf/6d992P8EhWW/qE5vPw52voHBfGX7rF0b55KB8v3c79M1cDwZzn+isd/Yv4+Jmf2Z1TTEDhc9xRPJAJ2ImJC3/Povy4KbQKdPGBMydkZ/hlnFayhKiwIPzDYiFomO2S6nOBreSZT9gPsp+fIrvnRZz+2M88e0EiA9p7ud+HR9cz4Jfn4LuH7ZpSvSYc+Jt9XDf7oT73QdtyGHilXUX3+0dg9q12tV3/IDsCKCQGTrrddi+FNLeBCKDHGBh4Ffz2kvPBGmBzHhNesxMXf37KBpjEi23LCOx8j+8fsbmd0FgbfPauh1MfsoslfvewDSi/PAedT7fdaJ9dB2+cZfM9W36yLYTPrqv5fiLbwviXbLCr3YJo5QSIsiLoNb7Wc8fb4LRjiW1NbPgKBl9jF4H88Qk7Si4wxAYmsNdkobM68ahH4Zfn4dcXbKtv4X/t+01+HdoNtV1YPiDe+kvr5cQiLmADcCqQBiwCJhtj1lTb51rgeGPM1SIyCRhnjDlfRPyBJcDFxpjlIhID7DPGM8V0f0lJSSY52ct9ApRqYOUVBj+pmWivbt2uHO7+ZBWLt2TRLCQAA3x0zRA6xdq+7fziMgpKytmdU8R36/aQsieP4rJymoe5Wbk9m9/35jPn5pMoKatg+GPf8/DYnnSMDePC/y1kTJ/W3D6qK7c+/QZhFXlsDBvAlCHtudwZQgyQsieXjLwSBsUHcvPH6/hk+R7G9GnNM5MTD/KmyuDx4+y387iecMlnNknr2J1TRF5xWeV7oLQQnu1v8w8XfGAXS3zVfvv+Jmg08Re/SM9fboU1M+0H9coPYdgtcMr9NV933zZY9wXk7bbdaxUVtiW08kM707tFT7j4Mzv09+u7bGDoNd4GlaJsO/rr1vW22+v7/7NreJUWwJXf2Q/edbMxMy5HygopH3w9rtP/DzZ+U7UCcM52+PpuG1CzfoepP9hupeqe7G3zNLesrbmiMcALJ9gg2elkWPAMXLvQnuv5gbb1FhBiz3v9IpsjSp1vF2/se4ENEN/cbefilObbLqeI1nYEXUTrA/+u6iAii40xSd6e82ULYiCQYozZ7FRiOjAWWFNtn7HAA872DOA5sf+LTgNWGGOWAxhj6vmekEodPd7WrKquW8sI3rtyMA/MWs2s5Tt447KBVR+sQKjbn1C3v81bxEfWODZ1bz6jnp7PbTOW079dMwAGdYyhc1wY7/51EP3aNSMowMXtl03m06Xbyd2Vy0OfryE40MXkgW0pKCmzQ3xzirjt9G58umIP4W5/vlmzi7ziMt5duIX3ftuGy09wieAO8GNIp+ac2y+ezv2nwNaFfNP7CcJ2C0OcKmfkFTP+hQWk5xbz6ITejEtMoMIVxJfxN9Ij/0X8I/rTJjYKQmJIMfFclzWZv3y3iZfG/9vmJVZ+CENusPdIry2qDQy+2m53Od1OVFv+Ljs7nc+uwLYkrn0Mnk20Seguo2Dcf21Lo/vZdv2sPpNtUvnEW2330uI37Qd0fH/nl3EGM/u9yoafP+WlHwYxPm8F/55wes06ZP5uWzKInalfW/ezbHdV7eAA9n3Nugl2r4SEAVWrHp/+SNU9R8Y8a+sMNuHv0e9iuw5YZAKc+6q9va+P+bIFMQEYZYz5q/P4YmCQMeb6avuscvZJcx5vAgYBF2G7neKAWGC6MebfXl5jKjAVoG3btv23bNlSexeljinlFabOgFLb27+kcu9n9r7h0aGBLL7nlAO2VkrLK7jyrWTmb0jnobG92JVdxHPfp9AxNpTN6fmEBrp4elIif30rmQsHteXd37bSJyGK+KhgyioqyC4srVyaZNpfB1FWbrjoVXsjphM6xjCmb2s+W7adpVv30aN1BEu37mNA+2aUlhuWbdtHgEtoHRXMjKuHsH3LRs5/ZyPNoyLZkV3It7ecRKfSjXa0TudTvV6brIISYkIDq97f13djFr3KeX5PsCInhF8i7yY0LILVHa+g52lTcAdU6/bKS7dJ9DqS3Gc+8yPFZRV0bRHOFyt38s3Nw2vcy52CTCqeScQEReG6afmBT3Qgmb/bIbC9zrXDjsEmwz+42I5WumTmgfMJRTl21FztRPUfcLAWRGMNEFOA64ABQAEwF7jHGDP3QK+nXUyqKduWWcAvmzOIjwpmqDMb/UAKSsq4dtoS5q1PRwTO6RvPfWf14JppixndqxWXnNCOEY/PY0tGAfFRwXx983DC3FWdDem5xZz/0i/kFJUR6BKCAl1cOKgd//txMzudyYZPnt+HM3u35um5G/jt90zSc4u5cnhHureK4MJXFlJuDC4RmoUE8P5VJzDyPz9wbr94/jn+eK91zikq5YJXfmXV9hwigwO496weTOifAMbwy+qNTH5nI/3aRrF0aybGGb0/ZUh7Hqg2nNkYc8DA6bEpPY+RT/zAvWf1YFxiPIP/OZeJ/RN4ZFxVcn9lWjbPv/YazdzlPHLbrfgdZkA/IGfZlAqk/s55CBqqi2k7UH1mS4JT5m2fNCfvEIlNVqcB840xewFEZDbQDxsolFK1tIkOqTFh8GBCAv159dIBPDlnA1+u2smdo7vRLDSQ6VNPqNxnfGICT367gUfG9aoRHABiw928eFF/znn+ZzLLyplxzRD6tW3G5UPbsyk9n4y8YgZ1jAHgttO7Udt7Uwcze+VO9uYWM6F/Am2iQ5jYP4EPkrfRrWUEl5zQjoKScnbsK2R3TjEi8MzcjazbmcuNIzvzw/o9PDBzNSO6xtI8zM17K/OJCPLn3SsHM2fNbopKy1myNYs3FqQysnscJ3aO5atVu7j3s1WM6BLLo+ceX/kBXF5hMMbg77JBZdbyHYjAmb1bER0ayNg+rfl4yXZuH9WNiCB/Pl6ynXs+XYWfdCe/oJzTN6YzpFNz5qzZzcjucQQF2G/2RaXlXP/uUiqMYXDHaC4c1I5Q9/4ftxUVpioYiLBiezZXvpXMpAFtufnUw1ip10d82YLwxyapR2IDwSLgAmPM6mr7XAf0rpakHm+MOU9EmmGDwTCgBPgKeNIY88WBXk9bEErVn6LSctbuzCGxbbMD7vPr5gwy80s4o7eXvvbDlJVfws0fLGPe+nRCA13kl+w/HuXpSX0Z2zeeTel5nP7kfM4b0IZ/jOrGwEe+5bykNjx8TtVdEItKyznr2Z/YnlVIdGgg2/cV0joyiB3ZRYxLjCc6NJBfNmWQkp6Hn0Dv+EiGd47l46XbiQt38/5VNliu2p7NWc/+RLeW4bgDXCzfto/+7ZrxzORExj73M8cnRNIpNpRXfvydm07pzE2n2A/1B2au5o0FqbSPCSE1o4AerSJ4dUoSrSKrRrkt27aPy17/jbvO6M7EpDb8uDGdq99eTGFpOS4/4aubhlfmoj5bth0RYUyfI09GH0iDdDE5L3wG8BR2mOtrxphHROQhINkYM1NEgoC3gUQgE5hULal9EXAnYIDZxpjbD/ZaGiCUOrYZY5ixOI0Vadm0jgqmdVQQLSPsfTViwgI5Lq4qD/DgLPsBHBEUQHZhKTOvH1o50dEjZU8er8zfTHFZOd1bRXD5sA48/e1Gnvs+hUCXHwM7RNO9VTjlFbB4axbLnbsePjKuFxcOald5npd+2MT36/eQlV/KRYPbcuGgdvj5Cf/5Zj3Pfp+CMRAa6MLPT/jpH39h4eYMpr69mMuGtuf+s3vy/fo93PDuUkLdLj6/4URiw90YYxj3wgKWbduHy0+Y0C+BDxdvo0uLcJ44rw+TXvqVxHbNePr8vvzvp808//0mAl1+zLttBK1rDaX+oxosQBxNGiCUajqyC0p5YNZqggNd9I6PZNKANnXmF8AGoZXbs+kYG7Zf19mOfYUkb8liVM+WBPrXPelsV3YRwx79juPiwvjn+N6Me2EBQzrFsCg1ky4twvn42iGVi1Gu2p7NuS8u4IROMbw+ZQAzl+/gb9OXcf/ZPfhoSRqrtucwpk9r/jm+N6Fuf1796Xce/rxqwOeYPq35atUuzu2/f57m55S95BSW1pj5fzg0QCillA8s27aPNs2CiQlzc/Xbi/lq9S6Gd4nl2UmJRIbUHC315oJU7p+5mkEdolm9I4d2MSHMun4YuUVlLE/bx4mdm1cGufIKwxcrd5KZV0yLiCBG9WrJg7PW8PavW7h2RCe2ZxUyuncrysor+Nv0ZXRrFc4n1w497BFwoAFCKaV8Lj23mHnr9zAuMb4y6V2dMYZrpy0heUsWJx7XnOv/chwdq813OZTzn/z4PPKKywgP8ie3qAyAfm2jeH3KwP0C0qHSAKGUUn8Cu7LtGl9hQf58tmwH63bmcMtpXQgJPPIBqQ01zFUppVQ9ahkZVLk9oX/CQfasH3o/CKWUUl5pgFBKKeWVBgillFJeaYBQSinllQYIpZRSXmmAUEop5ZUGCKWUUl5pgFBKKeXVn2YmtYikA0dyS7nmwN56ro4vHUv1PZbqClpfXzuW6nss1RX+WH3bGWNivT3xpwkQR0pEkg80zbwxOpbqeyzVFbS+vnYs1fdYqiv4rr7axaSUUsorDRBKKaW80gABLzd0BQ7TsVTfY6muoPX1tWOpvsdSXcFH9W3yOQillFLeaQtCKaWUVxoglFJKedVkA4SIjBKR9SKSIiJ3NHR9ahORNiLyvYisEZHVIvI3p/wBEdkuIsucf2c0dF09RCRVRFY69Up2yqJFZI6IbHR+NmvoegKISNdq13CZiOSIyE2N6fqKyGsiskdEVlUr83o9xXrG+XteISL9GkFdHxORdU59PhGRKKe8vYgUVrvG/z2adT1IfQ/4uxeRO51ru15ETm8k9X2/Wl1TRWSZU15/19cY0+T+AS5gE9ARCASWAz0aul616tgK6OdshwMbgB7AA8DfG7p+B6hzKtC8Vtm/gTuc7TuARxu6ngf4e9gFtGtM1xcYDvQDVtV1PYEzgC8BAQYDCxtBXU8D/J3tR6vVtX31/RrRtfX6u3f+3y0H3EAH57PD1dD1rfX8E8B99X19m2oLYiCQYozZbIwpAaYDYxu4TjUYY3YaY5Y427nAWiC+YWt1RMYCbzrbbwLnNFxVDmgksMkYcyQz8X3GGDMfyKxVfKDrORZ4y1i/AlEi0uqoVBTvdTXGfGOMKXMe/gr4/h6Zh+gA1/ZAxgLTjTHFxpjfgRTsZ8hRc7D6iogA5wHv1ffrNtUAEQ9sq/Y4jUb84Ssi7YFEYKFTdL3TbH+tsXTZOAzwjYgsFpGpTlkLY8xOZ3sX0KJhqnZQk6j5n6uxXl848PVs7H/Tl2NbOB4dRGSpiPwgIic2VKW88Pa7b+zX9kRgtzFmY7Wyerm+TTVAHDNEJAz4CLjJGJMDvAh0AvoCO7FNy8ZimDGmHzAauE5Ehld/0tj2b6MaVy0igcAY4EOnqDFf3xoa4/X0RkTuBsqAaU7RTqCtMSYRuAV4V0QiGqp+1Rwzv/taJlPzC069Xd+mGiC2A22qPU5wyhoVEQnABodpxpiPAYwxu40x5caYCuAVjnJT92CMMdudn3uAT7B12+3p6nB+7mm4Gno1GlhijNkNjfv6Og50PRvl37SITAHOAi50AhpOV02Gs70Y26ffpcEq6TjI775RXlsAEfEHxgPve8rq8/o21QCxCOgsIh2cb5CTgJkNXKcanH7FV4G1xpj/VCuv3q88DlhV+9iGICKhIhLu2cYmKFdhr+ulzm6XAp81TA0PqMa3r8Z6fas50PWcCVzijGYaDGRX64pqECIyCrgdGGOMKahWHisiLme7I9AZ2NwwtaxykN/9TGCSiLhFpAO2vr8d7fodwCnAOmNMmqegXq/v0czEN6Z/2FEfG7DR9e6Gro+X+g3Ddh+sAJY5/84A3gZWOuUzgVYNXVenvh2xIz2WA6s91xSIAeYCG4FvgeiGrmu1OocCGUBktbJGc32xgWsnUIrt977iQNcTO3rpeefveSWQ1AjqmoLtu/f8/f7X2fdc529kGbAEOLuRXNsD/u6Bu51rux4Y3Rjq65S/AVxda996u7661IZSSimvmmoXk1JKqTpogFBKKeWVBgillFJeaYBQSinllQYIpZRSXmmAUKoREJERIvJ5Q9dDqeo0QCillPJKA4RSh0FELhKR35x19l8SEZeI5InIk2Lv2zFXRGKdffuKyK/V7ofguXfDcSLyrYgsF5ElItLJOX2YiMxw7qEwzZlNr1SD0QCh1CESke7A+cBQY0xfoBy4EDsjO9kY0xP4AbjfOeQt4B/GmOOxM3Q95dOA540xfYAh2BmyYFfsvQl7/4GOwFAfvyWlDsq/oSug1DFkJNAfWOR8uQ/GLpZXQdViae8AH4tIJBBljPnBKX8T+NBZryreGPMJgDGmCMA532/GWVPHuTtYe+Ann78rpQ5AA4RSh06AN40xd9YoFLm31n5Hun5NcbXtcvT/p2pg2sWk1KGbC0wQkTiovD90O+z/ownOPhcAPxljsoGsajdruRj4wdi7A6aJyDnOOdwiEnI034RSh0q/oSh1iIwxa0TkHuxd8/ywK2teB+QDA53n9mDzFGCX4/6vEwA2A5c55RcDL4nIQ845Jh7Ft6HUIdPVXJX6g0QkzxgT1tD1UKq+aReTUkopr7QFoZRSyittQSillPJKA4RSSimvNEAopZTySgOEUkoprzRAKKWU8ur/A2AjzIH55TkSAAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_err_df[1:].plot(xlabel='epoch', ylabel='MSE')\n",
    "plt.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FlG5Ky25vDpm",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1650894219922,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "TBZ4eHAdvDpn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_size = 30\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_out = model(X_test[0:test_size])\n",
    "\n",
    "test_out = output_sc.inverse_transform(test_out.cpu().detach().numpy())\n",
    "real_out = output_sc.inverse_transform(y_test[0:test_size].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1650894219926,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "wK1WeGIZvDpo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['strike', 'close', 'hv_21', 'moneyness', 'tau', 'r',\n",
    "       'call', 'put']\n",
    "test_options = pd.DataFrame(input_sc.inverse_transform(X_test[0:test_size].detach().cpu().numpy()), columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 68,
     "status": "ok",
     "timestamp": 1650894220542,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "_dvE5LGXvDpq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         strike        close     hv_21  moneyness       tau         r  \\\n0    168.130478  1094.110352  0.595204   0.153761  0.217177  0.005150   \n1   1900.244019  1009.010193  0.556156   0.531474  2.175713  0.008362   \n2    420.016449   289.492157  0.372215   0.689547  0.214165  0.008408   \n3    414.875916   179.259857  0.322410   0.431638  0.219779  0.005298   \n4    509.853302   199.831390  1.548694   2.556479  0.049287  0.009201   \n5    639.835266   187.022736  0.464121   0.291867  0.222518  0.008431   \n6    120.152206   211.087494  0.780288   1.759768  1.126194  0.009201   \n7   1600.135010  1045.980713  0.620141   1.529417  0.543954  0.006859   \n8    570.070923  1009.010193  0.556156   0.564752  0.079688  0.008362   \n9   3089.909424  2489.868652  0.645044   0.806023  0.049287  0.009201   \n10  5298.868164  2787.961426  0.380332   1.901364  1.738596  0.008331   \n11   599.934937  1091.005249  0.590320   0.549777  0.008205  0.006832   \n12   165.193039   187.798981  0.516128   1.138809  0.738787  0.008331   \n13   990.003174   998.045227  0.554195   1.008190  0.395475  0.008431   \n14  1875.275757  1014.056091  0.597646   0.541457  0.233473  0.005359   \n15   150.016281    90.763527  0.491225   0.604687  0.068733  0.008431   \n16   275.347290   283.281891  0.366849   0.970752  0.313310  0.008232   \n17  1179.835571  1022.498169  0.581059   0.865924  0.101599  0.007851   \n18  1575.166748  1028.029175  0.574218   0.652109  0.046548  0.008202   \n19   729.916870  1091.005249  0.590320   1.494266  0.065994  0.006832   \n20  1149.971558  1022.498169  0.581059   1.125081  0.601572  0.007851   \n21   799.987183  1099.932495  0.595703   0.726986  0.469714  0.005298   \n22  2324.215332  1009.010193  0.556156   0.433302  1.156321  0.008362   \n23  1374.930908   998.045227  0.554195   1.377999  0.222518  0.008431   \n24   370.324646   270.085052  0.333004   0.730314  0.392805  0.008331   \n25   409.980164   209.534943  1.515674   1.953122  0.222518  0.008431   \n26   649.871521   881.481323  0.645044   0.736969  0.486327  0.008232   \n27   118.193954    89.599098  0.541495   0.761096  0.010944  0.009201   \n28  1700.008179  1014.056091  0.597646   0.596367  0.310571  0.005359   \n29   170.088791   198.278839  1.515674   0.856772  1.142627  0.008331   \n\n        call       put   Prediction         Real  \n0  -0.000044  1.000044     3.580143     0.835361  \n1   0.999914  0.000086   184.174286   169.994904  \n2   0.999914  0.000086    -2.991131     0.024723  \n3   0.999914  0.000086   144.796707   116.472633  \n4  -0.000044  1.000044   268.504913   297.447205  \n5   0.999914  0.000086    19.672764     0.024723  \n6   0.999914  0.000086    85.863930    94.707047  \n7  -0.000044  1.000044   527.555969   530.018738  \n8  -0.000044  1.000044     0.448353     0.511112  \n9   0.999914  0.000086     8.256046     2.132389  \n10 -0.000044  1.000044  2598.672119  1974.572632  \n11 -0.000044  1.000044     2.687366     0.024723  \n12  0.999914  0.000086    40.505817    51.256947  \n13  0.999914  0.000086   159.906036   160.490189  \n14  0.999914  0.000086   432.474976     4.240040  \n15  0.999914  0.000086    -6.987713     0.186863  \n16 -0.000044  1.000044    15.948902    17.534473  \n17  0.999914  0.000086    23.040897    21.587650  \n18  0.999914  0.000086     3.500568     0.348987  \n19  0.999914  0.000086   307.064148   349.733246  \n20 -0.000044  1.000044   252.852646   274.465637  \n21 -0.000044  1.000044    55.219318    53.850986  \n22  0.999914  0.000086    47.589069    53.607792  \n23 -0.000044  1.000044   385.453552   377.943390  \n24  0.999914  0.000086    -3.330227     1.483875  \n25 -0.000044  1.000044   206.378357   201.001740  \n26 -0.000044  1.000044    51.232502    52.878223  \n27  0.999914  0.000086    -5.605785     0.186863  \n28  0.999914  0.000086    18.877949    10.887257  \n29 -0.000044  1.000044    29.708057    24.181690  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>strike</th>\n      <th>close</th>\n      <th>hv_21</th>\n      <th>moneyness</th>\n      <th>tau</th>\n      <th>r</th>\n      <th>call</th>\n      <th>put</th>\n      <th>Prediction</th>\n      <th>Real</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>168.130478</td>\n      <td>1094.110352</td>\n      <td>0.595204</td>\n      <td>0.153761</td>\n      <td>0.217177</td>\n      <td>0.005150</td>\n      <td>-0.000044</td>\n      <td>1.000044</td>\n      <td>3.580143</td>\n      <td>0.835361</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1900.244019</td>\n      <td>1009.010193</td>\n      <td>0.556156</td>\n      <td>0.531474</td>\n      <td>2.175713</td>\n      <td>0.008362</td>\n      <td>0.999914</td>\n      <td>0.000086</td>\n      <td>184.174286</td>\n      <td>169.994904</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>420.016449</td>\n      <td>289.492157</td>\n      <td>0.372215</td>\n      <td>0.689547</td>\n      <td>0.214165</td>\n      <td>0.008408</td>\n      <td>0.999914</td>\n      <td>0.000086</td>\n      <td>-2.991131</td>\n      <td>0.024723</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>414.875916</td>\n      <td>179.259857</td>\n      <td>0.322410</td>\n      <td>0.431638</td>\n      <td>0.219779</td>\n      <td>0.005298</td>\n      <td>0.999914</td>\n      <td>0.000086</td>\n      <td>144.796707</td>\n      <td>116.472633</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>509.853302</td>\n      <td>199.831390</td>\n      <td>1.548694</td>\n      <td>2.556479</td>\n      <td>0.049287</td>\n      <td>0.009201</td>\n      <td>-0.000044</td>\n      <td>1.000044</td>\n      <td>268.504913</td>\n      <td>297.447205</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>639.835266</td>\n      <td>187.022736</td>\n      <td>0.464121</td>\n      <td>0.291867</td>\n      <td>0.222518</td>\n      <td>0.008431</td>\n      <td>0.999914</td>\n      <td>0.000086</td>\n      <td>19.672764</td>\n      <td>0.024723</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>120.152206</td>\n      <td>211.087494</td>\n      <td>0.780288</td>\n      <td>1.759768</td>\n      <td>1.126194</td>\n      <td>0.009201</td>\n      <td>0.999914</td>\n      <td>0.000086</td>\n      <td>85.863930</td>\n      <td>94.707047</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1600.135010</td>\n      <td>1045.980713</td>\n      <td>0.620141</td>\n      <td>1.529417</td>\n      <td>0.543954</td>\n      <td>0.006859</td>\n      <td>-0.000044</td>\n      <td>1.000044</td>\n      <td>527.555969</td>\n      <td>530.018738</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>570.070923</td>\n      <td>1009.010193</td>\n      <td>0.556156</td>\n      <td>0.564752</td>\n      <td>0.079688</td>\n      <td>0.008362</td>\n      <td>-0.000044</td>\n      <td>1.000044</td>\n      <td>0.448353</td>\n      <td>0.511112</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3089.909424</td>\n      <td>2489.868652</td>\n      <td>0.645044</td>\n      <td>0.806023</td>\n      <td>0.049287</td>\n      <td>0.009201</td>\n      <td>0.999914</td>\n      <td>0.000086</td>\n      <td>8.256046</td>\n      <td>2.132389</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>5298.868164</td>\n      <td>2787.961426</td>\n      <td>0.380332</td>\n      <td>1.901364</td>\n      <td>1.738596</td>\n      <td>0.008331</td>\n      <td>-0.000044</td>\n      <td>1.000044</td>\n      <td>2598.672119</td>\n      <td>1974.572632</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>599.934937</td>\n      <td>1091.005249</td>\n      <td>0.590320</td>\n      <td>0.549777</td>\n      <td>0.008205</td>\n      <td>0.006832</td>\n      <td>-0.000044</td>\n      <td>1.000044</td>\n      <td>2.687366</td>\n      <td>0.024723</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>165.193039</td>\n      <td>187.798981</td>\n      <td>0.516128</td>\n      <td>1.138809</td>\n      <td>0.738787</td>\n      <td>0.008331</td>\n      <td>0.999914</td>\n      <td>0.000086</td>\n      <td>40.505817</td>\n      <td>51.256947</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>990.003174</td>\n      <td>998.045227</td>\n      <td>0.554195</td>\n      <td>1.008190</td>\n      <td>0.395475</td>\n      <td>0.008431</td>\n      <td>0.999914</td>\n      <td>0.000086</td>\n      <td>159.906036</td>\n      <td>160.490189</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1875.275757</td>\n      <td>1014.056091</td>\n      <td>0.597646</td>\n      <td>0.541457</td>\n      <td>0.233473</td>\n      <td>0.005359</td>\n      <td>0.999914</td>\n      <td>0.000086</td>\n      <td>432.474976</td>\n      <td>4.240040</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>150.016281</td>\n      <td>90.763527</td>\n      <td>0.491225</td>\n      <td>0.604687</td>\n      <td>0.068733</td>\n      <td>0.008431</td>\n      <td>0.999914</td>\n      <td>0.000086</td>\n      <td>-6.987713</td>\n      <td>0.186863</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>275.347290</td>\n      <td>283.281891</td>\n      <td>0.366849</td>\n      <td>0.970752</td>\n      <td>0.313310</td>\n      <td>0.008232</td>\n      <td>-0.000044</td>\n      <td>1.000044</td>\n      <td>15.948902</td>\n      <td>17.534473</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>1179.835571</td>\n      <td>1022.498169</td>\n      <td>0.581059</td>\n      <td>0.865924</td>\n      <td>0.101599</td>\n      <td>0.007851</td>\n      <td>0.999914</td>\n      <td>0.000086</td>\n      <td>23.040897</td>\n      <td>21.587650</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>1575.166748</td>\n      <td>1028.029175</td>\n      <td>0.574218</td>\n      <td>0.652109</td>\n      <td>0.046548</td>\n      <td>0.008202</td>\n      <td>0.999914</td>\n      <td>0.000086</td>\n      <td>3.500568</td>\n      <td>0.348987</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>729.916870</td>\n      <td>1091.005249</td>\n      <td>0.590320</td>\n      <td>1.494266</td>\n      <td>0.065994</td>\n      <td>0.006832</td>\n      <td>0.999914</td>\n      <td>0.000086</td>\n      <td>307.064148</td>\n      <td>349.733246</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>1149.971558</td>\n      <td>1022.498169</td>\n      <td>0.581059</td>\n      <td>1.125081</td>\n      <td>0.601572</td>\n      <td>0.007851</td>\n      <td>-0.000044</td>\n      <td>1.000044</td>\n      <td>252.852646</td>\n      <td>274.465637</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>799.987183</td>\n      <td>1099.932495</td>\n      <td>0.595703</td>\n      <td>0.726986</td>\n      <td>0.469714</td>\n      <td>0.005298</td>\n      <td>-0.000044</td>\n      <td>1.000044</td>\n      <td>55.219318</td>\n      <td>53.850986</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>2324.215332</td>\n      <td>1009.010193</td>\n      <td>0.556156</td>\n      <td>0.433302</td>\n      <td>1.156321</td>\n      <td>0.008362</td>\n      <td>0.999914</td>\n      <td>0.000086</td>\n      <td>47.589069</td>\n      <td>53.607792</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>1374.930908</td>\n      <td>998.045227</td>\n      <td>0.554195</td>\n      <td>1.377999</td>\n      <td>0.222518</td>\n      <td>0.008431</td>\n      <td>-0.000044</td>\n      <td>1.000044</td>\n      <td>385.453552</td>\n      <td>377.943390</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>370.324646</td>\n      <td>270.085052</td>\n      <td>0.333004</td>\n      <td>0.730314</td>\n      <td>0.392805</td>\n      <td>0.008331</td>\n      <td>0.999914</td>\n      <td>0.000086</td>\n      <td>-3.330227</td>\n      <td>1.483875</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>409.980164</td>\n      <td>209.534943</td>\n      <td>1.515674</td>\n      <td>1.953122</td>\n      <td>0.222518</td>\n      <td>0.008431</td>\n      <td>-0.000044</td>\n      <td>1.000044</td>\n      <td>206.378357</td>\n      <td>201.001740</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>649.871521</td>\n      <td>881.481323</td>\n      <td>0.645044</td>\n      <td>0.736969</td>\n      <td>0.486327</td>\n      <td>0.008232</td>\n      <td>-0.000044</td>\n      <td>1.000044</td>\n      <td>51.232502</td>\n      <td>52.878223</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>118.193954</td>\n      <td>89.599098</td>\n      <td>0.541495</td>\n      <td>0.761096</td>\n      <td>0.010944</td>\n      <td>0.009201</td>\n      <td>0.999914</td>\n      <td>0.000086</td>\n      <td>-5.605785</td>\n      <td>0.186863</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>1700.008179</td>\n      <td>1014.056091</td>\n      <td>0.597646</td>\n      <td>0.596367</td>\n      <td>0.310571</td>\n      <td>0.005359</td>\n      <td>0.999914</td>\n      <td>0.000086</td>\n      <td>18.877949</td>\n      <td>10.887257</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>170.088791</td>\n      <td>198.278839</td>\n      <td>1.515674</td>\n      <td>0.856772</td>\n      <td>1.142627</td>\n      <td>0.008331</td>\n      <td>-0.000044</td>\n      <td>1.000044</td>\n      <td>29.708057</td>\n      <td>24.181690</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_options['Prediction'] = test_out\n",
    "test_options['Real'] = real_out\n",
    "test_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 67,
     "status": "ok",
     "timestamp": 1650894220545,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "TNw5-1jgvDpr",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_options['Abs Error'] = np.abs(test_options.Prediction - test_options.Real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 990
    },
    "executionInfo": {
     "elapsed": 65,
     "status": "ok",
     "timestamp": 1650894220546,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "lAC6AdeVvDpr",
    "outputId": "78bd13cc-c5a0-4746-f402-9e84d8b78696",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         strike        close     hv_21  moneyness       tau         r  \\\n8    570.070923  1009.010193  0.556156   0.564752  0.079688  0.008362   \n13   990.003174   998.045227  0.554195   1.008190  0.395475  0.008431   \n21   799.987183  1099.932495  0.595703   0.726986  0.469714  0.005298   \n17  1179.835571  1022.498169  0.581059   0.865924  0.101599  0.007851   \n16   275.347290   283.281891  0.366849   0.970752  0.313310  0.008232   \n26   649.871521   881.481323  0.645044   0.736969  0.486327  0.008232   \n7   1600.135010  1045.980713  0.620141   1.529417  0.543954  0.006859   \n11   599.934937  1091.005249  0.590320   0.549777  0.008205  0.006832   \n0    168.130478  1094.110352  0.595204   0.153761  0.217177  0.005150   \n2    420.016449   289.492157  0.372215   0.689547  0.214165  0.008408   \n18  1575.166748  1028.029175  0.574218   0.652109  0.046548  0.008202   \n24   370.324646   270.085052  0.333004   0.730314  0.392805  0.008331   \n25   409.980164   209.534943  1.515674   1.953122  0.222518  0.008431   \n29   170.088791   198.278839  1.515674   0.856772  1.142627  0.008331   \n27   118.193954    89.599098  0.541495   0.761096  0.010944  0.009201   \n22  2324.215332  1009.010193  0.556156   0.433302  1.156321  0.008362   \n9   3089.909424  2489.868652  0.645044   0.806023  0.049287  0.009201   \n15   150.016281    90.763527  0.491225   0.604687  0.068733  0.008431   \n23  1374.930908   998.045227  0.554195   1.377999  0.222518  0.008431   \n28  1700.008179  1014.056091  0.597646   0.596367  0.310571  0.005359   \n6    120.152206   211.087494  0.780288   1.759768  1.126194  0.009201   \n12   165.193039   187.798981  0.516128   1.138809  0.738787  0.008331   \n1   1900.244019  1009.010193  0.556156   0.531474  2.175713  0.008362   \n5    639.835266   187.022736  0.464121   0.291867  0.222518  0.008431   \n20  1149.971558  1022.498169  0.581059   1.125081  0.601572  0.007851   \n3    414.875916   179.259857  0.322410   0.431638  0.219779  0.005298   \n4    509.853302   199.831390  1.548694   2.556479  0.049287  0.009201   \n19   729.916870  1091.005249  0.590320   1.494266  0.065994  0.006832   \n14  1875.275757  1014.056091  0.597646   0.541457  0.233473  0.005359   \n10  5298.868164  2787.961426  0.380332   1.901364  1.738596  0.008331   \n\n        call       put   Prediction         Real   Abs Error  \n8  -0.000044  1.000044     0.448353     0.511112    0.062759  \n13  0.999914  0.000086   159.906036   160.490189    0.584152  \n21 -0.000044  1.000044    55.219318    53.850986    1.368332  \n17  0.999914  0.000086    23.040897    21.587650    1.453247  \n16 -0.000044  1.000044    15.948902    17.534473    1.585571  \n26 -0.000044  1.000044    51.232502    52.878223    1.645721  \n7  -0.000044  1.000044   527.555969   530.018738    2.462769  \n11 -0.000044  1.000044     2.687366     0.024723    2.662643  \n0  -0.000044  1.000044     3.580143     0.835361    2.744781  \n2   0.999914  0.000086    -2.991131     0.024723    3.015854  \n18  0.999914  0.000086     3.500568     0.348987    3.151581  \n24  0.999914  0.000086    -3.330227     1.483875    4.814102  \n25 -0.000044  1.000044   206.378357   201.001740    5.376617  \n29 -0.000044  1.000044    29.708057    24.181690    5.526367  \n27  0.999914  0.000086    -5.605785     0.186863    5.792648  \n22  0.999914  0.000086    47.589069    53.607792    6.018723  \n9   0.999914  0.000086     8.256046     2.132389    6.123657  \n15  0.999914  0.000086    -6.987713     0.186863    7.174576  \n23 -0.000044  1.000044   385.453552   377.943390    7.510162  \n28  0.999914  0.000086    18.877949    10.887257    7.990692  \n6   0.999914  0.000086    85.863930    94.707047    8.843117  \n12  0.999914  0.000086    40.505817    51.256947   10.751129  \n1   0.999914  0.000086   184.174286   169.994904   14.179382  \n5   0.999914  0.000086    19.672764     0.024723   19.648041  \n20 -0.000044  1.000044   252.852646   274.465637   21.612991  \n3   0.999914  0.000086   144.796707   116.472633   28.324074  \n4  -0.000044  1.000044   268.504913   297.447205   28.942291  \n19  0.999914  0.000086   307.064148   349.733246   42.669098  \n14  0.999914  0.000086   432.474976     4.240040  428.234924  \n10 -0.000044  1.000044  2598.672119  1974.572632  624.099487  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>strike</th>\n      <th>close</th>\n      <th>hv_21</th>\n      <th>moneyness</th>\n      <th>tau</th>\n      <th>r</th>\n      <th>call</th>\n      <th>put</th>\n      <th>Prediction</th>\n      <th>Real</th>\n      <th>Abs Error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8</th>\n      <td>570.070923</td>\n      <td>1009.010193</td>\n      <td>0.556156</td>\n      <td>0.564752</td>\n      <td>0.079688</td>\n      <td>0.008362</td>\n      <td>-0.000044</td>\n      <td>1.000044</td>\n      <td>0.448353</td>\n      <td>0.511112</td>\n      <td>0.062759</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>990.003174</td>\n      <td>998.045227</td>\n      <td>0.554195</td>\n      <td>1.008190</td>\n      <td>0.395475</td>\n      <td>0.008431</td>\n      <td>0.999914</td>\n      <td>0.000086</td>\n      <td>159.906036</td>\n      <td>160.490189</td>\n      <td>0.584152</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>799.987183</td>\n      <td>1099.932495</td>\n      <td>0.595703</td>\n      <td>0.726986</td>\n      <td>0.469714</td>\n      <td>0.005298</td>\n      <td>-0.000044</td>\n      <td>1.000044</td>\n      <td>55.219318</td>\n      <td>53.850986</td>\n      <td>1.368332</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>1179.835571</td>\n      <td>1022.498169</td>\n      <td>0.581059</td>\n      <td>0.865924</td>\n      <td>0.101599</td>\n      <td>0.007851</td>\n      <td>0.999914</td>\n      <td>0.000086</td>\n      <td>23.040897</td>\n      <td>21.587650</td>\n      <td>1.453247</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>275.347290</td>\n      <td>283.281891</td>\n      <td>0.366849</td>\n      <td>0.970752</td>\n      <td>0.313310</td>\n      <td>0.008232</td>\n      <td>-0.000044</td>\n      <td>1.000044</td>\n      <td>15.948902</td>\n      <td>17.534473</td>\n      <td>1.585571</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>649.871521</td>\n      <td>881.481323</td>\n      <td>0.645044</td>\n      <td>0.736969</td>\n      <td>0.486327</td>\n      <td>0.008232</td>\n      <td>-0.000044</td>\n      <td>1.000044</td>\n      <td>51.232502</td>\n      <td>52.878223</td>\n      <td>1.645721</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1600.135010</td>\n      <td>1045.980713</td>\n      <td>0.620141</td>\n      <td>1.529417</td>\n      <td>0.543954</td>\n      <td>0.006859</td>\n      <td>-0.000044</td>\n      <td>1.000044</td>\n      <td>527.555969</td>\n      <td>530.018738</td>\n      <td>2.462769</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>599.934937</td>\n      <td>1091.005249</td>\n      <td>0.590320</td>\n      <td>0.549777</td>\n      <td>0.008205</td>\n      <td>0.006832</td>\n      <td>-0.000044</td>\n      <td>1.000044</td>\n      <td>2.687366</td>\n      <td>0.024723</td>\n      <td>2.662643</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>168.130478</td>\n      <td>1094.110352</td>\n      <td>0.595204</td>\n      <td>0.153761</td>\n      <td>0.217177</td>\n      <td>0.005150</td>\n      <td>-0.000044</td>\n      <td>1.000044</td>\n      <td>3.580143</td>\n      <td>0.835361</td>\n      <td>2.744781</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>420.016449</td>\n      <td>289.492157</td>\n      <td>0.372215</td>\n      <td>0.689547</td>\n      <td>0.214165</td>\n      <td>0.008408</td>\n      <td>0.999914</td>\n      <td>0.000086</td>\n      <td>-2.991131</td>\n      <td>0.024723</td>\n      <td>3.015854</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>1575.166748</td>\n      <td>1028.029175</td>\n      <td>0.574218</td>\n      <td>0.652109</td>\n      <td>0.046548</td>\n      <td>0.008202</td>\n      <td>0.999914</td>\n      <td>0.000086</td>\n      <td>3.500568</td>\n      <td>0.348987</td>\n      <td>3.151581</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>370.324646</td>\n      <td>270.085052</td>\n      <td>0.333004</td>\n      <td>0.730314</td>\n      <td>0.392805</td>\n      <td>0.008331</td>\n      <td>0.999914</td>\n      <td>0.000086</td>\n      <td>-3.330227</td>\n      <td>1.483875</td>\n      <td>4.814102</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>409.980164</td>\n      <td>209.534943</td>\n      <td>1.515674</td>\n      <td>1.953122</td>\n      <td>0.222518</td>\n      <td>0.008431</td>\n      <td>-0.000044</td>\n      <td>1.000044</td>\n      <td>206.378357</td>\n      <td>201.001740</td>\n      <td>5.376617</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>170.088791</td>\n      <td>198.278839</td>\n      <td>1.515674</td>\n      <td>0.856772</td>\n      <td>1.142627</td>\n      <td>0.008331</td>\n      <td>-0.000044</td>\n      <td>1.000044</td>\n      <td>29.708057</td>\n      <td>24.181690</td>\n      <td>5.526367</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>118.193954</td>\n      <td>89.599098</td>\n      <td>0.541495</td>\n      <td>0.761096</td>\n      <td>0.010944</td>\n      <td>0.009201</td>\n      <td>0.999914</td>\n      <td>0.000086</td>\n      <td>-5.605785</td>\n      <td>0.186863</td>\n      <td>5.792648</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>2324.215332</td>\n      <td>1009.010193</td>\n      <td>0.556156</td>\n      <td>0.433302</td>\n      <td>1.156321</td>\n      <td>0.008362</td>\n      <td>0.999914</td>\n      <td>0.000086</td>\n      <td>47.589069</td>\n      <td>53.607792</td>\n      <td>6.018723</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3089.909424</td>\n      <td>2489.868652</td>\n      <td>0.645044</td>\n      <td>0.806023</td>\n      <td>0.049287</td>\n      <td>0.009201</td>\n      <td>0.999914</td>\n      <td>0.000086</td>\n      <td>8.256046</td>\n      <td>2.132389</td>\n      <td>6.123657</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>150.016281</td>\n      <td>90.763527</td>\n      <td>0.491225</td>\n      <td>0.604687</td>\n      <td>0.068733</td>\n      <td>0.008431</td>\n      <td>0.999914</td>\n      <td>0.000086</td>\n      <td>-6.987713</td>\n      <td>0.186863</td>\n      <td>7.174576</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>1374.930908</td>\n      <td>998.045227</td>\n      <td>0.554195</td>\n      <td>1.377999</td>\n      <td>0.222518</td>\n      <td>0.008431</td>\n      <td>-0.000044</td>\n      <td>1.000044</td>\n      <td>385.453552</td>\n      <td>377.943390</td>\n      <td>7.510162</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>1700.008179</td>\n      <td>1014.056091</td>\n      <td>0.597646</td>\n      <td>0.596367</td>\n      <td>0.310571</td>\n      <td>0.005359</td>\n      <td>0.999914</td>\n      <td>0.000086</td>\n      <td>18.877949</td>\n      <td>10.887257</td>\n      <td>7.990692</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>120.152206</td>\n      <td>211.087494</td>\n      <td>0.780288</td>\n      <td>1.759768</td>\n      <td>1.126194</td>\n      <td>0.009201</td>\n      <td>0.999914</td>\n      <td>0.000086</td>\n      <td>85.863930</td>\n      <td>94.707047</td>\n      <td>8.843117</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>165.193039</td>\n      <td>187.798981</td>\n      <td>0.516128</td>\n      <td>1.138809</td>\n      <td>0.738787</td>\n      <td>0.008331</td>\n      <td>0.999914</td>\n      <td>0.000086</td>\n      <td>40.505817</td>\n      <td>51.256947</td>\n      <td>10.751129</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1900.244019</td>\n      <td>1009.010193</td>\n      <td>0.556156</td>\n      <td>0.531474</td>\n      <td>2.175713</td>\n      <td>0.008362</td>\n      <td>0.999914</td>\n      <td>0.000086</td>\n      <td>184.174286</td>\n      <td>169.994904</td>\n      <td>14.179382</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>639.835266</td>\n      <td>187.022736</td>\n      <td>0.464121</td>\n      <td>0.291867</td>\n      <td>0.222518</td>\n      <td>0.008431</td>\n      <td>0.999914</td>\n      <td>0.000086</td>\n      <td>19.672764</td>\n      <td>0.024723</td>\n      <td>19.648041</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>1149.971558</td>\n      <td>1022.498169</td>\n      <td>0.581059</td>\n      <td>1.125081</td>\n      <td>0.601572</td>\n      <td>0.007851</td>\n      <td>-0.000044</td>\n      <td>1.000044</td>\n      <td>252.852646</td>\n      <td>274.465637</td>\n      <td>21.612991</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>414.875916</td>\n      <td>179.259857</td>\n      <td>0.322410</td>\n      <td>0.431638</td>\n      <td>0.219779</td>\n      <td>0.005298</td>\n      <td>0.999914</td>\n      <td>0.000086</td>\n      <td>144.796707</td>\n      <td>116.472633</td>\n      <td>28.324074</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>509.853302</td>\n      <td>199.831390</td>\n      <td>1.548694</td>\n      <td>2.556479</td>\n      <td>0.049287</td>\n      <td>0.009201</td>\n      <td>-0.000044</td>\n      <td>1.000044</td>\n      <td>268.504913</td>\n      <td>297.447205</td>\n      <td>28.942291</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>729.916870</td>\n      <td>1091.005249</td>\n      <td>0.590320</td>\n      <td>1.494266</td>\n      <td>0.065994</td>\n      <td>0.006832</td>\n      <td>0.999914</td>\n      <td>0.000086</td>\n      <td>307.064148</td>\n      <td>349.733246</td>\n      <td>42.669098</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1875.275757</td>\n      <td>1014.056091</td>\n      <td>0.597646</td>\n      <td>0.541457</td>\n      <td>0.233473</td>\n      <td>0.005359</td>\n      <td>0.999914</td>\n      <td>0.000086</td>\n      <td>432.474976</td>\n      <td>4.240040</td>\n      <td>428.234924</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>5298.868164</td>\n      <td>2787.961426</td>\n      <td>0.380332</td>\n      <td>1.901364</td>\n      <td>1.738596</td>\n      <td>0.008331</td>\n      <td>-0.000044</td>\n      <td>1.000044</td>\n      <td>2598.672119</td>\n      <td>1974.572632</td>\n      <td>624.099487</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_options.sort_values('Abs Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fDJ-hkrSAqVh",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### MSE on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 276,
     "status": "ok",
     "timestamp": 1650895213041,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "GG64Xp3vAib-",
    "outputId": "f846ee65-029d-4a76-b006-d65e4ac07a48",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE on the test set is:  0.06431712210178375\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(X_test)\n",
    "    loss = loss_fn(out, y_test)\n",
    "    print('The MSE on the test set is: ', loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCLf2KQJAvoE",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### MAE on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1650895213494,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "mZohsEyLAu7S",
    "outputId": "4d6bfba3-5751-478d-d53e-73751702414e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAE on the test set is:  0.08930504322052002\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "mae_loss = nn.L1Loss()\n",
    "with torch.no_grad():\n",
    "    out = model(X_test)\n",
    "    loss = mae_loss(out, y_test)\n",
    "    print('The MAE on the test set is: ', loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmsZ4aPaA1SJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### RSME on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1650895213496,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "f01KkBxRA0t7",
    "outputId": "6492967a-db0c-49f4-fee1-8eb52ef33119",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE on the test set is:  0.25360820590387795\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(X_test)\n",
    "    loss = loss_fn(out, y_test)\n",
    "    print('The RMSE on the test set is: ', np.sqrt(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8Jxp0L4A5zb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### MAPE on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 335,
     "status": "ok",
     "timestamp": 1650895213818,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "fHghkyflA79o",
    "outputId": "37838323-11f0-4eb9-d7d7-50303bf4e9ce",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAPE on the test set is:  0.3327904939651489\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(X_test)\n",
    "    loss = MAPELoss(out, y_test).item()\n",
    "    print('The MAPE on the test set is: ', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLLLqkX6BEle",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1650895213820,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "sf8FmLxxBGcu",
    "outputId": "764313a9-78fc-46ca-dd08-9fb8834e4374",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the R^2 score is:  0.9360338935876047\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(X_test).squeeze().cpu().detach().numpy()\n",
    "\n",
    "y_true = y_test.cpu().squeeze().detach().numpy()\n",
    "\n",
    "r2 = r2_score(y_pred=out, y_true=y_true)\n",
    "\n",
    "print('the R^2 score is: ', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "executionInfo": {
     "elapsed": 744,
     "status": "ok",
     "timestamp": 1650895214553,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "awvWu7WxBIHB",
    "outputId": "1b3dccd3-90ef-47d5-9895-267fdf93020c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 648x432 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(9, 6))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "ax.scatter(\n",
    "    y=output_sc.inverse_transform(out.reshape(-1, 1)),\n",
    "    x=output_sc.inverse_transform(y_true.squeeze().reshape(-1, 1))\n",
    ")\n",
    "ax.set_xlabel('Actual Value')\n",
    "ax.set_ylabel('Predicted Value')\n",
    "\n",
    "ax.text(20, 80, f'$R^2$ = {np.round(r2, 6)}', fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Greeks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "def get_d1_d2(S, X, T, t, r, sigma):\n",
    "    \"\"\"\n",
    "    Compute d1 and d2 values for the black-scholes pricing model\n",
    "\n",
    "\n",
    "    :param S: underlying price\n",
    "    :param X: option's strike price\n",
    "    :param T: option's time to maturity (in years)\n",
    "    :param t: current time (in years)\n",
    "    :param r: interest rate\n",
    "    :param sigma: underlying volatility\n",
    "    :return: (d1, d2)\n",
    "    \"\"\"\n",
    "    d1 = (np.log(S / X) + (r + sigma * sigma / 2.) * (T - t)) / (sigma * np.sqrt(T - t))\n",
    "    d2 = d1 - sigma * np.sqrt(T - t)\n",
    "    return d1, d2\n",
    "\n",
    "\n",
    "def black_scholes(S, X, T, t, r, sigma, o_type: str = \"C\") -> np.single:\n",
    "    \"\"\"\n",
    "    Compute option price using the black-scholes model\n",
    "\n",
    "    :param S: underlying price\n",
    "    :param X: option's strike price\n",
    "    :param T: option's time to maturity (in years)\n",
    "    :param t: current time (in years)\n",
    "    :param r: interest rate (in percentual)\n",
    "    :param sigma: underlying volatility\n",
    "    :param o_type: option type, \"C\" for a call option and \"P\" for a put option\n",
    "    :return: the black-scholes option price\n",
    "    \"\"\"\n",
    "    d1, d2 = get_d1_d2(S, X, T, t, r, sigma)\n",
    "    if o_type == \"C\":\n",
    "        return S * stats.norm.cdf(d1, 0, 1) - X * np.exp(-r * (T - t)) * stats.norm.cdf(d2, 0, 1)\n",
    "    else:\n",
    "        return X * np.exp(-r * (T - t)) * stats.norm.cdf(-d2, 0, 1) - S * stats.norm.cdf(-d1, 0, 1)\n",
    "\n",
    "\n",
    "def delta_fdm_bs(S, X, sigma, tau, r, delta_S, o_type: str = 'C'):\n",
    "  return (black_scholes(S + delta_S, X, tau, 0, r, sigma, o_type) - black_scholes(S, X, tau, 0, r, sigma, o_type)) / delta_S\n",
    "\n",
    "def theta_fdm_bs(S, X, sigma, tau, r, delta_tau, o_type: str = 'C'):\n",
    "  return (black_scholes(S, X, tau + delta_tau, 0, r, sigma, o_type) - black_scholes(S, X, tau, 0, r, sigma, o_type)) / delta_tau\n",
    "\n",
    "def vega_fdm_bs(S, X, sigma, tau, r, delta_sigma, o_type: str = 'C'):\n",
    "  return (black_scholes(S, X, tau, 0, r, sigma + delta_sigma, o_type) - black_scholes(S, X, tau, 0, r, sigma, o_type)) / delta_sigma\n",
    "\n",
    "def delta_fdm_net(S, X, sigma_1, m, tau, r, delta_S, o_type: str = 'C'):\n",
    "  c = 1 if o_type == 'C' else 0\n",
    "  p = 1 if o_type == 'P' else 0\n",
    "  input_df_1 = pd.DataFrame(np.array([[X, S + delta_S, sigma_1, m, r,  tau,  c, p]]), columns=df_cols)\n",
    "  input_df_2 = pd.DataFrame(np.array([[X, S, sigma_1,  m, r,  tau,  c, p]]), columns=df_cols)\n",
    "  net_input_1 = torch.Tensor(\n",
    "      input_sc.transform(input_df_1)).to(device)\n",
    "  net_input_2 = torch.Tensor(\n",
    "      input_sc.transform(input_df_2)).to(device)\n",
    "  sc_output_1 = output_sc.inverse_transform(model(net_input_1).detach().cpu().numpy())\n",
    "  sc_output_2 = output_sc.inverse_transform(model(net_input_2).detach().cpu().numpy())\n",
    "  return (sc_output_1 - sc_output_2) / delta_S\n",
    "\n",
    "\n",
    "def theta_fdm_net(S, X, sigma_1, m, tau, r, delta_tau, o_type: str = 'C'):\n",
    "  c = 1 if o_type == 'C' else 0\n",
    "  p = 1 if o_type == 'P' else 0\n",
    "  input_df_1 = pd.DataFrame(np.array([[X, S, sigma_1, m, r,  tau + delta_tau,  c, p]]), columns=df_cols)\n",
    "  input_df_2 = pd.DataFrame(np.array([[X, S, sigma_1, m, r,  tau,  c, p]]), columns=df_cols)\n",
    "  net_input_1 = torch.Tensor(\n",
    "      input_sc.transform(input_df_1)).to(device)\n",
    "  net_input_2 = torch.Tensor(\n",
    "      input_sc.transform(input_df_2)).to(device)\n",
    "  sc_output_1 = output_sc.inverse_transform(model(net_input_1).detach().cpu().numpy())\n",
    "  sc_output_2 = output_sc.inverse_transform(model(net_input_2).detach().cpu().numpy())\n",
    "  return (sc_output_1 - sc_output_2) / delta_tau\n",
    "\n",
    "\n",
    "def vega_fdm_net(S, X, sigma_1, m, tau, r, delta_sigma, o_type: str = 'C'):\n",
    "  c = 1 if o_type == 'C' else 0\n",
    "  p = 1 if o_type == 'P' else 0\n",
    "  input_df_1 = pd.DataFrame(np.array([[X, S, sigma_1 + delta_sigma, m, r,  tau,  c, p]]), columns=df_cols)\n",
    "  input_df_2 = pd.DataFrame(np.array([[X, S, sigma_1, m, r,  tau,  c, p]]), columns=df_cols)\n",
    "  net_input_1 = torch.Tensor(\n",
    "      input_sc.transform(input_df_1)).to(device)\n",
    "  net_input_2 = torch.Tensor(\n",
    "      input_sc.transform(input_df_2)).to(device)\n",
    "  sc_output_1 = output_sc.inverse_transform(model(net_input_1).detach().cpu().numpy())\n",
    "  sc_output_2 = output_sc.inverse_transform(model(net_input_2).detach().cpu().numpy())\n",
    "  return (sc_output_1 - sc_output_2) / delta_sigma"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "test_size = 30\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_out = model(X_test[0:test_size])\n",
    "\n",
    "test_out = output_sc.inverse_transform(test_out.cpu().detach().numpy())\n",
    "real_out = output_sc.inverse_transform(y_test[0:test_size].cpu().detach().numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "model.zero_grad()\n",
    "inp_g = X_test[0].clone().detach().requires_grad_(True)\n",
    "test_out_g = model(inp_g)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-3.3260e-02,  5.4478e-02,  5.6752e-02,  8.1515e-01,  7.4593e-02,\n        -1.8408e-04,  2.1228e-01, -2.1125e-01], device='cuda:0')"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_ns = torch.autograd.grad(test_out_g, inp_g, retain_graph=True)[0].data\n",
    "grad_ns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[8.8285150e+02, 8.8745239e+02, 5.8673936e-01, 1.3020522e+01,\n        5.4139084e-01, 7.6687844e-03, 6.2236869e-01, 3.7814638e-01]],\n      dtype=float32)"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sc.inverse_transform(grad_ns.detach().cpu().numpy().reshape(1, -1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "998.045227, 990.003174, 0.554195, 0.395475, 0.008431, 'C'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5820663402130322"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_fdm_bs(998.045227, 990.003174, 0.554195, 0.395475, 0.008431, 0.1, 'C')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.32714844]], dtype=float32)"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_fdm_net(998.045227, 990.003174, 0.554195, 998.045227 / 990.003174, 0.395475, 0.008431, 0.1,'C')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "0.4810723834326066"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_fdm_bs(998.045227, 990.003174, 0.554195, 0.395475, 0.008431, 0.0027, 'C') / 364"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[10.518689]], dtype=float32)"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_fdm_net(998.045227, 990.003174, 0.554195, 998.045227 / 990.003174, 0.395475, 0.008431, 0.0027, 'C') / 364"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "245.01700202394545"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vega_fdm_bs(998.045227, 990.003174, 0.554195, 0.395475, 0.008431, 0.01, 'C')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[180.0415]], dtype=float32)"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vega_fdm_net(998.045227, 990.003174, 0.554195, 998.045227 / 990.003174,0.395475, 0.008431, 0.01, 'C')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Model-Testing-Heston.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}