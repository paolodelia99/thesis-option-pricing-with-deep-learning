{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ju-WUaXnY5cr",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Models Testing on Heston data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hH3-v8y-AuXg",
    "pycharm": {
     "name": "#%%\n"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650891681415,
     "user_tz": -120,
     "elapsed": 824,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     }
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "QXEzFQ3iAyj_",
    "pycharm": {
     "name": "#%%\n"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650891681417,
     "user_tz": -120,
     "elapsed": 21,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Set seeds\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gsH02HCWA0gC",
    "pycharm": {
     "name": "#%%\n"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650891681418,
     "user_tz": -120,
     "elapsed": 17,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     }
    }
   },
   "outputs": [],
   "source": [
    "synthetic_calls_path = '../data/heston_mc_synthetic_calls.csv'\n",
    "synthetic_puts_path = '../data/heston_mc_synthetic_puts.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jT4n95T6A4S6",
    "pycharm": {
     "name": "#%%\n"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650891681421,
     "user_tz": -120,
     "elapsed": 15,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     }
    }
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7H8lEQPCA5IS",
    "pycharm": {
     "name": "#%%\n"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650891684820,
     "user_tz": -120,
     "elapsed": 3413,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     }
    }
   },
   "outputs": [],
   "source": [
    "synthetic_calls = pd.read_csv(synthetic_calls_path, index_col=0)\n",
    "synthetic_puts = pd.read_csv(synthetic_puts_path, index_col=0)\n",
    "\n",
    "synthetic_calls = reduce_mem_usage(synthetic_calls)\n",
    "synthetic_puts = reduce_mem_usage(synthetic_puts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9TKRgvuOA8pC",
    "pycharm": {
     "name": "#%%\n"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650891684821,
     "user_tz": -120,
     "elapsed": 20,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     }
    }
   },
   "outputs": [],
   "source": [
    "synthetic_options = pd.concat([synthetic_calls, synthetic_puts], axis=0)\n",
    "synthetic_options = shuffle(synthetic_options, random_state=0)\n",
    "synthetic_options = synthetic_options.reset_index()\n",
    "synthetic_options = synthetic_options.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "3HXliAsq132p",
    "outputId": "09bc2eb1-d20d-4471-ed50-5fa0eba727fb",
    "pycharm": {
     "name": "#%%\n"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650891684822,
     "user_tz": -120,
     "elapsed": 19,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        Price  Strike Type     Kappa       Rho     Theta        Xi       V_0  \\\n0         100    63.0    P  1.512695 -0.217773  0.169189  0.383057  0.170166   \n1         100   131.0    P  1.711914 -0.697754  0.138306  0.284424  0.338379   \n2         100   105.0    C  1.034180 -0.854004  0.064819  0.009300  0.458252   \n3         100    68.0    P  0.064087 -0.727051  0.437988  0.199463  0.429688   \n4         100    77.0    C  1.453125 -0.607910  0.258301  0.198975  0.073425   \n...       ...     ...  ...       ...       ...       ...       ...       ...   \n605995    100    71.0    P  1.464844 -0.116516  0.241699  0.188965  0.128662   \n605996    100    57.0    C  1.024414 -0.244263  0.100403  0.268311  0.241821   \n605997    100   135.0    C  0.631836 -0.868164  0.079468  0.410156  0.410889   \n605998    100    64.0    P  1.348633 -0.256348  0.433105  0.422852  0.160278   \n605999    100   135.0    P  1.585938 -0.060059  0.371826  0.157959  0.474121   \n\n        Interest Rate  Time to Expiration  Option Price  \n0            0.073792            0.464844      0.039307  \n1            0.011772            1.075195     31.203125  \n2            0.044006            0.818848      7.769531  \n3            0.024658            0.580566      0.789551  \n4            0.081238            0.756836     22.828125  \n...               ...                 ...           ...  \n605995       0.054077            0.931152      0.270996  \n605996       0.021622            1.020508     41.593750  \n605997       0.084778            0.396729      1.692383  \n605998       0.024384            0.922852      0.453857  \n605999       0.084351            0.749512     34.937500  \n\n[606000 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Price</th>\n      <th>Strike</th>\n      <th>Type</th>\n      <th>Kappa</th>\n      <th>Rho</th>\n      <th>Theta</th>\n      <th>Xi</th>\n      <th>V_0</th>\n      <th>Interest Rate</th>\n      <th>Time to Expiration</th>\n      <th>Option Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100</td>\n      <td>63.0</td>\n      <td>P</td>\n      <td>1.512695</td>\n      <td>-0.217773</td>\n      <td>0.169189</td>\n      <td>0.383057</td>\n      <td>0.170166</td>\n      <td>0.073792</td>\n      <td>0.464844</td>\n      <td>0.039307</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100</td>\n      <td>131.0</td>\n      <td>P</td>\n      <td>1.711914</td>\n      <td>-0.697754</td>\n      <td>0.138306</td>\n      <td>0.284424</td>\n      <td>0.338379</td>\n      <td>0.011772</td>\n      <td>1.075195</td>\n      <td>31.203125</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100</td>\n      <td>105.0</td>\n      <td>C</td>\n      <td>1.034180</td>\n      <td>-0.854004</td>\n      <td>0.064819</td>\n      <td>0.009300</td>\n      <td>0.458252</td>\n      <td>0.044006</td>\n      <td>0.818848</td>\n      <td>7.769531</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100</td>\n      <td>68.0</td>\n      <td>P</td>\n      <td>0.064087</td>\n      <td>-0.727051</td>\n      <td>0.437988</td>\n      <td>0.199463</td>\n      <td>0.429688</td>\n      <td>0.024658</td>\n      <td>0.580566</td>\n      <td>0.789551</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100</td>\n      <td>77.0</td>\n      <td>C</td>\n      <td>1.453125</td>\n      <td>-0.607910</td>\n      <td>0.258301</td>\n      <td>0.198975</td>\n      <td>0.073425</td>\n      <td>0.081238</td>\n      <td>0.756836</td>\n      <td>22.828125</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>605995</th>\n      <td>100</td>\n      <td>71.0</td>\n      <td>P</td>\n      <td>1.464844</td>\n      <td>-0.116516</td>\n      <td>0.241699</td>\n      <td>0.188965</td>\n      <td>0.128662</td>\n      <td>0.054077</td>\n      <td>0.931152</td>\n      <td>0.270996</td>\n    </tr>\n    <tr>\n      <th>605996</th>\n      <td>100</td>\n      <td>57.0</td>\n      <td>C</td>\n      <td>1.024414</td>\n      <td>-0.244263</td>\n      <td>0.100403</td>\n      <td>0.268311</td>\n      <td>0.241821</td>\n      <td>0.021622</td>\n      <td>1.020508</td>\n      <td>41.593750</td>\n    </tr>\n    <tr>\n      <th>605997</th>\n      <td>100</td>\n      <td>135.0</td>\n      <td>C</td>\n      <td>0.631836</td>\n      <td>-0.868164</td>\n      <td>0.079468</td>\n      <td>0.410156</td>\n      <td>0.410889</td>\n      <td>0.084778</td>\n      <td>0.396729</td>\n      <td>1.692383</td>\n    </tr>\n    <tr>\n      <th>605998</th>\n      <td>100</td>\n      <td>64.0</td>\n      <td>P</td>\n      <td>1.348633</td>\n      <td>-0.256348</td>\n      <td>0.433105</td>\n      <td>0.422852</td>\n      <td>0.160278</td>\n      <td>0.024384</td>\n      <td>0.922852</td>\n      <td>0.453857</td>\n    </tr>\n    <tr>\n      <th>605999</th>\n      <td>100</td>\n      <td>135.0</td>\n      <td>P</td>\n      <td>1.585938</td>\n      <td>-0.060059</td>\n      <td>0.371826</td>\n      <td>0.157959</td>\n      <td>0.474121</td>\n      <td>0.084351</td>\n      <td>0.749512</td>\n      <td>34.937500</td>\n    </tr>\n  </tbody>\n</table>\n<p>606000 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pn28_RUMBAFH",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "32oPe6XUBCTF",
    "pycharm": {
     "name": "#%%\n"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650891685322,
     "user_tz": -120,
     "elapsed": 515,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     }
    }
   },
   "outputs": [],
   "source": [
    "synthetic_options = pd.get_dummies(synthetic_options, prefix='', prefix_sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_Tlc7k7xBDPV",
    "pycharm": {
     "name": "#%%\n"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650891686346,
     "user_tz": -120,
     "elapsed": 1032,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     }
    }
   },
   "outputs": [],
   "source": [
    "input_sc = StandardScaler()\n",
    "output_sc = StandardScaler()\n",
    "input_data = input_sc.fit_transform(synthetic_options.drop('Option Price', axis=1))\n",
    "output_data = output_sc.fit_transform(synthetic_options['Option Price'].values.reshape(-1, 1))\n",
    "\n",
    "train_size = 0.8\n",
    "val_size = 0.1\n",
    "\n",
    "last_train_idx = int(np.round(len(input_data) * train_size))\n",
    "last_val_idx = last_train_idx + int(np.round(len(input_data) * val_size))\n",
    "\n",
    "X_train = input_data[0:last_train_idx]\n",
    "X_val = input_data[last_train_idx:last_val_idx]\n",
    "X_test = input_data[last_val_idx:]\n",
    "\n",
    "y_train = output_data[0:last_train_idx]\n",
    "y_val = output_data[last_train_idx:last_val_idx]\n",
    "y_test = output_data[last_val_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['Price', 'Strike', 'Kappa', 'Rho', 'Theta', 'Xi', 'V_0',\n       'Interest Rate', 'Time to Expiration', 'C', 'P'],\n      dtype='object')"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_options.drop('Option Price', axis=1).columns"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7nEEoQGvvDpL",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650891686347,
     "user_tz": -120,
     "elapsed": 21,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     }
    },
    "outputId": "88b4d863-d037-439b-e625-5ebb52ad41ef"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "IwMVtvfABIhR",
    "pycharm": {
     "name": "#%%\n"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650891686349,
     "user_tz": -120,
     "elapsed": 19,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     }
    }
   },
   "outputs": [],
   "source": [
    "X_train = Variable(torch.Tensor(X_train))\n",
    "X_val = Variable(torch.Tensor(X_val))\n",
    "X_test = Variable(torch.Tensor(X_test))\n",
    "\n",
    "y_train = Variable(torch.Tensor(y_train))\n",
    "y_val = Variable(torch.Tensor(y_val))\n",
    "y_test = Variable(torch.Tensor(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ra2l5P1nBVCz",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xTLMLFoSBWDy",
    "pycharm": {
     "name": "#%%\n"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650891686350,
     "user_tz": -120,
     "elapsed": 17,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     }
    }
   },
   "outputs": [],
   "source": [
    "CUDA = torch.cuda.is_available()\n",
    "device = 'cuda:0' if CUDA else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "CQ9Gl3bUBWsj",
    "pycharm": {
     "name": "#%%\n"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650891686352,
     "user_tz": -120,
     "elapsed": 18,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     }
    }
   },
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "\n",
    "  def __init__(self, module):\n",
    "    super(ResBlock, self).__init__()\n",
    "    self.module = module\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.module(x) + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "YL3SicQPBYq0",
    "pycharm": {
     "name": "#%%\n"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650891686353,
     "user_tz": -120,
     "elapsed": 17,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     }
    }
   },
   "outputs": [],
   "source": [
    "class HiddenLayer(nn.Module):\n",
    "\n",
    "  def __init__(self, layer_size, act_fn):\n",
    "      super(HiddenLayer, self).__init__()\n",
    "      \n",
    "      if act_fn == 'ReLU':\n",
    "        self.layer = nn.Sequential(\n",
    "          nn.Linear(layer_size, layer_size),\n",
    "          nn.ReLU())\n",
    "      elif act_fn == 'LeakyReLU':\n",
    "        self.layer = nn.Sequential(\n",
    "          nn.Linear(layer_size, layer_size),\n",
    "          nn.LeakyReLU())\n",
    "      elif act_fn == 'ELU':\n",
    "        self.layer = nn.Sequential(\n",
    "          nn.Linear(layer_size, layer_size),\n",
    "          nn.ELU())\n",
    "    \n",
    "  def forward(self, x):\n",
    "    return self.layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "lHUFGf9xBawS",
    "pycharm": {
     "name": "#%%\n"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650891686792,
     "user_tz": -120,
     "elapsed": 455,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     }
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "  def __init__(self, input_size, output_size, hidden_size, num_layers, act_fn):\n",
    "    super(Net, self).__init__()\n",
    "    self.input_size = input_size\n",
    "    self.output_size = output_size\n",
    "    self.hidden_size = hidden_size\n",
    "\n",
    "    if act_fn == 'ReLU':\n",
    "      self.initial_layer = nn.Sequential(\n",
    "          nn.Linear(self.input_size, self.hidden_size),\n",
    "          nn.ReLU())\n",
    "    elif act_fn == 'LeakyReLU':\n",
    "      self.initial_layer = nn.Sequential(\n",
    "          nn.Linear(self.input_size, self.hidden_size),\n",
    "          nn.LeakyReLU())\n",
    "    elif act_fn == 'ELU':\n",
    "      self.initial_layer = nn.Sequential(\n",
    "          nn.Linear(self.input_size, self.hidden_size),\n",
    "          nn.ELU())\n",
    "\n",
    "    self.hidden_layers_list = []\n",
    "\n",
    "    for i in range(num_layers // 2):\n",
    "      self.hidden_layers_list.append(\n",
    "          ResBlock(\n",
    "            nn.Sequential(\n",
    "                HiddenLayer(self.hidden_size, act_fn),\n",
    "                HiddenLayer(self.hidden_size, act_fn)\n",
    "            )\n",
    "        )\n",
    "      )\n",
    "\n",
    "    self.hidden_layers = nn.Sequential(*self.hidden_layers_list)\n",
    "\n",
    "    self.net = nn.Sequential(\n",
    "        self.initial_layer,\n",
    "        self.hidden_layers,\n",
    "        nn.Linear(self.hidden_size, self.output_size)\n",
    "    )\n",
    "  \n",
    "  def forward(self, x):\n",
    "    return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "zcq_lQrHBdH8",
    "pycharm": {
     "name": "#%%\n"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650891686793,
     "user_tz": -120,
     "elapsed": 11,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     }
    }
   },
   "outputs": [],
   "source": [
    "def init_weights(m, init_m: str):\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def init_uniform(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "      torch.nn.init.uniform_(m.weight)\n",
    "      m.bias.data.fill_(0.01)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def init_normal(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "      torch.nn.init.normal_(m.weight)\n",
    "      m.bias.data.fill_(0.01)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def init_xuniform(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "      torch.nn.init.xavier_uniform_(m.weight)\n",
    "      m.bias.data.fill_(0.01)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def init_xnormal(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "      torch.nn.init.xavier_normal_(m.weight)\n",
    "      m.bias.data.fill_(0.01)\n",
    "\n",
    "  if init_m == 'uniform':\n",
    "    m.apply(init_uniform)\n",
    "  elif init_m == 'normal':\n",
    "    m.apply(init_normal)\n",
    "  elif init_m == 'xaiver uniform':\n",
    "    m.apply(init_xuniform)\n",
    "  elif init_m == 'xavier normal':\n",
    "    m.apply(init_xnormal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vuCpyycNCKEZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "YbCOnCSNCL25",
    "pycharm": {
     "name": "#%%\n"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650891686794,
     "user_tz": -120,
     "elapsed": 10,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     }
    }
   },
   "outputs": [],
   "source": [
    "input_size = 11\n",
    "output_size = 1\n",
    "num_layers = 4\n",
    "hidden_size = 600\n",
    "batch_size = 1134\n",
    "epochs = 2000\n",
    "lr = 0.000125\n",
    "init_method = 'xaiver uniform'\n",
    "act_fn = 'LeakyReLU'\n",
    "\n",
    "model = Net(input_size, output_size, hidden_size, num_layers, act_fn)\n",
    "init_weights(model, init_method)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "X_train = X_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "\n",
    "X_val = X_val.to(device)\n",
    "y_val = y_val.to(device)\n",
    "\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "QqZbxrppvDpZ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650891694138,
     "user_tz": -120,
     "elapsed": 7351,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Q-9T0GArCMgp",
    "pycharm": {
     "name": "#%%\n"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650891694142,
     "user_tz": -120,
     "elapsed": 42,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     }
    }
   },
   "outputs": [],
   "source": [
    "class OptDataset(Dataset):\n",
    "\n",
    "  def __init__(self, X, y):\n",
    "    self.X = X\n",
    "    self.y = y\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.X[idx], self.y[idx]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Losses Metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "J6-hCH2ivDpb"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "mVaO8TruHW4M",
    "pycharm": {
     "name": "#%%\n"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650891694144,
     "user_tz": -120,
     "elapsed": 40,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     }
    }
   },
   "outputs": [],
   "source": [
    "def MAPELoss(output, target):\n",
    "  return torch.mean(torch.abs((target - output) / target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def evaluate(model, loss_fn, X_val, y_val):\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    out = model(X_val)\n",
    "    loss = loss_fn(out, y_val)\n",
    "    print('\\nVal set: Average loss: {:.8f}\\n'.format(\n",
    "            loss.item()))\n",
    "    return loss.item()"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "tVLW5dHhvDpe",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650891694149,
     "user_tz": -120,
     "elapsed": 37,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Early Stopping class"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "68eF5_EovDpf"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# Code took form: https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, \n",
    "                 patience=10, \n",
    "                 verbose=False, \n",
    "                 delta=0, \n",
    "                 path='../models/final_heston_model.chkpt',\n",
    "                 trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score > self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "n2So2ffSvDpg",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650891694150,
     "user_tz": -120,
     "elapsed": 35,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train Loop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "dL_xmnKXvDph"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def train(\n",
    "    epochs,\n",
    "    batch_size,\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val\n",
    "):\n",
    "\n",
    "  training_losses = []\n",
    "  validation_losses = []\n",
    "\n",
    "  early_stopping = EarlyStopping(patience=20)\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "    i = 0\n",
    "\n",
    "    for batch, batch_labels in DataLoader(OptDataset(X_train, y_train), batch_size=batch_size):\n",
    "      out = model(batch.to(device))\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      loss = loss_fn(out, batch_labels.to(device))\n",
    "      epoch_losses.append(loss.item())\n",
    "      total_loss += loss.item()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      if i > 0 and i % 50 == 0:\n",
    "        avg_loss = total_loss / 50\n",
    "        elapsed = time.time() - start_time\n",
    "        print('| Epoch {:3d} | {:5d}/{:5d} batches | lr {:2.5f} | ms/batch {:5.2f} | '\n",
    "                  'loss {:5.8f}'.format(\n",
    "              epoch, i, len(X_train) // batch_size+1, lr, elapsed * 1000 / 50,\n",
    "              avg_loss))\n",
    "        start_time = time.time()\n",
    "        total_loss = 0\n",
    "\n",
    "      i += 1\n",
    "\n",
    "    training_losses.append(np.array(epoch_losses).mean())\n",
    "    val_loss = evaluate(model, loss_fn, X_val, y_val)\n",
    "    validation_losses.append(val_loss)\n",
    "\n",
    "    early_stopping(val_loss, model)\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(f\"Stopping at Epoch: {epoch}\")\n",
    "        break\n",
    "\n",
    "  return training_losses, validation_losses"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "DrBBTGKJvDph",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650891694152,
     "user_tz": -120,
     "elapsed": 34,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch   0 |    50/  428 batches | lr 0.00013 | ms/batch 24.14 | loss 0.23410818\n",
      "| Epoch   0 |   100/  428 batches | lr 0.00013 | ms/batch 20.13 | loss 0.01525971\n",
      "| Epoch   0 |   150/  428 batches | lr 0.00013 | ms/batch 19.54 | loss 0.00859198\n",
      "| Epoch   0 |   200/  428 batches | lr 0.00013 | ms/batch 18.96 | loss 0.00526474\n",
      "| Epoch   0 |   250/  428 batches | lr 0.00013 | ms/batch 17.29 | loss 0.00349154\n",
      "| Epoch   0 |   300/  428 batches | lr 0.00013 | ms/batch 20.19 | loss 0.00278501\n",
      "| Epoch   0 |   350/  428 batches | lr 0.00013 | ms/batch 19.49 | loss 0.00246913\n",
      "| Epoch   0 |   400/  428 batches | lr 0.00013 | ms/batch 18.94 | loss 0.00220285\n",
      "\n",
      "Val set: Average loss: 0.00206423\n",
      "\n",
      "| Epoch   1 |    50/  428 batches | lr 0.00013 | ms/batch 21.28 | loss 0.00204241\n",
      "| Epoch   1 |   100/  428 batches | lr 0.00013 | ms/batch 19.42 | loss 0.00196730\n",
      "| Epoch   1 |   150/  428 batches | lr 0.00013 | ms/batch 19.32 | loss 0.00193645\n",
      "| Epoch   1 |   200/  428 batches | lr 0.00013 | ms/batch 21.38 | loss 0.00184451\n",
      "| Epoch   1 |   250/  428 batches | lr 0.00013 | ms/batch 19.16 | loss 0.00186464\n",
      "| Epoch   1 |   300/  428 batches | lr 0.00013 | ms/batch 19.22 | loss 0.00172496\n",
      "| Epoch   1 |   350/  428 batches | lr 0.00013 | ms/batch 20.74 | loss 0.00182471\n",
      "| Epoch   1 |   400/  428 batches | lr 0.00013 | ms/batch 19.40 | loss 0.00172603\n",
      "\n",
      "Val set: Average loss: 0.00161694\n",
      "\n",
      "| Epoch   2 |    50/  428 batches | lr 0.00013 | ms/batch 19.76 | loss 0.00169761\n",
      "| Epoch   2 |   100/  428 batches | lr 0.00013 | ms/batch 19.22 | loss 0.00153063\n",
      "| Epoch   2 |   150/  428 batches | lr 0.00013 | ms/batch 21.12 | loss 0.00165950\n",
      "| Epoch   2 |   200/  428 batches | lr 0.00013 | ms/batch 19.46 | loss 0.00159752\n",
      "| Epoch   2 |   250/  428 batches | lr 0.00013 | ms/batch 19.24 | loss 0.00165073\n",
      "| Epoch   2 |   300/  428 batches | lr 0.00013 | ms/batch 22.19 | loss 0.00146770\n",
      "| Epoch   2 |   350/  428 batches | lr 0.00013 | ms/batch 20.13 | loss 0.00152491\n",
      "| Epoch   2 |   400/  428 batches | lr 0.00013 | ms/batch 19.72 | loss 0.00154923\n",
      "\n",
      "Val set: Average loss: 0.00138598\n",
      "\n",
      "| Epoch   3 |    50/  428 batches | lr 0.00013 | ms/batch 20.78 | loss 0.00148062\n",
      "| Epoch   3 |   100/  428 batches | lr 0.00013 | ms/batch 21.36 | loss 0.00132796\n",
      "| Epoch   3 |   150/  428 batches | lr 0.00013 | ms/batch 19.56 | loss 0.00146260\n",
      "| Epoch   3 |   200/  428 batches | lr 0.00013 | ms/batch 19.57 | loss 0.00139102\n",
      "| Epoch   3 |   250/  428 batches | lr 0.00013 | ms/batch 20.90 | loss 0.00144829\n",
      "| Epoch   3 |   300/  428 batches | lr 0.00013 | ms/batch 19.46 | loss 0.00132521\n",
      "| Epoch   3 |   350/  428 batches | lr 0.00013 | ms/batch 19.68 | loss 0.00139405\n",
      "| Epoch   3 |   400/  428 batches | lr 0.00013 | ms/batch 21.04 | loss 0.00141613\n",
      "\n",
      "Val set: Average loss: 0.00123172\n",
      "\n",
      "| Epoch   4 |    50/  428 batches | lr 0.00013 | ms/batch 21.98 | loss 0.00130629\n",
      "| Epoch   4 |   100/  428 batches | lr 0.00013 | ms/batch 20.15 | loss 0.00119578\n",
      "| Epoch   4 |   150/  428 batches | lr 0.00013 | ms/batch 19.53 | loss 0.00132874\n",
      "| Epoch   4 |   200/  428 batches | lr 0.00013 | ms/batch 20.93 | loss 0.00122295\n",
      "| Epoch   4 |   250/  428 batches | lr 0.00013 | ms/batch 19.34 | loss 0.00130580\n",
      "| Epoch   4 |   300/  428 batches | lr 0.00013 | ms/batch 20.08 | loss 0.00128995\n",
      "| Epoch   4 |   350/  428 batches | lr 0.00013 | ms/batch 21.58 | loss 0.00136465\n",
      "| Epoch   4 |   400/  428 batches | lr 0.00013 | ms/batch 20.63 | loss 0.00124278\n",
      "\n",
      "Val set: Average loss: 0.00111507\n",
      "\n",
      "| Epoch   5 |    50/  428 batches | lr 0.00013 | ms/batch 18.23 | loss 0.00116038\n",
      "| Epoch   5 |   100/  428 batches | lr 0.00013 | ms/batch 19.91 | loss 0.00109453\n",
      "| Epoch   5 |   150/  428 batches | lr 0.00013 | ms/batch 17.77 | loss 0.00119499\n",
      "| Epoch   5 |   200/  428 batches | lr 0.00013 | ms/batch 17.78 | loss 0.00110003\n",
      "| Epoch   5 |   250/  428 batches | lr 0.00013 | ms/batch 19.08 | loss 0.00143445\n",
      "| Epoch   5 |   300/  428 batches | lr 0.00013 | ms/batch 17.42 | loss 0.00108668\n",
      "| Epoch   5 |   350/  428 batches | lr 0.00013 | ms/batch 19.49 | loss 0.00117852\n",
      "| Epoch   5 |   400/  428 batches | lr 0.00013 | ms/batch 18.38 | loss 0.00118237\n",
      "\n",
      "Val set: Average loss: 0.00104295\n",
      "\n",
      "| Epoch   6 |    50/  428 batches | lr 0.00013 | ms/batch 20.62 | loss 0.00108761\n",
      "| Epoch   6 |   100/  428 batches | lr 0.00013 | ms/batch 20.21 | loss 0.00100378\n",
      "| Epoch   6 |   150/  428 batches | lr 0.00013 | ms/batch 20.38 | loss 0.00110031\n",
      "| Epoch   6 |   200/  428 batches | lr 0.00013 | ms/batch 19.82 | loss 0.00100463\n",
      "| Epoch   6 |   250/  428 batches | lr 0.00013 | ms/batch 18.08 | loss 0.00140293\n",
      "| Epoch   6 |   300/  428 batches | lr 0.00013 | ms/batch 19.47 | loss 0.00101543\n",
      "| Epoch   6 |   350/  428 batches | lr 0.00013 | ms/batch 19.54 | loss 0.00111591\n",
      "| Epoch   6 |   400/  428 batches | lr 0.00013 | ms/batch 19.50 | loss 0.00109652\n",
      "\n",
      "Val set: Average loss: 0.00095769\n",
      "\n",
      "| Epoch   7 |    50/  428 batches | lr 0.00013 | ms/batch 22.47 | loss 0.00097807\n",
      "| Epoch   7 |   100/  428 batches | lr 0.00013 | ms/batch 19.28 | loss 0.00092101\n",
      "| Epoch   7 |   150/  428 batches | lr 0.00013 | ms/batch 19.17 | loss 0.00102101\n",
      "| Epoch   7 |   200/  428 batches | lr 0.00013 | ms/batch 20.84 | loss 0.00094215\n",
      "| Epoch   7 |   250/  428 batches | lr 0.00013 | ms/batch 23.49 | loss 0.00129788\n",
      "| Epoch   7 |   300/  428 batches | lr 0.00013 | ms/batch 21.81 | loss 0.00094363\n",
      "| Epoch   7 |   350/  428 batches | lr 0.00013 | ms/batch 24.11 | loss 0.00101591\n",
      "| Epoch   7 |   400/  428 batches | lr 0.00013 | ms/batch 19.83 | loss 0.00094864\n",
      "\n",
      "Val set: Average loss: 0.00100949\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch   8 |    50/  428 batches | lr 0.00013 | ms/batch 17.94 | loss 0.00090150\n",
      "| Epoch   8 |   100/  428 batches | lr 0.00013 | ms/batch 17.59 | loss 0.00085773\n",
      "| Epoch   8 |   150/  428 batches | lr 0.00013 | ms/batch 19.73 | loss 0.00098362\n",
      "| Epoch   8 |   200/  428 batches | lr 0.00013 | ms/batch 17.59 | loss 0.00089363\n",
      "| Epoch   8 |   250/  428 batches | lr 0.00013 | ms/batch 19.33 | loss 0.00139501\n",
      "| Epoch   8 |   300/  428 batches | lr 0.00013 | ms/batch 17.61 | loss 0.00090102\n",
      "| Epoch   8 |   350/  428 batches | lr 0.00013 | ms/batch 20.65 | loss 0.00098139\n",
      "| Epoch   8 |   400/  428 batches | lr 0.00013 | ms/batch 20.66 | loss 0.00092961\n",
      "\n",
      "Val set: Average loss: 0.00086850\n",
      "\n",
      "| Epoch   9 |    50/  428 batches | lr 0.00013 | ms/batch 20.28 | loss 0.00084321\n",
      "| Epoch   9 |   100/  428 batches | lr 0.00013 | ms/batch 22.60 | loss 0.00081663\n",
      "| Epoch   9 |   150/  428 batches | lr 0.00013 | ms/batch 20.64 | loss 0.00091048\n",
      "| Epoch   9 |   200/  428 batches | lr 0.00013 | ms/batch 19.28 | loss 0.00080616\n",
      "| Epoch   9 |   250/  428 batches | lr 0.00013 | ms/batch 20.55 | loss 0.00100453\n",
      "| Epoch   9 |   300/  428 batches | lr 0.00013 | ms/batch 21.69 | loss 0.00086732\n",
      "| Epoch   9 |   350/  428 batches | lr 0.00013 | ms/batch 19.48 | loss 0.00090563\n",
      "| Epoch   9 |   400/  428 batches | lr 0.00013 | ms/batch 19.93 | loss 0.00080883\n",
      "\n",
      "Val set: Average loss: 0.00088756\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  10 |    50/  428 batches | lr 0.00013 | ms/batch 20.03 | loss 0.00085565\n",
      "| Epoch  10 |   100/  428 batches | lr 0.00013 | ms/batch 22.61 | loss 0.00075359\n",
      "| Epoch  10 |   150/  428 batches | lr 0.00013 | ms/batch 20.70 | loss 0.00080895\n",
      "| Epoch  10 |   200/  428 batches | lr 0.00013 | ms/batch 20.13 | loss 0.00082554\n",
      "| Epoch  10 |   250/  428 batches | lr 0.00013 | ms/batch 21.54 | loss 0.00113187\n",
      "| Epoch  10 |   300/  428 batches | lr 0.00013 | ms/batch 21.13 | loss 0.00080095\n",
      "| Epoch  10 |   350/  428 batches | lr 0.00013 | ms/batch 20.57 | loss 0.00084154\n",
      "| Epoch  10 |   400/  428 batches | lr 0.00013 | ms/batch 21.41 | loss 0.00076432\n",
      "\n",
      "Val set: Average loss: 0.00077985\n",
      "\n",
      "| Epoch  11 |    50/  428 batches | lr 0.00013 | ms/batch 21.40 | loss 0.00080237\n",
      "| Epoch  11 |   100/  428 batches | lr 0.00013 | ms/batch 19.36 | loss 0.00074023\n",
      "| Epoch  11 |   150/  428 batches | lr 0.00013 | ms/batch 19.87 | loss 0.00073004\n",
      "| Epoch  11 |   200/  428 batches | lr 0.00013 | ms/batch 20.91 | loss 0.00075899\n",
      "| Epoch  11 |   250/  428 batches | lr 0.00013 | ms/batch 19.73 | loss 0.00112766\n",
      "| Epoch  11 |   300/  428 batches | lr 0.00013 | ms/batch 19.35 | loss 0.00072175\n",
      "| Epoch  11 |   350/  428 batches | lr 0.00013 | ms/batch 21.32 | loss 0.00083873\n",
      "| Epoch  11 |   400/  428 batches | lr 0.00013 | ms/batch 19.39 | loss 0.00070549\n",
      "\n",
      "Val set: Average loss: 0.00081421\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  12 |    50/  428 batches | lr 0.00013 | ms/batch 19.77 | loss 0.00073828\n",
      "| Epoch  12 |   100/  428 batches | lr 0.00013 | ms/batch 17.69 | loss 0.00068972\n",
      "| Epoch  12 |   150/  428 batches | lr 0.00013 | ms/batch 20.34 | loss 0.00068438\n",
      "| Epoch  12 |   200/  428 batches | lr 0.00013 | ms/batch 20.04 | loss 0.00079888\n",
      "| Epoch  12 |   250/  428 batches | lr 0.00013 | ms/batch 19.46 | loss 0.00108338\n",
      "| Epoch  12 |   300/  428 batches | lr 0.00013 | ms/batch 17.69 | loss 0.00070320\n",
      "| Epoch  12 |   350/  428 batches | lr 0.00013 | ms/batch 19.37 | loss 0.00082908\n",
      "| Epoch  12 |   400/  428 batches | lr 0.00013 | ms/batch 19.82 | loss 0.00072754\n",
      "\n",
      "Val set: Average loss: 0.00069433\n",
      "\n",
      "| Epoch  13 |    50/  428 batches | lr 0.00013 | ms/batch 22.04 | loss 0.00065277\n",
      "| Epoch  13 |   100/  428 batches | lr 0.00013 | ms/batch 19.87 | loss 0.00067626\n",
      "| Epoch  13 |   150/  428 batches | lr 0.00013 | ms/batch 21.50 | loss 0.00080278\n",
      "| Epoch  13 |   200/  428 batches | lr 0.00013 | ms/batch 19.90 | loss 0.00066790\n",
      "| Epoch  13 |   250/  428 batches | lr 0.00013 | ms/batch 20.18 | loss 0.00076400\n",
      "| Epoch  13 |   300/  428 batches | lr 0.00013 | ms/batch 21.10 | loss 0.00061222\n",
      "| Epoch  13 |   350/  428 batches | lr 0.00013 | ms/batch 21.31 | loss 0.00066732\n",
      "| Epoch  13 |   400/  428 batches | lr 0.00013 | ms/batch 20.43 | loss 0.00066935\n",
      "\n",
      "Val set: Average loss: 0.00066461\n",
      "\n",
      "| Epoch  14 |    50/  428 batches | lr 0.00013 | ms/batch 19.98 | loss 0.00074622\n",
      "| Epoch  14 |   100/  428 batches | lr 0.00013 | ms/batch 21.10 | loss 0.00066705\n",
      "| Epoch  14 |   150/  428 batches | lr 0.00013 | ms/batch 19.53 | loss 0.00066795\n",
      "| Epoch  14 |   200/  428 batches | lr 0.00013 | ms/batch 19.69 | loss 0.00060940\n",
      "| Epoch  14 |   250/  428 batches | lr 0.00013 | ms/batch 21.22 | loss 0.00058759\n",
      "| Epoch  14 |   300/  428 batches | lr 0.00013 | ms/batch 19.28 | loss 0.00074003\n",
      "| Epoch  14 |   350/  428 batches | lr 0.00013 | ms/batch 19.53 | loss 0.00077855\n",
      "| Epoch  14 |   400/  428 batches | lr 0.00013 | ms/batch 21.08 | loss 0.00057174\n",
      "\n",
      "Val set: Average loss: 0.00058593\n",
      "\n",
      "| Epoch  15 |    50/  428 batches | lr 0.00013 | ms/batch 21.37 | loss 0.00073739\n",
      "| Epoch  15 |   100/  428 batches | lr 0.00013 | ms/batch 19.38 | loss 0.00068076\n",
      "| Epoch  15 |   150/  428 batches | lr 0.00013 | ms/batch 19.59 | loss 0.00071536\n",
      "| Epoch  15 |   200/  428 batches | lr 0.00013 | ms/batch 21.97 | loss 0.00057912\n",
      "| Epoch  15 |   250/  428 batches | lr 0.00013 | ms/batch 19.64 | loss 0.00057782\n",
      "| Epoch  15 |   300/  428 batches | lr 0.00013 | ms/batch 19.49 | loss 0.00075587\n",
      "| Epoch  15 |   350/  428 batches | lr 0.00013 | ms/batch 21.33 | loss 0.00067504\n",
      "| Epoch  15 |   400/  428 batches | lr 0.00013 | ms/batch 20.60 | loss 0.00056250\n",
      "\n",
      "Val set: Average loss: 0.00065955\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  16 |    50/  428 batches | lr 0.00013 | ms/batch 18.34 | loss 0.00059530\n",
      "| Epoch  16 |   100/  428 batches | lr 0.00013 | ms/batch 20.20 | loss 0.00066256\n",
      "| Epoch  16 |   150/  428 batches | lr 0.00013 | ms/batch 19.57 | loss 0.00058876\n",
      "| Epoch  16 |   200/  428 batches | lr 0.00013 | ms/batch 19.57 | loss 0.00051411\n",
      "| Epoch  16 |   250/  428 batches | lr 0.00013 | ms/batch 19.32 | loss 0.00074606\n",
      "| Epoch  16 |   300/  428 batches | lr 0.00013 | ms/batch 17.83 | loss 0.00064760\n",
      "| Epoch  16 |   350/  428 batches | lr 0.00013 | ms/batch 19.51 | loss 0.00066453\n",
      "| Epoch  16 |   400/  428 batches | lr 0.00013 | ms/batch 19.52 | loss 0.00055497\n",
      "\n",
      "Val set: Average loss: 0.00059775\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  17 |    50/  428 batches | lr 0.00013 | ms/batch 21.63 | loss 0.00062490\n",
      "| Epoch  17 |   100/  428 batches | lr 0.00013 | ms/batch 20.42 | loss 0.00066266\n",
      "| Epoch  17 |   150/  428 batches | lr 0.00013 | ms/batch 19.73 | loss 0.00072451\n",
      "| Epoch  17 |   200/  428 batches | lr 0.00013 | ms/batch 20.99 | loss 0.00065636\n",
      "| Epoch  17 |   250/  428 batches | lr 0.00013 | ms/batch 19.36 | loss 0.00063557\n",
      "| Epoch  17 |   300/  428 batches | lr 0.00013 | ms/batch 19.58 | loss 0.00055831\n",
      "| Epoch  17 |   350/  428 batches | lr 0.00013 | ms/batch 21.30 | loss 0.00082216\n",
      "| Epoch  17 |   400/  428 batches | lr 0.00013 | ms/batch 19.53 | loss 0.00058089\n",
      "\n",
      "Val set: Average loss: 0.00061731\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  18 |    50/  428 batches | lr 0.00013 | ms/batch 20.39 | loss 0.00047607\n",
      "| Epoch  18 |   100/  428 batches | lr 0.00013 | ms/batch 17.45 | loss 0.00061049\n",
      "| Epoch  18 |   150/  428 batches | lr 0.00013 | ms/batch 19.41 | loss 0.00065828\n",
      "| Epoch  18 |   200/  428 batches | lr 0.00013 | ms/batch 20.78 | loss 0.00062895\n",
      "| Epoch  18 |   250/  428 batches | lr 0.00013 | ms/batch 20.18 | loss 0.00054166\n",
      "| Epoch  18 |   300/  428 batches | lr 0.00013 | ms/batch 18.42 | loss 0.00055236\n",
      "| Epoch  18 |   350/  428 batches | lr 0.00013 | ms/batch 20.31 | loss 0.00070338\n",
      "| Epoch  18 |   400/  428 batches | lr 0.00013 | ms/batch 20.36 | loss 0.00054738\n",
      "\n",
      "Val set: Average loss: 0.00057422\n",
      "\n",
      "| Epoch  19 |    50/  428 batches | lr 0.00013 | ms/batch 21.49 | loss 0.00044366\n",
      "| Epoch  19 |   100/  428 batches | lr 0.00013 | ms/batch 19.21 | loss 0.00053045\n",
      "| Epoch  19 |   150/  428 batches | lr 0.00013 | ms/batch 21.07 | loss 0.00055808\n",
      "| Epoch  19 |   200/  428 batches | lr 0.00013 | ms/batch 19.39 | loss 0.00047901\n",
      "| Epoch  19 |   250/  428 batches | lr 0.00013 | ms/batch 19.72 | loss 0.00046363\n",
      "| Epoch  19 |   300/  428 batches | lr 0.00013 | ms/batch 21.07 | loss 0.00043758\n",
      "| Epoch  19 |   350/  428 batches | lr 0.00013 | ms/batch 19.55 | loss 0.00050602\n",
      "| Epoch  19 |   400/  428 batches | lr 0.00013 | ms/batch 19.41 | loss 0.00052644\n",
      "\n",
      "Val set: Average loss: 0.00062567\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  20 |    50/  428 batches | lr 0.00013 | ms/batch 19.98 | loss 0.00048475\n",
      "| Epoch  20 |   100/  428 batches | lr 0.00013 | ms/batch 17.73 | loss 0.00040923\n",
      "| Epoch  20 |   150/  428 batches | lr 0.00013 | ms/batch 19.90 | loss 0.00058061\n",
      "| Epoch  20 |   200/  428 batches | lr 0.00013 | ms/batch 19.69 | loss 0.00043324\n",
      "| Epoch  20 |   250/  428 batches | lr 0.00013 | ms/batch 19.68 | loss 0.00077086\n",
      "| Epoch  20 |   300/  428 batches | lr 0.00013 | ms/batch 19.43 | loss 0.00042120\n",
      "| Epoch  20 |   350/  428 batches | lr 0.00013 | ms/batch 17.99 | loss 0.00045124\n",
      "| Epoch  20 |   400/  428 batches | lr 0.00013 | ms/batch 19.15 | loss 0.00052726\n",
      "\n",
      "Val set: Average loss: 0.00051511\n",
      "\n",
      "| Epoch  21 |    50/  428 batches | lr 0.00013 | ms/batch 20.11 | loss 0.00052046\n",
      "| Epoch  21 |   100/  428 batches | lr 0.00013 | ms/batch 19.33 | loss 0.00043014\n",
      "| Epoch  21 |   150/  428 batches | lr 0.00013 | ms/batch 21.17 | loss 0.00052431\n",
      "| Epoch  21 |   200/  428 batches | lr 0.00013 | ms/batch 19.45 | loss 0.00047465\n",
      "| Epoch  21 |   250/  428 batches | lr 0.00013 | ms/batch 19.81 | loss 0.00051554\n",
      "| Epoch  21 |   300/  428 batches | lr 0.00013 | ms/batch 21.08 | loss 0.00045998\n",
      "| Epoch  21 |   350/  428 batches | lr 0.00013 | ms/batch 19.58 | loss 0.00049752\n",
      "| Epoch  21 |   400/  428 batches | lr 0.00013 | ms/batch 19.78 | loss 0.00069638\n",
      "\n",
      "Val set: Average loss: 0.00053469\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  22 |    50/  428 batches | lr 0.00013 | ms/batch 20.01 | loss 0.00041911\n",
      "| Epoch  22 |   100/  428 batches | lr 0.00013 | ms/batch 19.31 | loss 0.00044271\n",
      "| Epoch  22 |   150/  428 batches | lr 0.00013 | ms/batch 17.62 | loss 0.00042886\n",
      "| Epoch  22 |   200/  428 batches | lr 0.00013 | ms/batch 19.21 | loss 0.00044638\n",
      "| Epoch  22 |   250/  428 batches | lr 0.00013 | ms/batch 19.44 | loss 0.00042545\n",
      "| Epoch  22 |   300/  428 batches | lr 0.00013 | ms/batch 19.50 | loss 0.00045691\n",
      "| Epoch  22 |   350/  428 batches | lr 0.00013 | ms/batch 17.96 | loss 0.00051967\n",
      "| Epoch  22 |   400/  428 batches | lr 0.00013 | ms/batch 19.22 | loss 0.00050896\n",
      "\n",
      "Val set: Average loss: 0.00039556\n",
      "\n",
      "| Epoch  23 |    50/  428 batches | lr 0.00013 | ms/batch 20.19 | loss 0.00041510\n",
      "| Epoch  23 |   100/  428 batches | lr 0.00013 | ms/batch 19.60 | loss 0.00036361\n",
      "| Epoch  23 |   150/  428 batches | lr 0.00013 | ms/batch 21.34 | loss 0.00051725\n",
      "| Epoch  23 |   200/  428 batches | lr 0.00013 | ms/batch 19.46 | loss 0.00049711\n",
      "| Epoch  23 |   250/  428 batches | lr 0.00013 | ms/batch 19.25 | loss 0.00070939\n",
      "| Epoch  23 |   300/  428 batches | lr 0.00013 | ms/batch 21.38 | loss 0.00044967\n",
      "| Epoch  23 |   350/  428 batches | lr 0.00013 | ms/batch 19.39 | loss 0.00050413\n",
      "| Epoch  23 |   400/  428 batches | lr 0.00013 | ms/batch 19.23 | loss 0.00043099\n",
      "\n",
      "Val set: Average loss: 0.00072047\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  24 |    50/  428 batches | lr 0.00013 | ms/batch 19.79 | loss 0.00039546\n",
      "| Epoch  24 |   100/  428 batches | lr 0.00013 | ms/batch 19.19 | loss 0.00042083\n",
      "| Epoch  24 |   150/  428 batches | lr 0.00013 | ms/batch 18.02 | loss 0.00039173\n",
      "| Epoch  24 |   200/  428 batches | lr 0.00013 | ms/batch 19.48 | loss 0.00038407\n",
      "| Epoch  24 |   250/  428 batches | lr 0.00013 | ms/batch 19.57 | loss 0.00059462\n",
      "| Epoch  24 |   300/  428 batches | lr 0.00013 | ms/batch 19.41 | loss 0.00038609\n",
      "| Epoch  24 |   350/  428 batches | lr 0.00013 | ms/batch 19.44 | loss 0.00038714\n",
      "| Epoch  24 |   400/  428 batches | lr 0.00013 | ms/batch 17.84 | loss 0.00040844\n",
      "\n",
      "Val set: Average loss: 0.00037849\n",
      "\n",
      "| Epoch  25 |    50/  428 batches | lr 0.00013 | ms/batch 20.03 | loss 0.00040963\n",
      "| Epoch  25 |   100/  428 batches | lr 0.00013 | ms/batch 19.99 | loss 0.00044478\n",
      "| Epoch  25 |   150/  428 batches | lr 0.00013 | ms/batch 21.31 | loss 0.00037721\n",
      "| Epoch  25 |   200/  428 batches | lr 0.00013 | ms/batch 19.48 | loss 0.00050023\n",
      "| Epoch  25 |   250/  428 batches | lr 0.00013 | ms/batch 20.92 | loss 0.00093658\n",
      "| Epoch  25 |   300/  428 batches | lr 0.00013 | ms/batch 21.86 | loss 0.00049480\n",
      "| Epoch  25 |   350/  428 batches | lr 0.00013 | ms/batch 20.03 | loss 0.00047150\n",
      "| Epoch  25 |   400/  428 batches | lr 0.00013 | ms/batch 19.92 | loss 0.00049124\n",
      "\n",
      "Val set: Average loss: 0.00038516\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  26 |    50/  428 batches | lr 0.00013 | ms/batch 20.32 | loss 0.00033756\n",
      "| Epoch  26 |   100/  428 batches | lr 0.00013 | ms/batch 19.46 | loss 0.00042107\n",
      "| Epoch  26 |   150/  428 batches | lr 0.00013 | ms/batch 19.77 | loss 0.00050627\n",
      "| Epoch  26 |   200/  428 batches | lr 0.00013 | ms/batch 18.33 | loss 0.00052989\n",
      "| Epoch  26 |   250/  428 batches | lr 0.00013 | ms/batch 19.25 | loss 0.00041904\n",
      "| Epoch  26 |   300/  428 batches | lr 0.00013 | ms/batch 19.27 | loss 0.00041566\n",
      "| Epoch  26 |   350/  428 batches | lr 0.00013 | ms/batch 19.48 | loss 0.00041824\n",
      "| Epoch  26 |   400/  428 batches | lr 0.00013 | ms/batch 19.62 | loss 0.00041257\n",
      "\n",
      "Val set: Average loss: 0.00039702\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  27 |    50/  428 batches | lr 0.00013 | ms/batch 20.25 | loss 0.00034463\n",
      "| Epoch  27 |   100/  428 batches | lr 0.00013 | ms/batch 21.32 | loss 0.00039404\n",
      "| Epoch  27 |   150/  428 batches | lr 0.00013 | ms/batch 19.71 | loss 0.00040451\n",
      "| Epoch  27 |   200/  428 batches | lr 0.00013 | ms/batch 19.54 | loss 0.00037294\n",
      "| Epoch  27 |   250/  428 batches | lr 0.00013 | ms/batch 21.45 | loss 0.00036275\n",
      "| Epoch  27 |   300/  428 batches | lr 0.00013 | ms/batch 19.89 | loss 0.00035932\n",
      "| Epoch  27 |   350/  428 batches | lr 0.00013 | ms/batch 19.56 | loss 0.00035379\n",
      "| Epoch  27 |   400/  428 batches | lr 0.00013 | ms/batch 21.80 | loss 0.00048401\n",
      "\n",
      "Val set: Average loss: 0.00034962\n",
      "\n",
      "| Epoch  28 |    50/  428 batches | lr 0.00013 | ms/batch 21.38 | loss 0.00034239\n",
      "| Epoch  28 |   100/  428 batches | lr 0.00013 | ms/batch 19.78 | loss 0.00036701\n",
      "| Epoch  28 |   150/  428 batches | lr 0.00013 | ms/batch 19.67 | loss 0.00042660\n",
      "| Epoch  28 |   200/  428 batches | lr 0.00013 | ms/batch 21.20 | loss 0.00031925\n",
      "| Epoch  28 |   250/  428 batches | lr 0.00013 | ms/batch 20.27 | loss 0.00085782\n",
      "| Epoch  28 |   300/  428 batches | lr 0.00013 | ms/batch 19.49 | loss 0.00038433\n",
      "| Epoch  28 |   350/  428 batches | lr 0.00013 | ms/batch 21.18 | loss 0.00039237\n",
      "| Epoch  28 |   400/  428 batches | lr 0.00013 | ms/batch 19.40 | loss 0.00038313\n",
      "\n",
      "Val set: Average loss: 0.00036695\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  29 |    50/  428 batches | lr 0.00013 | ms/batch 19.95 | loss 0.00031330\n",
      "| Epoch  29 |   100/  428 batches | lr 0.00013 | ms/batch 17.86 | loss 0.00035155\n",
      "| Epoch  29 |   150/  428 batches | lr 0.00013 | ms/batch 19.28 | loss 0.00035423\n",
      "| Epoch  29 |   200/  428 batches | lr 0.00013 | ms/batch 19.63 | loss 0.00031105\n",
      "| Epoch  29 |   250/  428 batches | lr 0.00013 | ms/batch 19.37 | loss 0.00049136\n",
      "| Epoch  29 |   300/  428 batches | lr 0.00013 | ms/batch 19.50 | loss 0.00030537\n",
      "| Epoch  29 |   350/  428 batches | lr 0.00013 | ms/batch 18.02 | loss 0.00043518\n",
      "| Epoch  29 |   400/  428 batches | lr 0.00013 | ms/batch 19.34 | loss 0.00033659\n",
      "\n",
      "Val set: Average loss: 0.00037132\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  30 |    50/  428 batches | lr 0.00013 | ms/batch 19.98 | loss 0.00031704\n",
      "| Epoch  30 |   100/  428 batches | lr 0.00013 | ms/batch 19.26 | loss 0.00049318\n",
      "| Epoch  30 |   150/  428 batches | lr 0.00013 | ms/batch 21.49 | loss 0.00032423\n",
      "| Epoch  30 |   200/  428 batches | lr 0.00013 | ms/batch 19.60 | loss 0.00033575\n",
      "| Epoch  30 |   250/  428 batches | lr 0.00013 | ms/batch 19.39 | loss 0.00053056\n",
      "| Epoch  30 |   300/  428 batches | lr 0.00013 | ms/batch 21.03 | loss 0.00031878\n",
      "| Epoch  30 |   350/  428 batches | lr 0.00013 | ms/batch 19.48 | loss 0.00039168\n",
      "| Epoch  30 |   400/  428 batches | lr 0.00013 | ms/batch 19.49 | loss 0.00035843\n",
      "\n",
      "Val set: Average loss: 0.00062501\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  31 |    50/  428 batches | lr 0.00013 | ms/batch 18.20 | loss 0.00043640\n",
      "| Epoch  31 |   100/  428 batches | lr 0.00013 | ms/batch 19.15 | loss 0.00036618\n",
      "| Epoch  31 |   150/  428 batches | lr 0.00013 | ms/batch 17.73 | loss 0.00041874\n",
      "| Epoch  31 |   200/  428 batches | lr 0.00013 | ms/batch 19.26 | loss 0.00035222\n",
      "| Epoch  31 |   250/  428 batches | lr 0.00013 | ms/batch 17.67 | loss 0.00054615\n",
      "| Epoch  31 |   300/  428 batches | lr 0.00013 | ms/batch 19.37 | loss 0.00033714\n",
      "| Epoch  31 |   350/  428 batches | lr 0.00013 | ms/batch 17.63 | loss 0.00034793\n",
      "| Epoch  31 |   400/  428 batches | lr 0.00013 | ms/batch 17.81 | loss 0.00032377\n",
      "\n",
      "Val set: Average loss: 0.00034880\n",
      "\n",
      "| Epoch  32 |    50/  428 batches | lr 0.00013 | ms/batch 18.25 | loss 0.00039354\n",
      "| Epoch  32 |   100/  428 batches | lr 0.00013 | ms/batch 19.47 | loss 0.00034438\n",
      "| Epoch  32 |   150/  428 batches | lr 0.00013 | ms/batch 19.47 | loss 0.00042956\n",
      "| Epoch  32 |   200/  428 batches | lr 0.00013 | ms/batch 19.33 | loss 0.00039784\n",
      "| Epoch  32 |   250/  428 batches | lr 0.00013 | ms/batch 19.71 | loss 0.00060722\n",
      "| Epoch  32 |   300/  428 batches | lr 0.00013 | ms/batch 17.98 | loss 0.00035537\n",
      "| Epoch  32 |   350/  428 batches | lr 0.00013 | ms/batch 19.57 | loss 0.00037936\n",
      "| Epoch  32 |   400/  428 batches | lr 0.00013 | ms/batch 19.65 | loss 0.00043638\n",
      "\n",
      "Val set: Average loss: 0.00033458\n",
      "\n",
      "| Epoch  33 |    50/  428 batches | lr 0.00013 | ms/batch 22.00 | loss 0.00032521\n",
      "| Epoch  33 |   100/  428 batches | lr 0.00013 | ms/batch 19.78 | loss 0.00058652\n",
      "| Epoch  33 |   150/  428 batches | lr 0.00013 | ms/batch 19.53 | loss 0.00049182\n",
      "| Epoch  33 |   200/  428 batches | lr 0.00013 | ms/batch 21.54 | loss 0.00040500\n",
      "| Epoch  33 |   250/  428 batches | lr 0.00013 | ms/batch 19.82 | loss 0.00029536\n",
      "| Epoch  33 |   300/  428 batches | lr 0.00013 | ms/batch 19.60 | loss 0.00030964\n",
      "| Epoch  33 |   350/  428 batches | lr 0.00013 | ms/batch 21.47 | loss 0.00035422\n",
      "| Epoch  33 |   400/  428 batches | lr 0.00013 | ms/batch 19.64 | loss 0.00043974\n",
      "\n",
      "Val set: Average loss: 0.00030852\n",
      "\n",
      "| Epoch  34 |    50/  428 batches | lr 0.00013 | ms/batch 19.88 | loss 0.00029399\n",
      "| Epoch  34 |   100/  428 batches | lr 0.00013 | ms/batch 21.95 | loss 0.00046584\n",
      "| Epoch  34 |   150/  428 batches | lr 0.00013 | ms/batch 19.66 | loss 0.00040558\n",
      "| Epoch  34 |   200/  428 batches | lr 0.00013 | ms/batch 19.94 | loss 0.00044392\n",
      "| Epoch  34 |   250/  428 batches | lr 0.00013 | ms/batch 21.26 | loss 0.00028460\n",
      "| Epoch  34 |   300/  428 batches | lr 0.00013 | ms/batch 19.54 | loss 0.00028330\n",
      "| Epoch  34 |   350/  428 batches | lr 0.00013 | ms/batch 19.49 | loss 0.00026503\n",
      "| Epoch  34 |   400/  428 batches | lr 0.00013 | ms/batch 21.33 | loss 0.00029073\n",
      "\n",
      "Val set: Average loss: 0.00029559\n",
      "\n",
      "| Epoch  35 |    50/  428 batches | lr 0.00013 | ms/batch 22.12 | loss 0.00026101\n",
      "| Epoch  35 |   100/  428 batches | lr 0.00013 | ms/batch 19.33 | loss 0.00029526\n",
      "| Epoch  35 |   150/  428 batches | lr 0.00013 | ms/batch 19.60 | loss 0.00041331\n",
      "| Epoch  35 |   200/  428 batches | lr 0.00013 | ms/batch 21.17 | loss 0.00030351\n",
      "| Epoch  35 |   250/  428 batches | lr 0.00013 | ms/batch 19.48 | loss 0.00038764\n",
      "| Epoch  35 |   300/  428 batches | lr 0.00013 | ms/batch 19.94 | loss 0.00031747\n",
      "| Epoch  35 |   350/  428 batches | lr 0.00013 | ms/batch 21.12 | loss 0.00047182\n",
      "| Epoch  35 |   400/  428 batches | lr 0.00013 | ms/batch 19.63 | loss 0.00030179\n",
      "\n",
      "Val set: Average loss: 0.00029123\n",
      "\n",
      "| Epoch  36 |    50/  428 batches | lr 0.00013 | ms/batch 18.08 | loss 0.00025310\n",
      "| Epoch  36 |   100/  428 batches | lr 0.00013 | ms/batch 17.91 | loss 0.00057005\n",
      "| Epoch  36 |   150/  428 batches | lr 0.00013 | ms/batch 19.35 | loss 0.00040056\n",
      "| Epoch  36 |   200/  428 batches | lr 0.00013 | ms/batch 17.57 | loss 0.00040781\n",
      "| Epoch  36 |   250/  428 batches | lr 0.00013 | ms/batch 19.80 | loss 0.00032809\n",
      "| Epoch  36 |   300/  428 batches | lr 0.00013 | ms/batch 17.60 | loss 0.00026755\n",
      "| Epoch  36 |   350/  428 batches | lr 0.00013 | ms/batch 19.40 | loss 0.00025879\n",
      "| Epoch  36 |   400/  428 batches | lr 0.00013 | ms/batch 17.50 | loss 0.00026977\n",
      "\n",
      "Val set: Average loss: 0.00032756\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  37 |    50/  428 batches | lr 0.00013 | ms/batch 21.27 | loss 0.00030678\n",
      "| Epoch  37 |   100/  428 batches | lr 0.00013 | ms/batch 19.45 | loss 0.00043598\n",
      "| Epoch  37 |   150/  428 batches | lr 0.00013 | ms/batch 19.31 | loss 0.00031742\n",
      "| Epoch  37 |   200/  428 batches | lr 0.00013 | ms/batch 21.04 | loss 0.00027565\n",
      "| Epoch  37 |   250/  428 batches | lr 0.00013 | ms/batch 19.40 | loss 0.00033190\n",
      "| Epoch  37 |   300/  428 batches | lr 0.00013 | ms/batch 19.45 | loss 0.00035371\n",
      "| Epoch  37 |   350/  428 batches | lr 0.00013 | ms/batch 21.17 | loss 0.00034077\n",
      "| Epoch  37 |   400/  428 batches | lr 0.00013 | ms/batch 19.44 | loss 0.00031913\n",
      "\n",
      "Val set: Average loss: 0.00060443\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  38 |    50/  428 batches | lr 0.00013 | ms/batch 18.12 | loss 0.00028743\n",
      "| Epoch  38 |   100/  428 batches | lr 0.00013 | ms/batch 17.71 | loss 0.00032597\n",
      "| Epoch  38 |   150/  428 batches | lr 0.00013 | ms/batch 19.50 | loss 0.00031042\n",
      "| Epoch  38 |   200/  428 batches | lr 0.00013 | ms/batch 17.73 | loss 0.00036925\n",
      "| Epoch  38 |   250/  428 batches | lr 0.00013 | ms/batch 19.50 | loss 0.00052024\n",
      "| Epoch  38 |   300/  428 batches | lr 0.00013 | ms/batch 17.58 | loss 0.00032158\n",
      "| Epoch  38 |   350/  428 batches | lr 0.00013 | ms/batch 19.48 | loss 0.00028377\n",
      "| Epoch  38 |   400/  428 batches | lr 0.00013 | ms/batch 17.87 | loss 0.00035928\n",
      "\n",
      "Val set: Average loss: 0.00037033\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  39 |    50/  428 batches | lr 0.00013 | ms/batch 21.40 | loss 0.00032563\n",
      "| Epoch  39 |   100/  428 batches | lr 0.00013 | ms/batch 19.46 | loss 0.00031135\n",
      "| Epoch  39 |   150/  428 batches | lr 0.00013 | ms/batch 19.27 | loss 0.00033826\n",
      "| Epoch  39 |   200/  428 batches | lr 0.00013 | ms/batch 21.22 | loss 0.00031463\n",
      "| Epoch  39 |   250/  428 batches | lr 0.00013 | ms/batch 19.57 | loss 0.00036469\n",
      "| Epoch  39 |   300/  428 batches | lr 0.00013 | ms/batch 19.72 | loss 0.00028077\n",
      "| Epoch  39 |   350/  428 batches | lr 0.00013 | ms/batch 20.96 | loss 0.00027128\n",
      "| Epoch  39 |   400/  428 batches | lr 0.00013 | ms/batch 19.86 | loss 0.00026284\n",
      "\n",
      "Val set: Average loss: 0.00038055\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch  40 |    50/  428 batches | lr 0.00013 | ms/batch 18.17 | loss 0.00030283\n",
      "| Epoch  40 |   100/  428 batches | lr 0.00013 | ms/batch 19.12 | loss 0.00042220\n",
      "| Epoch  40 |   150/  428 batches | lr 0.00013 | ms/batch 18.17 | loss 0.00045861\n",
      "| Epoch  40 |   200/  428 batches | lr 0.00013 | ms/batch 17.88 | loss 0.00051337\n",
      "| Epoch  40 |   250/  428 batches | lr 0.00013 | ms/batch 19.57 | loss 0.00030427\n",
      "| Epoch  40 |   300/  428 batches | lr 0.00013 | ms/batch 17.92 | loss 0.00032102\n",
      "| Epoch  40 |   350/  428 batches | lr 0.00013 | ms/batch 19.23 | loss 0.00030879\n",
      "| Epoch  40 |   400/  428 batches | lr 0.00013 | ms/batch 17.51 | loss 0.00041794\n",
      "\n",
      "Val set: Average loss: 0.00030282\n",
      "\n",
      "EarlyStopping counter: 5 out of 20\n",
      "| Epoch  41 |    50/  428 batches | lr 0.00013 | ms/batch 21.87 | loss 0.00029462\n",
      "| Epoch  41 |   100/  428 batches | lr 0.00013 | ms/batch 19.67 | loss 0.00046459\n",
      "| Epoch  41 |   150/  428 batches | lr 0.00013 | ms/batch 19.72 | loss 0.00049153\n",
      "| Epoch  41 |   200/  428 batches | lr 0.00013 | ms/batch 21.48 | loss 0.00034468\n",
      "| Epoch  41 |   250/  428 batches | lr 0.00013 | ms/batch 19.76 | loss 0.00024241\n",
      "| Epoch  41 |   300/  428 batches | lr 0.00013 | ms/batch 19.83 | loss 0.00027414\n",
      "| Epoch  41 |   350/  428 batches | lr 0.00013 | ms/batch 21.62 | loss 0.00031106\n",
      "| Epoch  41 |   400/  428 batches | lr 0.00013 | ms/batch 19.50 | loss 0.00048693\n",
      "\n",
      "Val set: Average loss: 0.00028692\n",
      "\n",
      "| Epoch  42 |    50/  428 batches | lr 0.00013 | ms/batch 20.35 | loss 0.00028213\n",
      "| Epoch  42 |   100/  428 batches | lr 0.00013 | ms/batch 21.13 | loss 0.00044430\n",
      "| Epoch  42 |   150/  428 batches | lr 0.00013 | ms/batch 19.44 | loss 0.00035534\n",
      "| Epoch  42 |   200/  428 batches | lr 0.00013 | ms/batch 19.79 | loss 0.00030572\n",
      "| Epoch  42 |   250/  428 batches | lr 0.00013 | ms/batch 21.61 | loss 0.00023120\n",
      "| Epoch  42 |   300/  428 batches | lr 0.00013 | ms/batch 19.50 | loss 0.00025328\n",
      "| Epoch  42 |   350/  428 batches | lr 0.00013 | ms/batch 19.53 | loss 0.00024865\n",
      "| Epoch  42 |   400/  428 batches | lr 0.00013 | ms/batch 21.34 | loss 0.00032569\n",
      "\n",
      "Val set: Average loss: 0.00025421\n",
      "\n",
      "| Epoch  43 |    50/  428 batches | lr 0.00013 | ms/batch 19.87 | loss 0.00024904\n",
      "| Epoch  43 |   100/  428 batches | lr 0.00013 | ms/batch 21.86 | loss 0.00025630\n",
      "| Epoch  43 |   150/  428 batches | lr 0.00013 | ms/batch 19.51 | loss 0.00025312\n",
      "| Epoch  43 |   200/  428 batches | lr 0.00013 | ms/batch 19.52 | loss 0.00024097\n",
      "| Epoch  43 |   250/  428 batches | lr 0.00013 | ms/batch 21.05 | loss 0.00029459\n",
      "| Epoch  43 |   300/  428 batches | lr 0.00013 | ms/batch 19.35 | loss 0.00032450\n",
      "| Epoch  43 |   350/  428 batches | lr 0.00013 | ms/batch 19.36 | loss 0.00026213\n",
      "| Epoch  43 |   400/  428 batches | lr 0.00013 | ms/batch 20.95 | loss 0.00029707\n",
      "\n",
      "Val set: Average loss: 0.00026582\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  44 |    50/  428 batches | lr 0.00013 | ms/batch 19.54 | loss 0.00027310\n",
      "| Epoch  44 |   100/  428 batches | lr 0.00013 | ms/batch 17.72 | loss 0.00033209\n",
      "| Epoch  44 |   150/  428 batches | lr 0.00013 | ms/batch 19.41 | loss 0.00035381\n",
      "| Epoch  44 |   200/  428 batches | lr 0.00013 | ms/batch 17.65 | loss 0.00026273\n",
      "| Epoch  44 |   250/  428 batches | lr 0.00013 | ms/batch 19.24 | loss 0.00033918\n",
      "| Epoch  44 |   300/  428 batches | lr 0.00013 | ms/batch 17.49 | loss 0.00028562\n",
      "| Epoch  44 |   350/  428 batches | lr 0.00013 | ms/batch 17.65 | loss 0.00027431\n",
      "| Epoch  44 |   400/  428 batches | lr 0.00013 | ms/batch 20.10 | loss 0.00026258\n",
      "\n",
      "Val set: Average loss: 0.00027279\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  45 |    50/  428 batches | lr 0.00013 | ms/batch 20.13 | loss 0.00043637\n",
      "| Epoch  45 |   100/  428 batches | lr 0.00013 | ms/batch 21.22 | loss 0.00028679\n",
      "| Epoch  45 |   150/  428 batches | lr 0.00013 | ms/batch 19.46 | loss 0.00027898\n",
      "| Epoch  45 |   200/  428 batches | lr 0.00013 | ms/batch 19.49 | loss 0.00031154\n",
      "| Epoch  45 |   250/  428 batches | lr 0.00013 | ms/batch 20.87 | loss 0.00041279\n",
      "| Epoch  45 |   300/  428 batches | lr 0.00013 | ms/batch 20.47 | loss 0.00027210\n",
      "| Epoch  45 |   350/  428 batches | lr 0.00013 | ms/batch 19.75 | loss 0.00035537\n",
      "| Epoch  45 |   400/  428 batches | lr 0.00013 | ms/batch 21.54 | loss 0.00030376\n",
      "\n",
      "Val set: Average loss: 0.00026272\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  46 |    50/  428 batches | lr 0.00013 | ms/batch 18.33 | loss 0.00025706\n",
      "| Epoch  46 |   100/  428 batches | lr 0.00013 | ms/batch 17.59 | loss 0.00027399\n",
      "| Epoch  46 |   150/  428 batches | lr 0.00013 | ms/batch 19.06 | loss 0.00023540\n",
      "| Epoch  46 |   200/  428 batches | lr 0.00013 | ms/batch 17.50 | loss 0.00027484\n",
      "| Epoch  46 |   250/  428 batches | lr 0.00013 | ms/batch 19.31 | loss 0.00043425\n",
      "| Epoch  46 |   300/  428 batches | lr 0.00013 | ms/batch 18.18 | loss 0.00024052\n",
      "| Epoch  46 |   350/  428 batches | lr 0.00013 | ms/batch 17.64 | loss 0.00030657\n",
      "| Epoch  46 |   400/  428 batches | lr 0.00013 | ms/batch 19.15 | loss 0.00026263\n",
      "\n",
      "Val set: Average loss: 0.00049219\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch  47 |    50/  428 batches | lr 0.00013 | ms/batch 19.67 | loss 0.00026198\n",
      "| Epoch  47 |   100/  428 batches | lr 0.00013 | ms/batch 21.04 | loss 0.00024333\n",
      "| Epoch  47 |   150/  428 batches | lr 0.00013 | ms/batch 19.37 | loss 0.00029656\n",
      "| Epoch  47 |   200/  428 batches | lr 0.00013 | ms/batch 19.35 | loss 0.00038762\n",
      "| Epoch  47 |   250/  428 batches | lr 0.00013 | ms/batch 20.88 | loss 0.00032187\n",
      "| Epoch  47 |   300/  428 batches | lr 0.00013 | ms/batch 19.29 | loss 0.00022472\n",
      "| Epoch  47 |   350/  428 batches | lr 0.00013 | ms/batch 19.46 | loss 0.00029113\n",
      "| Epoch  47 |   400/  428 batches | lr 0.00013 | ms/batch 21.02 | loss 0.00025849\n",
      "\n",
      "Val set: Average loss: 0.00030821\n",
      "\n",
      "EarlyStopping counter: 5 out of 20\n",
      "| Epoch  48 |    50/  428 batches | lr 0.00013 | ms/batch 17.82 | loss 0.00030108\n",
      "| Epoch  48 |   100/  428 batches | lr 0.00013 | ms/batch 17.46 | loss 0.00029644\n",
      "| Epoch  48 |   150/  428 batches | lr 0.00013 | ms/batch 19.20 | loss 0.00030577\n",
      "| Epoch  48 |   200/  428 batches | lr 0.00013 | ms/batch 17.56 | loss 0.00029750\n",
      "| Epoch  48 |   250/  428 batches | lr 0.00013 | ms/batch 19.07 | loss 0.00028215\n",
      "| Epoch  48 |   300/  428 batches | lr 0.00013 | ms/batch 17.47 | loss 0.00027722\n",
      "| Epoch  48 |   350/  428 batches | lr 0.00013 | ms/batch 17.51 | loss 0.00042740\n",
      "| Epoch  48 |   400/  428 batches | lr 0.00013 | ms/batch 19.02 | loss 0.00032585\n",
      "\n",
      "Val set: Average loss: 0.00026565\n",
      "\n",
      "EarlyStopping counter: 6 out of 20\n",
      "| Epoch  49 |    50/  428 batches | lr 0.00013 | ms/batch 19.69 | loss 0.00027359\n",
      "| Epoch  49 |   100/  428 batches | lr 0.00013 | ms/batch 20.86 | loss 0.00026758\n",
      "| Epoch  49 |   150/  428 batches | lr 0.00013 | ms/batch 19.30 | loss 0.00031115\n",
      "| Epoch  49 |   200/  428 batches | lr 0.00013 | ms/batch 19.32 | loss 0.00044064\n",
      "| Epoch  49 |   250/  428 batches | lr 0.00013 | ms/batch 20.89 | loss 0.00027027\n",
      "| Epoch  49 |   300/  428 batches | lr 0.00013 | ms/batch 19.41 | loss 0.00028516\n",
      "| Epoch  49 |   350/  428 batches | lr 0.00013 | ms/batch 19.45 | loss 0.00025189\n",
      "| Epoch  49 |   400/  428 batches | lr 0.00013 | ms/batch 20.84 | loss 0.00035970\n",
      "\n",
      "Val set: Average loss: 0.00026621\n",
      "\n",
      "EarlyStopping counter: 7 out of 20\n",
      "| Epoch  50 |    50/  428 batches | lr 0.00013 | ms/batch 17.96 | loss 0.00027092\n",
      "| Epoch  50 |   100/  428 batches | lr 0.00013 | ms/batch 17.59 | loss 0.00033003\n",
      "| Epoch  50 |   150/  428 batches | lr 0.00013 | ms/batch 19.16 | loss 0.00031866\n",
      "| Epoch  50 |   200/  428 batches | lr 0.00013 | ms/batch 17.57 | loss 0.00045021\n",
      "| Epoch  50 |   250/  428 batches | lr 0.00013 | ms/batch 19.06 | loss 0.00023827\n",
      "| Epoch  50 |   300/  428 batches | lr 0.00013 | ms/batch 17.43 | loss 0.00025110\n",
      "| Epoch  50 |   350/  428 batches | lr 0.00013 | ms/batch 17.47 | loss 0.00025526\n",
      "| Epoch  50 |   400/  428 batches | lr 0.00013 | ms/batch 19.08 | loss 0.00042786\n",
      "\n",
      "Val set: Average loss: 0.00025937\n",
      "\n",
      "EarlyStopping counter: 8 out of 20\n",
      "| Epoch  51 |    50/  428 batches | lr 0.00013 | ms/batch 19.78 | loss 0.00025466\n",
      "| Epoch  51 |   100/  428 batches | lr 0.00013 | ms/batch 20.84 | loss 0.00037915\n",
      "| Epoch  51 |   150/  428 batches | lr 0.00013 | ms/batch 19.23 | loss 0.00034181\n",
      "| Epoch  51 |   200/  428 batches | lr 0.00013 | ms/batch 19.45 | loss 0.00036109\n",
      "| Epoch  51 |   250/  428 batches | lr 0.00013 | ms/batch 22.33 | loss 0.00023107\n",
      "| Epoch  51 |   300/  428 batches | lr 0.00013 | ms/batch 19.38 | loss 0.00023503\n",
      "| Epoch  51 |   350/  428 batches | lr 0.00013 | ms/batch 19.62 | loss 0.00024582\n",
      "| Epoch  51 |   400/  428 batches | lr 0.00013 | ms/batch 21.34 | loss 0.00067214\n",
      "\n",
      "Val set: Average loss: 0.00027579\n",
      "\n",
      "EarlyStopping counter: 9 out of 20\n",
      "| Epoch  52 |    50/  428 batches | lr 0.00013 | ms/batch 18.15 | loss 0.00030382\n",
      "| Epoch  52 |   100/  428 batches | lr 0.00013 | ms/batch 17.74 | loss 0.00028280\n",
      "| Epoch  52 |   150/  428 batches | lr 0.00013 | ms/batch 19.32 | loss 0.00029912\n",
      "| Epoch  52 |   200/  428 batches | lr 0.00013 | ms/batch 18.03 | loss 0.00031440\n",
      "| Epoch  52 |   250/  428 batches | lr 0.00013 | ms/batch 19.19 | loss 0.00032222\n",
      "| Epoch  52 |   300/  428 batches | lr 0.00013 | ms/batch 17.76 | loss 0.00032805\n",
      "| Epoch  52 |   350/  428 batches | lr 0.00013 | ms/batch 17.81 | loss 0.00025744\n",
      "| Epoch  52 |   400/  428 batches | lr 0.00013 | ms/batch 19.46 | loss 0.00034660\n",
      "\n",
      "Val set: Average loss: 0.00028222\n",
      "\n",
      "EarlyStopping counter: 10 out of 20\n",
      "| Epoch  53 |    50/  428 batches | lr 0.00013 | ms/batch 19.78 | loss 0.00026459\n",
      "| Epoch  53 |   100/  428 batches | lr 0.00013 | ms/batch 21.08 | loss 0.00029767\n",
      "| Epoch  53 |   150/  428 batches | lr 0.00013 | ms/batch 19.64 | loss 0.00023961\n",
      "| Epoch  53 |   200/  428 batches | lr 0.00013 | ms/batch 19.44 | loss 0.00025521\n",
      "| Epoch  53 |   250/  428 batches | lr 0.00013 | ms/batch 20.97 | loss 0.00020690\n",
      "| Epoch  53 |   300/  428 batches | lr 0.00013 | ms/batch 19.33 | loss 0.00020663\n",
      "| Epoch  53 |   350/  428 batches | lr 0.00013 | ms/batch 19.85 | loss 0.00019021\n",
      "| Epoch  53 |   400/  428 batches | lr 0.00013 | ms/batch 21.61 | loss 0.00024707\n",
      "\n",
      "Val set: Average loss: 0.00021947\n",
      "\n",
      "| Epoch  54 |    50/  428 batches | lr 0.00013 | ms/batch 20.04 | loss 0.00020685\n",
      "| Epoch  54 |   100/  428 batches | lr 0.00013 | ms/batch 19.84 | loss 0.00021092\n",
      "| Epoch  54 |   150/  428 batches | lr 0.00013 | ms/batch 21.22 | loss 0.00020106\n",
      "| Epoch  54 |   200/  428 batches | lr 0.00013 | ms/batch 20.00 | loss 0.00023099\n",
      "| Epoch  54 |   250/  428 batches | lr 0.00013 | ms/batch 20.18 | loss 0.00034146\n",
      "| Epoch  54 |   300/  428 batches | lr 0.00013 | ms/batch 21.73 | loss 0.00023340\n",
      "| Epoch  54 |   350/  428 batches | lr 0.00013 | ms/batch 20.42 | loss 0.00024142\n",
      "| Epoch  54 |   400/  428 batches | lr 0.00013 | ms/batch 19.67 | loss 0.00025016\n",
      "\n",
      "Val set: Average loss: 0.00025698\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  55 |    50/  428 batches | lr 0.00013 | ms/batch 18.30 | loss 0.00032851\n",
      "| Epoch  55 |   100/  428 batches | lr 0.00013 | ms/batch 19.49 | loss 0.00024100\n",
      "| Epoch  55 |   150/  428 batches | lr 0.00013 | ms/batch 17.49 | loss 0.00021066\n",
      "| Epoch  55 |   200/  428 batches | lr 0.00013 | ms/batch 19.34 | loss 0.00033958\n",
      "| Epoch  55 |   250/  428 batches | lr 0.00013 | ms/batch 17.57 | loss 0.00029275\n",
      "| Epoch  55 |   300/  428 batches | lr 0.00013 | ms/batch 19.14 | loss 0.00024006\n",
      "| Epoch  55 |   350/  428 batches | lr 0.00013 | ms/batch 17.82 | loss 0.00029111\n",
      "| Epoch  55 |   400/  428 batches | lr 0.00013 | ms/batch 17.88 | loss 0.00022080\n",
      "\n",
      "Val set: Average loss: 0.00075480\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  56 |    50/  428 batches | lr 0.00013 | ms/batch 19.84 | loss 0.00026989\n",
      "| Epoch  56 |   100/  428 batches | lr 0.00013 | ms/batch 19.58 | loss 0.00024638\n",
      "| Epoch  56 |   150/  428 batches | lr 0.00013 | ms/batch 21.29 | loss 0.00021761\n",
      "| Epoch  56 |   200/  428 batches | lr 0.00013 | ms/batch 20.46 | loss 0.00034344\n",
      "| Epoch  56 |   250/  428 batches | lr 0.00013 | ms/batch 19.64 | loss 0.00028591\n",
      "| Epoch  56 |   300/  428 batches | lr 0.00013 | ms/batch 21.94 | loss 0.00023383\n",
      "| Epoch  56 |   350/  428 batches | lr 0.00013 | ms/batch 19.87 | loss 0.00027454\n",
      "| Epoch  56 |   400/  428 batches | lr 0.00013 | ms/batch 20.18 | loss 0.00020841\n",
      "\n",
      "Val set: Average loss: 0.00067515\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  57 |    50/  428 batches | lr 0.00013 | ms/batch 19.95 | loss 0.00035618\n",
      "| Epoch  57 |   100/  428 batches | lr 0.00013 | ms/batch 19.48 | loss 0.00024583\n",
      "| Epoch  57 |   150/  428 batches | lr 0.00013 | ms/batch 17.60 | loss 0.00020715\n",
      "| Epoch  57 |   200/  428 batches | lr 0.00013 | ms/batch 19.19 | loss 0.00030247\n",
      "| Epoch  57 |   250/  428 batches | lr 0.00013 | ms/batch 19.18 | loss 0.00028594\n",
      "| Epoch  57 |   300/  428 batches | lr 0.00013 | ms/batch 19.30 | loss 0.00025709\n",
      "| Epoch  57 |   350/  428 batches | lr 0.00013 | ms/batch 19.23 | loss 0.00035816\n",
      "| Epoch  57 |   400/  428 batches | lr 0.00013 | ms/batch 17.55 | loss 0.00031776\n",
      "\n",
      "Val set: Average loss: 0.00022078\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch  58 |    50/  428 batches | lr 0.00013 | ms/batch 19.71 | loss 0.00025291\n",
      "| Epoch  58 |   100/  428 batches | lr 0.00013 | ms/batch 21.80 | loss 0.00024930\n",
      "| Epoch  58 |   150/  428 batches | lr 0.00013 | ms/batch 19.66 | loss 0.00024540\n",
      "| Epoch  58 |   200/  428 batches | lr 0.00013 | ms/batch 19.65 | loss 0.00037137\n",
      "| Epoch  58 |   250/  428 batches | lr 0.00013 | ms/batch 21.48 | loss 0.00023347\n",
      "| Epoch  58 |   300/  428 batches | lr 0.00013 | ms/batch 19.63 | loss 0.00024433\n",
      "| Epoch  58 |   350/  428 batches | lr 0.00013 | ms/batch 20.12 | loss 0.00024077\n",
      "| Epoch  58 |   400/  428 batches | lr 0.00013 | ms/batch 21.32 | loss 0.00026414\n",
      "\n",
      "Val set: Average loss: 0.00025044\n",
      "\n",
      "EarlyStopping counter: 5 out of 20\n",
      "| Epoch  59 |    50/  428 batches | lr 0.00013 | ms/batch 20.57 | loss 0.00021384\n",
      "| Epoch  59 |   100/  428 batches | lr 0.00013 | ms/batch 17.98 | loss 0.00020966\n",
      "| Epoch  59 |   150/  428 batches | lr 0.00013 | ms/batch 17.77 | loss 0.00019485\n",
      "| Epoch  59 |   200/  428 batches | lr 0.00013 | ms/batch 19.64 | loss 0.00022367\n",
      "| Epoch  59 |   250/  428 batches | lr 0.00013 | ms/batch 17.66 | loss 0.00030268\n",
      "| Epoch  59 |   300/  428 batches | lr 0.00013 | ms/batch 19.64 | loss 0.00024134\n",
      "| Epoch  59 |   350/  428 batches | lr 0.00013 | ms/batch 17.68 | loss 0.00025648\n",
      "| Epoch  59 |   400/  428 batches | lr 0.00013 | ms/batch 19.21 | loss 0.00020459\n",
      "\n",
      "Val set: Average loss: 0.00025175\n",
      "\n",
      "EarlyStopping counter: 6 out of 20\n",
      "| Epoch  60 |    50/  428 batches | lr 0.00013 | ms/batch 19.91 | loss 0.00023272\n",
      "| Epoch  60 |   100/  428 batches | lr 0.00013 | ms/batch 19.56 | loss 0.00023844\n",
      "| Epoch  60 |   150/  428 batches | lr 0.00013 | ms/batch 21.85 | loss 0.00029307\n",
      "| Epoch  60 |   200/  428 batches | lr 0.00013 | ms/batch 19.77 | loss 0.00023754\n",
      "| Epoch  60 |   250/  428 batches | lr 0.00013 | ms/batch 19.50 | loss 0.00035465\n",
      "| Epoch  60 |   300/  428 batches | lr 0.00013 | ms/batch 21.09 | loss 0.00024961\n",
      "| Epoch  60 |   350/  428 batches | lr 0.00013 | ms/batch 19.49 | loss 0.00025998\n",
      "| Epoch  60 |   400/  428 batches | lr 0.00013 | ms/batch 19.60 | loss 0.00025683\n",
      "\n",
      "Val set: Average loss: 0.00020871\n",
      "\n",
      "| Epoch  61 |    50/  428 batches | lr 0.00013 | ms/batch 19.85 | loss 0.00025807\n",
      "| Epoch  61 |   100/  428 batches | lr 0.00013 | ms/batch 17.98 | loss 0.00022297\n",
      "| Epoch  61 |   150/  428 batches | lr 0.00013 | ms/batch 17.95 | loss 0.00026498\n",
      "| Epoch  61 |   200/  428 batches | lr 0.00013 | ms/batch 19.38 | loss 0.00031045\n",
      "| Epoch  61 |   250/  428 batches | lr 0.00013 | ms/batch 17.76 | loss 0.00025619\n",
      "| Epoch  61 |   300/  428 batches | lr 0.00013 | ms/batch 19.26 | loss 0.00025621\n",
      "| Epoch  61 |   350/  428 batches | lr 0.00013 | ms/batch 17.85 | loss 0.00027189\n",
      "| Epoch  61 |   400/  428 batches | lr 0.00013 | ms/batch 17.68 | loss 0.00026161\n",
      "\n",
      "Val set: Average loss: 0.00026001\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  62 |    50/  428 batches | lr 0.00013 | ms/batch 20.11 | loss 0.00021825\n",
      "| Epoch  62 |   100/  428 batches | lr 0.00013 | ms/batch 19.52 | loss 0.00020385\n",
      "| Epoch  62 |   150/  428 batches | lr 0.00013 | ms/batch 21.17 | loss 0.00023234\n",
      "| Epoch  62 |   200/  428 batches | lr 0.00013 | ms/batch 19.36 | loss 0.00022885\n",
      "| Epoch  62 |   250/  428 batches | lr 0.00013 | ms/batch 19.36 | loss 0.00023736\n",
      "| Epoch  62 |   300/  428 batches | lr 0.00013 | ms/batch 21.06 | loss 0.00022084\n",
      "| Epoch  62 |   350/  428 batches | lr 0.00013 | ms/batch 19.31 | loss 0.00029353\n",
      "| Epoch  62 |   400/  428 batches | lr 0.00013 | ms/batch 19.31 | loss 0.00020530\n",
      "\n",
      "Val set: Average loss: 0.00022499\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  63 |    50/  428 batches | lr 0.00013 | ms/batch 19.70 | loss 0.00038951\n",
      "| Epoch  63 |   100/  428 batches | lr 0.00013 | ms/batch 19.24 | loss 0.00026865\n",
      "| Epoch  63 |   150/  428 batches | lr 0.00013 | ms/batch 19.20 | loss 0.00025783\n",
      "| Epoch  63 |   200/  428 batches | lr 0.00013 | ms/batch 17.61 | loss 0.00038982\n",
      "| Epoch  63 |   250/  428 batches | lr 0.00013 | ms/batch 19.32 | loss 0.00023167\n",
      "| Epoch  63 |   300/  428 batches | lr 0.00013 | ms/batch 19.51 | loss 0.00022081\n",
      "| Epoch  63 |   350/  428 batches | lr 0.00013 | ms/batch 19.36 | loss 0.00024643\n",
      "| Epoch  63 |   400/  428 batches | lr 0.00013 | ms/batch 17.67 | loss 0.00028789\n",
      "\n",
      "Val set: Average loss: 0.00028868\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  64 |    50/  428 batches | lr 0.00013 | ms/batch 19.69 | loss 0.00023201\n",
      "| Epoch  64 |   100/  428 batches | lr 0.00013 | ms/batch 21.00 | loss 0.00023268\n",
      "| Epoch  64 |   150/  428 batches | lr 0.00013 | ms/batch 19.46 | loss 0.00032589\n",
      "| Epoch  64 |   200/  428 batches | lr 0.00013 | ms/batch 19.44 | loss 0.00041347\n",
      "| Epoch  64 |   250/  428 batches | lr 0.00013 | ms/batch 21.01 | loss 0.00021667\n",
      "| Epoch  64 |   300/  428 batches | lr 0.00013 | ms/batch 19.81 | loss 0.00023348\n",
      "| Epoch  64 |   350/  428 batches | lr 0.00013 | ms/batch 19.35 | loss 0.00023954\n",
      "| Epoch  64 |   400/  428 batches | lr 0.00013 | ms/batch 21.01 | loss 0.00030544\n",
      "\n",
      "Val set: Average loss: 0.00024158\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch  65 |    50/  428 batches | lr 0.00013 | ms/batch 19.81 | loss 0.00024061\n",
      "| Epoch  65 |   100/  428 batches | lr 0.00013 | ms/batch 17.66 | loss 0.00030437\n",
      "| Epoch  65 |   150/  428 batches | lr 0.00013 | ms/batch 20.10 | loss 0.00042030\n",
      "| Epoch  65 |   200/  428 batches | lr 0.00013 | ms/batch 18.08 | loss 0.00027438\n",
      "| Epoch  65 |   250/  428 batches | lr 0.00013 | ms/batch 17.63 | loss 0.00022320\n",
      "| Epoch  65 |   300/  428 batches | lr 0.00013 | ms/batch 19.37 | loss 0.00022302\n",
      "| Epoch  65 |   350/  428 batches | lr 0.00013 | ms/batch 17.69 | loss 0.00021449\n",
      "| Epoch  65 |   400/  428 batches | lr 0.00013 | ms/batch 19.23 | loss 0.00048016\n",
      "\n",
      "Val set: Average loss: 0.00027642\n",
      "\n",
      "EarlyStopping counter: 5 out of 20\n",
      "| Epoch  66 |    50/  428 batches | lr 0.00013 | ms/batch 20.20 | loss 0.00025460\n",
      "| Epoch  66 |   100/  428 batches | lr 0.00013 | ms/batch 20.96 | loss 0.00032577\n",
      "| Epoch  66 |   150/  428 batches | lr 0.00013 | ms/batch 19.55 | loss 0.00026591\n",
      "| Epoch  66 |   200/  428 batches | lr 0.00013 | ms/batch 20.31 | loss 0.00022388\n",
      "| Epoch  66 |   250/  428 batches | lr 0.00013 | ms/batch 21.81 | loss 0.00026016\n",
      "| Epoch  66 |   300/  428 batches | lr 0.00013 | ms/batch 19.79 | loss 0.00029017\n",
      "| Epoch  66 |   350/  428 batches | lr 0.00013 | ms/batch 19.85 | loss 0.00025513\n",
      "| Epoch  66 |   400/  428 batches | lr 0.00013 | ms/batch 21.06 | loss 0.00028855\n",
      "\n",
      "Val set: Average loss: 0.00024477\n",
      "\n",
      "EarlyStopping counter: 6 out of 20\n",
      "| Epoch  67 |    50/  428 batches | lr 0.00013 | ms/batch 19.71 | loss 0.00023292\n",
      "| Epoch  67 |   100/  428 batches | lr 0.00013 | ms/batch 19.14 | loss 0.00029330\n",
      "| Epoch  67 |   150/  428 batches | lr 0.00013 | ms/batch 19.25 | loss 0.00021824\n",
      "| Epoch  67 |   200/  428 batches | lr 0.00013 | ms/batch 19.35 | loss 0.00020123\n",
      "| Epoch  67 |   250/  428 batches | lr 0.00013 | ms/batch 17.68 | loss 0.00019235\n",
      "| Epoch  67 |   300/  428 batches | lr 0.00013 | ms/batch 19.25 | loss 0.00018458\n",
      "| Epoch  67 |   350/  428 batches | lr 0.00013 | ms/batch 19.19 | loss 0.00017209\n",
      "| Epoch  67 |   400/  428 batches | lr 0.00013 | ms/batch 19.61 | loss 0.00021889\n",
      "\n",
      "Val set: Average loss: 0.00019555\n",
      "\n",
      "| Epoch  68 |    50/  428 batches | lr 0.00013 | ms/batch 21.51 | loss 0.00018795\n",
      "| Epoch  68 |   100/  428 batches | lr 0.00013 | ms/batch 19.28 | loss 0.00017818\n",
      "| Epoch  68 |   150/  428 batches | lr 0.00013 | ms/batch 19.24 | loss 0.00019727\n",
      "| Epoch  68 |   200/  428 batches | lr 0.00013 | ms/batch 20.91 | loss 0.00020051\n",
      "| Epoch  68 |   250/  428 batches | lr 0.00013 | ms/batch 19.52 | loss 0.00024416\n",
      "| Epoch  68 |   300/  428 batches | lr 0.00013 | ms/batch 19.50 | loss 0.00023776\n",
      "| Epoch  68 |   350/  428 batches | lr 0.00013 | ms/batch 21.06 | loss 0.00020568\n",
      "| Epoch  68 |   400/  428 batches | lr 0.00013 | ms/batch 19.64 | loss 0.00022755\n",
      "\n",
      "Val set: Average loss: 0.00020475\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  69 |    50/  428 batches | lr 0.00013 | ms/batch 18.73 | loss 0.00023128\n",
      "| Epoch  69 |   100/  428 batches | lr 0.00013 | ms/batch 17.54 | loss 0.00026672\n",
      "| Epoch  69 |   150/  428 batches | lr 0.00013 | ms/batch 19.21 | loss 0.00021821\n",
      "| Epoch  69 |   200/  428 batches | lr 0.00013 | ms/batch 17.51 | loss 0.00018733\n",
      "| Epoch  69 |   250/  428 batches | lr 0.00013 | ms/batch 19.19 | loss 0.00036031\n",
      "| Epoch  69 |   300/  428 batches | lr 0.00013 | ms/batch 17.63 | loss 0.00019374\n",
      "| Epoch  69 |   350/  428 batches | lr 0.00013 | ms/batch 19.66 | loss 0.00022164\n",
      "| Epoch  69 |   400/  428 batches | lr 0.00013 | ms/batch 17.98 | loss 0.00022669\n",
      "\n",
      "Val set: Average loss: 0.00049199\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  70 |    50/  428 batches | lr 0.00013 | ms/batch 22.60 | loss 0.00022570\n",
      "| Epoch  70 |   100/  428 batches | lr 0.00013 | ms/batch 19.58 | loss 0.00025072\n",
      "| Epoch  70 |   150/  428 batches | lr 0.00013 | ms/batch 20.13 | loss 0.00023235\n",
      "| Epoch  70 |   200/  428 batches | lr 0.00013 | ms/batch 21.68 | loss 0.00023880\n",
      "| Epoch  70 |   250/  428 batches | lr 0.00013 | ms/batch 19.65 | loss 0.00041293\n",
      "| Epoch  70 |   300/  428 batches | lr 0.00013 | ms/batch 19.38 | loss 0.00020187\n",
      "| Epoch  70 |   350/  428 batches | lr 0.00013 | ms/batch 21.38 | loss 0.00020114\n",
      "| Epoch  70 |   400/  428 batches | lr 0.00013 | ms/batch 20.17 | loss 0.00021521\n",
      "\n",
      "Val set: Average loss: 0.00020177\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  71 |    50/  428 batches | lr 0.00013 | ms/batch 18.20 | loss 0.00024007\n",
      "| Epoch  71 |   100/  428 batches | lr 0.00013 | ms/batch 17.76 | loss 0.00022709\n",
      "| Epoch  71 |   150/  428 batches | lr 0.00013 | ms/batch 19.48 | loss 0.00025300\n",
      "| Epoch  71 |   200/  428 batches | lr 0.00013 | ms/batch 17.49 | loss 0.00026164\n",
      "| Epoch  71 |   250/  428 batches | lr 0.00013 | ms/batch 19.53 | loss 0.00021673\n",
      "| Epoch  71 |   300/  428 batches | lr 0.00013 | ms/batch 17.73 | loss 0.00017818\n",
      "| Epoch  71 |   350/  428 batches | lr 0.00013 | ms/batch 19.46 | loss 0.00017572\n",
      "| Epoch  71 |   400/  428 batches | lr 0.00013 | ms/batch 17.69 | loss 0.00025710\n",
      "\n",
      "Val set: Average loss: 0.00031177\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch  72 |    50/  428 batches | lr 0.00013 | ms/batch 22.56 | loss 0.00019412\n",
      "| Epoch  72 |   100/  428 batches | lr 0.00013 | ms/batch 19.72 | loss 0.00026414\n",
      "| Epoch  72 |   150/  428 batches | lr 0.00013 | ms/batch 19.92 | loss 0.00037157\n",
      "| Epoch  72 |   200/  428 batches | lr 0.00013 | ms/batch 21.17 | loss 0.00030384\n",
      "| Epoch  72 |   250/  428 batches | lr 0.00013 | ms/batch 19.71 | loss 0.00021025\n",
      "| Epoch  72 |   300/  428 batches | lr 0.00013 | ms/batch 19.56 | loss 0.00018753\n",
      "| Epoch  72 |   350/  428 batches | lr 0.00013 | ms/batch 21.02 | loss 0.00020107\n",
      "| Epoch  72 |   400/  428 batches | lr 0.00013 | ms/batch 19.36 | loss 0.00022890\n",
      "\n",
      "Val set: Average loss: 0.00028810\n",
      "\n",
      "EarlyStopping counter: 5 out of 20\n",
      "| Epoch  73 |    50/  428 batches | lr 0.00013 | ms/batch 17.86 | loss 0.00027348\n",
      "| Epoch  73 |   100/  428 batches | lr 0.00013 | ms/batch 19.17 | loss 0.00023335\n",
      "| Epoch  73 |   150/  428 batches | lr 0.00013 | ms/batch 17.60 | loss 0.00025380\n",
      "| Epoch  73 |   200/  428 batches | lr 0.00013 | ms/batch 17.53 | loss 0.00021785\n",
      "| Epoch  73 |   250/  428 batches | lr 0.00013 | ms/batch 19.15 | loss 0.00019382\n",
      "| Epoch  73 |   300/  428 batches | lr 0.00013 | ms/batch 17.51 | loss 0.00018708\n",
      "| Epoch  73 |   350/  428 batches | lr 0.00013 | ms/batch 19.06 | loss 0.00021594\n",
      "| Epoch  73 |   400/  428 batches | lr 0.00013 | ms/batch 17.49 | loss 0.00021086\n",
      "\n",
      "Val set: Average loss: 0.00019887\n",
      "\n",
      "EarlyStopping counter: 6 out of 20\n",
      "| Epoch  74 |    50/  428 batches | lr 0.00013 | ms/batch 21.38 | loss 0.00026963\n",
      "| Epoch  74 |   100/  428 batches | lr 0.00013 | ms/batch 19.34 | loss 0.00021535\n",
      "| Epoch  74 |   150/  428 batches | lr 0.00013 | ms/batch 19.28 | loss 0.00020504\n",
      "| Epoch  74 |   200/  428 batches | lr 0.00013 | ms/batch 20.89 | loss 0.00025590\n",
      "| Epoch  74 |   250/  428 batches | lr 0.00013 | ms/batch 19.40 | loss 0.00022652\n",
      "| Epoch  74 |   300/  428 batches | lr 0.00013 | ms/batch 19.22 | loss 0.00026039\n",
      "| Epoch  74 |   350/  428 batches | lr 0.00013 | ms/batch 20.89 | loss 0.00019210\n",
      "| Epoch  74 |   400/  428 batches | lr 0.00013 | ms/batch 19.26 | loss 0.00024020\n",
      "\n",
      "Val set: Average loss: 0.00019994\n",
      "\n",
      "EarlyStopping counter: 7 out of 20\n",
      "| Epoch  75 |    50/  428 batches | lr 0.00013 | ms/batch 18.24 | loss 0.00022975\n",
      "| Epoch  75 |   100/  428 batches | lr 0.00013 | ms/batch 19.85 | loss 0.00020812\n",
      "| Epoch  75 |   150/  428 batches | lr 0.00013 | ms/batch 17.82 | loss 0.00034544\n",
      "| Epoch  75 |   200/  428 batches | lr 0.00013 | ms/batch 17.66 | loss 0.00026400\n",
      "| Epoch  75 |   250/  428 batches | lr 0.00013 | ms/batch 19.15 | loss 0.00020240\n",
      "| Epoch  75 |   300/  428 batches | lr 0.00013 | ms/batch 17.54 | loss 0.00023011\n",
      "| Epoch  75 |   350/  428 batches | lr 0.00013 | ms/batch 19.11 | loss 0.00027071\n",
      "| Epoch  75 |   400/  428 batches | lr 0.00013 | ms/batch 17.54 | loss 0.00031093\n",
      "\n",
      "Val set: Average loss: 0.00022804\n",
      "\n",
      "EarlyStopping counter: 8 out of 20\n",
      "| Epoch  76 |    50/  428 batches | lr 0.00013 | ms/batch 21.37 | loss 0.00021685\n",
      "| Epoch  76 |   100/  428 batches | lr 0.00013 | ms/batch 19.34 | loss 0.00021591\n",
      "| Epoch  76 |   150/  428 batches | lr 0.00013 | ms/batch 19.64 | loss 0.00030972\n",
      "| Epoch  76 |   200/  428 batches | lr 0.00013 | ms/batch 21.49 | loss 0.00023783\n",
      "| Epoch  76 |   250/  428 batches | lr 0.00013 | ms/batch 19.31 | loss 0.00021544\n",
      "| Epoch  76 |   300/  428 batches | lr 0.00013 | ms/batch 19.58 | loss 0.00021377\n",
      "| Epoch  76 |   350/  428 batches | lr 0.00013 | ms/batch 21.03 | loss 0.00023291\n",
      "| Epoch  76 |   400/  428 batches | lr 0.00013 | ms/batch 19.65 | loss 0.00028916\n",
      "\n",
      "Val set: Average loss: 0.00026489\n",
      "\n",
      "EarlyStopping counter: 9 out of 20\n",
      "| Epoch  77 |    50/  428 batches | lr 0.00013 | ms/batch 18.08 | loss 0.00024142\n",
      "| Epoch  77 |   100/  428 batches | lr 0.00013 | ms/batch 19.35 | loss 0.00027253\n",
      "| Epoch  77 |   150/  428 batches | lr 0.00013 | ms/batch 17.49 | loss 0.00037707\n",
      "| Epoch  77 |   200/  428 batches | lr 0.00013 | ms/batch 19.52 | loss 0.00024971\n",
      "| Epoch  77 |   250/  428 batches | lr 0.00013 | ms/batch 17.99 | loss 0.00022740\n",
      "| Epoch  77 |   300/  428 batches | lr 0.00013 | ms/batch 17.78 | loss 0.00022674\n",
      "| Epoch  77 |   350/  428 batches | lr 0.00013 | ms/batch 19.27 | loss 0.00020263\n",
      "| Epoch  77 |   400/  428 batches | lr 0.00013 | ms/batch 17.85 | loss 0.00039339\n",
      "\n",
      "Val set: Average loss: 0.00024714\n",
      "\n",
      "EarlyStopping counter: 10 out of 20\n",
      "| Epoch  78 |    50/  428 batches | lr 0.00013 | ms/batch 21.51 | loss 0.00024893\n",
      "| Epoch  78 |   100/  428 batches | lr 0.00013 | ms/batch 19.47 | loss 0.00030541\n",
      "| Epoch  78 |   150/  428 batches | lr 0.00013 | ms/batch 21.32 | loss 0.00026135\n",
      "| Epoch  78 |   200/  428 batches | lr 0.00013 | ms/batch 20.00 | loss 0.00027099\n",
      "| Epoch  78 |   250/  428 batches | lr 0.00013 | ms/batch 21.01 | loss 0.00029998\n",
      "| Epoch  78 |   300/  428 batches | lr 0.00013 | ms/batch 22.19 | loss 0.00023574\n",
      "| Epoch  78 |   350/  428 batches | lr 0.00013 | ms/batch 20.92 | loss 0.00018949\n",
      "| Epoch  78 |   400/  428 batches | lr 0.00013 | ms/batch 21.79 | loss 0.00024195\n",
      "\n",
      "Val set: Average loss: 0.00021474\n",
      "\n",
      "EarlyStopping counter: 11 out of 20\n",
      "| Epoch  79 |    50/  428 batches | lr 0.00013 | ms/batch 19.26 | loss 0.00022948\n",
      "| Epoch  79 |   100/  428 batches | lr 0.00013 | ms/batch 20.89 | loss 0.00026997\n",
      "| Epoch  79 |   150/  428 batches | lr 0.00013 | ms/batch 19.38 | loss 0.00023516\n",
      "| Epoch  79 |   200/  428 batches | lr 0.00013 | ms/batch 21.01 | loss 0.00022466\n",
      "| Epoch  79 |   250/  428 batches | lr 0.00013 | ms/batch 19.07 | loss 0.00023955\n",
      "| Epoch  79 |   300/  428 batches | lr 0.00013 | ms/batch 18.78 | loss 0.00021145\n",
      "| Epoch  79 |   350/  428 batches | lr 0.00013 | ms/batch 20.48 | loss 0.00018875\n",
      "| Epoch  79 |   400/  428 batches | lr 0.00013 | ms/batch 18.35 | loss 0.00024009\n",
      "\n",
      "Val set: Average loss: 0.00021309\n",
      "\n",
      "EarlyStopping counter: 12 out of 20\n",
      "| Epoch  80 |    50/  428 batches | lr 0.00013 | ms/batch 22.31 | loss 0.00018484\n",
      "| Epoch  80 |   100/  428 batches | lr 0.00013 | ms/batch 19.92 | loss 0.00020305\n",
      "| Epoch  80 |   150/  428 batches | lr 0.00013 | ms/batch 22.23 | loss 0.00022953\n",
      "| Epoch  80 |   200/  428 batches | lr 0.00013 | ms/batch 20.45 | loss 0.00023017\n",
      "| Epoch  80 |   250/  428 batches | lr 0.00013 | ms/batch 20.34 | loss 0.00017126\n",
      "| Epoch  80 |   300/  428 batches | lr 0.00013 | ms/batch 23.23 | loss 0.00016184\n",
      "| Epoch  80 |   350/  428 batches | lr 0.00013 | ms/batch 20.22 | loss 0.00015925\n",
      "| Epoch  80 |   400/  428 batches | lr 0.00013 | ms/batch 20.29 | loss 0.00016411\n",
      "\n",
      "Val set: Average loss: 0.00022380\n",
      "\n",
      "EarlyStopping counter: 13 out of 20\n",
      "| Epoch  81 |    50/  428 batches | lr 0.00013 | ms/batch 20.70 | loss 0.00016007\n",
      "| Epoch  81 |   100/  428 batches | lr 0.00013 | ms/batch 18.29 | loss 0.00022211\n",
      "| Epoch  81 |   150/  428 batches | lr 0.00013 | ms/batch 19.52 | loss 0.00026801\n",
      "| Epoch  81 |   200/  428 batches | lr 0.00013 | ms/batch 20.31 | loss 0.00016819\n",
      "| Epoch  81 |   250/  428 batches | lr 0.00013 | ms/batch 19.20 | loss 0.00020128\n",
      "| Epoch  81 |   300/  428 batches | lr 0.00013 | ms/batch 19.12 | loss 0.00019234\n",
      "| Epoch  81 |   350/  428 batches | lr 0.00013 | ms/batch 17.57 | loss 0.00033447\n",
      "| Epoch  81 |   400/  428 batches | lr 0.00013 | ms/batch 19.21 | loss 0.00019096\n",
      "\n",
      "Val set: Average loss: 0.00022845\n",
      "\n",
      "EarlyStopping counter: 14 out of 20\n",
      "| Epoch  82 |    50/  428 batches | lr 0.00013 | ms/batch 20.70 | loss 0.00019415\n",
      "| Epoch  82 |   100/  428 batches | lr 0.00013 | ms/batch 20.14 | loss 0.00027957\n",
      "| Epoch  82 |   150/  428 batches | lr 0.00013 | ms/batch 21.57 | loss 0.00021786\n",
      "| Epoch  82 |   200/  428 batches | lr 0.00013 | ms/batch 19.96 | loss 0.00017988\n",
      "| Epoch  82 |   250/  428 batches | lr 0.00013 | ms/batch 19.90 | loss 0.00026304\n",
      "| Epoch  82 |   300/  428 batches | lr 0.00013 | ms/batch 21.90 | loss 0.00021144\n",
      "| Epoch  82 |   350/  428 batches | lr 0.00013 | ms/batch 20.72 | loss 0.00032952\n",
      "| Epoch  82 |   400/  428 batches | lr 0.00013 | ms/batch 21.49 | loss 0.00024293\n",
      "\n",
      "Val set: Average loss: 0.00018652\n",
      "\n",
      "| Epoch  83 |    50/  428 batches | lr 0.00013 | ms/batch 20.10 | loss 0.00017441\n",
      "| Epoch  83 |   100/  428 batches | lr 0.00013 | ms/batch 20.98 | loss 0.00020003\n",
      "| Epoch  83 |   150/  428 batches | lr 0.00013 | ms/batch 20.71 | loss 0.00023448\n",
      "| Epoch  83 |   200/  428 batches | lr 0.00013 | ms/batch 20.52 | loss 0.00020045\n",
      "| Epoch  83 |   250/  428 batches | lr 0.00013 | ms/batch 24.04 | loss 0.00020618\n",
      "| Epoch  83 |   300/  428 batches | lr 0.00013 | ms/batch 20.21 | loss 0.00017932\n",
      "| Epoch  83 |   350/  428 batches | lr 0.00013 | ms/batch 19.83 | loss 0.00019670\n",
      "| Epoch  83 |   400/  428 batches | lr 0.00013 | ms/batch 21.18 | loss 0.00016711\n",
      "\n",
      "Val set: Average loss: 0.00018510\n",
      "\n",
      "| Epoch  84 |    50/  428 batches | lr 0.00013 | ms/batch 21.50 | loss 0.00022510\n",
      "| Epoch  84 |   100/  428 batches | lr 0.00013 | ms/batch 19.31 | loss 0.00020012\n",
      "| Epoch  84 |   150/  428 batches | lr 0.00013 | ms/batch 19.38 | loss 0.00030110\n",
      "| Epoch  84 |   200/  428 batches | lr 0.00013 | ms/batch 20.97 | loss 0.00017021\n",
      "| Epoch  84 |   250/  428 batches | lr 0.00013 | ms/batch 19.34 | loss 0.00021166\n",
      "| Epoch  84 |   300/  428 batches | lr 0.00013 | ms/batch 19.42 | loss 0.00020436\n",
      "| Epoch  84 |   350/  428 batches | lr 0.00013 | ms/batch 21.12 | loss 0.00022601\n",
      "| Epoch  84 |   400/  428 batches | lr 0.00013 | ms/batch 19.56 | loss 0.00017710\n",
      "\n",
      "Val set: Average loss: 0.00023190\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  85 |    50/  428 batches | lr 0.00013 | ms/batch 19.63 | loss 0.00026585\n",
      "| Epoch  85 |   100/  428 batches | lr 0.00013 | ms/batch 17.79 | loss 0.00019802\n",
      "| Epoch  85 |   150/  428 batches | lr 0.00013 | ms/batch 19.64 | loss 0.00024608\n",
      "| Epoch  85 |   200/  428 batches | lr 0.00013 | ms/batch 19.60 | loss 0.00019043\n",
      "| Epoch  85 |   250/  428 batches | lr 0.00013 | ms/batch 19.26 | loss 0.00025502\n",
      "| Epoch  85 |   300/  428 batches | lr 0.00013 | ms/batch 17.65 | loss 0.00030351\n",
      "| Epoch  85 |   350/  428 batches | lr 0.00013 | ms/batch 19.43 | loss 0.00019254\n",
      "| Epoch  85 |   400/  428 batches | lr 0.00013 | ms/batch 19.29 | loss 0.00021562\n",
      "\n",
      "Val set: Average loss: 0.00019097\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  86 |    50/  428 batches | lr 0.00013 | ms/batch 21.45 | loss 0.00017902\n",
      "| Epoch  86 |   100/  428 batches | lr 0.00013 | ms/batch 19.45 | loss 0.00021076\n",
      "| Epoch  86 |   150/  428 batches | lr 0.00013 | ms/batch 21.02 | loss 0.00022138\n",
      "| Epoch  86 |   200/  428 batches | lr 0.00013 | ms/batch 19.55 | loss 0.00029558\n",
      "| Epoch  86 |   250/  428 batches | lr 0.00013 | ms/batch 19.45 | loss 0.00020411\n",
      "| Epoch  86 |   300/  428 batches | lr 0.00013 | ms/batch 21.09 | loss 0.00024085\n",
      "| Epoch  86 |   350/  428 batches | lr 0.00013 | ms/batch 19.48 | loss 0.00019501\n",
      "| Epoch  86 |   400/  428 batches | lr 0.00013 | ms/batch 19.23 | loss 0.00021580\n",
      "\n",
      "Val set: Average loss: 0.00023572\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  87 |    50/  428 batches | lr 0.00013 | ms/batch 19.94 | loss 0.00018049\n",
      "| Epoch  87 |   100/  428 batches | lr 0.00013 | ms/batch 17.84 | loss 0.00019506\n",
      "| Epoch  87 |   150/  428 batches | lr 0.00013 | ms/batch 19.51 | loss 0.00023557\n",
      "| Epoch  87 |   200/  428 batches | lr 0.00013 | ms/batch 19.90 | loss 0.00026131\n",
      "| Epoch  87 |   250/  428 batches | lr 0.00013 | ms/batch 19.75 | loss 0.00018999\n",
      "| Epoch  87 |   300/  428 batches | lr 0.00013 | ms/batch 19.78 | loss 0.00021736\n",
      "| Epoch  87 |   350/  428 batches | lr 0.00013 | ms/batch 18.14 | loss 0.00018157\n",
      "| Epoch  87 |   400/  428 batches | lr 0.00013 | ms/batch 19.60 | loss 0.00018336\n",
      "\n",
      "Val set: Average loss: 0.00020712\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch  88 |    50/  428 batches | lr 0.00013 | ms/batch 20.35 | loss 0.00016130\n",
      "| Epoch  88 |   100/  428 batches | lr 0.00013 | ms/batch 19.68 | loss 0.00018145\n",
      "| Epoch  88 |   150/  428 batches | lr 0.00013 | ms/batch 21.68 | loss 0.00023347\n",
      "| Epoch  88 |   200/  428 batches | lr 0.00013 | ms/batch 19.81 | loss 0.00020863\n",
      "| Epoch  88 |   250/  428 batches | lr 0.00013 | ms/batch 20.93 | loss 0.00017339\n",
      "| Epoch  88 |   300/  428 batches | lr 0.00013 | ms/batch 23.55 | loss 0.00017454\n",
      "| Epoch  88 |   350/  428 batches | lr 0.00013 | ms/batch 20.52 | loss 0.00033687\n",
      "| Epoch  88 |   400/  428 batches | lr 0.00013 | ms/batch 20.78 | loss 0.00020604\n",
      "\n",
      "Val set: Average loss: 0.00020628\n",
      "\n",
      "EarlyStopping counter: 5 out of 20\n",
      "| Epoch  89 |    50/  428 batches | lr 0.00013 | ms/batch 18.50 | loss 0.00016730\n",
      "| Epoch  89 |   100/  428 batches | lr 0.00013 | ms/batch 20.74 | loss 0.00017860\n",
      "| Epoch  89 |   150/  428 batches | lr 0.00013 | ms/batch 17.51 | loss 0.00021695\n",
      "| Epoch  89 |   200/  428 batches | lr 0.00013 | ms/batch 19.30 | loss 0.00018214\n",
      "| Epoch  89 |   250/  428 batches | lr 0.00013 | ms/batch 17.52 | loss 0.00023605\n",
      "| Epoch  89 |   300/  428 batches | lr 0.00013 | ms/batch 19.13 | loss 0.00020888\n",
      "| Epoch  89 |   350/  428 batches | lr 0.00013 | ms/batch 17.62 | loss 0.00019996\n",
      "| Epoch  89 |   400/  428 batches | lr 0.00013 | ms/batch 17.68 | loss 0.00019321\n",
      "\n",
      "Val set: Average loss: 0.00019123\n",
      "\n",
      "EarlyStopping counter: 6 out of 20\n",
      "| Epoch  90 |    50/  428 batches | lr 0.00013 | ms/batch 19.98 | loss 0.00018933\n",
      "| Epoch  90 |   100/  428 batches | lr 0.00013 | ms/batch 19.29 | loss 0.00024784\n",
      "| Epoch  90 |   150/  428 batches | lr 0.00013 | ms/batch 20.90 | loss 0.00020724\n",
      "| Epoch  90 |   200/  428 batches | lr 0.00013 | ms/batch 19.35 | loss 0.00019369\n",
      "| Epoch  90 |   250/  428 batches | lr 0.00013 | ms/batch 19.35 | loss 0.00025510\n",
      "| Epoch  90 |   300/  428 batches | lr 0.00013 | ms/batch 21.00 | loss 0.00019621\n",
      "| Epoch  90 |   350/  428 batches | lr 0.00013 | ms/batch 19.38 | loss 0.00018636\n",
      "| Epoch  90 |   400/  428 batches | lr 0.00013 | ms/batch 19.38 | loss 0.00020994\n",
      "\n",
      "Val set: Average loss: 0.00022921\n",
      "\n",
      "EarlyStopping counter: 7 out of 20\n",
      "| Epoch  91 |    50/  428 batches | lr 0.00013 | ms/batch 19.63 | loss 0.00020866\n",
      "| Epoch  91 |   100/  428 batches | lr 0.00013 | ms/batch 19.22 | loss 0.00025511\n",
      "| Epoch  91 |   150/  428 batches | lr 0.00013 | ms/batch 17.68 | loss 0.00028882\n",
      "| Epoch  91 |   200/  428 batches | lr 0.00013 | ms/batch 19.16 | loss 0.00024093\n",
      "| Epoch  91 |   250/  428 batches | lr 0.00013 | ms/batch 19.21 | loss 0.00018693\n",
      "| Epoch  91 |   300/  428 batches | lr 0.00013 | ms/batch 19.21 | loss 0.00017838\n",
      "| Epoch  91 |   350/  428 batches | lr 0.00013 | ms/batch 19.30 | loss 0.00022722\n",
      "| Epoch  91 |   400/  428 batches | lr 0.00013 | ms/batch 17.62 | loss 0.00026586\n",
      "\n",
      "Val set: Average loss: 0.00029726\n",
      "\n",
      "EarlyStopping counter: 8 out of 20\n",
      "| Epoch  92 |    50/  428 batches | lr 0.00013 | ms/batch 19.87 | loss 0.00021970\n",
      "| Epoch  92 |   100/  428 batches | lr 0.00013 | ms/batch 21.03 | loss 0.00022938\n",
      "| Epoch  92 |   150/  428 batches | lr 0.00013 | ms/batch 19.46 | loss 0.00036563\n",
      "| Epoch  92 |   200/  428 batches | lr 0.00013 | ms/batch 19.31 | loss 0.00023594\n",
      "| Epoch  92 |   250/  428 batches | lr 0.00013 | ms/batch 21.21 | loss 0.00022429\n",
      "| Epoch  92 |   300/  428 batches | lr 0.00013 | ms/batch 19.59 | loss 0.00022232\n",
      "| Epoch  92 |   350/  428 batches | lr 0.00013 | ms/batch 19.37 | loss 0.00018746\n",
      "| Epoch  92 |   400/  428 batches | lr 0.00013 | ms/batch 20.89 | loss 0.00031151\n",
      "\n",
      "Val set: Average loss: 0.00021601\n",
      "\n",
      "EarlyStopping counter: 9 out of 20\n",
      "| Epoch  93 |    50/  428 batches | lr 0.00013 | ms/batch 19.61 | loss 0.00021555\n",
      "| Epoch  93 |   100/  428 batches | lr 0.00013 | ms/batch 17.58 | loss 0.00028499\n",
      "| Epoch  93 |   150/  428 batches | lr 0.00013 | ms/batch 17.53 | loss 0.00025696\n",
      "| Epoch  93 |   200/  428 batches | lr 0.00013 | ms/batch 19.13 | loss 0.00024135\n",
      "| Epoch  93 |   250/  428 batches | lr 0.00013 | ms/batch 17.62 | loss 0.00027890\n",
      "| Epoch  93 |   300/  428 batches | lr 0.00013 | ms/batch 19.19 | loss 0.00022781\n",
      "| Epoch  93 |   350/  428 batches | lr 0.00013 | ms/batch 17.89 | loss 0.00017849\n",
      "| Epoch  93 |   400/  428 batches | lr 0.00013 | ms/batch 19.45 | loss 0.00020545\n",
      "\n",
      "Val set: Average loss: 0.00021895\n",
      "\n",
      "EarlyStopping counter: 10 out of 20\n",
      "| Epoch  94 |    50/  428 batches | lr 0.00013 | ms/batch 19.68 | loss 0.00021489\n",
      "| Epoch  94 |   100/  428 batches | lr 0.00013 | ms/batch 19.28 | loss 0.00029472\n",
      "| Epoch  94 |   150/  428 batches | lr 0.00013 | ms/batch 20.87 | loss 0.00027691\n",
      "| Epoch  94 |   200/  428 batches | lr 0.00013 | ms/batch 19.31 | loss 0.00031380\n",
      "| Epoch  94 |   250/  428 batches | lr 0.00013 | ms/batch 19.20 | loss 0.00020627\n",
      "| Epoch  94 |   300/  428 batches | lr 0.00013 | ms/batch 20.90 | loss 0.00022417\n",
      "| Epoch  94 |   350/  428 batches | lr 0.00013 | ms/batch 19.85 | loss 0.00016581\n",
      "| Epoch  94 |   400/  428 batches | lr 0.00013 | ms/batch 19.61 | loss 0.00019122\n",
      "\n",
      "Val set: Average loss: 0.00020073\n",
      "\n",
      "EarlyStopping counter: 11 out of 20\n",
      "| Epoch  95 |    50/  428 batches | lr 0.00013 | ms/batch 19.52 | loss 0.00020643\n",
      "| Epoch  95 |   100/  428 batches | lr 0.00013 | ms/batch 19.79 | loss 0.00025922\n",
      "| Epoch  95 |   150/  428 batches | lr 0.00013 | ms/batch 19.36 | loss 0.00022689\n",
      "| Epoch  95 |   200/  428 batches | lr 0.00013 | ms/batch 17.70 | loss 0.00022646\n",
      "| Epoch  95 |   250/  428 batches | lr 0.00013 | ms/batch 19.32 | loss 0.00021188\n",
      "| Epoch  95 |   300/  428 batches | lr 0.00013 | ms/batch 20.34 | loss 0.00017157\n",
      "| Epoch  95 |   350/  428 batches | lr 0.00013 | ms/batch 20.35 | loss 0.00015210\n",
      "| Epoch  95 |   400/  428 batches | lr 0.00013 | ms/batch 19.60 | loss 0.00018472\n",
      "\n",
      "Val set: Average loss: 0.00017258\n",
      "\n",
      "| Epoch  96 |    50/  428 batches | lr 0.00013 | ms/batch 20.11 | loss 0.00016313\n",
      "| Epoch  96 |   100/  428 batches | lr 0.00013 | ms/batch 21.06 | loss 0.00016396\n",
      "| Epoch  96 |   150/  428 batches | lr 0.00013 | ms/batch 19.41 | loss 0.00019798\n",
      "| Epoch  96 |   200/  428 batches | lr 0.00013 | ms/batch 19.51 | loss 0.00016127\n",
      "| Epoch  96 |   250/  428 batches | lr 0.00013 | ms/batch 21.28 | loss 0.00016162\n",
      "| Epoch  96 |   300/  428 batches | lr 0.00013 | ms/batch 19.73 | loss 0.00015916\n",
      "| Epoch  96 |   350/  428 batches | lr 0.00013 | ms/batch 19.86 | loss 0.00015960\n",
      "| Epoch  96 |   400/  428 batches | lr 0.00013 | ms/batch 21.33 | loss 0.00020713\n",
      "\n",
      "Val set: Average loss: 0.00019044\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  97 |    50/  428 batches | lr 0.00013 | ms/batch 20.33 | loss 0.00019951\n",
      "| Epoch  97 |   100/  428 batches | lr 0.00013 | ms/batch 19.70 | loss 0.00018817\n",
      "| Epoch  97 |   150/  428 batches | lr 0.00013 | ms/batch 20.63 | loss 0.00023567\n",
      "| Epoch  97 |   200/  428 batches | lr 0.00013 | ms/batch 19.47 | loss 0.00017607\n",
      "| Epoch  97 |   250/  428 batches | lr 0.00013 | ms/batch 18.12 | loss 0.00017952\n",
      "| Epoch  97 |   300/  428 batches | lr 0.00013 | ms/batch 21.33 | loss 0.00016835\n",
      "| Epoch  97 |   350/  428 batches | lr 0.00013 | ms/batch 19.54 | loss 0.00020307\n",
      "| Epoch  97 |   400/  428 batches | lr 0.00013 | ms/batch 19.68 | loss 0.00021339\n",
      "\n",
      "Val set: Average loss: 0.00023512\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  98 |    50/  428 batches | lr 0.00013 | ms/batch 20.33 | loss 0.00022745\n",
      "| Epoch  98 |   100/  428 batches | lr 0.00013 | ms/batch 21.24 | loss 0.00019819\n",
      "| Epoch  98 |   150/  428 batches | lr 0.00013 | ms/batch 19.76 | loss 0.00020152\n",
      "| Epoch  98 |   200/  428 batches | lr 0.00013 | ms/batch 19.66 | loss 0.00019194\n",
      "| Epoch  98 |   250/  428 batches | lr 0.00013 | ms/batch 21.46 | loss 0.00022423\n",
      "| Epoch  98 |   300/  428 batches | lr 0.00013 | ms/batch 20.31 | loss 0.00022382\n",
      "| Epoch  98 |   350/  428 batches | lr 0.00013 | ms/batch 19.30 | loss 0.00018409\n",
      "| Epoch  98 |   400/  428 batches | lr 0.00013 | ms/batch 20.92 | loss 0.00023728\n",
      "\n",
      "Val set: Average loss: 0.00019106\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  99 |    50/  428 batches | lr 0.00013 | ms/batch 19.98 | loss 0.00020042\n",
      "| Epoch  99 |   100/  428 batches | lr 0.00013 | ms/batch 17.82 | loss 0.00020133\n",
      "| Epoch  99 |   150/  428 batches | lr 0.00013 | ms/batch 19.29 | loss 0.00017104\n",
      "| Epoch  99 |   200/  428 batches | lr 0.00013 | ms/batch 17.70 | loss 0.00020641\n",
      "| Epoch  99 |   250/  428 batches | lr 0.00013 | ms/batch 19.23 | loss 0.00018467\n",
      "| Epoch  99 |   300/  428 batches | lr 0.00013 | ms/batch 17.88 | loss 0.00020968\n",
      "| Epoch  99 |   350/  428 batches | lr 0.00013 | ms/batch 18.15 | loss 0.00015603\n",
      "| Epoch  99 |   400/  428 batches | lr 0.00013 | ms/batch 19.55 | loss 0.00018490\n",
      "\n",
      "Val set: Average loss: 0.00022247\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch 100 |    50/  428 batches | lr 0.00013 | ms/batch 20.28 | loss 0.00019042\n",
      "| Epoch 100 |   100/  428 batches | lr 0.00013 | ms/batch 21.46 | loss 0.00020801\n",
      "| Epoch 100 |   150/  428 batches | lr 0.00013 | ms/batch 19.95 | loss 0.00017858\n",
      "| Epoch 100 |   200/  428 batches | lr 0.00013 | ms/batch 19.98 | loss 0.00018671\n",
      "| Epoch 100 |   250/  428 batches | lr 0.00013 | ms/batch 21.44 | loss 0.00019262\n",
      "| Epoch 100 |   300/  428 batches | lr 0.00013 | ms/batch 19.79 | loss 0.00028920\n",
      "| Epoch 100 |   350/  428 batches | lr 0.00013 | ms/batch 19.87 | loss 0.00018157\n",
      "| Epoch 100 |   400/  428 batches | lr 0.00013 | ms/batch 21.72 | loss 0.00019911\n",
      "\n",
      "Val set: Average loss: 0.00019562\n",
      "\n",
      "EarlyStopping counter: 5 out of 20\n",
      "| Epoch 101 |    50/  428 batches | lr 0.00013 | ms/batch 19.75 | loss 0.00020376\n",
      "| Epoch 101 |   100/  428 batches | lr 0.00013 | ms/batch 18.33 | loss 0.00022349\n",
      "| Epoch 101 |   150/  428 batches | lr 0.00013 | ms/batch 20.18 | loss 0.00021111\n",
      "| Epoch 101 |   200/  428 batches | lr 0.00013 | ms/batch 18.37 | loss 0.00023340\n",
      "| Epoch 101 |   250/  428 batches | lr 0.00013 | ms/batch 20.50 | loss 0.00018911\n",
      "| Epoch 101 |   300/  428 batches | lr 0.00013 | ms/batch 18.91 | loss 0.00021627\n",
      "| Epoch 101 |   350/  428 batches | lr 0.00013 | ms/batch 18.27 | loss 0.00020813\n",
      "| Epoch 101 |   400/  428 batches | lr 0.00013 | ms/batch 19.26 | loss 0.00021425\n",
      "\n",
      "Val set: Average loss: 0.00020775\n",
      "\n",
      "EarlyStopping counter: 6 out of 20\n",
      "| Epoch 102 |    50/  428 batches | lr 0.00013 | ms/batch 20.06 | loss 0.00021587\n",
      "| Epoch 102 |   100/  428 batches | lr 0.00013 | ms/batch 21.73 | loss 0.00021061\n",
      "| Epoch 102 |   150/  428 batches | lr 0.00013 | ms/batch 19.64 | loss 0.00030011\n",
      "| Epoch 102 |   200/  428 batches | lr 0.00013 | ms/batch 20.41 | loss 0.00029783\n",
      "| Epoch 102 |   250/  428 batches | lr 0.00013 | ms/batch 21.47 | loss 0.00020714\n",
      "| Epoch 102 |   300/  428 batches | lr 0.00013 | ms/batch 20.00 | loss 0.00018433\n",
      "| Epoch 102 |   350/  428 batches | lr 0.00013 | ms/batch 20.20 | loss 0.00016689\n",
      "| Epoch 102 |   400/  428 batches | lr 0.00013 | ms/batch 21.93 | loss 0.00027556\n",
      "\n",
      "Val set: Average loss: 0.00019349\n",
      "\n",
      "EarlyStopping counter: 7 out of 20\n",
      "| Epoch 103 |    50/  428 batches | lr 0.00013 | ms/batch 18.38 | loss 0.00018908\n",
      "| Epoch 103 |   100/  428 batches | lr 0.00013 | ms/batch 18.08 | loss 0.00023301\n",
      "| Epoch 103 |   150/  428 batches | lr 0.00013 | ms/batch 19.94 | loss 0.00029101\n",
      "| Epoch 103 |   200/  428 batches | lr 0.00013 | ms/batch 18.18 | loss 0.00025439\n",
      "| Epoch 103 |   250/  428 batches | lr 0.00013 | ms/batch 19.82 | loss 0.00026030\n",
      "| Epoch 103 |   300/  428 batches | lr 0.00013 | ms/batch 18.48 | loss 0.00020592\n",
      "| Epoch 103 |   350/  428 batches | lr 0.00013 | ms/batch 18.83 | loss 0.00017755\n",
      "| Epoch 103 |   400/  428 batches | lr 0.00013 | ms/batch 20.81 | loss 0.00021593\n",
      "\n",
      "Val set: Average loss: 0.00022457\n",
      "\n",
      "EarlyStopping counter: 8 out of 20\n",
      "| Epoch 104 |    50/  428 batches | lr 0.00013 | ms/batch 21.10 | loss 0.00022317\n",
      "| Epoch 104 |   100/  428 batches | lr 0.00013 | ms/batch 22.08 | loss 0.00027731\n",
      "| Epoch 104 |   150/  428 batches | lr 0.00013 | ms/batch 20.38 | loss 0.00025837\n",
      "| Epoch 104 |   200/  428 batches | lr 0.00013 | ms/batch 21.16 | loss 0.00027764\n",
      "| Epoch 104 |   250/  428 batches | lr 0.00013 | ms/batch 20.96 | loss 0.00021096\n",
      "| Epoch 104 |   300/  428 batches | lr 0.00013 | ms/batch 19.34 | loss 0.00023823\n",
      "| Epoch 104 |   350/  428 batches | lr 0.00013 | ms/batch 20.37 | loss 0.00015890\n",
      "| Epoch 104 |   400/  428 batches | lr 0.00013 | ms/batch 22.28 | loss 0.00019467\n",
      "\n",
      "Val set: Average loss: 0.00019661\n",
      "\n",
      "EarlyStopping counter: 9 out of 20\n",
      "| Epoch 105 |    50/  428 batches | lr 0.00013 | ms/batch 17.93 | loss 0.00024040\n",
      "| Epoch 105 |   100/  428 batches | lr 0.00013 | ms/batch 17.54 | loss 0.00023851\n",
      "| Epoch 105 |   150/  428 batches | lr 0.00013 | ms/batch 19.12 | loss 0.00024812\n",
      "| Epoch 105 |   200/  428 batches | lr 0.00013 | ms/batch 17.52 | loss 0.00022524\n",
      "| Epoch 105 |   250/  428 batches | lr 0.00013 | ms/batch 19.15 | loss 0.00018485\n",
      "| Epoch 105 |   300/  428 batches | lr 0.00013 | ms/batch 17.47 | loss 0.00019447\n",
      "| Epoch 105 |   350/  428 batches | lr 0.00013 | ms/batch 17.46 | loss 0.00014801\n",
      "| Epoch 105 |   400/  428 batches | lr 0.00013 | ms/batch 19.01 | loss 0.00017493\n",
      "\n",
      "Val set: Average loss: 0.00017508\n",
      "\n",
      "EarlyStopping counter: 10 out of 20\n",
      "| Epoch 106 |    50/  428 batches | lr 0.00013 | ms/batch 19.80 | loss 0.00017802\n",
      "| Epoch 106 |   100/  428 batches | lr 0.00013 | ms/batch 20.93 | loss 0.00016938\n",
      "| Epoch 106 |   150/  428 batches | lr 0.00013 | ms/batch 19.28 | loss 0.00020119\n",
      "| Epoch 106 |   200/  428 batches | lr 0.00013 | ms/batch 19.53 | loss 0.00019800\n",
      "| Epoch 106 |   250/  428 batches | lr 0.00013 | ms/batch 20.96 | loss 0.00015246\n",
      "| Epoch 106 |   300/  428 batches | lr 0.00013 | ms/batch 19.29 | loss 0.00015036\n",
      "| Epoch 106 |   350/  428 batches | lr 0.00013 | ms/batch 19.31 | loss 0.00014334\n",
      "| Epoch 106 |   400/  428 batches | lr 0.00013 | ms/batch 20.89 | loss 0.00014330\n",
      "\n",
      "Val set: Average loss: 0.00023772\n",
      "\n",
      "EarlyStopping counter: 11 out of 20\n",
      "| Epoch 107 |    50/  428 batches | lr 0.00013 | ms/batch 17.88 | loss 0.00016114\n",
      "| Epoch 107 |   100/  428 batches | lr 0.00013 | ms/batch 17.52 | loss 0.00016642\n",
      "| Epoch 107 |   150/  428 batches | lr 0.00013 | ms/batch 19.11 | loss 0.00020350\n",
      "| Epoch 107 |   200/  428 batches | lr 0.00013 | ms/batch 17.90 | loss 0.00014793\n",
      "| Epoch 107 |   250/  428 batches | lr 0.00013 | ms/batch 19.30 | loss 0.00018552\n",
      "| Epoch 107 |   300/  428 batches | lr 0.00013 | ms/batch 17.72 | loss 0.00017475\n",
      "| Epoch 107 |   350/  428 batches | lr 0.00013 | ms/batch 17.86 | loss 0.00018598\n",
      "| Epoch 107 |   400/  428 batches | lr 0.00013 | ms/batch 19.44 | loss 0.00015768\n",
      "\n",
      "Val set: Average loss: 0.00019328\n",
      "\n",
      "EarlyStopping counter: 12 out of 20\n",
      "| Epoch 108 |    50/  428 batches | lr 0.00013 | ms/batch 20.34 | loss 0.00018270\n",
      "| Epoch 108 |   100/  428 batches | lr 0.00013 | ms/batch 21.63 | loss 0.00020976\n",
      "| Epoch 108 |   150/  428 batches | lr 0.00013 | ms/batch 19.53 | loss 0.00020021\n",
      "| Epoch 108 |   200/  428 batches | lr 0.00013 | ms/batch 19.45 | loss 0.00019654\n",
      "| Epoch 108 |   250/  428 batches | lr 0.00013 | ms/batch 22.40 | loss 0.00021797\n",
      "| Epoch 108 |   300/  428 batches | lr 0.00013 | ms/batch 19.45 | loss 0.00018276\n",
      "| Epoch 108 |   350/  428 batches | lr 0.00013 | ms/batch 19.82 | loss 0.00019095\n",
      "| Epoch 108 |   400/  428 batches | lr 0.00013 | ms/batch 21.49 | loss 0.00016107\n",
      "\n",
      "Val set: Average loss: 0.00023088\n",
      "\n",
      "EarlyStopping counter: 13 out of 20\n",
      "| Epoch 109 |    50/  428 batches | lr 0.00013 | ms/batch 18.27 | loss 0.00021955\n",
      "| Epoch 109 |   100/  428 batches | lr 0.00013 | ms/batch 17.69 | loss 0.00020573\n",
      "| Epoch 109 |   150/  428 batches | lr 0.00013 | ms/batch 19.60 | loss 0.00018597\n",
      "| Epoch 109 |   200/  428 batches | lr 0.00013 | ms/batch 17.82 | loss 0.00019642\n",
      "| Epoch 109 |   250/  428 batches | lr 0.00013 | ms/batch 19.91 | loss 0.00017959\n",
      "| Epoch 109 |   300/  428 batches | lr 0.00013 | ms/batch 18.07 | loss 0.00016987\n",
      "| Epoch 109 |   350/  428 batches | lr 0.00013 | ms/batch 17.73 | loss 0.00017616\n",
      "| Epoch 109 |   400/  428 batches | lr 0.00013 | ms/batch 19.38 | loss 0.00018229\n",
      "\n",
      "Val set: Average loss: 0.00022313\n",
      "\n",
      "EarlyStopping counter: 14 out of 20\n",
      "| Epoch 110 |    50/  428 batches | lr 0.00013 | ms/batch 20.49 | loss 0.00017630\n",
      "| Epoch 110 |   100/  428 batches | lr 0.00013 | ms/batch 21.27 | loss 0.00016650\n",
      "| Epoch 110 |   150/  428 batches | lr 0.00013 | ms/batch 19.93 | loss 0.00017205\n",
      "| Epoch 110 |   200/  428 batches | lr 0.00013 | ms/batch 19.49 | loss 0.00015948\n",
      "| Epoch 110 |   250/  428 batches | lr 0.00013 | ms/batch 21.70 | loss 0.00019671\n",
      "| Epoch 110 |   300/  428 batches | lr 0.00013 | ms/batch 19.86 | loss 0.00016930\n",
      "| Epoch 110 |   350/  428 batches | lr 0.00013 | ms/batch 20.14 | loss 0.00021973\n",
      "| Epoch 110 |   400/  428 batches | lr 0.00013 | ms/batch 21.84 | loss 0.00015911\n",
      "\n",
      "Val set: Average loss: 0.00026374\n",
      "\n",
      "EarlyStopping counter: 15 out of 20\n",
      "| Epoch 111 |    50/  428 batches | lr 0.00013 | ms/batch 18.30 | loss 0.00021585\n",
      "| Epoch 111 |   100/  428 batches | lr 0.00013 | ms/batch 17.78 | loss 0.00017702\n",
      "| Epoch 111 |   150/  428 batches | lr 0.00013 | ms/batch 20.29 | loss 0.00017269\n",
      "| Epoch 111 |   200/  428 batches | lr 0.00013 | ms/batch 17.82 | loss 0.00016165\n",
      "| Epoch 111 |   250/  428 batches | lr 0.00013 | ms/batch 19.61 | loss 0.00024565\n",
      "| Epoch 111 |   300/  428 batches | lr 0.00013 | ms/batch 17.88 | loss 0.00029185\n",
      "| Epoch 111 |   350/  428 batches | lr 0.00013 | ms/batch 18.05 | loss 0.00017820\n",
      "| Epoch 111 |   400/  428 batches | lr 0.00013 | ms/batch 19.66 | loss 0.00017600\n",
      "\n",
      "Val set: Average loss: 0.00020887\n",
      "\n",
      "EarlyStopping counter: 16 out of 20\n",
      "| Epoch 112 |    50/  428 batches | lr 0.00013 | ms/batch 20.33 | loss 0.00017664\n",
      "| Epoch 112 |   100/  428 batches | lr 0.00013 | ms/batch 21.85 | loss 0.00020317\n",
      "| Epoch 112 |   150/  428 batches | lr 0.00013 | ms/batch 20.39 | loss 0.00019791\n",
      "| Epoch 112 |   200/  428 batches | lr 0.00013 | ms/batch 21.91 | loss 0.00019465\n",
      "| Epoch 112 |   250/  428 batches | lr 0.00013 | ms/batch 20.89 | loss 0.00020985\n",
      "| Epoch 112 |   300/  428 batches | lr 0.00013 | ms/batch 19.32 | loss 0.00016872\n",
      "| Epoch 112 |   350/  428 batches | lr 0.00013 | ms/batch 19.35 | loss 0.00014591\n",
      "| Epoch 112 |   400/  428 batches | lr 0.00013 | ms/batch 20.92 | loss 0.00015628\n",
      "\n",
      "Val set: Average loss: 0.00019173\n",
      "\n",
      "EarlyStopping counter: 17 out of 20\n",
      "| Epoch 113 |    50/  428 batches | lr 0.00013 | ms/batch 17.94 | loss 0.00017168\n",
      "| Epoch 113 |   100/  428 batches | lr 0.00013 | ms/batch 17.47 | loss 0.00018311\n",
      "| Epoch 113 |   150/  428 batches | lr 0.00013 | ms/batch 19.16 | loss 0.00022197\n",
      "| Epoch 113 |   200/  428 batches | lr 0.00013 | ms/batch 17.53 | loss 0.00025406\n",
      "| Epoch 113 |   250/  428 batches | lr 0.00013 | ms/batch 19.31 | loss 0.00021732\n",
      "| Epoch 113 |   300/  428 batches | lr 0.00013 | ms/batch 17.54 | loss 0.00016509\n",
      "| Epoch 113 |   350/  428 batches | lr 0.00013 | ms/batch 17.52 | loss 0.00015232\n",
      "| Epoch 113 |   400/  428 batches | lr 0.00013 | ms/batch 19.27 | loss 0.00019879\n",
      "\n",
      "Val set: Average loss: 0.00026492\n",
      "\n",
      "EarlyStopping counter: 18 out of 20\n",
      "| Epoch 114 |    50/  428 batches | lr 0.00013 | ms/batch 19.84 | loss 0.00021952\n",
      "| Epoch 114 |   100/  428 batches | lr 0.00013 | ms/batch 21.11 | loss 0.00022327\n",
      "| Epoch 114 |   150/  428 batches | lr 0.00013 | ms/batch 20.84 | loss 0.00033389\n",
      "| Epoch 114 |   200/  428 batches | lr 0.00013 | ms/batch 19.76 | loss 0.00024750\n",
      "| Epoch 114 |   250/  428 batches | lr 0.00013 | ms/batch 21.08 | loss 0.00020801\n",
      "| Epoch 114 |   300/  428 batches | lr 0.00013 | ms/batch 19.53 | loss 0.00018415\n",
      "| Epoch 114 |   350/  428 batches | lr 0.00013 | ms/batch 19.90 | loss 0.00016357\n",
      "| Epoch 114 |   400/  428 batches | lr 0.00013 | ms/batch 21.44 | loss 0.00023391\n",
      "\n",
      "Val set: Average loss: 0.00019525\n",
      "\n",
      "EarlyStopping counter: 19 out of 20\n",
      "| Epoch 115 |    50/  428 batches | lr 0.00013 | ms/batch 18.03 | loss 0.00017925\n",
      "| Epoch 115 |   100/  428 batches | lr 0.00013 | ms/batch 18.56 | loss 0.00021098\n",
      "| Epoch 115 |   150/  428 batches | lr 0.00013 | ms/batch 19.71 | loss 0.00025891\n",
      "| Epoch 115 |   200/  428 batches | lr 0.00013 | ms/batch 17.90 | loss 0.00016456\n",
      "| Epoch 115 |   250/  428 batches | lr 0.00013 | ms/batch 19.60 | loss 0.00018751\n",
      "| Epoch 115 |   300/  428 batches | lr 0.00013 | ms/batch 17.88 | loss 0.00017029\n",
      "| Epoch 115 |   350/  428 batches | lr 0.00013 | ms/batch 17.93 | loss 0.00015113\n",
      "| Epoch 115 |   400/  428 batches | lr 0.00013 | ms/batch 19.55 | loss 0.00019972\n",
      "\n",
      "Val set: Average loss: 0.00019241\n",
      "\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Stopping at Epoch: 115\n"
     ]
    }
   ],
   "source": [
    "load = False\n",
    "save_model_path = '../models/final_heston_model.chkpt'\n",
    "val_err_df_path = '../results/val_final_heston_model.csv'\n",
    "\n",
    "if not load:\n",
    "  train_losses, val_losses = train(\n",
    "      epochs,\n",
    "      batch_size,\n",
    "      model,\n",
    "      optimizer,\n",
    "      loss_fn,\n",
    "      X_train,\n",
    "      y_train,\n",
    "      X_val,\n",
    "      y_val)\n",
    "  val_err_df = pd.DataFrame({\n",
    "      'Training': train_losses,\n",
    "      'Validation': val_losses})\n",
    "  val_err_df.to_csv(val_err_df_path)\n",
    "  torch.save(model.state_dict(), save_model_path)\n",
    "else:\n",
    "  model = Net(input_size, output_size, hidden_size, num_layers, act_fn)\n",
    "  model.load_state_dict(torch.load(save_model_path, map_location=device))\n",
    "  model = model.to(device)\n",
    "  val_err_df = pd.read_csv(val_err_df_path, index_col=0)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hBETWoCfvDpj",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650894219916,
     "user_tz": -120,
     "elapsed": 2525796,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     }
    },
    "outputId": "30acf99f-3a1e-4d87-d1ff-13068ebe4cd4"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_err_df[1:].plot(xlabel='epoch', ylabel='MSE')\n",
    "plt.plot();"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "KkenWSRYvDpl",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650894219921,
     "user_tz": -120,
     "elapsed": 35,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     }
    },
    "outputId": "37746aa5-0b46-4a80-d14d-397868e89361"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "FlG5Ky25vDpm"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "model.eval();"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "test_size = 30\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_out = model(X_test[0:test_size])\n",
    "\n",
    "test_out = output_sc.inverse_transform(test_out.cpu().detach().numpy())\n",
    "real_out = output_sc.inverse_transform(y_test[0:test_size].cpu().detach().numpy())"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "TBZ4eHAdvDpn",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650894219922,
     "user_tz": -120,
     "elapsed": 28,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "cols = ['Price', 'Strike', 'Kappa', 'Rho', 'Theta', 'Xi', 'V_0',\n",
    "       'Interest Rate', 'Time to Expiration', 'C', 'P', 'Prediction', 'Real']\n",
    "test_options = pd.DataFrame(columns=cols)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "wK1WeGIZvDpo",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650894219926,
     "user_tz": -120,
     "elapsed": 27,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "for i, item in enumerate(input_sc.inverse_transform(X_test[0:test_size].cpu().detach().numpy())):\n",
    "  opt = {\n",
    "      'Price': item[0],\n",
    "      'Strike': item[1],\n",
    "      'Kappa': item[2],\n",
    "      'Rho': item[3],\n",
    "      'Theta': item[4],\n",
    "      'Xi': item[5],\n",
    "      'V_0': item[6],\n",
    "      'Interest Rate': item[7],\n",
    "      'Time to Expiration': item[8],\n",
    "      'C': item[9],\n",
    "      'P': item[10],\n",
    "      'Prediction': test_out[i][0],\n",
    "      'Real': real_out[i][0]\n",
    "  }\n",
    "  test_options = test_options.append(opt, ignore_index=True)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "_dvE5LGXvDpq",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650894220542,
     "user_tz": -120,
     "elapsed": 68,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "test_options['Moneyness'] = test_options.Price / test_options.Strike\n",
    "test_options['Abs Error'] = np.abs(test_options.Prediction - test_options.Real)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "TNw5-1jgvDpr",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650894220545,
     "user_tz": -120,
     "elapsed": 67,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "    Price      Strike     Kappa       Rho     Theta        Xi       V_0  \\\n23  100.0   93.999641  1.278389 -0.260981  0.348880  0.038147  0.068219   \n29  100.0   75.998573  0.874481 -0.705116  0.037440  0.019823  0.483177   \n2   100.0  119.004692  0.832547 -0.517111  0.150626  0.131811  0.051474   \n11  100.0   69.991096  0.135099 -0.234595  0.015873  0.254887  0.227777   \n27  100.0  139.005875  0.290150 -0.277600  0.241701  0.421684  0.492691   \n21  100.0  130.008911  1.138702 -0.671879  0.383766  0.185550  0.067204   \n18  100.0   78.005814  1.165061 -0.880056  0.105380  0.013057  0.296630   \n7   100.0   64.012093  0.095632 -0.855952  0.348880  0.319598  0.145096   \n9   100.0   69.991096  0.633236 -0.376233  0.375027  0.006432  0.260744   \n5   100.0   57.008118  1.814724 -0.617710  0.412803  0.248779  0.146809   \n8   100.0   79.002312  0.330181 -0.580160  0.204577  0.500055  0.051854   \n10  100.0  135.987915  0.092249 -0.055215  0.344017  0.328372  0.451335   \n16  100.0   50.004143  0.912116 -0.870668  0.460023  0.443814  0.170722   \n24  100.0  139.005875  1.722821 -0.719705  0.131245  0.334715  0.263179   \n4   100.0  141.995377  0.831983 -0.431639  0.284181  0.019118  0.475058   \n15  100.0   65.008591  1.762853 -0.509753  0.240353  0.208385  0.054265   \n6   100.0   59.997620  1.713800 -0.140972  0.075497  0.333235  0.206052   \n0   100.0   87.002785  0.554301 -0.218357  0.455089  0.107567  0.144208   \n14  100.0   69.991096  1.249070 -0.226476  0.377212  0.100167  0.077860   \n12  100.0  101.000061  1.531122 -0.667566  0.006148  0.380385  0.317879   \n19  100.0   64.012093  0.815491 -0.630904  0.278561  0.447761  0.423299   \n25  100.0  114.000832  1.806831 -0.365450  0.442403  0.314453  0.477722   \n22  100.0  131.005402  0.773486 -0.464845  0.169585  0.340565  0.207130   \n1   100.0   71.998337  1.804576 -0.772479  0.183222  0.002063  0.126194   \n28  100.0  127.005165  0.978524 -0.510229  0.404486  0.108060  0.324476   \n26  100.0   59.001118  1.007816 -0.154166  0.115740  0.410690  0.308364   \n3   100.0   79.998810  1.620206 -0.737719  0.300532  0.172477  0.133552   \n17  100.0   82.006042  1.792172 -0.240811  0.070282  0.395467  0.488505   \n20  100.0   71.001831  1.867160 -0.019948  0.381863  0.302260  0.198123   \n13  100.0   79.002312  0.643948 -0.105198  0.447478  0.263181  0.103867   \n\n    Interest Rate  Time to Expiration    C    P  Prediction       Real  \\\n23       0.041807            0.603514  1.0  0.0    7.025473   7.045724   \n29       0.034855            0.216040  0.0  1.0    1.546694   1.526171   \n2        0.027117            0.791562  1.0  0.0    0.434502   0.456434   \n11       0.060150            0.493652  0.0  1.0    0.533010   0.508435   \n27       0.087602            0.225343  1.0  0.0    3.084396   3.056491   \n21       0.080575            0.937451  0.0  1.0   29.292843  29.324509   \n18       0.080942            0.970999  0.0  1.0    1.050046   1.006160   \n7        0.072633            0.799315  1.0  0.0   35.527233  35.475506   \n9        0.048004            0.551761  0.0  1.0    0.825952   0.761011   \n5        0.098335            0.341773  1.0  0.0   42.880741  42.815098   \n8        0.026026            0.440019  0.0  1.0    0.020537   0.092425   \n10       0.065732            0.416056  0.0  1.0   35.729832  35.653793   \n16       0.094301            0.599609  0.0  1.0    0.153381   0.070139   \n24       0.089658            0.174035  1.0  0.0    0.240581   0.151855   \n4        0.019734            0.260018  1.0  0.0    2.142000   2.231901   \n15       0.081615            0.174881  1.0  0.0   34.221874  34.123474   \n6        0.020799            0.820317  0.0  1.0    0.160589   0.055281   \n0        0.059538            0.303996  0.0  1.0    1.631972   1.526171   \n14       0.083797            0.942808  0.0  1.0    0.329992   0.196428   \n12       0.082173            0.558104  1.0  0.0    6.570624   6.436567   \n19       0.057586            0.815525  0.0  1.0    0.717812   0.582722   \n25       0.029578            0.950701  1.0  0.0    7.282694   7.120011   \n22       0.040805            0.450731  0.0  1.0   30.859146  31.062834   \n1        0.054382            0.647964  1.0  0.0   28.179037  27.965050   \n28       0.024047            0.584472  0.0  1.0   27.827295  27.608471   \n26       0.088085            0.351640  1.0  0.0   41.052883  41.284779   \n3        0.062440            0.118781  0.0  1.0    0.295503   0.018137   \n17       0.071847            0.818344  1.0  0.0   19.392666  19.109995   \n20       0.027903            0.477090  1.0  0.0   28.896839  28.589064   \n13       0.077340            0.976919  1.0  0.0   21.074522  20.766603   \n\n    Moneyness  Abs Error  \n23   1.063834   0.020251  \n29   1.315814   0.020523  \n2    0.840303   0.021932  \n11   1.428753   0.024575  \n27   0.719394   0.027905  \n21   0.769178   0.031666  \n18   1.281956   0.043886  \n7    1.562205   0.051727  \n9    1.428753   0.064940  \n5    1.754136   0.065643  \n8    1.265786   0.071888  \n10   0.735359   0.076038  \n16   1.999834   0.083241  \n24   0.719394   0.088726  \n4    0.704248   0.089901  \n15   1.538258   0.098400  \n6    1.666733   0.105308  \n0    1.149388   0.105801  \n14   1.428753   0.133564  \n12   0.990098   0.134057  \n19   1.562205   0.135090  \n25   0.877187   0.162683  \n22   0.763327   0.203688  \n1    1.388921   0.213987  \n28   0.787370   0.218824  \n26   1.694883   0.231895  \n3    1.250019   0.277366  \n17   1.219422   0.282671  \n20   1.408414   0.307775  \n13   1.265786   0.307919  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Price</th>\n      <th>Strike</th>\n      <th>Kappa</th>\n      <th>Rho</th>\n      <th>Theta</th>\n      <th>Xi</th>\n      <th>V_0</th>\n      <th>Interest Rate</th>\n      <th>Time to Expiration</th>\n      <th>C</th>\n      <th>P</th>\n      <th>Prediction</th>\n      <th>Real</th>\n      <th>Moneyness</th>\n      <th>Abs Error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>23</th>\n      <td>100.0</td>\n      <td>93.999641</td>\n      <td>1.278389</td>\n      <td>-0.260981</td>\n      <td>0.348880</td>\n      <td>0.038147</td>\n      <td>0.068219</td>\n      <td>0.041807</td>\n      <td>0.603514</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>7.025473</td>\n      <td>7.045724</td>\n      <td>1.063834</td>\n      <td>0.020251</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>100.0</td>\n      <td>75.998573</td>\n      <td>0.874481</td>\n      <td>-0.705116</td>\n      <td>0.037440</td>\n      <td>0.019823</td>\n      <td>0.483177</td>\n      <td>0.034855</td>\n      <td>0.216040</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.546694</td>\n      <td>1.526171</td>\n      <td>1.315814</td>\n      <td>0.020523</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100.0</td>\n      <td>119.004692</td>\n      <td>0.832547</td>\n      <td>-0.517111</td>\n      <td>0.150626</td>\n      <td>0.131811</td>\n      <td>0.051474</td>\n      <td>0.027117</td>\n      <td>0.791562</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.434502</td>\n      <td>0.456434</td>\n      <td>0.840303</td>\n      <td>0.021932</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>100.0</td>\n      <td>69.991096</td>\n      <td>0.135099</td>\n      <td>-0.234595</td>\n      <td>0.015873</td>\n      <td>0.254887</td>\n      <td>0.227777</td>\n      <td>0.060150</td>\n      <td>0.493652</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.533010</td>\n      <td>0.508435</td>\n      <td>1.428753</td>\n      <td>0.024575</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>100.0</td>\n      <td>139.005875</td>\n      <td>0.290150</td>\n      <td>-0.277600</td>\n      <td>0.241701</td>\n      <td>0.421684</td>\n      <td>0.492691</td>\n      <td>0.087602</td>\n      <td>0.225343</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>3.084396</td>\n      <td>3.056491</td>\n      <td>0.719394</td>\n      <td>0.027905</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>100.0</td>\n      <td>130.008911</td>\n      <td>1.138702</td>\n      <td>-0.671879</td>\n      <td>0.383766</td>\n      <td>0.185550</td>\n      <td>0.067204</td>\n      <td>0.080575</td>\n      <td>0.937451</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.292843</td>\n      <td>29.324509</td>\n      <td>0.769178</td>\n      <td>0.031666</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>100.0</td>\n      <td>78.005814</td>\n      <td>1.165061</td>\n      <td>-0.880056</td>\n      <td>0.105380</td>\n      <td>0.013057</td>\n      <td>0.296630</td>\n      <td>0.080942</td>\n      <td>0.970999</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.050046</td>\n      <td>1.006160</td>\n      <td>1.281956</td>\n      <td>0.043886</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>100.0</td>\n      <td>64.012093</td>\n      <td>0.095632</td>\n      <td>-0.855952</td>\n      <td>0.348880</td>\n      <td>0.319598</td>\n      <td>0.145096</td>\n      <td>0.072633</td>\n      <td>0.799315</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>35.527233</td>\n      <td>35.475506</td>\n      <td>1.562205</td>\n      <td>0.051727</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>100.0</td>\n      <td>69.991096</td>\n      <td>0.633236</td>\n      <td>-0.376233</td>\n      <td>0.375027</td>\n      <td>0.006432</td>\n      <td>0.260744</td>\n      <td>0.048004</td>\n      <td>0.551761</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.825952</td>\n      <td>0.761011</td>\n      <td>1.428753</td>\n      <td>0.064940</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>100.0</td>\n      <td>57.008118</td>\n      <td>1.814724</td>\n      <td>-0.617710</td>\n      <td>0.412803</td>\n      <td>0.248779</td>\n      <td>0.146809</td>\n      <td>0.098335</td>\n      <td>0.341773</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>42.880741</td>\n      <td>42.815098</td>\n      <td>1.754136</td>\n      <td>0.065643</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>100.0</td>\n      <td>79.002312</td>\n      <td>0.330181</td>\n      <td>-0.580160</td>\n      <td>0.204577</td>\n      <td>0.500055</td>\n      <td>0.051854</td>\n      <td>0.026026</td>\n      <td>0.440019</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.020537</td>\n      <td>0.092425</td>\n      <td>1.265786</td>\n      <td>0.071888</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>100.0</td>\n      <td>135.987915</td>\n      <td>0.092249</td>\n      <td>-0.055215</td>\n      <td>0.344017</td>\n      <td>0.328372</td>\n      <td>0.451335</td>\n      <td>0.065732</td>\n      <td>0.416056</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>35.729832</td>\n      <td>35.653793</td>\n      <td>0.735359</td>\n      <td>0.076038</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>100.0</td>\n      <td>50.004143</td>\n      <td>0.912116</td>\n      <td>-0.870668</td>\n      <td>0.460023</td>\n      <td>0.443814</td>\n      <td>0.170722</td>\n      <td>0.094301</td>\n      <td>0.599609</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.153381</td>\n      <td>0.070139</td>\n      <td>1.999834</td>\n      <td>0.083241</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>100.0</td>\n      <td>139.005875</td>\n      <td>1.722821</td>\n      <td>-0.719705</td>\n      <td>0.131245</td>\n      <td>0.334715</td>\n      <td>0.263179</td>\n      <td>0.089658</td>\n      <td>0.174035</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.240581</td>\n      <td>0.151855</td>\n      <td>0.719394</td>\n      <td>0.088726</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100.0</td>\n      <td>141.995377</td>\n      <td>0.831983</td>\n      <td>-0.431639</td>\n      <td>0.284181</td>\n      <td>0.019118</td>\n      <td>0.475058</td>\n      <td>0.019734</td>\n      <td>0.260018</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.142000</td>\n      <td>2.231901</td>\n      <td>0.704248</td>\n      <td>0.089901</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>100.0</td>\n      <td>65.008591</td>\n      <td>1.762853</td>\n      <td>-0.509753</td>\n      <td>0.240353</td>\n      <td>0.208385</td>\n      <td>0.054265</td>\n      <td>0.081615</td>\n      <td>0.174881</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>34.221874</td>\n      <td>34.123474</td>\n      <td>1.538258</td>\n      <td>0.098400</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>100.0</td>\n      <td>59.997620</td>\n      <td>1.713800</td>\n      <td>-0.140972</td>\n      <td>0.075497</td>\n      <td>0.333235</td>\n      <td>0.206052</td>\n      <td>0.020799</td>\n      <td>0.820317</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.160589</td>\n      <td>0.055281</td>\n      <td>1.666733</td>\n      <td>0.105308</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>100.0</td>\n      <td>87.002785</td>\n      <td>0.554301</td>\n      <td>-0.218357</td>\n      <td>0.455089</td>\n      <td>0.107567</td>\n      <td>0.144208</td>\n      <td>0.059538</td>\n      <td>0.303996</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.631972</td>\n      <td>1.526171</td>\n      <td>1.149388</td>\n      <td>0.105801</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>100.0</td>\n      <td>69.991096</td>\n      <td>1.249070</td>\n      <td>-0.226476</td>\n      <td>0.377212</td>\n      <td>0.100167</td>\n      <td>0.077860</td>\n      <td>0.083797</td>\n      <td>0.942808</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.329992</td>\n      <td>0.196428</td>\n      <td>1.428753</td>\n      <td>0.133564</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>100.0</td>\n      <td>101.000061</td>\n      <td>1.531122</td>\n      <td>-0.667566</td>\n      <td>0.006148</td>\n      <td>0.380385</td>\n      <td>0.317879</td>\n      <td>0.082173</td>\n      <td>0.558104</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>6.570624</td>\n      <td>6.436567</td>\n      <td>0.990098</td>\n      <td>0.134057</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>100.0</td>\n      <td>64.012093</td>\n      <td>0.815491</td>\n      <td>-0.630904</td>\n      <td>0.278561</td>\n      <td>0.447761</td>\n      <td>0.423299</td>\n      <td>0.057586</td>\n      <td>0.815525</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.717812</td>\n      <td>0.582722</td>\n      <td>1.562205</td>\n      <td>0.135090</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>100.0</td>\n      <td>114.000832</td>\n      <td>1.806831</td>\n      <td>-0.365450</td>\n      <td>0.442403</td>\n      <td>0.314453</td>\n      <td>0.477722</td>\n      <td>0.029578</td>\n      <td>0.950701</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>7.282694</td>\n      <td>7.120011</td>\n      <td>0.877187</td>\n      <td>0.162683</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>100.0</td>\n      <td>131.005402</td>\n      <td>0.773486</td>\n      <td>-0.464845</td>\n      <td>0.169585</td>\n      <td>0.340565</td>\n      <td>0.207130</td>\n      <td>0.040805</td>\n      <td>0.450731</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>30.859146</td>\n      <td>31.062834</td>\n      <td>0.763327</td>\n      <td>0.203688</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100.0</td>\n      <td>71.998337</td>\n      <td>1.804576</td>\n      <td>-0.772479</td>\n      <td>0.183222</td>\n      <td>0.002063</td>\n      <td>0.126194</td>\n      <td>0.054382</td>\n      <td>0.647964</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>28.179037</td>\n      <td>27.965050</td>\n      <td>1.388921</td>\n      <td>0.213987</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>100.0</td>\n      <td>127.005165</td>\n      <td>0.978524</td>\n      <td>-0.510229</td>\n      <td>0.404486</td>\n      <td>0.108060</td>\n      <td>0.324476</td>\n      <td>0.024047</td>\n      <td>0.584472</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>27.827295</td>\n      <td>27.608471</td>\n      <td>0.787370</td>\n      <td>0.218824</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>100.0</td>\n      <td>59.001118</td>\n      <td>1.007816</td>\n      <td>-0.154166</td>\n      <td>0.115740</td>\n      <td>0.410690</td>\n      <td>0.308364</td>\n      <td>0.088085</td>\n      <td>0.351640</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>41.052883</td>\n      <td>41.284779</td>\n      <td>1.694883</td>\n      <td>0.231895</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100.0</td>\n      <td>79.998810</td>\n      <td>1.620206</td>\n      <td>-0.737719</td>\n      <td>0.300532</td>\n      <td>0.172477</td>\n      <td>0.133552</td>\n      <td>0.062440</td>\n      <td>0.118781</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.295503</td>\n      <td>0.018137</td>\n      <td>1.250019</td>\n      <td>0.277366</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>100.0</td>\n      <td>82.006042</td>\n      <td>1.792172</td>\n      <td>-0.240811</td>\n      <td>0.070282</td>\n      <td>0.395467</td>\n      <td>0.488505</td>\n      <td>0.071847</td>\n      <td>0.818344</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>19.392666</td>\n      <td>19.109995</td>\n      <td>1.219422</td>\n      <td>0.282671</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>100.0</td>\n      <td>71.001831</td>\n      <td>1.867160</td>\n      <td>-0.019948</td>\n      <td>0.381863</td>\n      <td>0.302260</td>\n      <td>0.198123</td>\n      <td>0.027903</td>\n      <td>0.477090</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>28.896839</td>\n      <td>28.589064</td>\n      <td>1.408414</td>\n      <td>0.307775</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>100.0</td>\n      <td>79.002312</td>\n      <td>0.643948</td>\n      <td>-0.105198</td>\n      <td>0.447478</td>\n      <td>0.263181</td>\n      <td>0.103867</td>\n      <td>0.077340</td>\n      <td>0.976919</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>21.074522</td>\n      <td>20.766603</td>\n      <td>1.265786</td>\n      <td>0.307919</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_options.sort_values('Abs Error')"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 990
    },
    "id": "lAC6AdeVvDpr",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650894220546,
     "user_tz": -120,
     "elapsed": 65,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     }
    },
    "outputId": "78bd13cc-c5a0-4746-f402-9e84d8b78696"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MSE on the test set"
   ],
   "metadata": {
    "id": "fDJ-hkrSAqVh",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(X_test)\n",
    "    loss = loss_fn(out, y_test)\n",
    "    print('The MSE on the test set is: ', loss.item())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GG64Xp3vAib-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650895213041,
     "user_tz": -120,
     "elapsed": 276,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     }
    },
    "outputId": "f846ee65-029d-4a76-b006-d65e4ac07a48",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE on the test set is:  0.00018996139988303185\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MAE on the test set"
   ],
   "metadata": {
    "id": "HCLf2KQJAvoE",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "mae_loss = nn.L1Loss()\n",
    "with torch.no_grad():\n",
    "    out = model(X_test)\n",
    "    loss = mae_loss(out, y_test)\n",
    "    print('The MAE on the test set is: ', loss.item())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mZohsEyLAu7S",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650895213494,
     "user_tz": -120,
     "elapsed": 27,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     }
    },
    "outputId": "4d6bfba3-5751-478d-d53e-73751702414e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAE on the test set is:  0.009961792267858982\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RSME on the test set"
   ],
   "metadata": {
    "id": "VmsZ4aPaA1SJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(X_test)\n",
    "    loss = loss_fn(out, y_test)\n",
    "    print('The RMSE on the test set is: ', np.sqrt(loss.item()))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f01KkBxRA0t7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650895213496,
     "user_tz": -120,
     "elapsed": 22,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     }
    },
    "outputId": "6492967a-db0c-49f4-fee1-8eb52ef33119",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE on the test set is:  0.013782648507563118\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MAPE on the test set"
   ],
   "metadata": {
    "id": "j8Jxp0L4A5zb",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(X_test)\n",
    "    loss = MAPELoss(out, y_test).item()\n",
    "    print('The MAPE on the test set is: ', loss)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fHghkyflA79o",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650895213818,
     "user_tz": -120,
     "elapsed": 335,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     }
    },
    "outputId": "37838323-11f0-4eb9-d7d7-50303bf4e9ce",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAPE on the test set is:  0.05627785623073578\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### $R^2$"
   ],
   "metadata": {
    "id": "uLLLqkX6BEle",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(X_test).squeeze().cpu().detach().numpy()\n",
    "\n",
    "y_true = y_test.cpu().squeeze().detach().numpy()\n",
    "\n",
    "r2 = r2_score(y_pred=out, y_true=y_true)\n",
    "\n",
    "print('the R^2 score is: ', r2)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sf8FmLxxBGcu",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650895213820,
     "user_tz": -120,
     "elapsed": 21,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     }
    },
    "outputId": "764313a9-78fc-46ca-dd08-9fb8834e4374",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the R^2 score is:  0.9998100914751962\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "fig = plt.figure(figsize=(9, 6))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "ax.scatter(\n",
    "    y=output_sc.inverse_transform(out.reshape(-1, 1)),\n",
    "    x=output_sc.inverse_transform(y_true.squeeze().reshape(-1, 1))\n",
    ")\n",
    "ax.set_xlabel('Actual Value')\n",
    "ax.set_ylabel('Predicted Value')\n",
    "\n",
    "ax.text(20, 80, f'$R^2$ = {np.round(r2, 6)}', fontsize=12)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "id": "awvWu7WxBIHB",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650895214553,
     "user_tz": -120,
     "elapsed": 744,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     }
    },
    "outputId": "1b3dccd3-90ef-47d5-9895-267fdf93020c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 648x432 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAAIXCAYAAACo6JVOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAxhklEQVR4nO3df5ycdX3v/ddnN4tsEFyiyEOiaShSqBSI3rk1NG0P0sMPf4CIAmrw0HN7Q8/paY+ITRskPQSPlHqnIj2nPW3BeuspiAGFEX9USlW0TYEW3EAaNa1aRAcEFVYRVsiPz/ljZumy7m4myXVdc83M6/l45JGZa2a+1zfzgM073x+fb2QmkiRJdTDU7Q5IkiRNMZhIkqTaMJhIkqTaMJhIkqTaMJhIkqTaMJhIkqTaMJhIkqTaMJhIAyAiXh4Rt0fElyLiuogY6XafJGk2BhNpMHwbOCEzfwW4D3hdd7sjSbNb0O0OSCpfZj447elTwM5u9UWS5uOIidQHIuLAiMiI+HFEPBER34qIt83yvp8BTgI+WfD9F0XETRHxePveb9nF+38+Ij4fET+MiK9HxOs7ea2Dzy6NiM9ExKMR8d2I+OOIWDDt9d+MiLsi4smI+FCBX4GkghhMpP6wDPh+Zj47MxcCFwF/HhHPm3pDRBwA/CXwa5m5reD7/wmtkZiDgVXAn0bEUbO9sR0UPgF8ClgEnA9cExE/N99ru/psu/n/BTwMvIDWd/LvgN+YdvsHgPcAHyzkTy2pcAYTqT8sA7487fkXgWHgQHj6L/SPApdm5tYibxwR+wFvAH4vM3+cmX8H3Ay8dY6PHAkcArw/M3dk5ueBje33z/farj4LcChwfWb+JDO/C3wWeDogZeaNmdkAflDQH19SwQwmUn94KXA3QESMAZe3n3+9/fqbgVcAvxcRt0XE2bM1EhGfioiJOX59ao57/xywPTP/edq1e5gWCDoQwC/swWszX78SeFNELIyIxcCraIUTST3CYCL1h2XA2yPiR8CjwPOBUzIzATLzLzPzuZl5fPvXhtkayczXZubYHL9eO8e9nw38aMa1HwL7z/H+rbSmW1ZHxEhEnERrymXhLl7b1WcBvkQrEP0I+A5wF9CYox+SashgIvW4iHgW8PPAMZl5APBGYAVQ9DqSufwYOGDGtQOAx2Z7c3t9y+nAa4DvAu8Erge+M99ru/psRAzRGh25EdgPeB6tqaz3FvGHlFQNg4nU+34B+AnwTYDM/DhwP611H7slIv6qvbNntl9/NcfH/hlYEBGHT7t2LLBlrvtk5r2Z+e/aozgnAz8L/MOuXtvF64uAJcAfZ+aTmfkD4P8HXr2734Ok7jGYSL3vpcCWqWmbts8Ap+1uQ5n5qvbOntl+vWqOzzxOa5Ti3RGxX0SspFXA7S/nuk9EHBMR+7bXgvw2rV00H9rVa/O9npnfB/4V+M8RsaC91uZc4N5pn10QEfvSWhg83G7Hek5SjRhMpN63jGl/+bZ9Fjix/ZdwFX4DGKW1/uM64D9n5tMjJu2RmHdNe/9bgQfb7/9V4MTMfLKD13b1+hnAKcD3aC383Qa8Y9pn1wKTwBrgnPbjtXv1J5dUqHjmP7IkSZK6xxETSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwYTSZJUGwu63YFOPO95z8ulS5d2uxuSJKkAd9999/cz86DZXuuJYLJ06VLuuuuubndDkiQVICK+NddrTuVIkqTaMJhIkqTaMJhIkqTaMJhIkqTaMJhIkqTaMJhIkqTaMJhIkqTaMJhIkqTaMJhIkqTa6InKr5IkqRqN8Sbrb9nKAxOTHDI2yuqTj+D0ly6u7P4GE0mSBtxUGGlOTBJAtq83Jya56MbNAJWFE4OJJEkDqjHe5NJPbuHRJ7Y9fS1nvGdy2w7W37LVYCJJksrRGG9y8U2befypHR29vzkxWXKP/o3BRJKkAdEYb3LRjfcyuW3nbn1uOKKkHv00g4kkSX1q+tqRvbEjZ07wlMdgIklSH2qMN7lgw6ZC2lo8NlpIO50oNZhExH3AY8AOYHtmLo+IRcAGYClwH3BWZj5aZj8kSRoEaxubufbO+ylygGN0ZJjVJx9RXIO7UEWBtVdm5rLMXN5+vgb4XGYeDnyu/VySJO2hxniTpWs+zTV3FBNKRkeGCFojJZefcXTf1zF5HXB8+/GHgduA3+1CPyRJ6klz1R3ZW4u7UFBtprKDSQJ/HREJ/HlmXgUcnJkPtl//LnBwyX2QJKlvNMabXHj9Jna200gRoWR0ZLjykZG5lB1MfikzmxHxfODWiPja9BczM9uh5adExPnA+QBLliwpuZuSJPWGCzdsYvc2+86vDqMk05UaTDKz2f794Yi4CXg58FBEvCAzH4yIFwAPz/HZq4CrAJYvX17dPiVJkmpk+tk1Rf9leOXZy2oTSKaUtvg1IvaLiP2nHgMnAf8E3Ayc237bucAnyuqDJEm9rFUQbTPNEkLJysMW1S6UQLkjJgcDN0WrWtwC4COZ+dmI+Efg+oh4G/At4KwS+yBJUs/63Y/fy5Pbi5y4aTlnxRLec/rRhbdbhNKCSWZ+Ezh2lus/AH61rPtKktQPXnHZrYWHkpWHLeLa844rtM2iWflVkqQaWdvYzDV33F94u3UeJZnOYCJJUg2suvp2Nn7jkVLa7pVQAgYTSZK67hWX3cpDjz1VStu9FEqgmpL0kiRpDmWGksVjoz0VSsARE0mSuqLI039nU/Xhe0UxmEiSVJFWXZJ7mdxW/BbgAJ4zOsIPJ7dxSM2que4Og4kkSSVrjDdZd/MWJia3ldJ+3crK7w2DiSRJJSpryma/fYa57PX1OHivSAYTSZJKVEYo6bWdNrvDXTmSJJWgMd5k6ZpPF95uP4cScMREkqTCNMabXPrJLTz6RLFrSQ5cOMIlpx7Vd9M2szGYSJJUgLLWkvTC+TZFMphIkrSXygglQwFveUV/T9vMxmAiSdJeKPrQvX2Hg69d9urC2us1BhNJknZDY7zJ+lu20pyYJIAssO3Dn78ft154fIEt9h6DiSRJHZo5ZVNkKLny7GUDsbh1V9wuLElSh8o62+acFUsMJW2OmEiS1IFVV99eeJtjoyOsO20wtgF3ymAiSdIcGuNN3nXjvTxRwqF7/V4obU8ZTCRJmqGsQmnQXwfulcFgIknSNEVv/53i4tbOuPhVkqS2xniz8FAyMhSGkt1gMJEkiXKqt46NjrD+zGMNJbvBqRxJ0sArevpm0M63KZLBRJI0sIoOJMMB7zvLaZu9YTCRJA2kQ9d82sqtNeQaE0nSQGmMN1lqKKktR0wkSQOhMd7knddvYkeBieTAhSNccqqVW4tkMJEk9b0yapMsHhtl45oTCm1TBhNJUp97xWW38tBjTxXa5ujIMKtPPqLQNtViMJEk9aVVV9/Oxm88Ulh7I0OwfSccYkn5UhlMJEl9ozHeZP0tW2lOTBbW5rMWDPHeNxxjEKmIwUSS1Bca401Wf+wethW4utUTgKtnMJEk9aSp0ZEHJibZd2SIyW07C23fLcDdYTCRJPWctY3NXHvH/U/XIikylIyNjrDuNLcAd4vBRJLUUxrjzWeEkqIsCPj65a8puFXtLiu/SpJ6yvpbthYeSlYetshQUhMGE0lSTylyxw3A4c/fz5OAa8RgIknqCVNn3BRp5WGLuPXC4wttU3vHNSaSpFprjDe5YMOmQtscHRnm8jOOdoFrDRlMJEm1VXT11sDKrXVnMJEk1dKRF3+GnxRULO2AZw1z76WnFNKWymUwkSTVyolX3Ma/PPx4IW3tOxx87bJXF9KWqmEwkSTVwtrGZq654/7C2rNya28ymEiSuu6YSz7Lj57cUVh7Y6MjhpIeZTCRJHVFY7zJpZ/cwqNPbCu03dGRYdaddlShbao6BhNJUuWKnrYZCsh0x00/MJhIkipVdCg5Z8US3nP60YW1p+4ymEiSKtEYb/KODZsKPefGBa79p/RgEhHDwF1AMzNfGxGHAh8FngvcDbw1M58qux+SpO4punrrPsPBP7sNuC9VcVbO24GvTnv+XuD9mfli4FHgbRX0QZLUJSdecVuhoWR0ZJj/743HFtae6qXUYBIRLwReA3yg/TyAE4CPtd/yYeD0MvsgSeqOqUP3iiqWBrB4bNQzbvpc2VM5VwK/A+zffv5cYCIzt7effweY9b+uiDgfOB9gyZIl5fZSklSYMg7dO3DhCOP/7aRC21Q9lTZiEhGvBR7OzLv35POZeVVmLs/M5QcddFDBvZMklaGsk4AvOdW6JIOizBGTlcBpEfFqYF/gAOCPgLGIWNAeNXkh0CyxD5KkkjXGm7zrxnt5YtvOQtv1JODBVFowycyLgIsAIuJ44Lczc1VE3AC8kdbOnHOBT5TVB0lS8RrjTdbfspUHJiYZWzhSeOXWlYct4trzjiu0TfWOKnblzPS7wIUR8XVaa07+ogt9kCTtgcZ4k4tu3ExzYpKEQkNJ0CqWZigZbJUUWMvM24Db2o+/Cby8ivtKkoq1/patTG4r7rC9KRZK0xQrv0qSOtIYb9KcmCy0TadtNFM3pnIkST2mjN02hhLNxhETSdKcGuNNLv3klkLXkowMwfoznbrR7AwmkqRZlTFK4knA2hWDiSTppxQdSoYCvnn5awprT/3LYCJJeoZVV9/Oxm88Ulh7w0PB+8700D11xmAiSQKKDyTQOnTPyq3aHQYTSRIvvujTbM9i21w8NsrGNScU26j6nsFEkgZUWWfcQOvgvdUnH1F4u+p/BhNJGiBT59wUXSgNWtuAt+/04D3tHYOJJA2IqXNuyigp7zZgFcVgIkl9rIwCadONjY6w6ZKTSmlbg8lgIkl9qjHeZPXH7mHbjoJXtbaNjgyz7rSjSmlbg8tgIkl9at3NW0oLJW4DVlkMJpLUh1ZdfTsTk8VP34yODHP5GUcbSFQag4kk9Zm1jc2FF0oDR0lUDYOJJPWJck4CDtafeaxhRJUxmEhSH3jFZbfy0GNPFdrmcBhKVD2DiST1qDKLpQHszDSUqHIGE0nqQWUcuDfTIWOjpbYvzWao2x2QJO2esha3TudZN+oWg4kk9ZDGeJNr7ri/0DYXj41yzoolLB4bJdrP3RKsbnEqR5JqrjHeZN3NWwqtSxLA+89eZvhQ7RhMJKnGGuNNLtywiZ0FtnnAs4a599JTCmxRKo7BRJJqaG1jM9fd+W12ZLEl5Q/efx/uvPjEQtuUimQwkaQaaYw3+d2P38uT24scI2k5Z8US3nP60YW3KxXJYCJJNdEYb/KODZso+tg9z7dRLzGYSFJN/PYN9xQeSjzfRr3GYCJJNbDq6tvZvrPYWLJ4bJSNa04otE2pbAYTSeqSMg7dm2KBNPUqg4kkVayMuiQzuaZEvcpgIkklmzps74GJScYWjjDxxLbC15JMt3hs1FCinmUwkaSSzDYyUvS0zRA8o/iaUzjqdQYTSSpBY7zJRTduZnLbjlLaf9aCId77hmMAnh6NOcQdOOoDBhNJKsH6W7aWFkrGRkfYdMlJTz83iKifeLqwJJWgOTFZSrujI8OsO+2oUtqW6sARE0kqwPQFrhHl3MNiaRoEBhNJ2ksz15MUee7elWcvM4hooBhMJGkvlbGeZN/h4GuXvbrQNqVeYDCRpD00NX1T9HoSTwHWIOsomETEKLAkM7eW3B9J6glrG5u55o77C2/XUKJBt8tgEhGnAn8I7AMcGhHLgHdn5mkl902SamnV1bez8RuPFNrmysMWce15xxXaptSLOtkuvA54OTABkJmbgENL65Ek1diJV9xWeCg5Z8USQ4nU1slUzrbM/GE8c/9bmcc8SFLtlDFK4o4b6ad1Eky2RMRbgOGIOBz4r8Dfl9stSaqHxniTCzZsKrxdQ4k0u06CyW8BFwNPAtcBtwD/vcxOSVK3NcabXHzTZh5/qthtwBZJk+a3y2CSmU/QCiYXl98dSeq+MnbcuNtG6kwnu3K+wCxrSjLzhFJ6JEklml46fuZpvGWsIwEIMJRIHepkKue3pz3eF3gDsL2c7khSeWaWjm9OTHLBhk2868Z7eWLbztLue8jYaGltS/2mk6mcu2dc2hgR/7Crz0XEvsCXgGe17/OxzLwkIg4FPgo8F7gbeGtmPrXbPZek3TRX6fgyQ8nIULD65CNKa1/qN7usYxIRi6b9el5EnAw8p4O2nwROyMxjgWXAKRGxAngv8P7MfDHwKPC2Pe++JHXugYJLx89mn+F/K60wNjrC+jOPdaGrtBs6mcq5m9Yak6A1hfOvdBAmMjOBH7efjrR/JXAC8Jb29Q/TKuD2p7vTaUnaE88ZHWFicltp7R+4cITx/3ZSae1Lg6CTqZw9rvIaEcO0gs2LgT8BvgFMZObUGpXvALP+UyIizgfOB1iyZMmedkGSgNb6ksefKm953MhwcMmpR5XWvjQo5gwmEXHGfB/MzBt31Xhm7gCWRcQYcBNwZKcdy8yrgKsAli9fbqVZSbtt+g6cMn+IWJtEKs58IyanzvNaArsMJk+/OXOive34OGAsIha0R01eCDQ7bUeSOjVzB04ZrN4qFW/OYJKZ/3FvGo6Ig2idszMREaPAibQWvn4BeCOtnTnnAp/Ym/tI0nRToyTNEhe6jgzB+jMNJVIZOln8SkS8BjiKVh0TADLz3bv42AuAD7fXmQwB12fmpyLiK8BHI+I9wDjwF3vUc0maoTHe5J033MOOneVN3Kw8bJEnAUsl6qTy658BC4FXAh+gNdqxyzommXkv8NJZrn8TePlu91SSduHimzaXFkoiYNUrLCsvla2TEZNfzMxjIuLezLw0It4H/FXZHZOkTk1N3xR94N6UsdERNl3iNmCpCp0Ek6mJ2ici4hDgB7SmaSSpqxrjTS795BYefaK82iSjI8OsO81twFJVOgkmn2pv910PfJnWjpyry+yUJO1KFetJ3AYsVW++OiafAT5Cq3z8j4GPR8SngH0z84dVdVDSYJrvFOC1jc1cc8f9pdz3nBWuI5G6ab4Rkz8H3gRcERG3AdcBnzaUSCrbbKcAX3TjZu761iPccNd3eHJ7sYfuLRwZ4vfPOMaREakG5qtj8gngExGxkFaxtf8A/GlE/BXwkcy8taI+Shows50CPLltRymjJKMjQ3zlv7+q8HYl7Zldni6cmU9k5obMfD1wEq2Tgj9bdsckDa4qTgGe8pNtxY6+SNo7uwwmEXFwRPxWRGwEGsAtwMvK7pikwXXI2Ghf3kvSrs0ZTCLivIj4PK2dOIcDqzPzZzNzTWbeU1kPJQ2c1Scfset/NRVgdGSY1ScfUcGdJHVqvsWvxwGXA5/LTMc6JZWuMd5k9Q2bKGN25cqzlwHMudNHUj3Mt/j1/6myI5IGV5mBBFpbgKcCiEFEqreODvGTpLI0xptcsGFTKW0HsMq6JFJPMZhIqlxjvMm6m7cwMVlOKfnhgPedtczREakHzVf5ddF8H8zMR4rvjqR+V2bVVoCVhy3i2vOOK619SeWab8Tkblrn4gSwBHi0/XgMuB84tOzOSeovZYYSz7WR+sN8i18PBYiIq4GbMvMz7eevAk6vpHeSet7UmTfNEoumHbhwhI1rTiitfUnV6aRUwIqpUAKQmX8F/GJ5XZLUL6bOvCkzlIwMB5ecelRp7UuqVieLXx+IiLXANe3nq4AHyuuSpH6x7uYtP3XmTZGcvpH6TyfB5M3AJcBNtNacfKl9TZLmtLaxubRdN0PAFWe760bqR7sMJu3dN2+PiP0y8/EK+iSph5VdLG1sdIR1px1lKJH61C6DSUT8IvAB4NnAkog4Fvj1zPyNsjsnqf6mFrc+MDHJ6MgQT5SUSNwGLA2GTqZy3g+cDNwMkJn3RMSvlNorST1h5vbfskLJOVZvlQZGR5VfM/PbETH9Unmr2ST1hMZ4s9RCaVOudC2JNFA6CSbfbk/nZESMAG8HvlputyTVWWO8yTuvv6fUewwFXGFZeWngdBJM/hPwR8BioAn8NeD6EmnAVFEobYoLXKXB1UkwOSIzV02/EBErgY3ldElS3UwVSiuzJskU15NIg62TYPI/gZd1cE1Sn6lylMRiaZJg/tOFj6NVev6giLhw2ksHAMNld0xSd1U1SvKsBUNsfc+rSr2HpN4x34jJPrRqlywA9p92/UfAG8vslKTuaYw3WXfzltKqtk43PBS89w3HlH4fSb1jvtOFvwh8MSI+lJnfqrBPkrqgMd7k0k9u4dEnyg0k++0zzBNP7eAQp24kzaKTNSYfiIgzM3MCICIOBD6amSeX2jNJlWmVkb+HbTuz1PsEsOXdp5R6D0m9rZNg8rypUAKQmY9GxPPL65KkqlS5uBXgkLHRSu4jqXd1Ekx2RsSSzLwfICJ+htYpw5J6WJVbgAFGR4ZZffIRldxLUu/qJJhcDPxdRHyR1kjsLwPnl9orSaWpepQE3AosqXO7DCaZ+dmIeBmwon3pgsz8frndklSGqkdJAA5cOMLGNSdUdj9JvW2+OiZHZubX2qEE4IH270vaUztfLr97kvbW2sZmrrvz2+zI6mdgR4aDS049qvL7Supd842YvBM4D3jfLK8l4D+BpJpb29hcyQnA0Drf5rXHvoAvfO17PDAx6XZgSXtkvjom57V/f2V13ZFUpKpCyeKxUadrJBVivqmcM+b7YGbeWHx3JBVlbWNzZfdyt42kosw3lXNq+/fn0zoz5/Pt568E/h4wmEg1tLaxmY/ceT8l10p72jkrljhdI6kw803l/EeAiPhr4CWZ+WD7+QuAD1XSO0kdcQuwpH7RSR2TF02FkraHgCUl9UfSbqpqC3AA7z97mUFEUqk6CSafi4hbgOvaz88G/qa8LknqVGO8yTuvv6f0rcCGEklV6aTA2m9GxOuBX2lfuiozbyq3W5J2ZWqkpIr6JKtcRyKpIp2MmAB8GXgsM/8mIhZGxP6Z+ViZHZM0t8Z4k3ds2FTZoVXvOf3oiu4kadDtMphExHm0zsZZBBwGLAb+DPjVcrsmaTZVFk2D1iJXSapKJyMm/wV4OXAnQGb+S0Q8v9ReSQNqanfNVOXUVx55EF/42vdoTkwSVH+stycCS6paJ8Hkycx8KiIAiIgFVP/zUep7axubufaO+5/+n6s5MfmMkZGy/6cbGQ7O/r9fZEl5SV3VSTD5YkS8CxiNiBOB3wA+uasPRcSLgP8NHEzrZ+pVmflHEbEI2AAsBe4DzsrMR/es+1J/aIw3nxFKqnbgwhEuOfUoQ4ikruskmPwu8P8Cm4FfBz4DfKCDz20H3pmZX46I/YG7I+JW4NeAz2XmH0TEGmBN+x7SwFp/y9bKQ4lbgCXV0bzBJCKGgS2ZeSRw9e403C7K9mD78WMR8VVaC2dfBxzfftuHgdswmGhAdaNiK8DIULD+zGMNJZJqZ95gkpk7ImJrRCzJzD3eBhARS4GX0lpAe/C0SrLfpTXVIw2cxniT1Tfcw7aqDrVps5S8pDrrZCrnQGBLRPwD8PjUxcw8rZMbRMSzgY8DF2Tmj6YW0bbbyIiY9adyRJxPa5syS5ZYAV/9Z93NWyoNJeesWGI9Ekm110kw+b09bTwiRmiFkmszc+o04oci4gWZ+WD7QMCHZ/tsZl4FXAWwfPlydwGp70xMbqvsXoYSSb1izmASEfsC/wl4Ma2Fr3+Rmds7bThaQyN/AXw1M6+Y9tLNwLnAH7R//8Qe9FvqWY3xJhfftLmy+xlKJPWS+UZMPgxsA/4WeBXwEuDtu9H2SuCtwOaI2NS+9i5ageT6iHgb8C3grN3ss9QTZhZLW33yEdz1rUcqrdp6pbtuJPWYyDkOAIuIzZl5dPvxAuAfMvNlVXZuyvLly/Ouu+7qxq2lPTJ1wN7kth1dub+7biTVWUTcnZnLZ3ttvhGTpyfAM3P79EWrkua3/patXQsl7rqR1MvmCybHRsSP2o+DVuXXH7UfZ2YeUHrvpB71QMV1SaYsHhtl45oTunJvSSrCnMEkM4er7IjUTw4ZG628aJoH7knqB0Pd7oDUTxrjTV767r8uPZQMRWu3zeKxUYLWSMnlZxzt9I2kntdJHRNJu9Cq4rqJbTvLv1cAV5zlbhtJ/clgIu2lxniTCzdsooJMQgCrViwxlEjqWwYTaS80xpu8Y8Omyk4G9jRgSf3OYCLNYrbiaNMDwdrG5koLpUFrHYmhRFK/M5hIM8wsjtacmOSiG1sl5E9/6WJOvOI2/uXhx+dronDuuJE0KOas/FonVn5VlVb+wedn3VUzHMGOiv5/GQIOGB3hh5PbZh2xkaRetqeVX6WBNFdxtCpCyXAE7zvLUvKSBpd1TKQZDhkb7dq9DSWSBp3BRJph9clHMDJU/dlQ57gNWJKcytFgm9p905yYfHoNydjoCNt2Vrf2auHIEL9/xjGGEknCYKIBNnP3zdQakonJbfN9rDBjoyOsO+0oA4kkTWMw0cBaf8vWp0NJlUZHhj3XRpLm4BoTDaTGeLPy03+hNUpiKJGkuTliooEzNYVTtXNWLOE9px9d+X0lqZcYTDRQGuNN3nn9PZUVSptiKJGkzhhMNDBWXX07G7/xSKX3HB0Z4nJ33EhSxwwmGghVh5IDF45wyanuuJGk3WUwUV9rjDdZd/OWyrYAB7DKaRtJ2mMGE/WFqUJpD0xMMrZwhMzq6pFM9/6zlzlKIkl7wWCinjezUNqjT1QfSAAWj40aSiRpL1nHRD2vW4XSpgtaZ+xIkvaOwUQ9rxuF0qabWlfiaIkk7T2DiXrecFR7EvA5K5aweGyUoDV98/6zl7nYVZIK4hoT9ZzpJwIPBVR1ELA7biSpfAYT1cpsu2t+OLmNQ8ZGeeWRB/Hpex98xuLWqkKJdUkkqRoGE9XGfLtrmhOTXHPH/V3p18rDFnHtecd15d6SNGhcY6LaqMPumpnOWbHEUCJJFXLERLXxQJd310y3eGyUjWtO6HY3JGngOGKi2jhkbLTbXQBgdGTYmiSS1CUGE9XG6pOPYGSo2q2/My0eG+XyM452kaskdYlTOaqNu771CNuq2mYzTeAZN5JUF46YqBbWNjZ3ZdfN6MiwoUSSasQRE3VdY7zZlVCyeGyU1ScfYSiRpBoxmKgrpldvrdo5Vm+VpNoymKhSaxub+cid91dWsXUmQ4kk1ZvBRJVojDdZfcMmtu3sXh8MJZJUfwYTla4x3uTC6zd1bZTEw/ckqXcYTFSKxniTSz+55Rnn3VQlgLGFI0w80Tr8zwWuktQ7DCYqXGO8yeqP3cO2HdUPkXjgniT1NoOJCrf+lq2Vh5Ih4ArrkUhSzzOYqFCN8WblW4DHRkfYdMlJld5TklQOg4kKs7axmWsrLpQ2MhSsO+2oSu8pSSqPwUR7rTHeZN3NW5iYrHah69joCOtOO8rpG0nqIwYTdWSqUusDE5PP2OnSGG9y0Y2bmdy2o7K+jAwF68881kAiSX3IYKJdmhk+mhOTXHTjZm646342fuORSvviKIkk9bfSgklEfBB4LfBwZv5C+9oiYAOwFLgPOCszHy2rDyrG+lu2/tSIyOS2HZWGksVjo2xcc0Jl95MkdcdQiW1/CDhlxrU1wOcy83Dgc+3nqrkHunDQ3nSjI8OsPvmIrvZBklSN0oJJZn4JmPlP6tcBH24//jBweln3VzEa402GIrp2/wMXjnD5GUc7dSNJA6LqNSYHZ+aD7cffBQ6e640RcT5wPsCSJUsq6Jpmmtr+240jbkaGYP2ZFkyTpEHTtcWvmZkRMeffeZl5FXAVwPLly7t0/NvgWnX17ZUvbAVYODLE759xjIFEkgZU1cHkoYh4QWY+GBEvAB6u+P5qm2v7L7RGSqoOJed4+q8kieqDyc3AucAftH//RMX3F7Nv/119wz1dOQ3YERJJ0nRlbhe+DjgeeF5EfAe4hFYguT4i3gZ8CzirrPtrbrNt/922MysNJVd64J4kaRalBZPMfPMcL/1qWfdUZ7q9/XflYYsMJZKkWZVZx0Q11BhvdmWXzXT3/aC7wUiSVF8GkwHSGG9y4fWbut2Nro/YSJLqy2AyQNbfspWd3R4uAQ4ZG+12FyRJNeUhfn1s+pbg54yOMDFZ7Y4bgIBnTB1ZXl6SNB+DSR9qjDd/autvN0LJysMWcebyJXPWS5EkaSaDSZ9pjDdZ/bF72Laje3M2Y6MjrDvtqKcDiEFEktQpg0mfufSTW7oWShY7IiJJ2ksGkz5TdeXWKRZMkyQVwWDSw2aed/PKIw+qvA+eAixJKpLBpIdMBZHmxORP7XZpTkxyzR33V9ofD96TJBXNYNIjZh68181yJAcuHOGSU49ylESSVDiDSY+Y7eC9qu23zzCXvf5oA4kkqTQGkx7RzTLuQwFXnOU6EklS+SxJ3yO6Vcb9wIUjhhJJUmUcMekRq08+gguv31TJWTcHPGuYey89pfwbSZI0g8GkpmZuBV64z1AloeRZC4YMJZKkrjGY1MT0IDK2cIQf/2Q729pJpFnR+pKR4eC9bzimkntJkjQbg0kNzNwK3I3qrTPPt5EkqRsMJjXQza3AbgGWJNWJwaQGurEV+PDn78etFx5f+X0lSZqPwaQGDhkbrW4diWfbSJJqzGDSZY3xJt/9YTWhxLNtJEl1ZzDpksZ4k3U3b2FisvyFrk7bSJJ6hcGkCxrjzUqKpS0YCv7wzGOdtpEk9QyDScUa400u2LCp9PusPGwR1553XOn3kSSpSAaTClURSoaAK852caskqTcZTCqy6urb2fiNR0pr/+D99+HOi08srX1JkqpgMKnAiVfcxr88/Hhp7d/3B68prW1JkqpkMClR2aMkngIsSeo3BpMSNMab/M7H7uGpHeVtu3FxqySpHxlMClb2KEkAqyyUJknqUwaTAq1tbC4tlDhtI0kaBEPd7kA/ueaO+0tp95wVSwwlkqSB4IjJXmqMN7lwwyZ2ltC2W4AlSYPGYLIXylpPYil5SdKgMpjsoTJCiSMkkqRBZzDZA8dc8ll+9OSOQts8x502kiQZTHbX0jWfLrS9AP7Vyq2SJAEGk4694rJbeeixpwpt06kbSZKeyWDSgUPXfJoia7iOjgxx+RnHuLhVkqQZDCbzaIw3uWDDpkLbdC2JJElzM5jMoei1JEPAFWcvc5REkqR5GExmUXQocZREkqTOGEymKXotyYELR7jk1KMcJZEkqUMGE4ovlnb48/fj1guPL6w9SZIGxUAHkzIWt17pOhJJkvbYwAaTF1/0abYXOG/jKIkkSXtvIIPJkRd/prBQsvKwRVx73nHFNCZJ0oAb6sZNI+KUiNgaEV+PiDVV3/8nO4pJJVeevcxQIklSgSofMYmIYeBPgBOB7wD/GBE3Z+ZXqu7LnnIdiSRJ5ejGVM7Lga9n5jcBIuKjwOuA2gcTz7aRJKlc3Qgmi4FvT3v+HeAVXejHbrnPE4AlSSpdV9aYdCIizo+IuyLiru9973td68fKwxYZSiRJqkg3RkyawIumPX9h+9ozZOZVwFUAy5cvL7Iga8cMJJIkVasbweQfgcMj4lBageRNwFu60I85ubhVkqTuqDyYZOb2iPhN4BZgGPhgZm6psg8LgjnrmDhKIklS93RljUlmfiYzfy4zD8vMy6q+/9cvfw0L4pnXFoShRJKkbhvIyq/QCieSJKlearsrR5IkDR6DiSRJqg2DiSRJqg2DiSRJqg2DiSRJqg2DiSRJqg2DiSRJqg2DiSRJqg2DiSRJqg2DiSRJqo3InOM0uxqJiO8B3yqp+ecB3y+pbfn9ls3vt1x+v+Xy+y1fXb/jn8nMg2Z7oSeCSZki4q7MXN7tfvQrv99y+f2Wy++3XH6/5evF79ipHEmSVBsGE0mSVBsGE7iq2x3oc36/5fL7LZffb7n8fsvXc9/xwK8xkSRJ9eGIiSRJqo2BDSYRcUpEbI2Ir0fEmm73px9ExAcj4uGI+Kdp1xZFxK0R8S/t3w/sZh97WUS8KCK+EBFfiYgtEfH29nW/4wJExL4R8Q8RcU/7+720ff3QiLiz/bNiQ0Ts0+2+9rKIGI6I8Yj4VPu5329BIuK+iNgcEZsi4q72tZ77+TCQwSQihoE/AV4FvAR4c0S8pLu96gsfAk6ZcW0N8LnMPBz4XPu59sx24J2Z+RJgBfBf2v/d+h0X40nghMw8FlgGnBIRK4D3Au/PzBcDjwJv614X+8Lbga9Oe+73W6xXZuayaVuEe+7nw0AGE+DlwNcz85uZ+RTwUeB1Xe5Tz8vMLwGPzLj8OuDD7ccfBk6vsk/9JDMfzMwvtx8/RuuH+2L8jguRLT9uPx1p/0rgBOBj7et+v3shIl4IvAb4QPt54Pdbtp77+TCowWQx8O1pz7/TvqbiHZyZD7Yffxc4uJud6RcRsRR4KXAnfseFaU8zbAIeBm4FvgFMZOb29lv8WbF3rgR+B9jZfv5c/H6LlMBfR8TdEXF++1rP/XxY0O0OaHBkZkaE28D2UkQ8G/g4cEFm/qj1j84Wv+O9k5k7gGURMQbcBBzZ3R71j4h4LfBwZt4dEcd3uTv96pcysxkRzwdujYivTX+xV34+DOqISRN40bTnL2xfU/EeiogXALR/f7jL/elpETFCK5Rcm5k3ti/7HRcsMyeALwDHAWMRMfWPOH9W7LmVwGkRcR+t6fMTgD/C77cwmdls//4wrWD9cnrw58OgBpN/BA5vrwbfB3gTcHOX+9SvbgbObT8+F/hEF/vS09rz8X8BfDUzr5j2kt9xASLioPZICRExCpxIax3PF4A3tt/m97uHMvOizHxhZi6l9TP385m5Cr/fQkTEfhGx/9Rj4CTgn+jBnw8DW2AtIl5Na75zGPhgZl7W3R71voi4Djie1mmWDwGXAA3gemAJrROiz8rMmQtk1YGI+CXgb4HN/Nsc/btorTPxO95LEXEMrcWBw7T+0XZ9Zr47In6W1r/wFwHjwDmZ+WT3etr72lM5v52Zr/X7LUb7e7yp/XQB8JHMvCwinkuP/XwY2GAiSZLqZ1CnciRJUg0ZTCRJUm0YTCRJUm0YTCRJUm0YTCRJUm0YTCTNKiJOj4iMiF1WP42ICyJi4V7c69ci4o9nXFsaEd+JiKEZ1zdFxCvmaGfp9NOtJfUeg4mkubwZ+Lv277tyAbDHwWQ2mXkfcD/wy1PX2iFp/8y8s8h7SaoPg4mkn9I+j+eXaB1B/6Zp14cj4g8j4p8i4t6I+K2I+K/AIcAXIuIL7ff9eNpn3hgRH2o/PjUi7oyI8Yj4m4jY1YFi102/f/vxR9sjI38bEV9u//rFWf4MzxiFiYhPTZ3REhEnRcTt7c/e0P7zSqoBg4mk2bwO+Gxm/jPwg4j4v9rXzweWAssy8xhaZ/b8D+AB4JWZ+cpdtPt3wIrMfCmtap+/s4v3Xw+cPu0slbNphZWHgRMz82Xta/+j0z9YRDwPWAv8+/bn7wIu7PTzksrl6cKSZvNmWgesQStAvBm4G/j3wJ9NHVO/B6WtXwhsaB8mtg/wr/O9OTMfaq8Z+dWIeAjYnpn/FBHPAf44IpYBO4Cf240+rABeAmxsn8y8D3D7bv45JJXEYCLpGSJiEa2TX49uH5E+DGRErN6NZqafdbHvtMf/E7giM29uT6us66Ctqemch9qPAd7Rfn4srZHfn8zyue08c1R4qh8B3JqZnaydkVQxp3IkzfRG4C8z82cyc2lmvojWyMYvA7cCvz41tdIOMQCPAftPa+OhiPj59o6a10+7/hz+7Vj7c+nMjcCraU3ZfHRaOw9m5k7grbTC00z3AcsiYigiXkTrCHiAO4CVEfHi9p9hv4jYnREXSSUymEia6c382ymlUz7evv4BWjtl7o2Ie4C3tF+/Cvjs1OJXYA3wKeDvgQentbMOuCEi7ga+30lnMnOC1lTLQ5n5zfbl/wWc2+7DkcDjs3x0I61A9RVaa1C+3G7ve8CvAddFxL3ttne5JVpSNTxdWJIk1YYjJpIkqTYMJpIkqTYMJpIkqTYMJpIkqTYMJpIkqTYMJpIkqTYMJpIkqTYMJpIkqTb+Dwd4bqCRv9OFAAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Model-Testing-Heston.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "pytorch",
   "language": "python",
   "display_name": "pytorch"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}