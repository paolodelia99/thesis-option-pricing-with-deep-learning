{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ju-WUaXnY5cr",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Models Testing on Heston data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 824,
     "status": "ok",
     "timestamp": 1650891681415,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "hH3-v8y-AuXg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1650891681417,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "QXEzFQ3iAyj_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set seeds\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1650891681418,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "gsH02HCWA0gC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "synthetic_calls_path = '../data/heston_mc_synthetic_calls.csv'\n",
    "synthetic_puts_path = '../data/heston_mc_synthetic_puts.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1650891681421,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "jT4n95T6A4S6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 3413,
     "status": "ok",
     "timestamp": 1650891684820,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "7H8lEQPCA5IS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "synthetic_calls = pd.read_csv(synthetic_calls_path, index_col=0)\n",
    "synthetic_puts = pd.read_csv(synthetic_puts_path, index_col=0)\n",
    "\n",
    "synthetic_calls = reduce_mem_usage(synthetic_calls)\n",
    "synthetic_puts = reduce_mem_usage(synthetic_puts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1650891684821,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "9TKRgvuOA8pC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "synthetic_options = pd.concat([synthetic_calls, synthetic_puts], axis=0)\n",
    "synthetic_options = shuffle(synthetic_options, random_state=0)\n",
    "synthetic_options = synthetic_options.reset_index()\n",
    "synthetic_options = synthetic_options.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1650891684822,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "3HXliAsq132p",
    "outputId": "09bc2eb1-d20d-4471-ed50-5fa0eba727fb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        Price  Strike Type     Kappa       Rho     Theta        Xi       V_0  \\\n0         100    63.0    P  1.877930 -0.603516  0.252441  0.050323  0.364258   \n1         100   131.0    P  1.459961 -0.262451  0.310059  0.153198  0.338867   \n2         100   105.0    C  0.247192 -0.742676  0.471924  0.463135  0.268311   \n3         100    68.0    P  1.594727 -0.576172  0.099670  0.465088  0.366455   \n4         100    77.0    C  1.563477 -0.328125  0.308838  0.409912  0.241455   \n...       ...     ...  ...       ...       ...       ...       ...       ...   \n605995    100    71.0    P  1.039062 -0.757324  0.227661  0.312500  0.445068   \n605996    100    57.0    C  1.905273 -0.276855  0.322266  0.061432  0.120117   \n605997    100   135.0    C  0.971680 -0.711426  0.270508  0.438477  0.483887   \n605998    100    64.0    P  1.767578 -0.417480  0.054260  0.137573  0.226440   \n605999    100   135.0    P  1.183594 -0.541504  0.479980  0.091614  0.104736   \n\n        Interest Rate  Time to Expiration  Option Price  \n0            0.065308            1.000977      0.002708  \n1            0.069153            0.363525     28.703125  \n2            0.040802            1.099609      2.324219  \n3            0.062683            1.072266      0.060577  \n4            0.011162            0.940430     24.359375  \n...               ...                 ...           ...  \n605995       0.016006            0.487061      1.505859  \n605996       0.025070            0.947754     41.687500  \n605997       0.097107            0.289307      0.180542  \n605998       0.070374            0.365479      0.001135  \n605999       0.095215            0.864746     32.093750  \n\n[606000 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Price</th>\n      <th>Strike</th>\n      <th>Type</th>\n      <th>Kappa</th>\n      <th>Rho</th>\n      <th>Theta</th>\n      <th>Xi</th>\n      <th>V_0</th>\n      <th>Interest Rate</th>\n      <th>Time to Expiration</th>\n      <th>Option Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100</td>\n      <td>63.0</td>\n      <td>P</td>\n      <td>1.877930</td>\n      <td>-0.603516</td>\n      <td>0.252441</td>\n      <td>0.050323</td>\n      <td>0.364258</td>\n      <td>0.065308</td>\n      <td>1.000977</td>\n      <td>0.002708</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100</td>\n      <td>131.0</td>\n      <td>P</td>\n      <td>1.459961</td>\n      <td>-0.262451</td>\n      <td>0.310059</td>\n      <td>0.153198</td>\n      <td>0.338867</td>\n      <td>0.069153</td>\n      <td>0.363525</td>\n      <td>28.703125</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100</td>\n      <td>105.0</td>\n      <td>C</td>\n      <td>0.247192</td>\n      <td>-0.742676</td>\n      <td>0.471924</td>\n      <td>0.463135</td>\n      <td>0.268311</td>\n      <td>0.040802</td>\n      <td>1.099609</td>\n      <td>2.324219</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100</td>\n      <td>68.0</td>\n      <td>P</td>\n      <td>1.594727</td>\n      <td>-0.576172</td>\n      <td>0.099670</td>\n      <td>0.465088</td>\n      <td>0.366455</td>\n      <td>0.062683</td>\n      <td>1.072266</td>\n      <td>0.060577</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100</td>\n      <td>77.0</td>\n      <td>C</td>\n      <td>1.563477</td>\n      <td>-0.328125</td>\n      <td>0.308838</td>\n      <td>0.409912</td>\n      <td>0.241455</td>\n      <td>0.011162</td>\n      <td>0.940430</td>\n      <td>24.359375</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>605995</th>\n      <td>100</td>\n      <td>71.0</td>\n      <td>P</td>\n      <td>1.039062</td>\n      <td>-0.757324</td>\n      <td>0.227661</td>\n      <td>0.312500</td>\n      <td>0.445068</td>\n      <td>0.016006</td>\n      <td>0.487061</td>\n      <td>1.505859</td>\n    </tr>\n    <tr>\n      <th>605996</th>\n      <td>100</td>\n      <td>57.0</td>\n      <td>C</td>\n      <td>1.905273</td>\n      <td>-0.276855</td>\n      <td>0.322266</td>\n      <td>0.061432</td>\n      <td>0.120117</td>\n      <td>0.025070</td>\n      <td>0.947754</td>\n      <td>41.687500</td>\n    </tr>\n    <tr>\n      <th>605997</th>\n      <td>100</td>\n      <td>135.0</td>\n      <td>C</td>\n      <td>0.971680</td>\n      <td>-0.711426</td>\n      <td>0.270508</td>\n      <td>0.438477</td>\n      <td>0.483887</td>\n      <td>0.097107</td>\n      <td>0.289307</td>\n      <td>0.180542</td>\n    </tr>\n    <tr>\n      <th>605998</th>\n      <td>100</td>\n      <td>64.0</td>\n      <td>P</td>\n      <td>1.767578</td>\n      <td>-0.417480</td>\n      <td>0.054260</td>\n      <td>0.137573</td>\n      <td>0.226440</td>\n      <td>0.070374</td>\n      <td>0.365479</td>\n      <td>0.001135</td>\n    </tr>\n    <tr>\n      <th>605999</th>\n      <td>100</td>\n      <td>135.0</td>\n      <td>P</td>\n      <td>1.183594</td>\n      <td>-0.541504</td>\n      <td>0.479980</td>\n      <td>0.091614</td>\n      <td>0.104736</td>\n      <td>0.095215</td>\n      <td>0.864746</td>\n      <td>32.093750</td>\n    </tr>\n  </tbody>\n</table>\n<p>606000 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pn28_RUMBAFH",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 515,
     "status": "ok",
     "timestamp": 1650891685322,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "32oPe6XUBCTF",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "synthetic_options = pd.get_dummies(synthetic_options, prefix='', prefix_sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 1032,
     "status": "ok",
     "timestamp": 1650891686346,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "_Tlc7k7xBDPV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_sc = StandardScaler()\n",
    "output_sc = StandardScaler()\n",
    "input_data = input_sc.fit_transform(synthetic_options.drop('Option Price', axis=1))\n",
    "output_data = output_sc.fit_transform(synthetic_options['Option Price'].values.reshape(-1, 1))\n",
    "\n",
    "train_size = 0.8\n",
    "val_size = 0.1\n",
    "\n",
    "last_train_idx = int(np.round(len(input_data) * train_size))\n",
    "last_val_idx = last_train_idx + int(np.round(len(input_data) * val_size))\n",
    "\n",
    "X_train = input_data[0:last_train_idx]\n",
    "X_val = input_data[last_train_idx:last_val_idx]\n",
    "X_test = input_data[last_val_idx:]\n",
    "\n",
    "y_train = output_data[0:last_train_idx]\n",
    "y_val = output_data[last_train_idx:last_val_idx]\n",
    "y_test = output_data[last_val_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1650891686347,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "7nEEoQGvvDpL",
    "outputId": "88b4d863-d037-439b-e625-5ebb52ad41ef",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['Price', 'Strike', 'Kappa', 'Rho', 'Theta', 'Xi', 'V_0',\n       'Interest Rate', 'Time to Expiration', 'C', 'P'],\n      dtype='object')"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_options.drop('Option Price', axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1650891686349,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "IwMVtvfABIhR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train = Variable(torch.Tensor(X_train))\n",
    "X_val = Variable(torch.Tensor(X_val))\n",
    "X_test = Variable(torch.Tensor(X_test))\n",
    "\n",
    "y_train = Variable(torch.Tensor(y_train))\n",
    "y_val = Variable(torch.Tensor(y_val))\n",
    "y_test = Variable(torch.Tensor(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ra2l5P1nBVCz",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1650891686350,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "xTLMLFoSBWDy",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "CUDA = torch.cuda.is_available()\n",
    "device = 'cuda:0' if CUDA else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1650891686352,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "CQ9Gl3bUBWsj",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "\n",
    "  def __init__(self, module):\n",
    "    super(ResBlock, self).__init__()\n",
    "    self.module = module\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.module(x) + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1650891686353,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "YL3SicQPBYq0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class HiddenLayer(nn.Module):\n",
    "\n",
    "  def __init__(self, layer_size, act_fn):\n",
    "      super(HiddenLayer, self).__init__()\n",
    "      \n",
    "      if act_fn == 'ReLU':\n",
    "        self.layer = nn.Sequential(\n",
    "          nn.Linear(layer_size, layer_size),\n",
    "          nn.ReLU())\n",
    "      elif act_fn == 'LeakyReLU':\n",
    "        self.layer = nn.Sequential(\n",
    "          nn.Linear(layer_size, layer_size),\n",
    "          nn.LeakyReLU())\n",
    "      elif act_fn == 'ELU':\n",
    "        self.layer = nn.Sequential(\n",
    "          nn.Linear(layer_size, layer_size),\n",
    "          nn.ELU())\n",
    "    \n",
    "  def forward(self, x):\n",
    "    return self.layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 455,
     "status": "ok",
     "timestamp": 1650891686792,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "lHUFGf9xBawS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "  def __init__(self, input_size, output_size, hidden_size, num_layers, act_fn):\n",
    "    super(Net, self).__init__()\n",
    "    self.input_size = input_size\n",
    "    self.output_size = output_size\n",
    "    self.hidden_size = hidden_size\n",
    "\n",
    "    if act_fn == 'ReLU':\n",
    "      self.initial_layer = nn.Sequential(\n",
    "          nn.Linear(self.input_size, self.hidden_size),\n",
    "          nn.ReLU())\n",
    "    elif act_fn == 'LeakyReLU':\n",
    "      self.initial_layer = nn.Sequential(\n",
    "          nn.Linear(self.input_size, self.hidden_size),\n",
    "          nn.LeakyReLU())\n",
    "    elif act_fn == 'ELU':\n",
    "      self.initial_layer = nn.Sequential(\n",
    "          nn.Linear(self.input_size, self.hidden_size),\n",
    "          nn.ELU())\n",
    "\n",
    "    self.hidden_layers_list = []\n",
    "\n",
    "    for i in range(num_layers // 2):\n",
    "      self.hidden_layers_list.append(\n",
    "          ResBlock(\n",
    "            nn.Sequential(\n",
    "                HiddenLayer(self.hidden_size, act_fn),\n",
    "                HiddenLayer(self.hidden_size, act_fn)\n",
    "            )\n",
    "        )\n",
    "      )\n",
    "\n",
    "    self.hidden_layers = nn.Sequential(*self.hidden_layers_list)\n",
    "\n",
    "    self.net = nn.Sequential(\n",
    "        self.initial_layer,\n",
    "        self.hidden_layers,\n",
    "        nn.Linear(self.hidden_size, self.output_size)\n",
    "    )\n",
    "  \n",
    "  def forward(self, x):\n",
    "    return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1650891686793,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "zcq_lQrHBdH8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def init_weights(m, init_m: str):\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def init_uniform(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "      torch.nn.init.uniform_(m.weight)\n",
    "      m.bias.data.fill_(0.01)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def init_normal(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "      torch.nn.init.normal_(m.weight)\n",
    "      m.bias.data.fill_(0.01)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def init_xuniform(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "      torch.nn.init.xavier_uniform_(m.weight)\n",
    "      m.bias.data.fill_(0.01)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def init_xnormal(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "      torch.nn.init.xavier_normal_(m.weight)\n",
    "      m.bias.data.fill_(0.01)\n",
    "\n",
    "  if init_m == 'uniform':\n",
    "    m.apply(init_uniform)\n",
    "  elif init_m == 'normal':\n",
    "    m.apply(init_normal)\n",
    "  elif init_m == 'xaiver uniform':\n",
    "    m.apply(init_xuniform)\n",
    "  elif init_m == 'xavier normal':\n",
    "    m.apply(init_xnormal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vuCpyycNCKEZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1650891686794,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "YbCOnCSNCL25",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_size = 11\n",
    "output_size = 1\n",
    "num_layers = 4\n",
    "hidden_size = 600\n",
    "batch_size = 1151\n",
    "epochs = 2000\n",
    "lr = 0.000148458\n",
    "init_method = 'xaiver uniform'\n",
    "act_fn = 'LeakyReLU'\n",
    "\n",
    "model = Net(input_size, output_size, hidden_size, num_layers, act_fn)\n",
    "init_weights(model, init_method)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 7351,
     "status": "ok",
     "timestamp": 1650891694138,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "QqZbxrppvDpZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "X_train = X_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "\n",
    "X_val = X_val.to(device)\n",
    "y_val = y_val.to(device)\n",
    "\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1650891694142,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "Q-9T0GArCMgp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class OptDataset(Dataset):\n",
    "\n",
    "  def __init__(self, X, y):\n",
    "    self.X = X\n",
    "    self.y = y\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.X[idx], self.y[idx]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6-hCH2ivDpb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Losses Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1650891694144,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "mVaO8TruHW4M",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def MAPELoss(output, target):\n",
    "  return torch.mean(torch.abs((target - output) / target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1650891694149,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "tVLW5dHhvDpe",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, loss_fn, X_val, y_val):\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    out = model(X_val)\n",
    "    loss = loss_fn(out, y_val)\n",
    "    print('\\nVal set: Average loss: {:.8f}\\n'.format(\n",
    "            loss.item()))\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68eF5_EovDpf",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Early Stopping class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1650891694150,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "n2So2ffSvDpg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Code took form: https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, \n",
    "                 patience=10, \n",
    "                 verbose=False, \n",
    "                 delta=0, \n",
    "                 path='../models/final_heston_model.chkpt',\n",
    "                 trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score > self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dL_xmnKXvDph",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1650891694152,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "DrBBTGKJvDph",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    epochs,\n",
    "    batch_size,\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val\n",
    "):\n",
    "\n",
    "  training_losses = []\n",
    "  validation_losses = []\n",
    "\n",
    "  early_stopping = EarlyStopping(patience=20)\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "    i = 0\n",
    "\n",
    "    for batch, batch_labels in DataLoader(OptDataset(X_train, y_train), batch_size=batch_size):\n",
    "      out = model(batch.to(device))\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      loss = loss_fn(out, batch_labels.to(device))\n",
    "      epoch_losses.append(loss.item())\n",
    "      total_loss += loss.item()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      if i > 0 and i % 50 == 0:\n",
    "        avg_loss = total_loss / 50\n",
    "        elapsed = time.time() - start_time\n",
    "        print('| Epoch {:3d} | {:5d}/{:5d} batches | lr {:2.5f} | ms/batch {:5.2f} | '\n",
    "                  'loss {:5.8f}'.format(\n",
    "              epoch, i, len(X_train) // batch_size+1, lr, elapsed * 1000 / 50,\n",
    "              avg_loss))\n",
    "        start_time = time.time()\n",
    "        total_loss = 0\n",
    "\n",
    "      i += 1\n",
    "\n",
    "    training_losses.append(np.array(epoch_losses).mean())\n",
    "    val_loss = evaluate(model, loss_fn, X_val, y_val)\n",
    "    validation_losses.append(val_loss)\n",
    "\n",
    "    early_stopping(val_loss, model)\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(f\"Stopping at Epoch: {epoch}\")\n",
    "        break\n",
    "\n",
    "  return training_losses, validation_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2525796,
     "status": "ok",
     "timestamp": 1650894219916,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "hBETWoCfvDpj",
    "outputId": "30acf99f-3a1e-4d87-d1ff-13068ebe4cd4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch   0 |    50/  422 batches | lr 0.00015 | ms/batch 22.68 | loss 0.20403363\n",
      "| Epoch   0 |   100/  422 batches | lr 0.00015 | ms/batch 18.94 | loss 0.01192438\n",
      "| Epoch   0 |   150/  422 batches | lr 0.00015 | ms/batch 20.10 | loss 0.00636712\n",
      "| Epoch   0 |   200/  422 batches | lr 0.00015 | ms/batch 17.99 | loss 0.00390655\n",
      "| Epoch   0 |   250/  422 batches | lr 0.00015 | ms/batch 19.65 | loss 0.00257519\n",
      "| Epoch   0 |   300/  422 batches | lr 0.00015 | ms/batch 21.37 | loss 0.00204312\n",
      "| Epoch   0 |   350/  422 batches | lr 0.00015 | ms/batch 19.87 | loss 0.00186667\n",
      "| Epoch   0 |   400/  422 batches | lr 0.00015 | ms/batch 19.91 | loss 0.00177615\n",
      "\n",
      "Val set: Average loss: 0.00161779\n",
      "\n",
      "| Epoch   1 |    50/  422 batches | lr 0.00015 | ms/batch 20.06 | loss 0.00152920\n",
      "| Epoch   1 |   100/  422 batches | lr 0.00015 | ms/batch 18.14 | loss 0.00140401\n",
      "| Epoch   1 |   150/  422 batches | lr 0.00015 | ms/batch 19.96 | loss 0.00131647\n",
      "| Epoch   1 |   200/  422 batches | lr 0.00015 | ms/batch 19.95 | loss 0.00136728\n",
      "| Epoch   1 |   250/  422 batches | lr 0.00015 | ms/batch 19.93 | loss 0.00134326\n",
      "| Epoch   1 |   300/  422 batches | lr 0.00015 | ms/batch 17.98 | loss 0.00118999\n",
      "| Epoch   1 |   350/  422 batches | lr 0.00015 | ms/batch 19.97 | loss 0.00127192\n",
      "| Epoch   1 |   400/  422 batches | lr 0.00015 | ms/batch 20.65 | loss 0.00111155\n",
      "\n",
      "Val set: Average loss: 0.00124796\n",
      "\n",
      "| Epoch   2 |    50/  422 batches | lr 0.00015 | ms/batch 20.45 | loss 0.00102226\n",
      "| Epoch   2 |   100/  422 batches | lr 0.00015 | ms/batch 20.20 | loss 0.00100248\n",
      "| Epoch   2 |   150/  422 batches | lr 0.00015 | ms/batch 20.95 | loss 0.00104679\n",
      "| Epoch   2 |   200/  422 batches | lr 0.00015 | ms/batch 17.90 | loss 0.00121710\n",
      "| Epoch   2 |   250/  422 batches | lr 0.00015 | ms/batch 19.68 | loss 0.00104970\n",
      "| Epoch   2 |   300/  422 batches | lr 0.00015 | ms/batch 19.75 | loss 0.00092070\n",
      "| Epoch   2 |   350/  422 batches | lr 0.00015 | ms/batch 19.55 | loss 0.00086725\n",
      "| Epoch   2 |   400/  422 batches | lr 0.00015 | ms/batch 17.90 | loss 0.00106639\n",
      "\n",
      "Val set: Average loss: 0.00125516\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch   3 |    50/  422 batches | lr 0.00015 | ms/batch 19.90 | loss 0.00091234\n",
      "| Epoch   3 |   100/  422 batches | lr 0.00015 | ms/batch 19.66 | loss 0.00084948\n",
      "| Epoch   3 |   150/  422 batches | lr 0.00015 | ms/batch 19.63 | loss 0.00095257\n",
      "| Epoch   3 |   200/  422 batches | lr 0.00015 | ms/batch 17.83 | loss 0.00108460\n",
      "| Epoch   3 |   250/  422 batches | lr 0.00015 | ms/batch 17.93 | loss 0.00094201\n",
      "| Epoch   3 |   300/  422 batches | lr 0.00015 | ms/batch 19.42 | loss 0.00079448\n",
      "| Epoch   3 |   350/  422 batches | lr 0.00015 | ms/batch 18.03 | loss 0.00077253\n",
      "| Epoch   3 |   400/  422 batches | lr 0.00015 | ms/batch 19.64 | loss 0.00083258\n",
      "\n",
      "Val set: Average loss: 0.00076482\n",
      "\n",
      "| Epoch   4 |    50/  422 batches | lr 0.00015 | ms/batch 18.16 | loss 0.00082191\n",
      "| Epoch   4 |   100/  422 batches | lr 0.00015 | ms/batch 17.90 | loss 0.00074696\n",
      "| Epoch   4 |   150/  422 batches | lr 0.00015 | ms/batch 19.44 | loss 0.00078151\n",
      "| Epoch   4 |   200/  422 batches | lr 0.00015 | ms/batch 17.92 | loss 0.00082732\n",
      "| Epoch   4 |   250/  422 batches | lr 0.00015 | ms/batch 19.78 | loss 0.00075338\n",
      "| Epoch   4 |   300/  422 batches | lr 0.00015 | ms/batch 19.63 | loss 0.00079487\n",
      "| Epoch   4 |   350/  422 batches | lr 0.00015 | ms/batch 19.48 | loss 0.00074254\n",
      "| Epoch   4 |   400/  422 batches | lr 0.00015 | ms/batch 17.88 | loss 0.00090012\n",
      "\n",
      "Val set: Average loss: 0.00080064\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch   5 |    50/  422 batches | lr 0.00015 | ms/batch 21.71 | loss 0.00079604\n",
      "| Epoch   5 |   100/  422 batches | lr 0.00015 | ms/batch 17.98 | loss 0.00070037\n",
      "| Epoch   5 |   150/  422 batches | lr 0.00015 | ms/batch 19.56 | loss 0.00083239\n",
      "| Epoch   5 |   200/  422 batches | lr 0.00015 | ms/batch 17.80 | loss 0.00081156\n",
      "| Epoch   5 |   250/  422 batches | lr 0.00015 | ms/batch 19.54 | loss 0.00085094\n",
      "| Epoch   5 |   300/  422 batches | lr 0.00015 | ms/batch 19.48 | loss 0.00064686\n",
      "| Epoch   5 |   350/  422 batches | lr 0.00015 | ms/batch 19.65 | loss 0.00068155\n",
      "| Epoch   5 |   400/  422 batches | lr 0.00015 | ms/batch 17.88 | loss 0.00059628\n",
      "\n",
      "Val set: Average loss: 0.00057872\n",
      "\n",
      "| Epoch   6 |    50/  422 batches | lr 0.00015 | ms/batch 21.76 | loss 0.00064902\n",
      "| Epoch   6 |   100/  422 batches | lr 0.00015 | ms/batch 19.76 | loss 0.00061621\n",
      "| Epoch   6 |   150/  422 batches | lr 0.00015 | ms/batch 19.67 | loss 0.00064109\n",
      "| Epoch   6 |   200/  422 batches | lr 0.00015 | ms/batch 19.75 | loss 0.00075128\n",
      "| Epoch   6 |   250/  422 batches | lr 0.00015 | ms/batch 19.85 | loss 0.00064568\n",
      "| Epoch   6 |   300/  422 batches | lr 0.00015 | ms/batch 21.31 | loss 0.00069152\n",
      "| Epoch   6 |   350/  422 batches | lr 0.00015 | ms/batch 19.75 | loss 0.00059154\n",
      "| Epoch   6 |   400/  422 batches | lr 0.00015 | ms/batch 19.74 | loss 0.00071754\n",
      "\n",
      "Val set: Average loss: 0.00049851\n",
      "\n",
      "| Epoch   7 |    50/  422 batches | lr 0.00015 | ms/batch 19.88 | loss 0.00057874\n",
      "| Epoch   7 |   100/  422 batches | lr 0.00015 | ms/batch 19.38 | loss 0.00059459\n",
      "| Epoch   7 |   150/  422 batches | lr 0.00015 | ms/batch 17.92 | loss 0.00064977\n",
      "| Epoch   7 |   200/  422 batches | lr 0.00015 | ms/batch 19.56 | loss 0.00075735\n",
      "| Epoch   7 |   250/  422 batches | lr 0.00015 | ms/batch 19.86 | loss 0.00063920\n",
      "| Epoch   7 |   300/  422 batches | lr 0.00015 | ms/batch 19.54 | loss 0.00051495\n",
      "| Epoch   7 |   350/  422 batches | lr 0.00015 | ms/batch 17.95 | loss 0.00051830\n",
      "| Epoch   7 |   400/  422 batches | lr 0.00015 | ms/batch 18.01 | loss 0.00074359\n",
      "\n",
      "Val set: Average loss: 0.00046008\n",
      "\n",
      "| Epoch   8 |    50/  422 batches | lr 0.00015 | ms/batch 19.93 | loss 0.00059830\n",
      "| Epoch   8 |   100/  422 batches | lr 0.00015 | ms/batch 19.65 | loss 0.00056666\n",
      "| Epoch   8 |   150/  422 batches | lr 0.00015 | ms/batch 17.95 | loss 0.00065910\n",
      "| Epoch   8 |   200/  422 batches | lr 0.00015 | ms/batch 17.93 | loss 0.00065898\n",
      "| Epoch   8 |   250/  422 batches | lr 0.00015 | ms/batch 19.68 | loss 0.00068471\n",
      "| Epoch   8 |   300/  422 batches | lr 0.00015 | ms/batch 17.87 | loss 0.00045091\n",
      "| Epoch   8 |   350/  422 batches | lr 0.00015 | ms/batch 19.67 | loss 0.00045172\n",
      "| Epoch   8 |   400/  422 batches | lr 0.00015 | ms/batch 19.62 | loss 0.00089632\n",
      "\n",
      "Val set: Average loss: 0.00048403\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch   9 |    50/  422 batches | lr 0.00015 | ms/batch 19.97 | loss 0.00049846\n",
      "| Epoch   9 |   100/  422 batches | lr 0.00015 | ms/batch 17.85 | loss 0.00066460\n",
      "| Epoch   9 |   150/  422 batches | lr 0.00015 | ms/batch 19.52 | loss 0.00045866\n",
      "| Epoch   9 |   200/  422 batches | lr 0.00015 | ms/batch 21.35 | loss 0.00045752\n",
      "| Epoch   9 |   250/  422 batches | lr 0.00015 | ms/batch 19.74 | loss 0.00051416\n",
      "| Epoch   9 |   300/  422 batches | lr 0.00015 | ms/batch 19.56 | loss 0.00042220\n",
      "| Epoch   9 |   350/  422 batches | lr 0.00015 | ms/batch 19.69 | loss 0.00044290\n",
      "| Epoch   9 |   400/  422 batches | lr 0.00015 | ms/batch 19.66 | loss 0.00057566\n",
      "\n",
      "Val set: Average loss: 0.00046426\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  10 |    50/  422 batches | lr 0.00015 | ms/batch 20.14 | loss 0.00043554\n",
      "| Epoch  10 |   100/  422 batches | lr 0.00015 | ms/batch 19.70 | loss 0.00057567\n",
      "| Epoch  10 |   150/  422 batches | lr 0.00015 | ms/batch 19.63 | loss 0.00045750\n",
      "| Epoch  10 |   200/  422 batches | lr 0.00015 | ms/batch 21.24 | loss 0.00060097\n",
      "| Epoch  10 |   250/  422 batches | lr 0.00015 | ms/batch 19.63 | loss 0.00049695\n",
      "| Epoch  10 |   300/  422 batches | lr 0.00015 | ms/batch 19.55 | loss 0.00043278\n",
      "| Epoch  10 |   350/  422 batches | lr 0.00015 | ms/batch 19.51 | loss 0.00043342\n",
      "| Epoch  10 |   400/  422 batches | lr 0.00015 | ms/batch 19.71 | loss 0.00058363\n",
      "\n",
      "Val set: Average loss: 0.00038093\n",
      "\n",
      "| Epoch  11 |    50/  422 batches | lr 0.00015 | ms/batch 20.09 | loss 0.00040611\n",
      "| Epoch  11 |   100/  422 batches | lr 0.00015 | ms/batch 17.98 | loss 0.00064465\n",
      "| Epoch  11 |   150/  422 batches | lr 0.00015 | ms/batch 17.91 | loss 0.00050677\n",
      "| Epoch  11 |   200/  422 batches | lr 0.00015 | ms/batch 21.48 | loss 0.00042819\n",
      "| Epoch  11 |   250/  422 batches | lr 0.00015 | ms/batch 18.14 | loss 0.00038290\n",
      "| Epoch  11 |   300/  422 batches | lr 0.00015 | ms/batch 19.68 | loss 0.00041144\n",
      "| Epoch  11 |   350/  422 batches | lr 0.00015 | ms/batch 19.64 | loss 0.00051923\n",
      "| Epoch  11 |   400/  422 batches | lr 0.00015 | ms/batch 18.22 | loss 0.00085041\n",
      "\n",
      "Val set: Average loss: 0.00051374\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  12 |    50/  422 batches | lr 0.00015 | ms/batch 20.10 | loss 0.00041998\n",
      "| Epoch  12 |   100/  422 batches | lr 0.00015 | ms/batch 19.83 | loss 0.00053217\n",
      "| Epoch  12 |   150/  422 batches | lr 0.00015 | ms/batch 19.63 | loss 0.00035021\n",
      "| Epoch  12 |   200/  422 batches | lr 0.00015 | ms/batch 17.96 | loss 0.00035495\n",
      "| Epoch  12 |   250/  422 batches | lr 0.00015 | ms/batch 19.55 | loss 0.00042576\n",
      "| Epoch  12 |   300/  422 batches | lr 0.00015 | ms/batch 19.65 | loss 0.00038495\n",
      "| Epoch  12 |   350/  422 batches | lr 0.00015 | ms/batch 19.70 | loss 0.00050937\n",
      "| Epoch  12 |   400/  422 batches | lr 0.00015 | ms/batch 17.88 | loss 0.00040279\n",
      "\n",
      "Val set: Average loss: 0.00032553\n",
      "\n",
      "| Epoch  13 |    50/  422 batches | lr 0.00015 | ms/batch 22.06 | loss 0.00037562\n",
      "| Epoch  13 |   100/  422 batches | lr 0.00015 | ms/batch 19.77 | loss 0.00050225\n",
      "| Epoch  13 |   150/  422 batches | lr 0.00015 | ms/batch 20.05 | loss 0.00035497\n",
      "| Epoch  13 |   200/  422 batches | lr 0.00015 | ms/batch 19.81 | loss 0.00034602\n",
      "| Epoch  13 |   250/  422 batches | lr 0.00015 | ms/batch 19.82 | loss 0.00046596\n",
      "| Epoch  13 |   300/  422 batches | lr 0.00015 | ms/batch 19.74 | loss 0.00041612\n",
      "| Epoch  13 |   350/  422 batches | lr 0.00015 | ms/batch 21.44 | loss 0.00036109\n",
      "| Epoch  13 |   400/  422 batches | lr 0.00015 | ms/batch 19.70 | loss 0.00038785\n",
      "\n",
      "Val set: Average loss: 0.00033661\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  14 |    50/  422 batches | lr 0.00015 | ms/batch 21.86 | loss 0.00043802\n",
      "| Epoch  14 |   100/  422 batches | lr 0.00015 | ms/batch 19.87 | loss 0.00051314\n",
      "| Epoch  14 |   150/  422 batches | lr 0.00015 | ms/batch 19.82 | loss 0.00038549\n",
      "| Epoch  14 |   200/  422 batches | lr 0.00015 | ms/batch 19.66 | loss 0.00046258\n",
      "| Epoch  14 |   250/  422 batches | lr 0.00015 | ms/batch 19.82 | loss 0.00041295\n",
      "| Epoch  14 |   300/  422 batches | lr 0.00015 | ms/batch 19.69 | loss 0.00035740\n",
      "| Epoch  14 |   350/  422 batches | lr 0.00015 | ms/batch 21.36 | loss 0.00039949\n",
      "| Epoch  14 |   400/  422 batches | lr 0.00015 | ms/batch 19.92 | loss 0.00040554\n",
      "\n",
      "Val set: Average loss: 0.00028154\n",
      "\n",
      "| Epoch  15 |    50/  422 batches | lr 0.00015 | ms/batch 19.97 | loss 0.00037573\n",
      "| Epoch  15 |   100/  422 batches | lr 0.00015 | ms/batch 19.65 | loss 0.00051358\n",
      "| Epoch  15 |   150/  422 batches | lr 0.00015 | ms/batch 17.93 | loss 0.00030238\n",
      "| Epoch  15 |   200/  422 batches | lr 0.00015 | ms/batch 19.56 | loss 0.00041705\n",
      "| Epoch  15 |   250/  422 batches | lr 0.00015 | ms/batch 19.77 | loss 0.00040688\n",
      "| Epoch  15 |   300/  422 batches | lr 0.00015 | ms/batch 19.64 | loss 0.00033748\n",
      "| Epoch  15 |   350/  422 batches | lr 0.00015 | ms/batch 17.91 | loss 0.00030104\n",
      "| Epoch  15 |   400/  422 batches | lr 0.00015 | ms/batch 17.98 | loss 0.00033512\n",
      "\n",
      "Val set: Average loss: 0.00053712\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  16 |    50/  422 batches | lr 0.00015 | ms/batch 18.47 | loss 0.00039117\n",
      "| Epoch  16 |   100/  422 batches | lr 0.00015 | ms/batch 17.89 | loss 0.00033203\n",
      "| Epoch  16 |   150/  422 batches | lr 0.00015 | ms/batch 19.53 | loss 0.00040087\n",
      "| Epoch  16 |   200/  422 batches | lr 0.00015 | ms/batch 17.93 | loss 0.00029571\n",
      "| Epoch  16 |   250/  422 batches | lr 0.00015 | ms/batch 19.71 | loss 0.00036374\n",
      "| Epoch  16 |   300/  422 batches | lr 0.00015 | ms/batch 19.76 | loss 0.00044929\n",
      "| Epoch  16 |   350/  422 batches | lr 0.00015 | ms/batch 21.28 | loss 0.00053995\n",
      "| Epoch  16 |   400/  422 batches | lr 0.00015 | ms/batch 19.73 | loss 0.00033162\n",
      "\n",
      "Val set: Average loss: 0.00030890\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  17 |    50/  422 batches | lr 0.00015 | ms/batch 22.03 | loss 0.00041394\n",
      "| Epoch  17 |   100/  422 batches | lr 0.00015 | ms/batch 19.69 | loss 0.00045397\n",
      "| Epoch  17 |   150/  422 batches | lr 0.00015 | ms/batch 19.69 | loss 0.00026969\n",
      "| Epoch  17 |   200/  422 batches | lr 0.00015 | ms/batch 19.74 | loss 0.00032616\n",
      "| Epoch  17 |   250/  422 batches | lr 0.00015 | ms/batch 19.58 | loss 0.00035334\n",
      "| Epoch  17 |   300/  422 batches | lr 0.00015 | ms/batch 19.86 | loss 0.00034321\n",
      "| Epoch  17 |   350/  422 batches | lr 0.00015 | ms/batch 21.42 | loss 0.00040744\n",
      "| Epoch  17 |   400/  422 batches | lr 0.00015 | ms/batch 19.78 | loss 0.00027893\n",
      "\n",
      "Val set: Average loss: 0.00028551\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  18 |    50/  422 batches | lr 0.00015 | ms/batch 21.91 | loss 0.00029959\n",
      "| Epoch  18 |   100/  422 batches | lr 0.00015 | ms/batch 19.74 | loss 0.00031328\n",
      "| Epoch  18 |   150/  422 batches | lr 0.00015 | ms/batch 19.89 | loss 0.00023526\n",
      "| Epoch  18 |   200/  422 batches | lr 0.00015 | ms/batch 19.92 | loss 0.00024559\n",
      "| Epoch  18 |   250/  422 batches | lr 0.00015 | ms/batch 19.82 | loss 0.00036689\n",
      "| Epoch  18 |   300/  422 batches | lr 0.00015 | ms/batch 19.88 | loss 0.00034073\n",
      "| Epoch  18 |   350/  422 batches | lr 0.00015 | ms/batch 21.40 | loss 0.00025004\n",
      "| Epoch  18 |   400/  422 batches | lr 0.00015 | ms/batch 19.83 | loss 0.00036598\n",
      "\n",
      "Val set: Average loss: 0.00035771\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch  19 |    50/  422 batches | lr 0.00015 | ms/batch 21.70 | loss 0.00024881\n",
      "| Epoch  19 |   100/  422 batches | lr 0.00015 | ms/batch 19.70 | loss 0.00059440\n",
      "| Epoch  19 |   150/  422 batches | lr 0.00015 | ms/batch 19.70 | loss 0.00036256\n",
      "| Epoch  19 |   200/  422 batches | lr 0.00015 | ms/batch 19.74 | loss 0.00023577\n",
      "| Epoch  19 |   250/  422 batches | lr 0.00015 | ms/batch 19.74 | loss 0.00031849\n",
      "| Epoch  19 |   300/  422 batches | lr 0.00015 | ms/batch 21.31 | loss 0.00024360\n",
      "| Epoch  19 |   350/  422 batches | lr 0.00015 | ms/batch 19.69 | loss 0.00027369\n",
      "| Epoch  19 |   400/  422 batches | lr 0.00015 | ms/batch 19.78 | loss 0.00029492\n",
      "\n",
      "Val set: Average loss: 0.00041646\n",
      "\n",
      "EarlyStopping counter: 5 out of 20\n",
      "| Epoch  20 |    50/  422 batches | lr 0.00015 | ms/batch 21.64 | loss 0.00032628\n",
      "| Epoch  20 |   100/  422 batches | lr 0.00015 | ms/batch 19.62 | loss 0.00034162\n",
      "| Epoch  20 |   150/  422 batches | lr 0.00015 | ms/batch 19.97 | loss 0.00023988\n",
      "| Epoch  20 |   200/  422 batches | lr 0.00015 | ms/batch 19.67 | loss 0.00023871\n",
      "| Epoch  20 |   250/  422 batches | lr 0.00015 | ms/batch 19.77 | loss 0.00033031\n",
      "| Epoch  20 |   300/  422 batches | lr 0.00015 | ms/batch 21.28 | loss 0.00041060\n",
      "| Epoch  20 |   350/  422 batches | lr 0.00015 | ms/batch 19.75 | loss 0.00028527\n",
      "| Epoch  20 |   400/  422 batches | lr 0.00015 | ms/batch 19.67 | loss 0.00033561\n",
      "\n",
      "Val set: Average loss: 0.00021116\n",
      "\n",
      "| Epoch  21 |    50/  422 batches | lr 0.00015 | ms/batch 20.36 | loss 0.00029469\n",
      "| Epoch  21 |   100/  422 batches | lr 0.00015 | ms/batch 19.61 | loss 0.00027705\n",
      "| Epoch  21 |   150/  422 batches | lr 0.00015 | ms/batch 17.94 | loss 0.00024302\n",
      "| Epoch  21 |   200/  422 batches | lr 0.00015 | ms/batch 19.59 | loss 0.00028456\n",
      "| Epoch  21 |   250/  422 batches | lr 0.00015 | ms/batch 19.87 | loss 0.00037133\n",
      "| Epoch  21 |   300/  422 batches | lr 0.00015 | ms/batch 19.73 | loss 0.00026857\n",
      "| Epoch  21 |   350/  422 batches | lr 0.00015 | ms/batch 17.94 | loss 0.00022236\n",
      "| Epoch  21 |   400/  422 batches | lr 0.00015 | ms/batch 17.90 | loss 0.00024948\n",
      "\n",
      "Val set: Average loss: 0.00028178\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  22 |    50/  422 batches | lr 0.00015 | ms/batch 18.33 | loss 0.00041422\n",
      "| Epoch  22 |   100/  422 batches | lr 0.00015 | ms/batch 18.05 | loss 0.00035566\n",
      "| Epoch  22 |   150/  422 batches | lr 0.00015 | ms/batch 21.29 | loss 0.00023100\n",
      "| Epoch  22 |   200/  422 batches | lr 0.00015 | ms/batch 19.62 | loss 0.00029697\n",
      "| Epoch  22 |   250/  422 batches | lr 0.00015 | ms/batch 17.95 | loss 0.00033699\n",
      "| Epoch  22 |   300/  422 batches | lr 0.00015 | ms/batch 17.89 | loss 0.00024510\n",
      "| Epoch  22 |   350/  422 batches | lr 0.00015 | ms/batch 19.53 | loss 0.00027885\n",
      "| Epoch  22 |   400/  422 batches | lr 0.00015 | ms/batch 19.67 | loss 0.00049247\n",
      "\n",
      "Val set: Average loss: 0.00023343\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  23 |    50/  422 batches | lr 0.00015 | ms/batch 18.44 | loss 0.00021577\n",
      "| Epoch  23 |   100/  422 batches | lr 0.00015 | ms/batch 18.46 | loss 0.00039910\n",
      "| Epoch  23 |   150/  422 batches | lr 0.00015 | ms/batch 21.43 | loss 0.00022163\n",
      "| Epoch  23 |   200/  422 batches | lr 0.00015 | ms/batch 18.36 | loss 0.00019532\n",
      "| Epoch  23 |   250/  422 batches | lr 0.00015 | ms/batch 19.86 | loss 0.00028522\n",
      "| Epoch  23 |   300/  422 batches | lr 0.00015 | ms/batch 19.64 | loss 0.00056461\n",
      "| Epoch  23 |   350/  422 batches | lr 0.00015 | ms/batch 17.97 | loss 0.00026755\n",
      "| Epoch  23 |   400/  422 batches | lr 0.00015 | ms/batch 19.73 | loss 0.00022057\n",
      "\n",
      "Val set: Average loss: 0.00020011\n",
      "\n",
      "| Epoch  24 |    50/  422 batches | lr 0.00015 | ms/batch 22.14 | loss 0.00018135\n",
      "| Epoch  24 |   100/  422 batches | lr 0.00015 | ms/batch 18.31 | loss 0.00030811\n",
      "| Epoch  24 |   150/  422 batches | lr 0.00015 | ms/batch 19.71 | loss 0.00017534\n",
      "| Epoch  24 |   200/  422 batches | lr 0.00015 | ms/batch 19.72 | loss 0.00019591\n",
      "| Epoch  24 |   250/  422 batches | lr 0.00015 | ms/batch 17.95 | loss 0.00020069\n",
      "| Epoch  24 |   300/  422 batches | lr 0.00015 | ms/batch 19.66 | loss 0.00020458\n",
      "| Epoch  24 |   350/  422 batches | lr 0.00015 | ms/batch 19.77 | loss 0.00021008\n",
      "| Epoch  24 |   400/  422 batches | lr 0.00015 | ms/batch 19.72 | loss 0.00023201\n",
      "\n",
      "Val set: Average loss: 0.00017771\n",
      "\n",
      "| Epoch  25 |    50/  422 batches | lr 0.00015 | ms/batch 20.22 | loss 0.00071964\n",
      "| Epoch  25 |   100/  422 batches | lr 0.00015 | ms/batch 19.77 | loss 0.00026429\n",
      "| Epoch  25 |   150/  422 batches | lr 0.00015 | ms/batch 17.92 | loss 0.00017407\n",
      "| Epoch  25 |   200/  422 batches | lr 0.00015 | ms/batch 18.02 | loss 0.00017557\n",
      "| Epoch  25 |   250/  422 batches | lr 0.00015 | ms/batch 21.34 | loss 0.00022643\n",
      "| Epoch  25 |   300/  422 batches | lr 0.00015 | ms/batch 19.76 | loss 0.00019077\n",
      "| Epoch  25 |   350/  422 batches | lr 0.00015 | ms/batch 18.00 | loss 0.00023491\n",
      "| Epoch  25 |   400/  422 batches | lr 0.00015 | ms/batch 18.17 | loss 0.00035468\n",
      "\n",
      "Val set: Average loss: 0.00021527\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  26 |    50/  422 batches | lr 0.00015 | ms/batch 20.27 | loss 0.00022960\n",
      "| Epoch  26 |   100/  422 batches | lr 0.00015 | ms/batch 18.18 | loss 0.00026924\n",
      "| Epoch  26 |   150/  422 batches | lr 0.00015 | ms/batch 19.81 | loss 0.00020698\n",
      "| Epoch  26 |   200/  422 batches | lr 0.00015 | ms/batch 19.81 | loss 0.00016649\n",
      "| Epoch  26 |   250/  422 batches | lr 0.00015 | ms/batch 19.89 | loss 0.00026412\n",
      "| Epoch  26 |   300/  422 batches | lr 0.00015 | ms/batch 19.77 | loss 0.00016412\n",
      "| Epoch  26 |   350/  422 batches | lr 0.00015 | ms/batch 18.03 | loss 0.00038713\n",
      "| Epoch  26 |   400/  422 batches | lr 0.00015 | ms/batch 19.70 | loss 0.00054004\n",
      "\n",
      "Val set: Average loss: 0.00018250\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  27 |    50/  422 batches | lr 0.00015 | ms/batch 20.37 | loss 0.00018302\n",
      "| Epoch  27 |   100/  422 batches | lr 0.00015 | ms/batch 21.57 | loss 0.00025128\n",
      "| Epoch  27 |   150/  422 batches | lr 0.00015 | ms/batch 20.03 | loss 0.00018396\n",
      "| Epoch  27 |   200/  422 batches | lr 0.00015 | ms/batch 19.86 | loss 0.00016708\n",
      "| Epoch  27 |   250/  422 batches | lr 0.00015 | ms/batch 20.01 | loss 0.00020643\n",
      "| Epoch  27 |   300/  422 batches | lr 0.00015 | ms/batch 19.98 | loss 0.00019474\n",
      "| Epoch  27 |   350/  422 batches | lr 0.00015 | ms/batch 21.46 | loss 0.00038700\n",
      "| Epoch  27 |   400/  422 batches | lr 0.00015 | ms/batch 19.71 | loss 0.00033742\n",
      "\n",
      "Val set: Average loss: 0.00015873\n",
      "\n",
      "| Epoch  28 |    50/  422 batches | lr 0.00015 | ms/batch 20.13 | loss 0.00017118\n",
      "| Epoch  28 |   100/  422 batches | lr 0.00015 | ms/batch 18.14 | loss 0.00016765\n",
      "| Epoch  28 |   150/  422 batches | lr 0.00015 | ms/batch 20.00 | loss 0.00014757\n",
      "| Epoch  28 |   200/  422 batches | lr 0.00015 | ms/batch 19.81 | loss 0.00024055\n",
      "| Epoch  28 |   250/  422 batches | lr 0.00015 | ms/batch 19.66 | loss 0.00023917\n",
      "| Epoch  28 |   300/  422 batches | lr 0.00015 | ms/batch 17.99 | loss 0.00027123\n",
      "| Epoch  28 |   350/  422 batches | lr 0.00015 | ms/batch 19.62 | loss 0.00015798\n",
      "| Epoch  28 |   400/  422 batches | lr 0.00015 | ms/batch 19.89 | loss 0.00019409\n",
      "\n",
      "Val set: Average loss: 0.00027856\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  29 |    50/  422 batches | lr 0.00015 | ms/batch 20.09 | loss 0.00024099\n",
      "| Epoch  29 |   100/  422 batches | lr 0.00015 | ms/batch 18.09 | loss 0.00024206\n",
      "| Epoch  29 |   150/  422 batches | lr 0.00015 | ms/batch 19.78 | loss 0.00018778\n",
      "| Epoch  29 |   200/  422 batches | lr 0.00015 | ms/batch 19.80 | loss 0.00016489\n",
      "| Epoch  29 |   250/  422 batches | lr 0.00015 | ms/batch 19.77 | loss 0.00019556\n",
      "| Epoch  29 |   300/  422 batches | lr 0.00015 | ms/batch 17.99 | loss 0.00035906\n",
      "| Epoch  29 |   350/  422 batches | lr 0.00015 | ms/batch 17.99 | loss 0.00030711\n",
      "| Epoch  29 |   400/  422 batches | lr 0.00015 | ms/batch 19.67 | loss 0.00019628\n",
      "\n",
      "Val set: Average loss: 0.00027985\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  30 |    50/  422 batches | lr 0.00015 | ms/batch 18.47 | loss 0.00019096\n",
      "| Epoch  30 |   100/  422 batches | lr 0.00015 | ms/batch 21.62 | loss 0.00015034\n",
      "| Epoch  30 |   150/  422 batches | lr 0.00015 | ms/batch 19.80 | loss 0.00014375\n",
      "| Epoch  30 |   200/  422 batches | lr 0.00015 | ms/batch 18.02 | loss 0.00036892\n",
      "| Epoch  30 |   250/  422 batches | lr 0.00015 | ms/batch 18.00 | loss 0.00048676\n",
      "| Epoch  30 |   300/  422 batches | lr 0.00015 | ms/batch 19.83 | loss 0.00019174\n",
      "| Epoch  30 |   350/  422 batches | lr 0.00015 | ms/batch 19.71 | loss 0.00026944\n",
      "| Epoch  30 |   400/  422 batches | lr 0.00015 | ms/batch 19.61 | loss 0.00015541\n",
      "\n",
      "Val set: Average loss: 0.00014731\n",
      "\n",
      "| Epoch  31 |    50/  422 batches | lr 0.00015 | ms/batch 20.23 | loss 0.00017187\n",
      "| Epoch  31 |   100/  422 batches | lr 0.00015 | ms/batch 19.66 | loss 0.00019526\n",
      "| Epoch  31 |   150/  422 batches | lr 0.00015 | ms/batch 18.11 | loss 0.00013437\n",
      "| Epoch  31 |   200/  422 batches | lr 0.00015 | ms/batch 19.85 | loss 0.00026667\n",
      "| Epoch  31 |   250/  422 batches | lr 0.00015 | ms/batch 19.80 | loss 0.00033143\n",
      "| Epoch  31 |   300/  422 batches | lr 0.00015 | ms/batch 19.73 | loss 0.00028960\n",
      "| Epoch  31 |   350/  422 batches | lr 0.00015 | ms/batch 18.00 | loss 0.00023675\n",
      "| Epoch  31 |   400/  422 batches | lr 0.00015 | ms/batch 18.11 | loss 0.00013560\n",
      "\n",
      "Val set: Average loss: 0.00013536\n",
      "\n",
      "| Epoch  32 |    50/  422 batches | lr 0.00015 | ms/batch 20.59 | loss 0.00013266\n",
      "| Epoch  32 |   100/  422 batches | lr 0.00015 | ms/batch 20.00 | loss 0.00014324\n",
      "| Epoch  32 |   150/  422 batches | lr 0.00015 | ms/batch 19.88 | loss 0.00015801\n",
      "| Epoch  32 |   200/  422 batches | lr 0.00015 | ms/batch 21.44 | loss 0.00033174\n",
      "| Epoch  32 |   250/  422 batches | lr 0.00015 | ms/batch 19.82 | loss 0.00060731\n",
      "| Epoch  32 |   300/  422 batches | lr 0.00015 | ms/batch 19.89 | loss 0.00021798\n",
      "| Epoch  32 |   350/  422 batches | lr 0.00015 | ms/batch 19.85 | loss 0.00026708\n",
      "| Epoch  32 |   400/  422 batches | lr 0.00015 | ms/batch 19.78 | loss 0.00018965\n",
      "\n",
      "Val set: Average loss: 0.00025482\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  33 |    50/  422 batches | lr 0.00015 | ms/batch 20.36 | loss 0.00017439\n",
      "| Epoch  33 |   100/  422 batches | lr 0.00015 | ms/batch 19.85 | loss 0.00024406\n",
      "| Epoch  33 |   150/  422 batches | lr 0.00015 | ms/batch 19.91 | loss 0.00014981\n",
      "| Epoch  33 |   200/  422 batches | lr 0.00015 | ms/batch 21.53 | loss 0.00014983\n",
      "| Epoch  33 |   250/  422 batches | lr 0.00015 | ms/batch 19.95 | loss 0.00036466\n",
      "| Epoch  33 |   300/  422 batches | lr 0.00015 | ms/batch 19.80 | loss 0.00014145\n",
      "| Epoch  33 |   350/  422 batches | lr 0.00015 | ms/batch 20.03 | loss 0.00016725\n",
      "| Epoch  33 |   400/  422 batches | lr 0.00015 | ms/batch 20.03 | loss 0.00012656\n",
      "\n",
      "Val set: Average loss: 0.00014485\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  34 |    50/  422 batches | lr 0.00015 | ms/batch 20.36 | loss 0.00013717\n",
      "| Epoch  34 |   100/  422 batches | lr 0.00015 | ms/batch 19.85 | loss 0.00013750\n",
      "| Epoch  34 |   150/  422 batches | lr 0.00015 | ms/batch 19.93 | loss 0.00018853\n",
      "| Epoch  34 |   200/  422 batches | lr 0.00015 | ms/batch 21.62 | loss 0.00020498\n",
      "| Epoch  34 |   250/  422 batches | lr 0.00015 | ms/batch 19.89 | loss 0.00014784\n",
      "| Epoch  34 |   300/  422 batches | lr 0.00015 | ms/batch 19.96 | loss 0.00023521\n",
      "| Epoch  34 |   350/  422 batches | lr 0.00015 | ms/batch 19.91 | loss 0.00012277\n",
      "| Epoch  34 |   400/  422 batches | lr 0.00015 | ms/batch 20.39 | loss 0.00024434\n",
      "\n",
      "Val set: Average loss: 0.00027850\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  35 |    50/  422 batches | lr 0.00015 | ms/batch 20.15 | loss 0.00021173\n",
      "| Epoch  35 |   100/  422 batches | lr 0.00015 | ms/batch 19.85 | loss 0.00017604\n",
      "| Epoch  35 |   150/  422 batches | lr 0.00015 | ms/batch 19.79 | loss 0.00031432\n",
      "| Epoch  35 |   200/  422 batches | lr 0.00015 | ms/batch 21.63 | loss 0.00014201\n",
      "| Epoch  35 |   250/  422 batches | lr 0.00015 | ms/batch 19.77 | loss 0.00013692\n",
      "| Epoch  35 |   300/  422 batches | lr 0.00015 | ms/batch 19.82 | loss 0.00026239\n",
      "| Epoch  35 |   350/  422 batches | lr 0.00015 | ms/batch 19.91 | loss 0.00017619\n",
      "| Epoch  35 |   400/  422 batches | lr 0.00015 | ms/batch 19.88 | loss 0.00032368\n",
      "\n",
      "Val set: Average loss: 0.00015819\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch  36 |    50/  422 batches | lr 0.00015 | ms/batch 20.12 | loss 0.00020023\n",
      "| Epoch  36 |   100/  422 batches | lr 0.00015 | ms/batch 19.88 | loss 0.00023394\n",
      "| Epoch  36 |   150/  422 batches | lr 0.00015 | ms/batch 19.71 | loss 0.00016365\n",
      "| Epoch  36 |   200/  422 batches | lr 0.00015 | ms/batch 21.43 | loss 0.00011284\n",
      "| Epoch  36 |   250/  422 batches | lr 0.00015 | ms/batch 19.95 | loss 0.00015564\n",
      "| Epoch  36 |   300/  422 batches | lr 0.00015 | ms/batch 19.89 | loss 0.00025300\n",
      "| Epoch  36 |   350/  422 batches | lr 0.00015 | ms/batch 19.94 | loss 0.00017800\n",
      "| Epoch  36 |   400/  422 batches | lr 0.00015 | ms/batch 19.78 | loss 0.00035936\n",
      "\n",
      "Val set: Average loss: 0.00014759\n",
      "\n",
      "EarlyStopping counter: 5 out of 20\n",
      "| Epoch  37 |    50/  422 batches | lr 0.00015 | ms/batch 20.41 | loss 0.00015778\n",
      "| Epoch  37 |   100/  422 batches | lr 0.00015 | ms/batch 19.92 | loss 0.00016643\n",
      "| Epoch  37 |   150/  422 batches | lr 0.00015 | ms/batch 20.00 | loss 0.00018465\n",
      "| Epoch  37 |   200/  422 batches | lr 0.00015 | ms/batch 21.54 | loss 0.00013660\n",
      "| Epoch  37 |   250/  422 batches | lr 0.00015 | ms/batch 19.94 | loss 0.00017745\n",
      "| Epoch  37 |   300/  422 batches | lr 0.00015 | ms/batch 19.81 | loss 0.00013197\n",
      "| Epoch  37 |   350/  422 batches | lr 0.00015 | ms/batch 19.75 | loss 0.00015285\n",
      "| Epoch  37 |   400/  422 batches | lr 0.00015 | ms/batch 19.68 | loss 0.00023636\n",
      "\n",
      "Val set: Average loss: 0.00011980\n",
      "\n",
      "| Epoch  38 |    50/  422 batches | lr 0.00015 | ms/batch 20.37 | loss 0.00013540\n",
      "| Epoch  38 |   100/  422 batches | lr 0.00015 | ms/batch 18.22 | loss 0.00016042\n",
      "| Epoch  38 |   150/  422 batches | lr 0.00015 | ms/batch 18.17 | loss 0.00022712\n",
      "| Epoch  38 |   200/  422 batches | lr 0.00015 | ms/batch 19.89 | loss 0.00022882\n",
      "| Epoch  38 |   250/  422 batches | lr 0.00015 | ms/batch 18.16 | loss 0.00024374\n",
      "| Epoch  38 |   300/  422 batches | lr 0.00015 | ms/batch 19.77 | loss 0.00021694\n",
      "| Epoch  38 |   350/  422 batches | lr 0.00015 | ms/batch 19.60 | loss 0.00018607\n",
      "| Epoch  38 |   400/  422 batches | lr 0.00015 | ms/batch 19.63 | loss 0.00031925\n",
      "\n",
      "Val set: Average loss: 0.00013225\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  39 |    50/  422 batches | lr 0.00015 | ms/batch 18.51 | loss 0.00017373\n",
      "| Epoch  39 |   100/  422 batches | lr 0.00015 | ms/batch 19.78 | loss 0.00014015\n",
      "| Epoch  39 |   150/  422 batches | lr 0.00015 | ms/batch 21.43 | loss 0.00019540\n",
      "| Epoch  39 |   200/  422 batches | lr 0.00015 | ms/batch 19.74 | loss 0.00016543\n",
      "| Epoch  39 |   250/  422 batches | lr 0.00015 | ms/batch 19.73 | loss 0.00021427\n",
      "| Epoch  39 |   300/  422 batches | lr 0.00015 | ms/batch 19.76 | loss 0.00024254\n",
      "| Epoch  39 |   350/  422 batches | lr 0.00015 | ms/batch 19.84 | loss 0.00022201\n",
      "| Epoch  39 |   400/  422 batches | lr 0.00015 | ms/batch 19.79 | loss 0.00021749\n",
      "\n",
      "Val set: Average loss: 0.00012227\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  40 |    50/  422 batches | lr 0.00015 | ms/batch 20.33 | loss 0.00016144\n",
      "| Epoch  40 |   100/  422 batches | lr 0.00015 | ms/batch 19.83 | loss 0.00015458\n",
      "| Epoch  40 |   150/  422 batches | lr 0.00015 | ms/batch 21.49 | loss 0.00024043\n",
      "| Epoch  40 |   200/  422 batches | lr 0.00015 | ms/batch 20.39 | loss 0.00026444\n",
      "| Epoch  40 |   250/  422 batches | lr 0.00015 | ms/batch 19.81 | loss 0.00046983\n",
      "| Epoch  40 |   300/  422 batches | lr 0.00015 | ms/batch 19.82 | loss 0.00013244\n",
      "| Epoch  40 |   350/  422 batches | lr 0.00015 | ms/batch 19.80 | loss 0.00023147\n",
      "| Epoch  40 |   400/  422 batches | lr 0.00015 | ms/batch 21.48 | loss 0.00017931\n",
      "\n",
      "Val set: Average loss: 0.00014930\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  41 |    50/  422 batches | lr 0.00015 | ms/batch 20.23 | loss 0.00016745\n",
      "| Epoch  41 |   100/  422 batches | lr 0.00015 | ms/batch 19.91 | loss 0.00020940\n",
      "| Epoch  41 |   150/  422 batches | lr 0.00015 | ms/batch 21.39 | loss 0.00014862\n",
      "| Epoch  41 |   200/  422 batches | lr 0.00015 | ms/batch 19.86 | loss 0.00017537\n",
      "| Epoch  41 |   250/  422 batches | lr 0.00015 | ms/batch 19.84 | loss 0.00048407\n",
      "| Epoch  41 |   300/  422 batches | lr 0.00015 | ms/batch 19.81 | loss 0.00016449\n",
      "| Epoch  41 |   350/  422 batches | lr 0.00015 | ms/batch 19.86 | loss 0.00014975\n",
      "| Epoch  41 |   400/  422 batches | lr 0.00015 | ms/batch 21.45 | loss 0.00016297\n",
      "\n",
      "Val set: Average loss: 0.00012243\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch  42 |    50/  422 batches | lr 0.00015 | ms/batch 20.24 | loss 0.00014029\n",
      "| Epoch  42 |   100/  422 batches | lr 0.00015 | ms/batch 21.56 | loss 0.00015342\n",
      "| Epoch  42 |   150/  422 batches | lr 0.00015 | ms/batch 18.17 | loss 0.00012046\n",
      "| Epoch  42 |   200/  422 batches | lr 0.00015 | ms/batch 19.63 | loss 0.00012089\n",
      "| Epoch  42 |   250/  422 batches | lr 0.00015 | ms/batch 18.01 | loss 0.00015284\n",
      "| Epoch  42 |   300/  422 batches | lr 0.00015 | ms/batch 19.76 | loss 0.00013191\n",
      "| Epoch  42 |   350/  422 batches | lr 0.00015 | ms/batch 19.81 | loss 0.00012200\n",
      "| Epoch  42 |   400/  422 batches | lr 0.00015 | ms/batch 21.41 | loss 0.00013187\n",
      "\n",
      "Val set: Average loss: 0.00011611\n",
      "\n",
      "| Epoch  43 |    50/  422 batches | lr 0.00015 | ms/batch 20.10 | loss 0.00012156\n",
      "| Epoch  43 |   100/  422 batches | lr 0.00015 | ms/batch 17.88 | loss 0.00013585\n",
      "| Epoch  43 |   150/  422 batches | lr 0.00015 | ms/batch 19.67 | loss 0.00027127\n",
      "| Epoch  43 |   200/  422 batches | lr 0.00015 | ms/batch 19.88 | loss 0.00013657\n",
      "| Epoch  43 |   250/  422 batches | lr 0.00015 | ms/batch 19.73 | loss 0.00016235\n",
      "| Epoch  43 |   300/  422 batches | lr 0.00015 | ms/batch 17.89 | loss 0.00011437\n",
      "| Epoch  43 |   350/  422 batches | lr 0.00015 | ms/batch 17.98 | loss 0.00013885\n",
      "| Epoch  43 |   400/  422 batches | lr 0.00015 | ms/batch 19.58 | loss 0.00019330\n",
      "\n",
      "Val set: Average loss: 0.00011998\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  44 |    50/  422 batches | lr 0.00015 | ms/batch 18.46 | loss 0.00015384\n",
      "| Epoch  44 |   100/  422 batches | lr 0.00015 | ms/batch 19.54 | loss 0.00023981\n",
      "| Epoch  44 |   150/  422 batches | lr 0.00015 | ms/batch 18.09 | loss 0.00018339\n",
      "| Epoch  44 |   200/  422 batches | lr 0.00015 | ms/batch 19.73 | loss 0.00013179\n",
      "| Epoch  44 |   250/  422 batches | lr 0.00015 | ms/batch 19.75 | loss 0.00013537\n",
      "| Epoch  44 |   300/  422 batches | lr 0.00015 | ms/batch 21.51 | loss 0.00018718\n",
      "| Epoch  44 |   350/  422 batches | lr 0.00015 | ms/batch 19.70 | loss 0.00027496\n",
      "| Epoch  44 |   400/  422 batches | lr 0.00015 | ms/batch 19.87 | loss 0.00016378\n",
      "\n",
      "Val set: Average loss: 0.00015758\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  45 |    50/  422 batches | lr 0.00015 | ms/batch 20.32 | loss 0.00031240\n",
      "| Epoch  45 |   100/  422 batches | lr 0.00015 | ms/batch 19.89 | loss 0.00015956\n",
      "| Epoch  45 |   150/  422 batches | lr 0.00015 | ms/batch 19.82 | loss 0.00016761\n",
      "| Epoch  45 |   200/  422 batches | lr 0.00015 | ms/batch 19.80 | loss 0.00019842\n",
      "| Epoch  45 |   250/  422 batches | lr 0.00015 | ms/batch 19.81 | loss 0.00028340\n",
      "| Epoch  45 |   300/  422 batches | lr 0.00015 | ms/batch 21.42 | loss 0.00011161\n",
      "| Epoch  45 |   350/  422 batches | lr 0.00015 | ms/batch 19.83 | loss 0.00013429\n",
      "| Epoch  45 |   400/  422 batches | lr 0.00015 | ms/batch 19.87 | loss 0.00014140\n",
      "\n",
      "Val set: Average loss: 0.00020027\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  46 |    50/  422 batches | lr 0.00015 | ms/batch 20.38 | loss 0.00017851\n",
      "| Epoch  46 |   100/  422 batches | lr 0.00015 | ms/batch 19.83 | loss 0.00018342\n",
      "| Epoch  46 |   150/  422 batches | lr 0.00015 | ms/batch 19.88 | loss 0.00014029\n",
      "| Epoch  46 |   200/  422 batches | lr 0.00015 | ms/batch 19.81 | loss 0.00019803\n",
      "| Epoch  46 |   250/  422 batches | lr 0.00015 | ms/batch 21.50 | loss 0.00041337\n",
      "| Epoch  46 |   300/  422 batches | lr 0.00015 | ms/batch 19.87 | loss 0.00010966\n",
      "| Epoch  46 |   350/  422 batches | lr 0.00015 | ms/batch 19.79 | loss 0.00016567\n",
      "| Epoch  46 |   400/  422 batches | lr 0.00015 | ms/batch 19.91 | loss 0.00009775\n",
      "\n",
      "Val set: Average loss: 0.00010799\n",
      "\n",
      "| Epoch  47 |    50/  422 batches | lr 0.00015 | ms/batch 18.50 | loss 0.00013827\n",
      "| Epoch  47 |   100/  422 batches | lr 0.00015 | ms/batch 19.61 | loss 0.00015750\n",
      "| Epoch  47 |   150/  422 batches | lr 0.00015 | ms/batch 17.95 | loss 0.00012928\n",
      "| Epoch  47 |   200/  422 batches | lr 0.00015 | ms/batch 19.77 | loss 0.00017527\n",
      "| Epoch  47 |   250/  422 batches | lr 0.00015 | ms/batch 19.80 | loss 0.00029913\n",
      "| Epoch  47 |   300/  422 batches | lr 0.00015 | ms/batch 19.76 | loss 0.00010506\n",
      "| Epoch  47 |   350/  422 batches | lr 0.00015 | ms/batch 17.91 | loss 0.00010682\n",
      "| Epoch  47 |   400/  422 batches | lr 0.00015 | ms/batch 19.60 | loss 0.00008228\n",
      "\n",
      "Val set: Average loss: 0.00012208\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  48 |    50/  422 batches | lr 0.00015 | ms/batch 21.88 | loss 0.00010026\n",
      "| Epoch  48 |   100/  422 batches | lr 0.00015 | ms/batch 19.82 | loss 0.00010366\n",
      "| Epoch  48 |   150/  422 batches | lr 0.00015 | ms/batch 19.72 | loss 0.00015880\n",
      "| Epoch  48 |   200/  422 batches | lr 0.00015 | ms/batch 19.80 | loss 0.00014122\n",
      "| Epoch  48 |   250/  422 batches | lr 0.00015 | ms/batch 19.77 | loss 0.00013181\n",
      "| Epoch  48 |   300/  422 batches | lr 0.00015 | ms/batch 21.64 | loss 0.00014571\n",
      "| Epoch  48 |   350/  422 batches | lr 0.00015 | ms/batch 20.01 | loss 0.00023794\n",
      "| Epoch  48 |   400/  422 batches | lr 0.00015 | ms/batch 19.84 | loss 0.00024735\n",
      "\n",
      "Val set: Average loss: 0.00010501\n",
      "\n",
      "| Epoch  49 |    50/  422 batches | lr 0.00015 | ms/batch 20.27 | loss 0.00017575\n",
      "| Epoch  49 |   100/  422 batches | lr 0.00015 | ms/batch 19.59 | loss 0.00009989\n",
      "| Epoch  49 |   150/  422 batches | lr 0.00015 | ms/batch 17.95 | loss 0.00013851\n",
      "| Epoch  49 |   200/  422 batches | lr 0.00015 | ms/batch 19.67 | loss 0.00014200\n",
      "| Epoch  49 |   250/  422 batches | lr 0.00015 | ms/batch 19.73 | loss 0.00019231\n",
      "| Epoch  49 |   300/  422 batches | lr 0.00015 | ms/batch 19.58 | loss 0.00012525\n",
      "| Epoch  49 |   350/  422 batches | lr 0.00015 | ms/batch 17.96 | loss 0.00015856\n",
      "| Epoch  49 |   400/  422 batches | lr 0.00015 | ms/batch 17.97 | loss 0.00014427\n",
      "\n",
      "Val set: Average loss: 0.00009901\n",
      "\n",
      "| Epoch  50 |    50/  422 batches | lr 0.00015 | ms/batch 20.31 | loss 0.00011008\n",
      "| Epoch  50 |   100/  422 batches | lr 0.00015 | ms/batch 19.75 | loss 0.00016626\n",
      "| Epoch  50 |   150/  422 batches | lr 0.00015 | ms/batch 18.09 | loss 0.00024713\n",
      "| Epoch  50 |   200/  422 batches | lr 0.00015 | ms/batch 18.15 | loss 0.00015457\n",
      "| Epoch  50 |   250/  422 batches | lr 0.00015 | ms/batch 19.73 | loss 0.00013783\n",
      "| Epoch  50 |   300/  422 batches | lr 0.00015 | ms/batch 18.18 | loss 0.00011111\n",
      "| Epoch  50 |   350/  422 batches | lr 0.00015 | ms/batch 19.87 | loss 0.00012885\n",
      "| Epoch  50 |   400/  422 batches | lr 0.00015 | ms/batch 19.87 | loss 0.00011123\n",
      "\n",
      "Val set: Average loss: 0.00011752\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  51 |    50/  422 batches | lr 0.00015 | ms/batch 19.82 | loss 0.00014474\n",
      "| Epoch  51 |   100/  422 batches | lr 0.00015 | ms/batch 17.87 | loss 0.00017219\n",
      "| Epoch  51 |   150/  422 batches | lr 0.00015 | ms/batch 19.77 | loss 0.00027388\n",
      "| Epoch  51 |   200/  422 batches | lr 0.00015 | ms/batch 21.34 | loss 0.00014598\n",
      "| Epoch  51 |   250/  422 batches | lr 0.00015 | ms/batch 19.69 | loss 0.00014249\n",
      "| Epoch  51 |   300/  422 batches | lr 0.00015 | ms/batch 19.91 | loss 0.00009796\n",
      "| Epoch  51 |   350/  422 batches | lr 0.00015 | ms/batch 20.53 | loss 0.00013687\n",
      "| Epoch  51 |   400/  422 batches | lr 0.00015 | ms/batch 19.71 | loss 0.00016107\n",
      "\n",
      "Val set: Average loss: 0.00010430\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  52 |    50/  422 batches | lr 0.00015 | ms/batch 20.38 | loss 0.00017891\n",
      "| Epoch  52 |   100/  422 batches | lr 0.00015 | ms/batch 19.85 | loss 0.00014672\n",
      "| Epoch  52 |   150/  422 batches | lr 0.00015 | ms/batch 19.66 | loss 0.00011100\n",
      "| Epoch  52 |   200/  422 batches | lr 0.00015 | ms/batch 21.51 | loss 0.00010521\n",
      "| Epoch  52 |   250/  422 batches | lr 0.00015 | ms/batch 19.75 | loss 0.00019719\n",
      "| Epoch  52 |   300/  422 batches | lr 0.00015 | ms/batch 19.64 | loss 0.00017466\n",
      "| Epoch  52 |   350/  422 batches | lr 0.00015 | ms/batch 19.86 | loss 0.00016288\n",
      "| Epoch  52 |   400/  422 batches | lr 0.00015 | ms/batch 19.85 | loss 0.00013098\n",
      "\n",
      "Val set: Average loss: 0.00012020\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  53 |    50/  422 batches | lr 0.00015 | ms/batch 20.19 | loss 0.00021732\n",
      "| Epoch  53 |   100/  422 batches | lr 0.00015 | ms/batch 19.78 | loss 0.00012392\n",
      "| Epoch  53 |   150/  422 batches | lr 0.00015 | ms/batch 19.73 | loss 0.00012611\n",
      "| Epoch  53 |   200/  422 batches | lr 0.00015 | ms/batch 21.49 | loss 0.00014302\n",
      "| Epoch  53 |   250/  422 batches | lr 0.00015 | ms/batch 19.75 | loss 0.00012559\n",
      "| Epoch  53 |   300/  422 batches | lr 0.00015 | ms/batch 19.93 | loss 0.00018627\n",
      "| Epoch  53 |   350/  422 batches | lr 0.00015 | ms/batch 19.82 | loss 0.00014924\n",
      "| Epoch  53 |   400/  422 batches | lr 0.00015 | ms/batch 19.89 | loss 0.00017834\n",
      "\n",
      "Val set: Average loss: 0.00011725\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch  54 |    50/  422 batches | lr 0.00015 | ms/batch 20.16 | loss 0.00022363\n",
      "| Epoch  54 |   100/  422 batches | lr 0.00015 | ms/batch 19.72 | loss 0.00014399\n",
      "| Epoch  54 |   150/  422 batches | lr 0.00015 | ms/batch 19.79 | loss 0.00012148\n",
      "| Epoch  54 |   200/  422 batches | lr 0.00015 | ms/batch 21.34 | loss 0.00010876\n",
      "| Epoch  54 |   250/  422 batches | lr 0.00015 | ms/batch 19.67 | loss 0.00014650\n",
      "| Epoch  54 |   300/  422 batches | lr 0.00015 | ms/batch 19.79 | loss 0.00013194\n",
      "| Epoch  54 |   350/  422 batches | lr 0.00015 | ms/batch 19.92 | loss 0.00016983\n",
      "| Epoch  54 |   400/  422 batches | lr 0.00015 | ms/batch 19.78 | loss 0.00016298\n",
      "\n",
      "Val set: Average loss: 0.00017272\n",
      "\n",
      "EarlyStopping counter: 5 out of 20\n",
      "| Epoch  55 |    50/  422 batches | lr 0.00015 | ms/batch 20.28 | loss 0.00019594\n",
      "| Epoch  55 |   100/  422 batches | lr 0.00015 | ms/batch 19.87 | loss 0.00016019\n",
      "| Epoch  55 |   150/  422 batches | lr 0.00015 | ms/batch 19.87 | loss 0.00014394\n",
      "| Epoch  55 |   200/  422 batches | lr 0.00015 | ms/batch 21.33 | loss 0.00019703\n",
      "| Epoch  55 |   250/  422 batches | lr 0.00015 | ms/batch 19.83 | loss 0.00045776\n",
      "| Epoch  55 |   300/  422 batches | lr 0.00015 | ms/batch 19.85 | loss 0.00015098\n",
      "| Epoch  55 |   350/  422 batches | lr 0.00015 | ms/batch 19.81 | loss 0.00012272\n",
      "| Epoch  55 |   400/  422 batches | lr 0.00015 | ms/batch 19.77 | loss 0.00012123\n",
      "\n",
      "Val set: Average loss: 0.00014142\n",
      "\n",
      "EarlyStopping counter: 6 out of 20\n",
      "| Epoch  56 |    50/  422 batches | lr 0.00015 | ms/batch 20.25 | loss 0.00014981\n",
      "| Epoch  56 |   100/  422 batches | lr 0.00015 | ms/batch 19.88 | loss 0.00017546\n",
      "| Epoch  56 |   150/  422 batches | lr 0.00015 | ms/batch 19.77 | loss 0.00011566\n",
      "| Epoch  56 |   200/  422 batches | lr 0.00015 | ms/batch 21.38 | loss 0.00016587\n",
      "| Epoch  56 |   250/  422 batches | lr 0.00015 | ms/batch 19.89 | loss 0.00021939\n",
      "| Epoch  56 |   300/  422 batches | lr 0.00015 | ms/batch 19.72 | loss 0.00008953\n",
      "| Epoch  56 |   350/  422 batches | lr 0.00015 | ms/batch 19.72 | loss 0.00009900\n",
      "| Epoch  56 |   400/  422 batches | lr 0.00015 | ms/batch 19.85 | loss 0.00008260\n",
      "\n",
      "Val set: Average loss: 0.00010212\n",
      "\n",
      "EarlyStopping counter: 7 out of 20\n",
      "| Epoch  57 |    50/  422 batches | lr 0.00015 | ms/batch 20.17 | loss 0.00010393\n",
      "| Epoch  57 |   100/  422 batches | lr 0.00015 | ms/batch 19.82 | loss 0.00008044\n",
      "| Epoch  57 |   150/  422 batches | lr 0.00015 | ms/batch 19.78 | loss 0.00007192\n",
      "| Epoch  57 |   200/  422 batches | lr 0.00015 | ms/batch 21.43 | loss 0.00007957\n",
      "| Epoch  57 |   250/  422 batches | lr 0.00015 | ms/batch 19.66 | loss 0.00015152\n",
      "| Epoch  57 |   300/  422 batches | lr 0.00015 | ms/batch 19.78 | loss 0.00013866\n",
      "| Epoch  57 |   350/  422 batches | lr 0.00015 | ms/batch 19.78 | loss 0.00011871\n",
      "| Epoch  57 |   400/  422 batches | lr 0.00015 | ms/batch 19.69 | loss 0.00015328\n",
      "\n",
      "Val set: Average loss: 0.00010111\n",
      "\n",
      "EarlyStopping counter: 8 out of 20\n",
      "| Epoch  58 |    50/  422 batches | lr 0.00015 | ms/batch 20.24 | loss 0.00015083\n",
      "| Epoch  58 |   100/  422 batches | lr 0.00015 | ms/batch 19.75 | loss 0.00009894\n",
      "| Epoch  58 |   150/  422 batches | lr 0.00015 | ms/batch 19.85 | loss 0.00015219\n",
      "| Epoch  58 |   200/  422 batches | lr 0.00015 | ms/batch 21.66 | loss 0.00013124\n",
      "| Epoch  58 |   250/  422 batches | lr 0.00015 | ms/batch 19.65 | loss 0.00014799\n",
      "| Epoch  58 |   300/  422 batches | lr 0.00015 | ms/batch 17.96 | loss 0.00016608\n",
      "| Epoch  58 |   350/  422 batches | lr 0.00015 | ms/batch 17.98 | loss 0.00014626\n",
      "| Epoch  58 |   400/  422 batches | lr 0.00015 | ms/batch 21.32 | loss 0.00015879\n",
      "\n",
      "Val set: Average loss: 0.00010529\n",
      "\n",
      "EarlyStopping counter: 9 out of 20\n",
      "| Epoch  59 |    50/  422 batches | lr 0.00015 | ms/batch 20.05 | loss 0.00012379\n",
      "| Epoch  59 |   100/  422 batches | lr 0.00015 | ms/batch 17.84 | loss 0.00010687\n",
      "| Epoch  59 |   150/  422 batches | lr 0.00015 | ms/batch 18.06 | loss 0.00013732\n",
      "| Epoch  59 |   200/  422 batches | lr 0.00015 | ms/batch 19.56 | loss 0.00016668\n",
      "| Epoch  59 |   250/  422 batches | lr 0.00015 | ms/batch 17.97 | loss 0.00014570\n",
      "| Epoch  59 |   300/  422 batches | lr 0.00015 | ms/batch 19.68 | loss 0.00009867\n",
      "| Epoch  59 |   350/  422 batches | lr 0.00015 | ms/batch 19.71 | loss 0.00009101\n",
      "| Epoch  59 |   400/  422 batches | lr 0.00015 | ms/batch 19.56 | loss 0.00012528\n",
      "\n",
      "Val set: Average loss: 0.00012671\n",
      "\n",
      "EarlyStopping counter: 10 out of 20\n",
      "| Epoch  60 |    50/  422 batches | lr 0.00015 | ms/batch 18.50 | loss 0.00014704\n",
      "| Epoch  60 |   100/  422 batches | lr 0.00015 | ms/batch 19.64 | loss 0.00012608\n",
      "| Epoch  60 |   150/  422 batches | lr 0.00015 | ms/batch 21.35 | loss 0.00017106\n",
      "| Epoch  60 |   200/  422 batches | lr 0.00015 | ms/batch 19.87 | loss 0.00009643\n",
      "| Epoch  60 |   250/  422 batches | lr 0.00015 | ms/batch 19.65 | loss 0.00009420\n",
      "| Epoch  60 |   300/  422 batches | lr 0.00015 | ms/batch 19.85 | loss 0.00020292\n",
      "| Epoch  60 |   350/  422 batches | lr 0.00015 | ms/batch 19.69 | loss 0.00013644\n",
      "| Epoch  60 |   400/  422 batches | lr 0.00015 | ms/batch 21.22 | loss 0.00011693\n",
      "\n",
      "Val set: Average loss: 0.00010749\n",
      "\n",
      "EarlyStopping counter: 11 out of 20\n",
      "| Epoch  61 |    50/  422 batches | lr 0.00015 | ms/batch 20.47 | loss 0.00014989\n",
      "| Epoch  61 |   100/  422 batches | lr 0.00015 | ms/batch 18.04 | loss 0.00011082\n",
      "| Epoch  61 |   150/  422 batches | lr 0.00015 | ms/batch 17.88 | loss 0.00019120\n",
      "| Epoch  61 |   200/  422 batches | lr 0.00015 | ms/batch 21.26 | loss 0.00012045\n",
      "| Epoch  61 |   250/  422 batches | lr 0.00015 | ms/batch 19.68 | loss 0.00011155\n",
      "| Epoch  61 |   300/  422 batches | lr 0.00015 | ms/batch 17.93 | loss 0.00010871\n",
      "| Epoch  61 |   350/  422 batches | lr 0.00015 | ms/batch 17.97 | loss 0.00009162\n",
      "| Epoch  61 |   400/  422 batches | lr 0.00015 | ms/batch 19.66 | loss 0.00009051\n",
      "\n",
      "Val set: Average loss: 0.00021962\n",
      "\n",
      "EarlyStopping counter: 12 out of 20\n",
      "| Epoch  62 |    50/  422 batches | lr 0.00015 | ms/batch 19.99 | loss 0.00017757\n",
      "| Epoch  62 |   100/  422 batches | lr 0.00015 | ms/batch 17.97 | loss 0.00017167\n",
      "| Epoch  62 |   150/  422 batches | lr 0.00015 | ms/batch 17.87 | loss 0.00016025\n",
      "| Epoch  62 |   200/  422 batches | lr 0.00015 | ms/batch 21.28 | loss 0.00013057\n",
      "| Epoch  62 |   250/  422 batches | lr 0.00015 | ms/batch 18.01 | loss 0.00015695\n",
      "| Epoch  62 |   300/  422 batches | lr 0.00015 | ms/batch 19.60 | loss 0.00017448\n",
      "| Epoch  62 |   350/  422 batches | lr 0.00015 | ms/batch 18.13 | loss 0.00013750\n",
      "| Epoch  62 |   400/  422 batches | lr 0.00015 | ms/batch 20.32 | loss 0.00009763\n",
      "\n",
      "Val set: Average loss: 0.00010120\n",
      "\n",
      "EarlyStopping counter: 13 out of 20\n",
      "| Epoch  63 |    50/  422 batches | lr 0.00015 | ms/batch 20.99 | loss 0.00017276\n",
      "| Epoch  63 |   100/  422 batches | lr 0.00015 | ms/batch 20.53 | loss 0.00014510\n",
      "| Epoch  63 |   150/  422 batches | lr 0.00015 | ms/batch 21.46 | loss 0.00014449\n",
      "| Epoch  63 |   200/  422 batches | lr 0.00015 | ms/batch 21.69 | loss 0.00019512\n",
      "| Epoch  63 |   250/  422 batches | lr 0.00015 | ms/batch 20.01 | loss 0.00030380\n",
      "| Epoch  63 |   300/  422 batches | lr 0.00015 | ms/batch 19.93 | loss 0.00009582\n",
      "| Epoch  63 |   350/  422 batches | lr 0.00015 | ms/batch 19.71 | loss 0.00012675\n",
      "| Epoch  63 |   400/  422 batches | lr 0.00015 | ms/batch 20.07 | loss 0.00008291\n",
      "\n",
      "Val set: Average loss: 0.00015250\n",
      "\n",
      "EarlyStopping counter: 14 out of 20\n",
      "| Epoch  64 |    50/  422 batches | lr 0.00015 | ms/batch 20.31 | loss 0.00018528\n",
      "| Epoch  64 |   100/  422 batches | lr 0.00015 | ms/batch 19.90 | loss 0.00014111\n",
      "| Epoch  64 |   150/  422 batches | lr 0.00015 | ms/batch 19.98 | loss 0.00012752\n",
      "| Epoch  64 |   200/  422 batches | lr 0.00015 | ms/batch 21.55 | loss 0.00019505\n",
      "| Epoch  64 |   250/  422 batches | lr 0.00015 | ms/batch 19.91 | loss 0.00012534\n",
      "| Epoch  64 |   300/  422 batches | lr 0.00015 | ms/batch 19.77 | loss 0.00007867\n",
      "| Epoch  64 |   350/  422 batches | lr 0.00015 | ms/batch 19.91 | loss 0.00009486\n",
      "| Epoch  64 |   400/  422 batches | lr 0.00015 | ms/batch 19.97 | loss 0.00007394\n",
      "\n",
      "Val set: Average loss: 0.00008623\n",
      "\n",
      "| Epoch  65 |    50/  422 batches | lr 0.00015 | ms/batch 20.13 | loss 0.00009280\n",
      "| Epoch  65 |   100/  422 batches | lr 0.00015 | ms/batch 17.92 | loss 0.00007173\n",
      "| Epoch  65 |   150/  422 batches | lr 0.00015 | ms/batch 17.98 | loss 0.00006894\n",
      "| Epoch  65 |   200/  422 batches | lr 0.00015 | ms/batch 21.37 | loss 0.00027909\n",
      "| Epoch  65 |   250/  422 batches | lr 0.00015 | ms/batch 18.09 | loss 0.00010441\n",
      "| Epoch  65 |   300/  422 batches | lr 0.00015 | ms/batch 19.81 | loss 0.00009304\n",
      "| Epoch  65 |   350/  422 batches | lr 0.00015 | ms/batch 19.75 | loss 0.00007999\n",
      "| Epoch  65 |   400/  422 batches | lr 0.00015 | ms/batch 17.95 | loss 0.00012019\n",
      "\n",
      "Val set: Average loss: 0.00009619\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  66 |    50/  422 batches | lr 0.00015 | ms/batch 20.08 | loss 0.00012020\n",
      "| Epoch  66 |   100/  422 batches | lr 0.00015 | ms/batch 19.73 | loss 0.00009358\n",
      "| Epoch  66 |   150/  422 batches | lr 0.00015 | ms/batch 19.53 | loss 0.00020340\n",
      "| Epoch  66 |   200/  422 batches | lr 0.00015 | ms/batch 17.91 | loss 0.00011214\n",
      "| Epoch  66 |   250/  422 batches | lr 0.00015 | ms/batch 19.67 | loss 0.00008885\n",
      "| Epoch  66 |   300/  422 batches | lr 0.00015 | ms/batch 19.66 | loss 0.00011294\n",
      "| Epoch  66 |   350/  422 batches | lr 0.00015 | ms/batch 19.72 | loss 0.00015743\n",
      "| Epoch  66 |   400/  422 batches | lr 0.00015 | ms/batch 17.92 | loss 0.00012460\n",
      "\n",
      "Val set: Average loss: 0.00010617\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  67 |    50/  422 batches | lr 0.00015 | ms/batch 20.23 | loss 0.00011695\n",
      "| Epoch  67 |   100/  422 batches | lr 0.00015 | ms/batch 19.86 | loss 0.00012686\n",
      "| Epoch  67 |   150/  422 batches | lr 0.00015 | ms/batch 19.70 | loss 0.00014692\n",
      "| Epoch  67 |   200/  422 batches | lr 0.00015 | ms/batch 18.01 | loss 0.00010126\n",
      "| Epoch  67 |   250/  422 batches | lr 0.00015 | ms/batch 19.60 | loss 0.00008652\n",
      "| Epoch  67 |   300/  422 batches | lr 0.00015 | ms/batch 19.75 | loss 0.00011231\n",
      "| Epoch  67 |   350/  422 batches | lr 0.00015 | ms/batch 19.76 | loss 0.00015558\n",
      "| Epoch  67 |   400/  422 batches | lr 0.00015 | ms/batch 18.12 | loss 0.00016959\n",
      "\n",
      "Val set: Average loss: 0.00011452\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  68 |    50/  422 batches | lr 0.00015 | ms/batch 19.95 | loss 0.00010993\n",
      "| Epoch  68 |   100/  422 batches | lr 0.00015 | ms/batch 20.00 | loss 0.00013746\n",
      "| Epoch  68 |   150/  422 batches | lr 0.00015 | ms/batch 19.64 | loss 0.00010146\n",
      "| Epoch  68 |   200/  422 batches | lr 0.00015 | ms/batch 17.89 | loss 0.00009858\n",
      "| Epoch  68 |   250/  422 batches | lr 0.00015 | ms/batch 17.99 | loss 0.00008465\n",
      "| Epoch  68 |   300/  422 batches | lr 0.00015 | ms/batch 21.34 | loss 0.00013496\n",
      "| Epoch  68 |   350/  422 batches | lr 0.00015 | ms/batch 19.61 | loss 0.00022283\n",
      "| Epoch  68 |   400/  422 batches | lr 0.00015 | ms/batch 17.95 | loss 0.00013762\n",
      "\n",
      "Val set: Average loss: 0.00013163\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch  69 |    50/  422 batches | lr 0.00015 | ms/batch 18.41 | loss 0.00020121\n",
      "| Epoch  69 |   100/  422 batches | lr 0.00015 | ms/batch 19.44 | loss 0.00013177\n",
      "| Epoch  69 |   150/  422 batches | lr 0.00015 | ms/batch 18.04 | loss 0.00011086\n",
      "| Epoch  69 |   200/  422 batches | lr 0.00015 | ms/batch 19.65 | loss 0.00013974\n",
      "| Epoch  69 |   250/  422 batches | lr 0.00015 | ms/batch 19.85 | loss 0.00018080\n",
      "| Epoch  69 |   300/  422 batches | lr 0.00015 | ms/batch 19.57 | loss 0.00009656\n",
      "| Epoch  69 |   350/  422 batches | lr 0.00015 | ms/batch 17.90 | loss 0.00014649\n",
      "| Epoch  69 |   400/  422 batches | lr 0.00015 | ms/batch 19.55 | loss 0.00011095\n",
      "\n",
      "Val set: Average loss: 0.00019155\n",
      "\n",
      "EarlyStopping counter: 5 out of 20\n",
      "| Epoch  70 |    50/  422 batches | lr 0.00015 | ms/batch 18.36 | loss 0.00022993\n",
      "| Epoch  70 |   100/  422 batches | lr 0.00015 | ms/batch 19.71 | loss 0.00013799\n",
      "| Epoch  70 |   150/  422 batches | lr 0.00015 | ms/batch 17.97 | loss 0.00010716\n",
      "| Epoch  70 |   200/  422 batches | lr 0.00015 | ms/batch 19.62 | loss 0.00012660\n",
      "| Epoch  70 |   250/  422 batches | lr 0.00015 | ms/batch 19.77 | loss 0.00017713\n",
      "| Epoch  70 |   300/  422 batches | lr 0.00015 | ms/batch 19.59 | loss 0.00008889\n",
      "| Epoch  70 |   350/  422 batches | lr 0.00015 | ms/batch 18.07 | loss 0.00013788\n",
      "| Epoch  70 |   400/  422 batches | lr 0.00015 | ms/batch 19.64 | loss 0.00008317\n",
      "\n",
      "Val set: Average loss: 0.00010798\n",
      "\n",
      "EarlyStopping counter: 6 out of 20\n",
      "| Epoch  71 |    50/  422 batches | lr 0.00015 | ms/batch 21.83 | loss 0.00022005\n",
      "| Epoch  71 |   100/  422 batches | lr 0.00015 | ms/batch 19.79 | loss 0.00012772\n",
      "| Epoch  71 |   150/  422 batches | lr 0.00015 | ms/batch 19.83 | loss 0.00009811\n",
      "| Epoch  71 |   200/  422 batches | lr 0.00015 | ms/batch 19.81 | loss 0.00010637\n",
      "| Epoch  71 |   250/  422 batches | lr 0.00015 | ms/batch 20.09 | loss 0.00011247\n",
      "| Epoch  71 |   300/  422 batches | lr 0.00015 | ms/batch 21.50 | loss 0.00008286\n",
      "| Epoch  71 |   350/  422 batches | lr 0.00015 | ms/batch 19.73 | loss 0.00008500\n",
      "| Epoch  71 |   400/  422 batches | lr 0.00015 | ms/batch 19.84 | loss 0.00006496\n",
      "\n",
      "Val set: Average loss: 0.00007584\n",
      "\n",
      "| Epoch  72 |    50/  422 batches | lr 0.00015 | ms/batch 20.05 | loss 0.00011584\n",
      "| Epoch  72 |   100/  422 batches | lr 0.00015 | ms/batch 19.54 | loss 0.00008144\n",
      "| Epoch  72 |   150/  422 batches | lr 0.00015 | ms/batch 17.98 | loss 0.00012489\n",
      "| Epoch  72 |   200/  422 batches | lr 0.00015 | ms/batch 19.60 | loss 0.00009728\n",
      "| Epoch  72 |   250/  422 batches | lr 0.00015 | ms/batch 19.85 | loss 0.00016517\n",
      "| Epoch  72 |   300/  422 batches | lr 0.00015 | ms/batch 19.72 | loss 0.00008468\n",
      "| Epoch  72 |   350/  422 batches | lr 0.00015 | ms/batch 17.94 | loss 0.00006291\n",
      "| Epoch  72 |   400/  422 batches | lr 0.00015 | ms/batch 18.05 | loss 0.00014001\n",
      "\n",
      "Val set: Average loss: 0.00011747\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  73 |    50/  422 batches | lr 0.00015 | ms/batch 18.39 | loss 0.00015492\n",
      "| Epoch  73 |   100/  422 batches | lr 0.00015 | ms/batch 18.15 | loss 0.00011700\n",
      "| Epoch  73 |   150/  422 batches | lr 0.00015 | ms/batch 19.64 | loss 0.00010219\n",
      "| Epoch  73 |   200/  422 batches | lr 0.00015 | ms/batch 17.96 | loss 0.00010745\n",
      "| Epoch  73 |   250/  422 batches | lr 0.00015 | ms/batch 19.64 | loss 0.00020266\n",
      "| Epoch  73 |   300/  422 batches | lr 0.00015 | ms/batch 19.69 | loss 0.00011196\n",
      "| Epoch  73 |   350/  422 batches | lr 0.00015 | ms/batch 21.43 | loss 0.00010650\n",
      "| Epoch  73 |   400/  422 batches | lr 0.00015 | ms/batch 19.82 | loss 0.00009067\n",
      "\n",
      "Val set: Average loss: 0.00007683\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  74 |    50/  422 batches | lr 0.00015 | ms/batch 21.90 | loss 0.00013265\n",
      "| Epoch  74 |   100/  422 batches | lr 0.00015 | ms/batch 19.84 | loss 0.00021568\n",
      "| Epoch  74 |   150/  422 batches | lr 0.00015 | ms/batch 19.94 | loss 0.00009085\n",
      "| Epoch  74 |   200/  422 batches | lr 0.00015 | ms/batch 19.90 | loss 0.00010236\n",
      "| Epoch  74 |   250/  422 batches | lr 0.00015 | ms/batch 20.00 | loss 0.00015310\n",
      "| Epoch  74 |   300/  422 batches | lr 0.00015 | ms/batch 19.88 | loss 0.00013270\n",
      "| Epoch  74 |   350/  422 batches | lr 0.00015 | ms/batch 21.56 | loss 0.00011004\n",
      "| Epoch  74 |   400/  422 batches | lr 0.00015 | ms/batch 19.71 | loss 0.00013282\n",
      "\n",
      "Val set: Average loss: 0.00010201\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  75 |    50/  422 batches | lr 0.00015 | ms/batch 18.60 | loss 0.00014001\n",
      "| Epoch  75 |   100/  422 batches | lr 0.00015 | ms/batch 19.60 | loss 0.00011472\n",
      "| Epoch  75 |   150/  422 batches | lr 0.00015 | ms/batch 19.79 | loss 0.00007323\n",
      "| Epoch  75 |   200/  422 batches | lr 0.00015 | ms/batch 19.68 | loss 0.00010545\n",
      "| Epoch  75 |   250/  422 batches | lr 0.00015 | ms/batch 18.03 | loss 0.00012267\n",
      "| Epoch  75 |   300/  422 batches | lr 0.00015 | ms/batch 18.04 | loss 0.00009366\n",
      "| Epoch  75 |   350/  422 batches | lr 0.00015 | ms/batch 19.77 | loss 0.00007069\n",
      "| Epoch  75 |   400/  422 batches | lr 0.00015 | ms/batch 17.92 | loss 0.00009529\n",
      "\n",
      "Val set: Average loss: 0.00010077\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch  76 |    50/  422 batches | lr 0.00015 | ms/batch 19.99 | loss 0.00011580\n",
      "| Epoch  76 |   100/  422 batches | lr 0.00015 | ms/batch 17.97 | loss 0.00009340\n",
      "| Epoch  76 |   150/  422 batches | lr 0.00015 | ms/batch 19.80 | loss 0.00013904\n",
      "| Epoch  76 |   200/  422 batches | lr 0.00015 | ms/batch 19.72 | loss 0.00008645\n",
      "| Epoch  76 |   250/  422 batches | lr 0.00015 | ms/batch 19.68 | loss 0.00010863\n",
      "| Epoch  76 |   300/  422 batches | lr 0.00015 | ms/batch 17.92 | loss 0.00012755\n",
      "| Epoch  76 |   350/  422 batches | lr 0.00015 | ms/batch 19.70 | loss 0.00008073\n",
      "| Epoch  76 |   400/  422 batches | lr 0.00015 | ms/batch 19.77 | loss 0.00012265\n",
      "\n",
      "Val set: Average loss: 0.00009500\n",
      "\n",
      "EarlyStopping counter: 5 out of 20\n",
      "| Epoch  77 |    50/  422 batches | lr 0.00015 | ms/batch 20.19 | loss 0.00012004\n",
      "| Epoch  77 |   100/  422 batches | lr 0.00015 | ms/batch 18.07 | loss 0.00012985\n",
      "| Epoch  77 |   150/  422 batches | lr 0.00015 | ms/batch 19.70 | loss 0.00011828\n",
      "| Epoch  77 |   200/  422 batches | lr 0.00015 | ms/batch 19.90 | loss 0.00009568\n",
      "| Epoch  77 |   250/  422 batches | lr 0.00015 | ms/batch 19.79 | loss 0.00012785\n",
      "| Epoch  77 |   300/  422 batches | lr 0.00015 | ms/batch 17.94 | loss 0.00010094\n",
      "| Epoch  77 |   350/  422 batches | lr 0.00015 | ms/batch 17.89 | loss 0.00019789\n",
      "| Epoch  77 |   400/  422 batches | lr 0.00015 | ms/batch 21.46 | loss 0.00019124\n",
      "\n",
      "Val set: Average loss: 0.00014423\n",
      "\n",
      "EarlyStopping counter: 6 out of 20\n",
      "| Epoch  78 |    50/  422 batches | lr 0.00015 | ms/batch 20.36 | loss 0.00019990\n",
      "| Epoch  78 |   100/  422 batches | lr 0.00015 | ms/batch 18.07 | loss 0.00011019\n",
      "| Epoch  78 |   150/  422 batches | lr 0.00015 | ms/batch 19.58 | loss 0.00008960\n",
      "| Epoch  78 |   200/  422 batches | lr 0.00015 | ms/batch 19.84 | loss 0.00010119\n",
      "| Epoch  78 |   250/  422 batches | lr 0.00015 | ms/batch 19.75 | loss 0.00009287\n",
      "| Epoch  78 |   300/  422 batches | lr 0.00015 | ms/batch 18.77 | loss 0.00010698\n",
      "| Epoch  78 |   350/  422 batches | lr 0.00015 | ms/batch 17.94 | loss 0.00009987\n",
      "| Epoch  78 |   400/  422 batches | lr 0.00015 | ms/batch 21.38 | loss 0.00010551\n",
      "\n",
      "Val set: Average loss: 0.00009355\n",
      "\n",
      "EarlyStopping counter: 7 out of 20\n",
      "| Epoch  79 |    50/  422 batches | lr 0.00015 | ms/batch 20.20 | loss 0.00011068\n",
      "| Epoch  79 |   100/  422 batches | lr 0.00015 | ms/batch 18.00 | loss 0.00009155\n",
      "| Epoch  79 |   150/  422 batches | lr 0.00015 | ms/batch 18.10 | loss 0.00008218\n",
      "| Epoch  79 |   200/  422 batches | lr 0.00015 | ms/batch 21.52 | loss 0.00007350\n",
      "| Epoch  79 |   250/  422 batches | lr 0.00015 | ms/batch 19.69 | loss 0.00008465\n",
      "| Epoch  79 |   300/  422 batches | lr 0.00015 | ms/batch 18.02 | loss 0.00010375\n",
      "| Epoch  79 |   350/  422 batches | lr 0.00015 | ms/batch 17.97 | loss 0.00012198\n",
      "| Epoch  79 |   400/  422 batches | lr 0.00015 | ms/batch 19.71 | loss 0.00015197\n",
      "\n",
      "Val set: Average loss: 0.00007721\n",
      "\n",
      "EarlyStopping counter: 8 out of 20\n",
      "| Epoch  80 |    50/  422 batches | lr 0.00015 | ms/batch 20.24 | loss 0.00011262\n",
      "| Epoch  80 |   100/  422 batches | lr 0.00015 | ms/batch 18.12 | loss 0.00010544\n",
      "| Epoch  80 |   150/  422 batches | lr 0.00015 | ms/batch 17.88 | loss 0.00012880\n",
      "| Epoch  80 |   200/  422 batches | lr 0.00015 | ms/batch 21.44 | loss 0.00010083\n",
      "| Epoch  80 |   250/  422 batches | lr 0.00015 | ms/batch 18.17 | loss 0.00011059\n",
      "| Epoch  80 |   300/  422 batches | lr 0.00015 | ms/batch 19.63 | loss 0.00012682\n",
      "| Epoch  80 |   350/  422 batches | lr 0.00015 | ms/batch 19.65 | loss 0.00009236\n",
      "| Epoch  80 |   400/  422 batches | lr 0.00015 | ms/batch 17.88 | loss 0.00007790\n",
      "\n",
      "Val set: Average loss: 0.00007251\n",
      "\n",
      "| Epoch  81 |    50/  422 batches | lr 0.00015 | ms/batch 20.04 | loss 0.00010507\n",
      "| Epoch  81 |   100/  422 batches | lr 0.00015 | ms/batch 19.63 | loss 0.00015338\n",
      "| Epoch  81 |   150/  422 batches | lr 0.00015 | ms/batch 17.95 | loss 0.00027356\n",
      "| Epoch  81 |   200/  422 batches | lr 0.00015 | ms/batch 19.61 | loss 0.00011815\n",
      "| Epoch  81 |   250/  422 batches | lr 0.00015 | ms/batch 19.72 | loss 0.00009023\n",
      "| Epoch  81 |   300/  422 batches | lr 0.00015 | ms/batch 19.57 | loss 0.00007717\n",
      "| Epoch  81 |   350/  422 batches | lr 0.00015 | ms/batch 18.00 | loss 0.00010596\n",
      "| Epoch  81 |   400/  422 batches | lr 0.00015 | ms/batch 17.92 | loss 0.00008944\n",
      "\n",
      "Val set: Average loss: 0.00012721\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  82 |    50/  422 batches | lr 0.00015 | ms/batch 20.41 | loss 0.00015889\n",
      "| Epoch  82 |   100/  422 batches | lr 0.00015 | ms/batch 19.76 | loss 0.00012340\n",
      "| Epoch  82 |   150/  422 batches | lr 0.00015 | ms/batch 18.01 | loss 0.00010365\n",
      "| Epoch  82 |   200/  422 batches | lr 0.00015 | ms/batch 19.63 | loss 0.00007567\n",
      "| Epoch  82 |   250/  422 batches | lr 0.00015 | ms/batch 19.78 | loss 0.00008140\n",
      "| Epoch  82 |   300/  422 batches | lr 0.00015 | ms/batch 19.71 | loss 0.00007152\n",
      "| Epoch  82 |   350/  422 batches | lr 0.00015 | ms/batch 17.96 | loss 0.00006805\n",
      "| Epoch  82 |   400/  422 batches | lr 0.00015 | ms/batch 17.96 | loss 0.00018075\n",
      "\n",
      "Val set: Average loss: 0.00012848\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  83 |    50/  422 batches | lr 0.00015 | ms/batch 18.47 | loss 0.00013576\n",
      "| Epoch  83 |   100/  422 batches | lr 0.00015 | ms/batch 18.01 | loss 0.00010473\n",
      "| Epoch  83 |   150/  422 batches | lr 0.00015 | ms/batch 19.47 | loss 0.00006199\n",
      "| Epoch  83 |   200/  422 batches | lr 0.00015 | ms/batch 17.94 | loss 0.00006466\n",
      "| Epoch  83 |   250/  422 batches | lr 0.00015 | ms/batch 19.57 | loss 0.00013297\n",
      "| Epoch  83 |   300/  422 batches | lr 0.00015 | ms/batch 20.26 | loss 0.00010581\n",
      "| Epoch  83 |   350/  422 batches | lr 0.00015 | ms/batch 19.64 | loss 0.00013157\n",
      "| Epoch  83 |   400/  422 batches | lr 0.00015 | ms/batch 18.04 | loss 0.00012381\n",
      "\n",
      "Val set: Average loss: 0.00021846\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  84 |    50/  422 batches | lr 0.00015 | ms/batch 19.99 | loss 0.00025338\n",
      "| Epoch  84 |   100/  422 batches | lr 0.00015 | ms/batch 19.76 | loss 0.00014502\n",
      "| Epoch  84 |   150/  422 batches | lr 0.00015 | ms/batch 19.66 | loss 0.00008131\n",
      "| Epoch  84 |   200/  422 batches | lr 0.00015 | ms/batch 17.99 | loss 0.00008898\n",
      "| Epoch  84 |   250/  422 batches | lr 0.00015 | ms/batch 19.74 | loss 0.00009169\n",
      "| Epoch  84 |   300/  422 batches | lr 0.00015 | ms/batch 19.89 | loss 0.00007782\n",
      "| Epoch  84 |   350/  422 batches | lr 0.00015 | ms/batch 19.71 | loss 0.00018497\n",
      "| Epoch  84 |   400/  422 batches | lr 0.00015 | ms/batch 18.08 | loss 0.00010514\n",
      "\n",
      "Val set: Average loss: 0.00016270\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch  85 |    50/  422 batches | lr 0.00015 | ms/batch 19.99 | loss 0.00021010\n",
      "| Epoch  85 |   100/  422 batches | lr 0.00015 | ms/batch 19.67 | loss 0.00020775\n",
      "| Epoch  85 |   150/  422 batches | lr 0.00015 | ms/batch 19.58 | loss 0.00014508\n",
      "| Epoch  85 |   200/  422 batches | lr 0.00015 | ms/batch 17.98 | loss 0.00015664\n",
      "| Epoch  85 |   250/  422 batches | lr 0.00015 | ms/batch 19.54 | loss 0.00014668\n",
      "| Epoch  85 |   300/  422 batches | lr 0.00015 | ms/batch 19.66 | loss 0.00008832\n",
      "| Epoch  85 |   350/  422 batches | lr 0.00015 | ms/batch 19.61 | loss 0.00015465\n",
      "| Epoch  85 |   400/  422 batches | lr 0.00015 | ms/batch 18.07 | loss 0.00011003\n",
      "\n",
      "Val set: Average loss: 0.00008998\n",
      "\n",
      "EarlyStopping counter: 5 out of 20\n",
      "| Epoch  86 |    50/  422 batches | lr 0.00015 | ms/batch 20.04 | loss 0.00014056\n",
      "| Epoch  86 |   100/  422 batches | lr 0.00015 | ms/batch 19.71 | loss 0.00018720\n",
      "| Epoch  86 |   150/  422 batches | lr 0.00015 | ms/batch 19.77 | loss 0.00010976\n",
      "| Epoch  86 |   200/  422 batches | lr 0.00015 | ms/batch 17.91 | loss 0.00015540\n",
      "| Epoch  86 |   250/  422 batches | lr 0.00015 | ms/batch 18.02 | loss 0.00014490\n",
      "| Epoch  86 |   300/  422 batches | lr 0.00015 | ms/batch 21.46 | loss 0.00007968\n",
      "| Epoch  86 |   350/  422 batches | lr 0.00015 | ms/batch 19.88 | loss 0.00011651\n",
      "| Epoch  86 |   400/  422 batches | lr 0.00015 | ms/batch 18.02 | loss 0.00009425\n",
      "\n",
      "Val set: Average loss: 0.00008420\n",
      "\n",
      "EarlyStopping counter: 6 out of 20\n",
      "| Epoch  87 |    50/  422 batches | lr 0.00015 | ms/batch 18.41 | loss 0.00010826\n",
      "| Epoch  87 |   100/  422 batches | lr 0.00015 | ms/batch 19.58 | loss 0.00012448\n",
      "| Epoch  87 |   150/  422 batches | lr 0.00015 | ms/batch 17.93 | loss 0.00007265\n",
      "| Epoch  87 |   200/  422 batches | lr 0.00015 | ms/batch 19.78 | loss 0.00010047\n",
      "| Epoch  87 |   250/  422 batches | lr 0.00015 | ms/batch 19.69 | loss 0.00008152\n",
      "| Epoch  87 |   300/  422 batches | lr 0.00015 | ms/batch 19.56 | loss 0.00006757\n",
      "| Epoch  87 |   350/  422 batches | lr 0.00015 | ms/batch 17.97 | loss 0.00010800\n",
      "| Epoch  87 |   400/  422 batches | lr 0.00015 | ms/batch 19.81 | loss 0.00007197\n",
      "\n",
      "Val set: Average loss: 0.00007966\n",
      "\n",
      "EarlyStopping counter: 7 out of 20\n",
      "| Epoch  88 |    50/  422 batches | lr 0.00015 | ms/batch 18.59 | loss 0.00008679\n",
      "| Epoch  88 |   100/  422 batches | lr 0.00015 | ms/batch 19.80 | loss 0.00006537\n",
      "| Epoch  88 |   150/  422 batches | lr 0.00015 | ms/batch 18.05 | loss 0.00005312\n",
      "| Epoch  88 |   200/  422 batches | lr 0.00015 | ms/batch 19.65 | loss 0.00007099\n",
      "| Epoch  88 |   250/  422 batches | lr 0.00015 | ms/batch 19.66 | loss 0.00015399\n",
      "| Epoch  88 |   300/  422 batches | lr 0.00015 | ms/batch 20.43 | loss 0.00006783\n",
      "| Epoch  88 |   350/  422 batches | lr 0.00015 | ms/batch 17.91 | loss 0.00008549\n",
      "| Epoch  88 |   400/  422 batches | lr 0.00015 | ms/batch 19.48 | loss 0.00011637\n",
      "\n",
      "Val set: Average loss: 0.00007054\n",
      "\n",
      "| Epoch  89 |    50/  422 batches | lr 0.00015 | ms/batch 20.08 | loss 0.00008378\n",
      "| Epoch  89 |   100/  422 batches | lr 0.00015 | ms/batch 21.57 | loss 0.00009211\n",
      "| Epoch  89 |   150/  422 batches | lr 0.00015 | ms/batch 19.80 | loss 0.00011204\n",
      "| Epoch  89 |   200/  422 batches | lr 0.00015 | ms/batch 17.93 | loss 0.00009963\n",
      "| Epoch  89 |   250/  422 batches | lr 0.00015 | ms/batch 18.11 | loss 0.00016388\n",
      "| Epoch  89 |   300/  422 batches | lr 0.00015 | ms/batch 21.46 | loss 0.00007512\n",
      "| Epoch  89 |   350/  422 batches | lr 0.00015 | ms/batch 18.02 | loss 0.00009654\n",
      "| Epoch  89 |   400/  422 batches | lr 0.00015 | ms/batch 19.58 | loss 0.00018148\n",
      "\n",
      "Val set: Average loss: 0.00007591\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  90 |    50/  422 batches | lr 0.00015 | ms/batch 19.95 | loss 0.00008102\n",
      "| Epoch  90 |   100/  422 batches | lr 0.00015 | ms/batch 17.99 | loss 0.00007953\n",
      "| Epoch  90 |   150/  422 batches | lr 0.00015 | ms/batch 19.73 | loss 0.00011130\n",
      "| Epoch  90 |   200/  422 batches | lr 0.00015 | ms/batch 19.57 | loss 0.00008936\n",
      "| Epoch  90 |   250/  422 batches | lr 0.00015 | ms/batch 19.73 | loss 0.00011151\n",
      "| Epoch  90 |   300/  422 batches | lr 0.00015 | ms/batch 17.94 | loss 0.00007965\n",
      "| Epoch  90 |   350/  422 batches | lr 0.00015 | ms/batch 19.65 | loss 0.00008140\n",
      "| Epoch  90 |   400/  422 batches | lr 0.00015 | ms/batch 19.73 | loss 0.00011923\n",
      "\n",
      "Val set: Average loss: 0.00007990\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  91 |    50/  422 batches | lr 0.00015 | ms/batch 20.03 | loss 0.00008466\n",
      "| Epoch  91 |   100/  422 batches | lr 0.00015 | ms/batch 19.64 | loss 0.00007895\n",
      "| Epoch  91 |   150/  422 batches | lr 0.00015 | ms/batch 17.94 | loss 0.00013843\n",
      "| Epoch  91 |   200/  422 batches | lr 0.00015 | ms/batch 19.71 | loss 0.00011970\n",
      "| Epoch  91 |   250/  422 batches | lr 0.00015 | ms/batch 19.68 | loss 0.00015387\n",
      "| Epoch  91 |   300/  422 batches | lr 0.00015 | ms/batch 19.63 | loss 0.00010528\n",
      "| Epoch  91 |   350/  422 batches | lr 0.00015 | ms/batch 17.94 | loss 0.00011526\n",
      "| Epoch  91 |   400/  422 batches | lr 0.00015 | ms/batch 17.91 | loss 0.00014128\n",
      "\n",
      "Val set: Average loss: 0.00009518\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  92 |    50/  422 batches | lr 0.00015 | ms/batch 18.34 | loss 0.00010519\n",
      "| Epoch  92 |   100/  422 batches | lr 0.00015 | ms/batch 17.94 | loss 0.00011974\n",
      "| Epoch  92 |   150/  422 batches | lr 0.00015 | ms/batch 19.55 | loss 0.00009007\n",
      "| Epoch  92 |   200/  422 batches | lr 0.00015 | ms/batch 18.07 | loss 0.00010020\n",
      "| Epoch  92 |   250/  422 batches | lr 0.00015 | ms/batch 19.58 | loss 0.00010551\n",
      "| Epoch  92 |   300/  422 batches | lr 0.00015 | ms/batch 19.69 | loss 0.00010815\n",
      "| Epoch  92 |   350/  422 batches | lr 0.00015 | ms/batch 19.60 | loss 0.00019073\n",
      "| Epoch  92 |   400/  422 batches | lr 0.00015 | ms/batch 17.97 | loss 0.00008780\n",
      "\n",
      "Val set: Average loss: 0.00014949\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch  93 |    50/  422 batches | lr 0.00015 | ms/batch 20.10 | loss 0.00016986\n",
      "| Epoch  93 |   100/  422 batches | lr 0.00015 | ms/batch 19.60 | loss 0.00010634\n",
      "| Epoch  93 |   150/  422 batches | lr 0.00015 | ms/batch 19.58 | loss 0.00007187\n",
      "| Epoch  93 |   200/  422 batches | lr 0.00015 | ms/batch 17.89 | loss 0.00010366\n",
      "| Epoch  93 |   250/  422 batches | lr 0.00015 | ms/batch 19.56 | loss 0.00009688\n",
      "| Epoch  93 |   300/  422 batches | lr 0.00015 | ms/batch 20.09 | loss 0.00008677\n",
      "| Epoch  93 |   350/  422 batches | lr 0.00015 | ms/batch 19.68 | loss 0.00007462\n",
      "| Epoch  93 |   400/  422 batches | lr 0.00015 | ms/batch 17.94 | loss 0.00007779\n",
      "\n",
      "Val set: Average loss: 0.00008086\n",
      "\n",
      "EarlyStopping counter: 5 out of 20\n",
      "| Epoch  94 |    50/  422 batches | lr 0.00015 | ms/batch 19.99 | loss 0.00008117\n",
      "| Epoch  94 |   100/  422 batches | lr 0.00015 | ms/batch 19.64 | loss 0.00005895\n",
      "| Epoch  94 |   150/  422 batches | lr 0.00015 | ms/batch 19.69 | loss 0.00008832\n",
      "| Epoch  94 |   200/  422 batches | lr 0.00015 | ms/batch 17.94 | loss 0.00007616\n",
      "| Epoch  94 |   250/  422 batches | lr 0.00015 | ms/batch 19.57 | loss 0.00010471\n",
      "| Epoch  94 |   300/  422 batches | lr 0.00015 | ms/batch 20.06 | loss 0.00006425\n",
      "| Epoch  94 |   350/  422 batches | lr 0.00015 | ms/batch 19.57 | loss 0.00018114\n",
      "| Epoch  94 |   400/  422 batches | lr 0.00015 | ms/batch 17.89 | loss 0.00017209\n",
      "\n",
      "Val set: Average loss: 0.00018101\n",
      "\n",
      "EarlyStopping counter: 6 out of 20\n",
      "| Epoch  95 |    50/  422 batches | lr 0.00015 | ms/batch 20.11 | loss 0.00017303\n",
      "| Epoch  95 |   100/  422 batches | lr 0.00015 | ms/batch 19.68 | loss 0.00008613\n",
      "| Epoch  95 |   150/  422 batches | lr 0.00015 | ms/batch 19.68 | loss 0.00007058\n",
      "| Epoch  95 |   200/  422 batches | lr 0.00015 | ms/batch 17.96 | loss 0.00007748\n",
      "| Epoch  95 |   250/  422 batches | lr 0.00015 | ms/batch 17.94 | loss 0.00007170\n",
      "| Epoch  95 |   300/  422 batches | lr 0.00015 | ms/batch 21.33 | loss 0.00006180\n",
      "| Epoch  95 |   350/  422 batches | lr 0.00015 | ms/batch 19.66 | loss 0.00011278\n",
      "| Epoch  95 |   400/  422 batches | lr 0.00015 | ms/batch 17.83 | loss 0.00010068\n",
      "\n",
      "Val set: Average loss: 0.00009293\n",
      "\n",
      "EarlyStopping counter: 7 out of 20\n",
      "| Epoch  96 |    50/  422 batches | lr 0.00015 | ms/batch 18.45 | loss 0.00008958\n",
      "| Epoch  96 |   100/  422 batches | lr 0.00015 | ms/batch 19.58 | loss 0.00006338\n",
      "| Epoch  96 |   150/  422 batches | lr 0.00015 | ms/batch 18.05 | loss 0.00014519\n",
      "| Epoch  96 |   200/  422 batches | lr 0.00015 | ms/batch 19.64 | loss 0.00008903\n",
      "| Epoch  96 |   250/  422 batches | lr 0.00015 | ms/batch 19.67 | loss 0.00006843\n",
      "| Epoch  96 |   300/  422 batches | lr 0.00015 | ms/batch 19.59 | loss 0.00006354\n",
      "| Epoch  96 |   350/  422 batches | lr 0.00015 | ms/batch 17.88 | loss 0.00020512\n",
      "| Epoch  96 |   400/  422 batches | lr 0.00015 | ms/batch 19.58 | loss 0.00009880\n",
      "\n",
      "Val set: Average loss: 0.00009217\n",
      "\n",
      "EarlyStopping counter: 8 out of 20\n",
      "| Epoch  97 |    50/  422 batches | lr 0.00015 | ms/batch 18.58 | loss 0.00010133\n",
      "| Epoch  97 |   100/  422 batches | lr 0.00015 | ms/batch 19.56 | loss 0.00007324\n",
      "| Epoch  97 |   150/  422 batches | lr 0.00015 | ms/batch 18.08 | loss 0.00012583\n",
      "| Epoch  97 |   200/  422 batches | lr 0.00015 | ms/batch 19.67 | loss 0.00011873\n",
      "| Epoch  97 |   250/  422 batches | lr 0.00015 | ms/batch 19.66 | loss 0.00010876\n",
      "| Epoch  97 |   300/  422 batches | lr 0.00015 | ms/batch 19.67 | loss 0.00008004\n",
      "| Epoch  97 |   350/  422 batches | lr 0.00015 | ms/batch 18.10 | loss 0.00010619\n",
      "| Epoch  97 |   400/  422 batches | lr 0.00015 | ms/batch 19.60 | loss 0.00006859\n",
      "\n",
      "Val set: Average loss: 0.00007742\n",
      "\n",
      "EarlyStopping counter: 9 out of 20\n",
      "| Epoch  98 |    50/  422 batches | lr 0.00015 | ms/batch 21.83 | loss 0.00007491\n",
      "| Epoch  98 |   100/  422 batches | lr 0.00015 | ms/batch 19.78 | loss 0.00006110\n",
      "| Epoch  98 |   150/  422 batches | lr 0.00015 | ms/batch 19.81 | loss 0.00014587\n",
      "| Epoch  98 |   200/  422 batches | lr 0.00015 | ms/batch 20.57 | loss 0.00010871\n",
      "| Epoch  98 |   250/  422 batches | lr 0.00015 | ms/batch 19.87 | loss 0.00009492\n",
      "| Epoch  98 |   300/  422 batches | lr 0.00015 | ms/batch 21.56 | loss 0.00006661\n",
      "| Epoch  98 |   350/  422 batches | lr 0.00015 | ms/batch 19.79 | loss 0.00007390\n",
      "| Epoch  98 |   400/  422 batches | lr 0.00015 | ms/batch 19.73 | loss 0.00008135\n",
      "\n",
      "Val set: Average loss: 0.00011236\n",
      "\n",
      "EarlyStopping counter: 10 out of 20\n",
      "| Epoch  99 |    50/  422 batches | lr 0.00015 | ms/batch 21.90 | loss 0.00014572\n",
      "| Epoch  99 |   100/  422 batches | lr 0.00015 | ms/batch 19.97 | loss 0.00009088\n",
      "| Epoch  99 |   150/  422 batches | lr 0.00015 | ms/batch 19.84 | loss 0.00011778\n",
      "| Epoch  99 |   200/  422 batches | lr 0.00015 | ms/batch 19.79 | loss 0.00015099\n",
      "| Epoch  99 |   250/  422 batches | lr 0.00015 | ms/batch 19.76 | loss 0.00019032\n",
      "| Epoch  99 |   300/  422 batches | lr 0.00015 | ms/batch 21.48 | loss 0.00013249\n",
      "| Epoch  99 |   350/  422 batches | lr 0.00015 | ms/batch 19.98 | loss 0.00010741\n",
      "| Epoch  99 |   400/  422 batches | lr 0.00015 | ms/batch 19.77 | loss 0.00008464\n",
      "\n",
      "Val set: Average loss: 0.00012570\n",
      "\n",
      "EarlyStopping counter: 11 out of 20\n",
      "| Epoch 100 |    50/  422 batches | lr 0.00015 | ms/batch 21.81 | loss 0.00015418\n",
      "| Epoch 100 |   100/  422 batches | lr 0.00015 | ms/batch 19.77 | loss 0.00010391\n",
      "| Epoch 100 |   150/  422 batches | lr 0.00015 | ms/batch 19.83 | loss 0.00008060\n",
      "| Epoch 100 |   200/  422 batches | lr 0.00015 | ms/batch 19.91 | loss 0.00014849\n",
      "| Epoch 100 |   250/  422 batches | lr 0.00015 | ms/batch 19.79 | loss 0.00014241\n",
      "| Epoch 100 |   300/  422 batches | lr 0.00015 | ms/batch 21.51 | loss 0.00013315\n",
      "| Epoch 100 |   350/  422 batches | lr 0.00015 | ms/batch 19.82 | loss 0.00010815\n",
      "| Epoch 100 |   400/  422 batches | lr 0.00015 | ms/batch 19.84 | loss 0.00012722\n",
      "\n",
      "Val set: Average loss: 0.00008343\n",
      "\n",
      "EarlyStopping counter: 12 out of 20\n",
      "| Epoch 101 |    50/  422 batches | lr 0.00015 | ms/batch 21.77 | loss 0.00010835\n",
      "| Epoch 101 |   100/  422 batches | lr 0.00015 | ms/batch 19.70 | loss 0.00018870\n",
      "| Epoch 101 |   150/  422 batches | lr 0.00015 | ms/batch 19.70 | loss 0.00010350\n",
      "| Epoch 101 |   200/  422 batches | lr 0.00015 | ms/batch 19.78 | loss 0.00019711\n",
      "| Epoch 101 |   250/  422 batches | lr 0.00015 | ms/batch 19.69 | loss 0.00014143\n",
      "| Epoch 101 |   300/  422 batches | lr 0.00015 | ms/batch 21.40 | loss 0.00009654\n",
      "| Epoch 101 |   350/  422 batches | lr 0.00015 | ms/batch 19.74 | loss 0.00009260\n",
      "| Epoch 101 |   400/  422 batches | lr 0.00015 | ms/batch 19.80 | loss 0.00009145\n",
      "\n",
      "Val set: Average loss: 0.00008800\n",
      "\n",
      "EarlyStopping counter: 13 out of 20\n",
      "| Epoch 102 |    50/  422 batches | lr 0.00015 | ms/batch 21.95 | loss 0.00013614\n",
      "| Epoch 102 |   100/  422 batches | lr 0.00015 | ms/batch 19.70 | loss 0.00012764\n",
      "| Epoch 102 |   150/  422 batches | lr 0.00015 | ms/batch 19.78 | loss 0.00007742\n",
      "| Epoch 102 |   200/  422 batches | lr 0.00015 | ms/batch 19.76 | loss 0.00015268\n",
      "| Epoch 102 |   250/  422 batches | lr 0.00015 | ms/batch 19.81 | loss 0.00011364\n",
      "| Epoch 102 |   300/  422 batches | lr 0.00015 | ms/batch 21.45 | loss 0.00007895\n",
      "| Epoch 102 |   350/  422 batches | lr 0.00015 | ms/batch 19.97 | loss 0.00007582\n",
      "| Epoch 102 |   400/  422 batches | lr 0.00015 | ms/batch 19.84 | loss 0.00007605\n",
      "\n",
      "Val set: Average loss: 0.00006683\n",
      "\n",
      "| Epoch 103 |    50/  422 batches | lr 0.00015 | ms/batch 20.00 | loss 0.00008247\n",
      "| Epoch 103 |   100/  422 batches | lr 0.00015 | ms/batch 18.54 | loss 0.00008302\n",
      "| Epoch 103 |   150/  422 batches | lr 0.00015 | ms/batch 19.75 | loss 0.00005883\n",
      "| Epoch 103 |   200/  422 batches | lr 0.00015 | ms/batch 19.81 | loss 0.00007616\n",
      "| Epoch 103 |   250/  422 batches | lr 0.00015 | ms/batch 19.67 | loss 0.00005714\n",
      "| Epoch 103 |   300/  422 batches | lr 0.00015 | ms/batch 17.99 | loss 0.00006358\n",
      "| Epoch 103 |   350/  422 batches | lr 0.00015 | ms/batch 19.66 | loss 0.00006953\n",
      "| Epoch 103 |   400/  422 batches | lr 0.00015 | ms/batch 19.75 | loss 0.00005608\n",
      "\n",
      "Val set: Average loss: 0.00006378\n",
      "\n",
      "| Epoch 104 |    50/  422 batches | lr 0.00015 | ms/batch 20.09 | loss 0.00007133\n",
      "| Epoch 104 |   100/  422 batches | lr 0.00015 | ms/batch 19.79 | loss 0.00007923\n",
      "| Epoch 104 |   150/  422 batches | lr 0.00015 | ms/batch 19.55 | loss 0.00007485\n",
      "| Epoch 104 |   200/  422 batches | lr 0.00015 | ms/batch 18.07 | loss 0.00009203\n",
      "| Epoch 104 |   250/  422 batches | lr 0.00015 | ms/batch 19.58 | loss 0.00009229\n",
      "| Epoch 104 |   300/  422 batches | lr 0.00015 | ms/batch 19.77 | loss 0.00007654\n",
      "| Epoch 104 |   350/  422 batches | lr 0.00015 | ms/batch 19.57 | loss 0.00008162\n",
      "| Epoch 104 |   400/  422 batches | lr 0.00015 | ms/batch 18.07 | loss 0.00012413\n",
      "\n",
      "Val set: Average loss: 0.00009565\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 105 |    50/  422 batches | lr 0.00015 | ms/batch 20.18 | loss 0.00012596\n",
      "| Epoch 105 |   100/  422 batches | lr 0.00015 | ms/batch 19.88 | loss 0.00009119\n",
      "| Epoch 105 |   150/  422 batches | lr 0.00015 | ms/batch 19.65 | loss 0.00007908\n",
      "| Epoch 105 |   200/  422 batches | lr 0.00015 | ms/batch 18.23 | loss 0.00009620\n",
      "| Epoch 105 |   250/  422 batches | lr 0.00015 | ms/batch 19.79 | loss 0.00010404\n",
      "| Epoch 105 |   300/  422 batches | lr 0.00015 | ms/batch 20.09 | loss 0.00007324\n",
      "| Epoch 105 |   350/  422 batches | lr 0.00015 | ms/batch 19.83 | loss 0.00010700\n",
      "| Epoch 105 |   400/  422 batches | lr 0.00015 | ms/batch 18.13 | loss 0.00011134\n",
      "\n",
      "Val set: Average loss: 0.00009148\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch 106 |    50/  422 batches | lr 0.00015 | ms/batch 20.00 | loss 0.00012916\n",
      "| Epoch 106 |   100/  422 batches | lr 0.00015 | ms/batch 19.72 | loss 0.00008959\n",
      "| Epoch 106 |   150/  422 batches | lr 0.00015 | ms/batch 19.70 | loss 0.00009750\n",
      "| Epoch 106 |   200/  422 batches | lr 0.00015 | ms/batch 18.01 | loss 0.00007826\n",
      "| Epoch 106 |   250/  422 batches | lr 0.00015 | ms/batch 18.02 | loss 0.00006897\n",
      "| Epoch 106 |   300/  422 batches | lr 0.00015 | ms/batch 21.55 | loss 0.00008840\n",
      "| Epoch 106 |   350/  422 batches | lr 0.00015 | ms/batch 19.61 | loss 0.00008924\n",
      "| Epoch 106 |   400/  422 batches | lr 0.00015 | ms/batch 17.88 | loss 0.00009982\n",
      "\n",
      "Val set: Average loss: 0.00007367\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch 107 |    50/  422 batches | lr 0.00015 | ms/batch 20.00 | loss 0.00007547\n",
      "| Epoch 107 |   100/  422 batches | lr 0.00015 | ms/batch 19.78 | loss 0.00007030\n",
      "| Epoch 107 |   150/  422 batches | lr 0.00015 | ms/batch 19.73 | loss 0.00007598\n",
      "| Epoch 107 |   200/  422 batches | lr 0.00015 | ms/batch 17.98 | loss 0.00008406\n",
      "| Epoch 107 |   250/  422 batches | lr 0.00015 | ms/batch 17.88 | loss 0.00009744\n",
      "| Epoch 107 |   300/  422 batches | lr 0.00015 | ms/batch 21.37 | loss 0.00015250\n",
      "| Epoch 107 |   350/  422 batches | lr 0.00015 | ms/batch 18.17 | loss 0.00013291\n",
      "| Epoch 107 |   400/  422 batches | lr 0.00015 | ms/batch 19.82 | loss 0.00006713\n",
      "\n",
      "Val set: Average loss: 0.00007184\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch 108 |    50/  422 batches | lr 0.00015 | ms/batch 18.68 | loss 0.00008641\n",
      "| Epoch 108 |   100/  422 batches | lr 0.00015 | ms/batch 19.68 | loss 0.00008696\n",
      "| Epoch 108 |   150/  422 batches | lr 0.00015 | ms/batch 18.15 | loss 0.00007092\n",
      "| Epoch 108 |   200/  422 batches | lr 0.00015 | ms/batch 19.78 | loss 0.00009124\n",
      "| Epoch 108 |   250/  422 batches | lr 0.00015 | ms/batch 19.84 | loss 0.00009281\n",
      "| Epoch 108 |   300/  422 batches | lr 0.00015 | ms/batch 21.41 | loss 0.00014463\n",
      "| Epoch 108 |   350/  422 batches | lr 0.00015 | ms/batch 19.71 | loss 0.00012130\n",
      "| Epoch 108 |   400/  422 batches | lr 0.00015 | ms/batch 19.75 | loss 0.00008268\n",
      "\n",
      "Val set: Average loss: 0.00008367\n",
      "\n",
      "EarlyStopping counter: 5 out of 20\n",
      "| Epoch 109 |    50/  422 batches | lr 0.00015 | ms/batch 20.35 | loss 0.00015447\n",
      "| Epoch 109 |   100/  422 batches | lr 0.00015 | ms/batch 19.94 | loss 0.00011965\n",
      "| Epoch 109 |   150/  422 batches | lr 0.00015 | ms/batch 19.85 | loss 0.00009315\n",
      "| Epoch 109 |   200/  422 batches | lr 0.00015 | ms/batch 19.94 | loss 0.00008420\n",
      "| Epoch 109 |   250/  422 batches | lr 0.00015 | ms/batch 19.90 | loss 0.00008808\n",
      "| Epoch 109 |   300/  422 batches | lr 0.00015 | ms/batch 21.43 | loss 0.00008731\n",
      "| Epoch 109 |   350/  422 batches | lr 0.00015 | ms/batch 19.90 | loss 0.00008958\n",
      "| Epoch 109 |   400/  422 batches | lr 0.00015 | ms/batch 19.89 | loss 0.00009949\n",
      "\n",
      "Val set: Average loss: 0.00015305\n",
      "\n",
      "EarlyStopping counter: 6 out of 20\n",
      "| Epoch 110 |    50/  422 batches | lr 0.00015 | ms/batch 20.18 | loss 0.00014944\n",
      "| Epoch 110 |   100/  422 batches | lr 0.00015 | ms/batch 19.97 | loss 0.00010906\n",
      "| Epoch 110 |   150/  422 batches | lr 0.00015 | ms/batch 19.92 | loss 0.00008764\n",
      "| Epoch 110 |   200/  422 batches | lr 0.00015 | ms/batch 19.82 | loss 0.00012459\n",
      "| Epoch 110 |   250/  422 batches | lr 0.00015 | ms/batch 21.32 | loss 0.00012494\n",
      "| Epoch 110 |   300/  422 batches | lr 0.00015 | ms/batch 19.78 | loss 0.00011009\n",
      "| Epoch 110 |   350/  422 batches | lr 0.00015 | ms/batch 19.86 | loss 0.00009586\n",
      "| Epoch 110 |   400/  422 batches | lr 0.00015 | ms/batch 20.34 | loss 0.00008271\n",
      "\n",
      "Val set: Average loss: 0.00015865\n",
      "\n",
      "EarlyStopping counter: 7 out of 20\n",
      "| Epoch 111 |    50/  422 batches | lr 0.00015 | ms/batch 20.56 | loss 0.00013271\n",
      "| Epoch 111 |   100/  422 batches | lr 0.00015 | ms/batch 19.98 | loss 0.00014481\n",
      "| Epoch 111 |   150/  422 batches | lr 0.00015 | ms/batch 19.94 | loss 0.00008778\n",
      "| Epoch 111 |   200/  422 batches | lr 0.00015 | ms/batch 19.87 | loss 0.00023646\n",
      "| Epoch 111 |   250/  422 batches | lr 0.00015 | ms/batch 21.42 | loss 0.00012309\n",
      "| Epoch 111 |   300/  422 batches | lr 0.00015 | ms/batch 19.84 | loss 0.00008706\n",
      "| Epoch 111 |   350/  422 batches | lr 0.00015 | ms/batch 19.79 | loss 0.00008008\n",
      "| Epoch 111 |   400/  422 batches | lr 0.00015 | ms/batch 19.93 | loss 0.00008143\n",
      "\n",
      "Val set: Average loss: 0.00007354\n",
      "\n",
      "EarlyStopping counter: 8 out of 20\n",
      "| Epoch 112 |    50/  422 batches | lr 0.00015 | ms/batch 20.24 | loss 0.00011060\n",
      "| Epoch 112 |   100/  422 batches | lr 0.00015 | ms/batch 19.69 | loss 0.00014846\n",
      "| Epoch 112 |   150/  422 batches | lr 0.00015 | ms/batch 19.86 | loss 0.00009032\n",
      "| Epoch 112 |   200/  422 batches | lr 0.00015 | ms/batch 19.89 | loss 0.00013179\n",
      "| Epoch 112 |   250/  422 batches | lr 0.00015 | ms/batch 22.00 | loss 0.00009266\n",
      "| Epoch 112 |   300/  422 batches | lr 0.00015 | ms/batch 19.78 | loss 0.00006877\n",
      "| Epoch 112 |   350/  422 batches | lr 0.00015 | ms/batch 19.73 | loss 0.00006871\n",
      "| Epoch 112 |   400/  422 batches | lr 0.00015 | ms/batch 19.76 | loss 0.00006740\n",
      "\n",
      "Val set: Average loss: 0.00006449\n",
      "\n",
      "EarlyStopping counter: 9 out of 20\n",
      "| Epoch 113 |    50/  422 batches | lr 0.00015 | ms/batch 20.32 | loss 0.00007375\n",
      "| Epoch 113 |   100/  422 batches | lr 0.00015 | ms/batch 19.67 | loss 0.00007137\n",
      "| Epoch 113 |   150/  422 batches | lr 0.00015 | ms/batch 19.84 | loss 0.00005177\n",
      "| Epoch 113 |   200/  422 batches | lr 0.00015 | ms/batch 19.87 | loss 0.00006476\n",
      "| Epoch 113 |   250/  422 batches | lr 0.00015 | ms/batch 21.24 | loss 0.00004759\n",
      "| Epoch 113 |   300/  422 batches | lr 0.00015 | ms/batch 19.91 | loss 0.00005651\n",
      "| Epoch 113 |   350/  422 batches | lr 0.00015 | ms/batch 20.02 | loss 0.00005352\n",
      "| Epoch 113 |   400/  422 batches | lr 0.00015 | ms/batch 19.83 | loss 0.00007766\n",
      "\n",
      "Val set: Average loss: 0.00006414\n",
      "\n",
      "EarlyStopping counter: 10 out of 20\n",
      "| Epoch 114 |    50/  422 batches | lr 0.00015 | ms/batch 20.32 | loss 0.00008642\n",
      "| Epoch 114 |   100/  422 batches | lr 0.00015 | ms/batch 19.77 | loss 0.00007163\n",
      "| Epoch 114 |   150/  422 batches | lr 0.00015 | ms/batch 19.92 | loss 0.00010846\n",
      "| Epoch 114 |   200/  422 batches | lr 0.00015 | ms/batch 19.79 | loss 0.00007457\n",
      "| Epoch 114 |   250/  422 batches | lr 0.00015 | ms/batch 21.47 | loss 0.00006688\n",
      "| Epoch 114 |   300/  422 batches | lr 0.00015 | ms/batch 19.74 | loss 0.00007979\n",
      "| Epoch 114 |   350/  422 batches | lr 0.00015 | ms/batch 19.86 | loss 0.00012716\n",
      "| Epoch 114 |   400/  422 batches | lr 0.00015 | ms/batch 19.86 | loss 0.00011905\n",
      "\n",
      "Val set: Average loss: 0.00006416\n",
      "\n",
      "EarlyStopping counter: 11 out of 20\n",
      "| Epoch 115 |    50/  422 batches | lr 0.00015 | ms/batch 20.28 | loss 0.00008105\n",
      "| Epoch 115 |   100/  422 batches | lr 0.00015 | ms/batch 19.80 | loss 0.00006093\n",
      "| Epoch 115 |   150/  422 batches | lr 0.00015 | ms/batch 19.82 | loss 0.00013269\n",
      "| Epoch 115 |   200/  422 batches | lr 0.00015 | ms/batch 19.80 | loss 0.00009136\n",
      "| Epoch 115 |   250/  422 batches | lr 0.00015 | ms/batch 21.72 | loss 0.00009544\n",
      "| Epoch 115 |   300/  422 batches | lr 0.00015 | ms/batch 19.88 | loss 0.00009756\n",
      "| Epoch 115 |   350/  422 batches | lr 0.00015 | ms/batch 19.69 | loss 0.00008484\n",
      "| Epoch 115 |   400/  422 batches | lr 0.00015 | ms/batch 19.80 | loss 0.00007893\n",
      "\n",
      "Val set: Average loss: 0.00009914\n",
      "\n",
      "EarlyStopping counter: 12 out of 20\n",
      "| Epoch 116 |    50/  422 batches | lr 0.00015 | ms/batch 20.26 | loss 0.00009837\n",
      "| Epoch 116 |   100/  422 batches | lr 0.00015 | ms/batch 19.70 | loss 0.00006511\n",
      "| Epoch 116 |   150/  422 batches | lr 0.00015 | ms/batch 19.74 | loss 0.00008641\n",
      "| Epoch 116 |   200/  422 batches | lr 0.00015 | ms/batch 19.73 | loss 0.00007108\n",
      "| Epoch 116 |   250/  422 batches | lr 0.00015 | ms/batch 21.49 | loss 0.00006876\n",
      "| Epoch 116 |   300/  422 batches | lr 0.00015 | ms/batch 19.79 | loss 0.00008242\n",
      "| Epoch 116 |   350/  422 batches | lr 0.00015 | ms/batch 19.78 | loss 0.00007544\n",
      "| Epoch 116 |   400/  422 batches | lr 0.00015 | ms/batch 19.71 | loss 0.00007674\n",
      "\n",
      "Val set: Average loss: 0.00011644\n",
      "\n",
      "EarlyStopping counter: 13 out of 20\n",
      "| Epoch 117 |    50/  422 batches | lr 0.00015 | ms/batch 20.18 | loss 0.00018630\n",
      "| Epoch 117 |   100/  422 batches | lr 0.00015 | ms/batch 19.77 | loss 0.00013564\n",
      "| Epoch 117 |   150/  422 batches | lr 0.00015 | ms/batch 20.60 | loss 0.00007017\n",
      "| Epoch 117 |   200/  422 batches | lr 0.00015 | ms/batch 19.73 | loss 0.00008622\n",
      "| Epoch 117 |   250/  422 batches | lr 0.00015 | ms/batch 21.43 | loss 0.00006650\n",
      "| Epoch 117 |   300/  422 batches | lr 0.00015 | ms/batch 19.82 | loss 0.00012888\n",
      "| Epoch 117 |   350/  422 batches | lr 0.00015 | ms/batch 19.90 | loss 0.00008976\n",
      "| Epoch 117 |   400/  422 batches | lr 0.00015 | ms/batch 19.78 | loss 0.00005669\n",
      "\n",
      "Val set: Average loss: 0.00017815\n",
      "\n",
      "EarlyStopping counter: 14 out of 20\n",
      "| Epoch 118 |    50/  422 batches | lr 0.00015 | ms/batch 20.15 | loss 0.00014115\n",
      "| Epoch 118 |   100/  422 batches | lr 0.00015 | ms/batch 19.77 | loss 0.00011993\n",
      "| Epoch 118 |   150/  422 batches | lr 0.00015 | ms/batch 19.80 | loss 0.00007526\n",
      "| Epoch 118 |   200/  422 batches | lr 0.00015 | ms/batch 21.51 | loss 0.00009828\n",
      "| Epoch 118 |   250/  422 batches | lr 0.00015 | ms/batch 19.82 | loss 0.00007905\n",
      "| Epoch 118 |   300/  422 batches | lr 0.00015 | ms/batch 19.77 | loss 0.00008464\n",
      "| Epoch 118 |   350/  422 batches | lr 0.00015 | ms/batch 19.86 | loss 0.00008494\n",
      "| Epoch 118 |   400/  422 batches | lr 0.00015 | ms/batch 19.74 | loss 0.00006137\n",
      "\n",
      "Val set: Average loss: 0.00013044\n",
      "\n",
      "EarlyStopping counter: 15 out of 20\n",
      "| Epoch 119 |    50/  422 batches | lr 0.00015 | ms/batch 20.27 | loss 0.00017505\n",
      "| Epoch 119 |   100/  422 batches | lr 0.00015 | ms/batch 19.77 | loss 0.00009036\n",
      "| Epoch 119 |   150/  422 batches | lr 0.00015 | ms/batch 19.87 | loss 0.00008883\n",
      "| Epoch 119 |   200/  422 batches | lr 0.00015 | ms/batch 21.36 | loss 0.00013677\n",
      "| Epoch 119 |   250/  422 batches | lr 0.00015 | ms/batch 19.79 | loss 0.00011596\n",
      "| Epoch 119 |   300/  422 batches | lr 0.00015 | ms/batch 19.75 | loss 0.00010790\n",
      "| Epoch 119 |   350/  422 batches | lr 0.00015 | ms/batch 19.80 | loss 0.00009686\n",
      "| Epoch 119 |   400/  422 batches | lr 0.00015 | ms/batch 19.77 | loss 0.00007564\n",
      "\n",
      "Val set: Average loss: 0.00011950\n",
      "\n",
      "EarlyStopping counter: 16 out of 20\n",
      "| Epoch 120 |    50/  422 batches | lr 0.00015 | ms/batch 20.33 | loss 0.00011621\n",
      "| Epoch 120 |   100/  422 batches | lr 0.00015 | ms/batch 19.91 | loss 0.00011819\n",
      "| Epoch 120 |   150/  422 batches | lr 0.00015 | ms/batch 19.82 | loss 0.00008929\n",
      "| Epoch 120 |   200/  422 batches | lr 0.00015 | ms/batch 21.53 | loss 0.00019732\n",
      "| Epoch 120 |   250/  422 batches | lr 0.00015 | ms/batch 19.70 | loss 0.00011141\n",
      "| Epoch 120 |   300/  422 batches | lr 0.00015 | ms/batch 19.79 | loss 0.00008054\n",
      "| Epoch 120 |   350/  422 batches | lr 0.00015 | ms/batch 20.37 | loss 0.00008018\n",
      "| Epoch 120 |   400/  422 batches | lr 0.00015 | ms/batch 19.74 | loss 0.00008798\n",
      "\n",
      "Val set: Average loss: 0.00007432\n",
      "\n",
      "EarlyStopping counter: 17 out of 20\n",
      "| Epoch 121 |    50/  422 batches | lr 0.00015 | ms/batch 20.13 | loss 0.00010151\n",
      "| Epoch 121 |   100/  422 batches | lr 0.00015 | ms/batch 19.75 | loss 0.00015299\n",
      "| Epoch 121 |   150/  422 batches | lr 0.00015 | ms/batch 19.68 | loss 0.00009323\n",
      "| Epoch 121 |   200/  422 batches | lr 0.00015 | ms/batch 21.43 | loss 0.00014097\n",
      "| Epoch 121 |   250/  422 batches | lr 0.00015 | ms/batch 19.76 | loss 0.00011350\n",
      "| Epoch 121 |   300/  422 batches | lr 0.00015 | ms/batch 19.80 | loss 0.00008914\n",
      "| Epoch 121 |   350/  422 batches | lr 0.00015 | ms/batch 19.86 | loss 0.00006944\n",
      "| Epoch 121 |   400/  422 batches | lr 0.00015 | ms/batch 20.54 | loss 0.00007508\n",
      "\n",
      "Val set: Average loss: 0.00007458\n",
      "\n",
      "EarlyStopping counter: 18 out of 20\n",
      "| Epoch 122 |    50/  422 batches | lr 0.00015 | ms/batch 20.35 | loss 0.00012710\n",
      "| Epoch 122 |   100/  422 batches | lr 0.00015 | ms/batch 19.87 | loss 0.00013641\n",
      "| Epoch 122 |   150/  422 batches | lr 0.00015 | ms/batch 19.87 | loss 0.00008843\n",
      "| Epoch 122 |   200/  422 batches | lr 0.00015 | ms/batch 21.56 | loss 0.00014183\n",
      "| Epoch 122 |   250/  422 batches | lr 0.00015 | ms/batch 19.94 | loss 0.00011329\n",
      "| Epoch 122 |   300/  422 batches | lr 0.00015 | ms/batch 19.91 | loss 0.00009816\n",
      "| Epoch 122 |   350/  422 batches | lr 0.00015 | ms/batch 19.93 | loss 0.00006759\n",
      "| Epoch 122 |   400/  422 batches | lr 0.00015 | ms/batch 20.01 | loss 0.00008338\n",
      "\n",
      "Val set: Average loss: 0.00010190\n",
      "\n",
      "EarlyStopping counter: 19 out of 20\n",
      "| Epoch 123 |    50/  422 batches | lr 0.00015 | ms/batch 20.23 | loss 0.00018491\n",
      "| Epoch 123 |   100/  422 batches | lr 0.00015 | ms/batch 19.91 | loss 0.00011699\n",
      "| Epoch 123 |   150/  422 batches | lr 0.00015 | ms/batch 19.86 | loss 0.00009137\n",
      "| Epoch 123 |   200/  422 batches | lr 0.00015 | ms/batch 21.40 | loss 0.00017616\n",
      "| Epoch 123 |   250/  422 batches | lr 0.00015 | ms/batch 19.77 | loss 0.00012666\n",
      "| Epoch 123 |   300/  422 batches | lr 0.00015 | ms/batch 19.89 | loss 0.00011617\n",
      "| Epoch 123 |   350/  422 batches | lr 0.00015 | ms/batch 19.96 | loss 0.00010523\n",
      "| Epoch 123 |   400/  422 batches | lr 0.00015 | ms/batch 19.74 | loss 0.00008489\n",
      "\n",
      "Val set: Average loss: 0.00020318\n",
      "\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Stopping at Epoch: 123\n"
     ]
    }
   ],
   "source": [
    "load = False\n",
    "save_model_path = '../models/final_heston_model.chkpt'\n",
    "val_err_df_path = '../results/val_final_heston_model.csv'\n",
    "\n",
    "if not load:\n",
    "  train_losses, val_losses = train(\n",
    "      epochs,\n",
    "      batch_size,\n",
    "      model,\n",
    "      optimizer,\n",
    "      loss_fn,\n",
    "      X_train,\n",
    "      y_train,\n",
    "      X_val,\n",
    "      y_val)\n",
    "  val_err_df = pd.DataFrame({\n",
    "      'Training': train_losses,\n",
    "      'Validation': val_losses})\n",
    "  val_err_df.to_csv(val_err_df_path)\n",
    "  torch.save(model.state_dict(), save_model_path)\n",
    "else:\n",
    "  model = Net(input_size, output_size, hidden_size, num_layers, act_fn)\n",
    "  model.load_state_dict(torch.load(save_model_path, map_location=device))\n",
    "  model = model.to(device)\n",
    "  val_err_df = pd.read_csv(val_err_df_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1650894219921,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "KkenWSRYvDpl",
    "outputId": "37746aa5-0b46-4a80-d14d-397868e89361",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_err_df[1:].plot(xlabel='epoch', ylabel='MSE')\n",
    "plt.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FlG5Ky25vDpm",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1650894219922,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "TBZ4eHAdvDpn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_size = 30\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_out = model(X_test[0:test_size])\n",
    "\n",
    "test_out = output_sc.inverse_transform(test_out.cpu().detach().numpy())\n",
    "real_out = output_sc.inverse_transform(y_test[0:test_size].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1650894219926,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "wK1WeGIZvDpo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['Price', 'Strike', 'Kappa', 'Rho', 'Theta', 'Xi', 'V_0',\n",
    "       'Interest Rate', 'Time to Expiration', 'C', 'P', 'Prediction', 'Real']\n",
    "test_options = pd.DataFrame(columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 68,
     "status": "ok",
     "timestamp": 1650894220542,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "_dvE5LGXvDpq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i, item in enumerate(input_sc.inverse_transform(X_test[0:test_size].cpu().detach().numpy())):\n",
    "  opt = {\n",
    "      'Price': item[0],\n",
    "      'Strike': item[1],\n",
    "      'Kappa': item[2],\n",
    "      'Rho': item[3],\n",
    "      'Theta': item[4],\n",
    "      'Xi': item[5],\n",
    "      'V_0': item[6],\n",
    "      'Interest Rate': item[7],\n",
    "      'Time to Expiration': item[8],\n",
    "      'C': item[9],\n",
    "      'P': item[10],\n",
    "      'Prediction': test_out[i][0],\n",
    "      'Real': real_out[i][0]\n",
    "  }\n",
    "  test_options = test_options.append(opt, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 67,
     "status": "ok",
     "timestamp": 1650894220545,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "TNw5-1jgvDpr",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_options['Moneyness'] = test_options.Price / test_options.Strike\n",
    "test_options['Abs Error'] = np.abs(test_options.Prediction - test_options.Real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 990
    },
    "executionInfo": {
     "elapsed": 65,
     "status": "ok",
     "timestamp": 1650894220546,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "lAC6AdeVvDpr",
    "outputId": "78bd13cc-c5a0-4746-f402-9e84d8b78696",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    Price      Strike     Kappa       Rho     Theta        Xi       V_0  \\\n29  100.0   75.998573  0.371918 -0.520473  0.366922  0.006149  0.382573   \n12  100.0  101.000061  1.015630 -0.353271  0.302717  0.203626  0.473911   \n21  100.0  130.008911  1.031258 -0.283688  0.103124  0.075076  0.127843   \n2   100.0  119.004692  0.459027 -0.607435  0.077329  0.265382  0.277832   \n19  100.0   64.012093  0.910638 -0.466795  0.011080  0.016862  0.121881   \n8   100.0   79.002312  1.801739 -0.378897  0.410829  0.456357  0.480254   \n3   100.0   79.998810  0.503286 -0.404776  0.419709  0.261232  0.160762   \n9   100.0   69.991096  0.683705 -0.383527  0.421824  0.168669  0.347116   \n28  100.0  127.005165  1.735210 -0.227743  0.030814  0.399412  0.451203   \n6   100.0   59.997620  1.071289 -0.051914  0.226319  0.450437  0.493193   \n18  100.0   78.005814  1.897587 -0.499509  0.404486  0.260008  0.170277   \n27  100.0  139.005875  0.122714 -0.755481  0.344510  0.490186  0.120866   \n10  100.0  135.987915  1.279229 -0.703722  0.254393  0.129273  0.361071   \n22  100.0  131.005402  0.392779 -0.482414  0.237058  0.081983  0.393039   \n24  100.0  139.005875  0.798299 -0.315530  0.376436  0.194464  0.166344   \n0   100.0   87.002785  0.549236 -0.723259  0.234988  0.453115  0.458942   \n23  100.0   93.999641  1.946074 -0.552251  0.120391  0.499207  0.088136   \n4   100.0  141.995377  1.385648 -0.217086  0.353742  0.094105  0.426973   \n15  100.0   65.008591  0.097906 -0.385240  0.157603  0.163102  0.308108   \n16  100.0   50.004143  0.162745 -0.759794  0.204118  0.282966  0.213250   \n11  100.0   69.991096  0.894499 -0.839463  0.263179  0.219730  0.277832   \n17  100.0   82.006042  1.389594 -0.474121  0.182376  0.283441  0.188100   \n1   100.0   71.998337  0.652695 -0.054705  0.007979  0.175506  0.292235   \n14  100.0   69.991096  0.798299 -0.764108  0.466366  0.192138  0.268556   \n13  100.0   79.002312  0.856442 -0.619741  0.093257  0.112922  0.475814   \n25  100.0  114.000832  1.831057 -0.492436  0.039130  0.267822  0.428496   \n7   100.0   64.012093  1.026378 -0.784659  0.051253  0.303457  0.401856   \n20  100.0   71.001831  0.709358 -0.811553  0.423092  0.093400  0.460971   \n5   100.0   57.008118  1.241171 -0.819926  0.266843  0.491455  0.424309   \n26  100.0   59.001118  0.579118 -0.159492  0.101855  0.353742  0.424309   \n\n    Interest Rate  Time to Expiration    C    P  Prediction       Real  \\\n29       0.026228            0.335287  0.0  1.0    0.751178   0.753466   \n12       0.037455            0.101866  1.0  0.0    6.258802   6.273540   \n21       0.071111            1.025401  0.0  1.0   27.749123  27.765026   \n2        0.073559            0.116525  1.0  0.0    0.350073   0.333941   \n19       0.011792            0.147253  0.0  1.0    0.029129   0.002737   \n8        0.055267            0.558594  0.0  1.0    0.543351   0.503223   \n3        0.028943            0.409147  0.0  1.0    0.410123   0.363381   \n9        0.086563            0.258607  0.0  1.0    0.086408   0.032177   \n28       0.039827            1.084884  0.0  1.0   26.106236  26.050123   \n6        0.058075            0.652823  0.0  1.0    0.121320   0.061618   \n18       0.072278            1.038087  0.0  1.0    0.097331   0.024817   \n27       0.081615            0.357980  1.0  0.0    0.102271   0.002737   \n10       0.040284            1.020327  0.0  1.0   34.444916  34.551037   \n22       0.079725            0.719248  0.0  1.0   29.849550  29.737534   \n24       0.039485            0.687039  1.0  0.0    0.154334   0.039537   \n0        0.068231            1.049646  0.0  1.0    1.175421   1.047870   \n23       0.099731            0.385044  1.0  0.0    5.815021   5.673692   \n4        0.037874            0.866122  1.0  0.0    0.586533   0.436983   \n15       0.084609            0.263682  1.0  0.0   32.298092  32.122204   \n16       0.037848            0.950695  0.0  1.0    0.185786   0.002737   \n11       0.033243            1.093623  0.0  1.0    0.301187   0.113138   \n17       0.092956            0.947030  1.0  0.0   16.560759  16.360556   \n1        0.089658            0.860202  1.0  0.0   25.095205  24.865149   \n14       0.030681            0.763225  0.0  1.0    0.512459   0.267700   \n13       0.093692            0.248459  1.0  0.0   19.520380  19.264114   \n25       0.044737            0.360095  1.0  0.0    2.304931   2.012044   \n7        0.081057            0.972120  1.0  0.0   33.167175  32.843494   \n20       0.028334            0.205890  1.0  0.0   29.462591  28.972084   \n5        0.048768            0.333595  1.0  0.0   41.110165  40.615757   \n26       0.024097            0.446077  1.0  0.0   40.775509  40.115273   \n\n    Moneyness  Abs Error  \n29   1.315814   0.002289  \n12   0.990098   0.014738  \n21   0.769178   0.015903  \n2    0.840303   0.016131  \n19   1.562205   0.026392  \n8    1.265786   0.040128  \n3    1.250019   0.046741  \n9    1.428753   0.054232  \n28   0.787370   0.056112  \n6    1.666733   0.059703  \n18   1.281956   0.072514  \n27   0.719394   0.099534  \n10   0.735359   0.106121  \n22   0.763327   0.112017  \n24   0.719394   0.114797  \n0    1.149388   0.127550  \n23   1.063834   0.141329  \n4    0.704248   0.149550  \n15   1.538258   0.175888  \n16   1.999834   0.183049  \n11   1.428753   0.188049  \n17   1.219422   0.200203  \n1    1.388921   0.230057  \n14   1.428753   0.244759  \n13   1.265786   0.256266  \n25   0.877187   0.292888  \n7    1.562205   0.323681  \n20   1.408414   0.490507  \n5    1.754136   0.494408  \n26   1.694883   0.660236  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Price</th>\n      <th>Strike</th>\n      <th>Kappa</th>\n      <th>Rho</th>\n      <th>Theta</th>\n      <th>Xi</th>\n      <th>V_0</th>\n      <th>Interest Rate</th>\n      <th>Time to Expiration</th>\n      <th>C</th>\n      <th>P</th>\n      <th>Prediction</th>\n      <th>Real</th>\n      <th>Moneyness</th>\n      <th>Abs Error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>29</th>\n      <td>100.0</td>\n      <td>75.998573</td>\n      <td>0.371918</td>\n      <td>-0.520473</td>\n      <td>0.366922</td>\n      <td>0.006149</td>\n      <td>0.382573</td>\n      <td>0.026228</td>\n      <td>0.335287</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.751178</td>\n      <td>0.753466</td>\n      <td>1.315814</td>\n      <td>0.002289</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>100.0</td>\n      <td>101.000061</td>\n      <td>1.015630</td>\n      <td>-0.353271</td>\n      <td>0.302717</td>\n      <td>0.203626</td>\n      <td>0.473911</td>\n      <td>0.037455</td>\n      <td>0.101866</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>6.258802</td>\n      <td>6.273540</td>\n      <td>0.990098</td>\n      <td>0.014738</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>100.0</td>\n      <td>130.008911</td>\n      <td>1.031258</td>\n      <td>-0.283688</td>\n      <td>0.103124</td>\n      <td>0.075076</td>\n      <td>0.127843</td>\n      <td>0.071111</td>\n      <td>1.025401</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>27.749123</td>\n      <td>27.765026</td>\n      <td>0.769178</td>\n      <td>0.015903</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100.0</td>\n      <td>119.004692</td>\n      <td>0.459027</td>\n      <td>-0.607435</td>\n      <td>0.077329</td>\n      <td>0.265382</td>\n      <td>0.277832</td>\n      <td>0.073559</td>\n      <td>0.116525</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.350073</td>\n      <td>0.333941</td>\n      <td>0.840303</td>\n      <td>0.016131</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>100.0</td>\n      <td>64.012093</td>\n      <td>0.910638</td>\n      <td>-0.466795</td>\n      <td>0.011080</td>\n      <td>0.016862</td>\n      <td>0.121881</td>\n      <td>0.011792</td>\n      <td>0.147253</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.029129</td>\n      <td>0.002737</td>\n      <td>1.562205</td>\n      <td>0.026392</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>100.0</td>\n      <td>79.002312</td>\n      <td>1.801739</td>\n      <td>-0.378897</td>\n      <td>0.410829</td>\n      <td>0.456357</td>\n      <td>0.480254</td>\n      <td>0.055267</td>\n      <td>0.558594</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.543351</td>\n      <td>0.503223</td>\n      <td>1.265786</td>\n      <td>0.040128</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100.0</td>\n      <td>79.998810</td>\n      <td>0.503286</td>\n      <td>-0.404776</td>\n      <td>0.419709</td>\n      <td>0.261232</td>\n      <td>0.160762</td>\n      <td>0.028943</td>\n      <td>0.409147</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.410123</td>\n      <td>0.363381</td>\n      <td>1.250019</td>\n      <td>0.046741</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>100.0</td>\n      <td>69.991096</td>\n      <td>0.683705</td>\n      <td>-0.383527</td>\n      <td>0.421824</td>\n      <td>0.168669</td>\n      <td>0.347116</td>\n      <td>0.086563</td>\n      <td>0.258607</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.086408</td>\n      <td>0.032177</td>\n      <td>1.428753</td>\n      <td>0.054232</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>100.0</td>\n      <td>127.005165</td>\n      <td>1.735210</td>\n      <td>-0.227743</td>\n      <td>0.030814</td>\n      <td>0.399412</td>\n      <td>0.451203</td>\n      <td>0.039827</td>\n      <td>1.084884</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>26.106236</td>\n      <td>26.050123</td>\n      <td>0.787370</td>\n      <td>0.056112</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>100.0</td>\n      <td>59.997620</td>\n      <td>1.071289</td>\n      <td>-0.051914</td>\n      <td>0.226319</td>\n      <td>0.450437</td>\n      <td>0.493193</td>\n      <td>0.058075</td>\n      <td>0.652823</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.121320</td>\n      <td>0.061618</td>\n      <td>1.666733</td>\n      <td>0.059703</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>100.0</td>\n      <td>78.005814</td>\n      <td>1.897587</td>\n      <td>-0.499509</td>\n      <td>0.404486</td>\n      <td>0.260008</td>\n      <td>0.170277</td>\n      <td>0.072278</td>\n      <td>1.038087</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.097331</td>\n      <td>0.024817</td>\n      <td>1.281956</td>\n      <td>0.072514</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>100.0</td>\n      <td>139.005875</td>\n      <td>0.122714</td>\n      <td>-0.755481</td>\n      <td>0.344510</td>\n      <td>0.490186</td>\n      <td>0.120866</td>\n      <td>0.081615</td>\n      <td>0.357980</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.102271</td>\n      <td>0.002737</td>\n      <td>0.719394</td>\n      <td>0.099534</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>100.0</td>\n      <td>135.987915</td>\n      <td>1.279229</td>\n      <td>-0.703722</td>\n      <td>0.254393</td>\n      <td>0.129273</td>\n      <td>0.361071</td>\n      <td>0.040284</td>\n      <td>1.020327</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>34.444916</td>\n      <td>34.551037</td>\n      <td>0.735359</td>\n      <td>0.106121</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>100.0</td>\n      <td>131.005402</td>\n      <td>0.392779</td>\n      <td>-0.482414</td>\n      <td>0.237058</td>\n      <td>0.081983</td>\n      <td>0.393039</td>\n      <td>0.079725</td>\n      <td>0.719248</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>29.849550</td>\n      <td>29.737534</td>\n      <td>0.763327</td>\n      <td>0.112017</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>100.0</td>\n      <td>139.005875</td>\n      <td>0.798299</td>\n      <td>-0.315530</td>\n      <td>0.376436</td>\n      <td>0.194464</td>\n      <td>0.166344</td>\n      <td>0.039485</td>\n      <td>0.687039</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.154334</td>\n      <td>0.039537</td>\n      <td>0.719394</td>\n      <td>0.114797</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>100.0</td>\n      <td>87.002785</td>\n      <td>0.549236</td>\n      <td>-0.723259</td>\n      <td>0.234988</td>\n      <td>0.453115</td>\n      <td>0.458942</td>\n      <td>0.068231</td>\n      <td>1.049646</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.175421</td>\n      <td>1.047870</td>\n      <td>1.149388</td>\n      <td>0.127550</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>100.0</td>\n      <td>93.999641</td>\n      <td>1.946074</td>\n      <td>-0.552251</td>\n      <td>0.120391</td>\n      <td>0.499207</td>\n      <td>0.088136</td>\n      <td>0.099731</td>\n      <td>0.385044</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>5.815021</td>\n      <td>5.673692</td>\n      <td>1.063834</td>\n      <td>0.141329</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100.0</td>\n      <td>141.995377</td>\n      <td>1.385648</td>\n      <td>-0.217086</td>\n      <td>0.353742</td>\n      <td>0.094105</td>\n      <td>0.426973</td>\n      <td>0.037874</td>\n      <td>0.866122</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.586533</td>\n      <td>0.436983</td>\n      <td>0.704248</td>\n      <td>0.149550</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>100.0</td>\n      <td>65.008591</td>\n      <td>0.097906</td>\n      <td>-0.385240</td>\n      <td>0.157603</td>\n      <td>0.163102</td>\n      <td>0.308108</td>\n      <td>0.084609</td>\n      <td>0.263682</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>32.298092</td>\n      <td>32.122204</td>\n      <td>1.538258</td>\n      <td>0.175888</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>100.0</td>\n      <td>50.004143</td>\n      <td>0.162745</td>\n      <td>-0.759794</td>\n      <td>0.204118</td>\n      <td>0.282966</td>\n      <td>0.213250</td>\n      <td>0.037848</td>\n      <td>0.950695</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.185786</td>\n      <td>0.002737</td>\n      <td>1.999834</td>\n      <td>0.183049</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>100.0</td>\n      <td>69.991096</td>\n      <td>0.894499</td>\n      <td>-0.839463</td>\n      <td>0.263179</td>\n      <td>0.219730</td>\n      <td>0.277832</td>\n      <td>0.033243</td>\n      <td>1.093623</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.301187</td>\n      <td>0.113138</td>\n      <td>1.428753</td>\n      <td>0.188049</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>100.0</td>\n      <td>82.006042</td>\n      <td>1.389594</td>\n      <td>-0.474121</td>\n      <td>0.182376</td>\n      <td>0.283441</td>\n      <td>0.188100</td>\n      <td>0.092956</td>\n      <td>0.947030</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>16.560759</td>\n      <td>16.360556</td>\n      <td>1.219422</td>\n      <td>0.200203</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100.0</td>\n      <td>71.998337</td>\n      <td>0.652695</td>\n      <td>-0.054705</td>\n      <td>0.007979</td>\n      <td>0.175506</td>\n      <td>0.292235</td>\n      <td>0.089658</td>\n      <td>0.860202</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>25.095205</td>\n      <td>24.865149</td>\n      <td>1.388921</td>\n      <td>0.230057</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>100.0</td>\n      <td>69.991096</td>\n      <td>0.798299</td>\n      <td>-0.764108</td>\n      <td>0.466366</td>\n      <td>0.192138</td>\n      <td>0.268556</td>\n      <td>0.030681</td>\n      <td>0.763225</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.512459</td>\n      <td>0.267700</td>\n      <td>1.428753</td>\n      <td>0.244759</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>100.0</td>\n      <td>79.002312</td>\n      <td>0.856442</td>\n      <td>-0.619741</td>\n      <td>0.093257</td>\n      <td>0.112922</td>\n      <td>0.475814</td>\n      <td>0.093692</td>\n      <td>0.248459</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>19.520380</td>\n      <td>19.264114</td>\n      <td>1.265786</td>\n      <td>0.256266</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>100.0</td>\n      <td>114.000832</td>\n      <td>1.831057</td>\n      <td>-0.492436</td>\n      <td>0.039130</td>\n      <td>0.267822</td>\n      <td>0.428496</td>\n      <td>0.044737</td>\n      <td>0.360095</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>2.304931</td>\n      <td>2.012044</td>\n      <td>0.877187</td>\n      <td>0.292888</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>100.0</td>\n      <td>64.012093</td>\n      <td>1.026378</td>\n      <td>-0.784659</td>\n      <td>0.051253</td>\n      <td>0.303457</td>\n      <td>0.401856</td>\n      <td>0.081057</td>\n      <td>0.972120</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>33.167175</td>\n      <td>32.843494</td>\n      <td>1.562205</td>\n      <td>0.323681</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>100.0</td>\n      <td>71.001831</td>\n      <td>0.709358</td>\n      <td>-0.811553</td>\n      <td>0.423092</td>\n      <td>0.093400</td>\n      <td>0.460971</td>\n      <td>0.028334</td>\n      <td>0.205890</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>29.462591</td>\n      <td>28.972084</td>\n      <td>1.408414</td>\n      <td>0.490507</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>100.0</td>\n      <td>57.008118</td>\n      <td>1.241171</td>\n      <td>-0.819926</td>\n      <td>0.266843</td>\n      <td>0.491455</td>\n      <td>0.424309</td>\n      <td>0.048768</td>\n      <td>0.333595</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>41.110165</td>\n      <td>40.615757</td>\n      <td>1.754136</td>\n      <td>0.494408</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>100.0</td>\n      <td>59.001118</td>\n      <td>0.579118</td>\n      <td>-0.159492</td>\n      <td>0.101855</td>\n      <td>0.353742</td>\n      <td>0.424309</td>\n      <td>0.024097</td>\n      <td>0.446077</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>40.775509</td>\n      <td>40.115273</td>\n      <td>1.694883</td>\n      <td>0.660236</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_options.sort_values('Abs Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fDJ-hkrSAqVh",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### MSE on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 276,
     "status": "ok",
     "timestamp": 1650895213041,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "GG64Xp3vAib-",
    "outputId": "f846ee65-029d-4a76-b006-d65e4ac07a48",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE on the test set is:  0.00020312648848630488\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(X_test)\n",
    "    loss = loss_fn(out, y_test)\n",
    "    print('The MSE on the test set is: ', loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCLf2KQJAvoE",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### MAE on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1650895213494,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "mZohsEyLAu7S",
    "outputId": "4d6bfba3-5751-478d-d53e-73751702414e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAE on the test set is:  0.010841299779713154\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "mae_loss = nn.L1Loss()\n",
    "with torch.no_grad():\n",
    "    out = model(X_test)\n",
    "    loss = mae_loss(out, y_test)\n",
    "    print('The MAE on the test set is: ', loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmsZ4aPaA1SJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### RSME on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1650895213496,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "f01KkBxRA0t7",
    "outputId": "6492967a-db0c-49f4-fee1-8eb52ef33119",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE on the test set is:  0.014252245033197573\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(X_test)\n",
    "    loss = loss_fn(out, y_test)\n",
    "    print('The RMSE on the test set is: ', np.sqrt(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8Jxp0L4A5zb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### MAPE on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 335,
     "status": "ok",
     "timestamp": 1650895213818,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "fHghkyflA79o",
    "outputId": "37838323-11f0-4eb9-d7d7-50303bf4e9ce",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAPE on the test set is:  0.05316658318042755\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(X_test)\n",
    "    loss = MAPELoss(out, y_test).item()\n",
    "    print('The MAPE on the test set is: ', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLLLqkX6BEle",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1650895213820,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "sf8FmLxxBGcu",
    "outputId": "764313a9-78fc-46ca-dd08-9fb8834e4374",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the R^2 score is:  0.9997967934315485\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(X_test).squeeze().cpu().detach().numpy()\n",
    "\n",
    "y_true = y_test.cpu().squeeze().detach().numpy()\n",
    "\n",
    "r2 = r2_score(y_pred=out, y_true=y_true)\n",
    "\n",
    "print('the R^2 score is: ', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "executionInfo": {
     "elapsed": 744,
     "status": "ok",
     "timestamp": 1650895214553,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "awvWu7WxBIHB",
    "outputId": "1b3dccd3-90ef-47d5-9895-267fdf93020c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 648x432 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(9, 6))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "ax.scatter(\n",
    "    y=output_sc.inverse_transform(out.reshape(-1, 1)),\n",
    "    x=output_sc.inverse_transform(y_true.squeeze().reshape(-1, 1))\n",
    ")\n",
    "ax.set_xlabel('Actual Value')\n",
    "ax.set_ylabel('Predicted Value')\n",
    "\n",
    "ax.text(20, 80, f'$R^2$ = {np.round(r2, 6)}', fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Model-Testing-Heston.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}