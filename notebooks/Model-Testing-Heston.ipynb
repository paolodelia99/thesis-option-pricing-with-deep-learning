{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ju-WUaXnY5cr",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Models Testing on Heston data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 824,
     "status": "ok",
     "timestamp": 1650891681415,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "hH3-v8y-AuXg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1650891681417,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "QXEzFQ3iAyj_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set seeds\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1650891681418,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "gsH02HCWA0gC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "synthetic_calls_path = '../data/heston_mc_synthetic_calls.csv'\n",
    "synthetic_puts_path = '../data/heston_mc_synthetic_puts.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1650891681421,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "jT4n95T6A4S6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 3413,
     "status": "ok",
     "timestamp": 1650891684820,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "7H8lEQPCA5IS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "synthetic_calls = pd.read_csv(synthetic_calls_path, index_col=0)\n",
    "synthetic_puts = pd.read_csv(synthetic_puts_path, index_col=0)\n",
    "\n",
    "synthetic_calls = reduce_mem_usage(synthetic_calls)\n",
    "synthetic_puts = reduce_mem_usage(synthetic_puts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1650891684821,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "9TKRgvuOA8pC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "synthetic_options = pd.concat([synthetic_calls, synthetic_puts], axis=0)\n",
    "synthetic_options = shuffle(synthetic_options, random_state=0)\n",
    "synthetic_options = synthetic_options.reset_index()\n",
    "synthetic_options = synthetic_options.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1650891684822,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "3HXliAsq132p",
    "outputId": "09bc2eb1-d20d-4471-ed50-5fa0eba727fb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Strike</th>\n",
       "      <th>Type</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>Rho</th>\n",
       "      <th>Theta</th>\n",
       "      <th>Xi</th>\n",
       "      <th>V_0</th>\n",
       "      <th>Interest Rate</th>\n",
       "      <th>Time to Expiration</th>\n",
       "      <th>Option Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>63.0</td>\n",
       "      <td>P</td>\n",
       "      <td>1.877930</td>\n",
       "      <td>-0.603516</td>\n",
       "      <td>0.252441</td>\n",
       "      <td>0.050323</td>\n",
       "      <td>0.364258</td>\n",
       "      <td>0.065308</td>\n",
       "      <td>1.000977</td>\n",
       "      <td>0.002708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>131.0</td>\n",
       "      <td>P</td>\n",
       "      <td>1.459961</td>\n",
       "      <td>-0.262451</td>\n",
       "      <td>0.310059</td>\n",
       "      <td>0.153198</td>\n",
       "      <td>0.338867</td>\n",
       "      <td>0.069153</td>\n",
       "      <td>0.363525</td>\n",
       "      <td>28.703125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>105.0</td>\n",
       "      <td>C</td>\n",
       "      <td>0.247192</td>\n",
       "      <td>-0.742676</td>\n",
       "      <td>0.471924</td>\n",
       "      <td>0.463135</td>\n",
       "      <td>0.268311</td>\n",
       "      <td>0.040802</td>\n",
       "      <td>1.099609</td>\n",
       "      <td>2.324219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>68.0</td>\n",
       "      <td>P</td>\n",
       "      <td>1.594727</td>\n",
       "      <td>-0.576172</td>\n",
       "      <td>0.099670</td>\n",
       "      <td>0.465088</td>\n",
       "      <td>0.366455</td>\n",
       "      <td>0.062683</td>\n",
       "      <td>1.072266</td>\n",
       "      <td>0.060577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>77.0</td>\n",
       "      <td>C</td>\n",
       "      <td>1.563477</td>\n",
       "      <td>-0.328125</td>\n",
       "      <td>0.308838</td>\n",
       "      <td>0.409912</td>\n",
       "      <td>0.241455</td>\n",
       "      <td>0.011162</td>\n",
       "      <td>0.940430</td>\n",
       "      <td>24.359375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605995</th>\n",
       "      <td>100</td>\n",
       "      <td>71.0</td>\n",
       "      <td>P</td>\n",
       "      <td>1.039062</td>\n",
       "      <td>-0.757324</td>\n",
       "      <td>0.227661</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.445068</td>\n",
       "      <td>0.016006</td>\n",
       "      <td>0.487061</td>\n",
       "      <td>1.505859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605996</th>\n",
       "      <td>100</td>\n",
       "      <td>57.0</td>\n",
       "      <td>C</td>\n",
       "      <td>1.905273</td>\n",
       "      <td>-0.276855</td>\n",
       "      <td>0.322266</td>\n",
       "      <td>0.061432</td>\n",
       "      <td>0.120117</td>\n",
       "      <td>0.025070</td>\n",
       "      <td>0.947754</td>\n",
       "      <td>41.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605997</th>\n",
       "      <td>100</td>\n",
       "      <td>135.0</td>\n",
       "      <td>C</td>\n",
       "      <td>0.971680</td>\n",
       "      <td>-0.711426</td>\n",
       "      <td>0.270508</td>\n",
       "      <td>0.438477</td>\n",
       "      <td>0.483887</td>\n",
       "      <td>0.097107</td>\n",
       "      <td>0.289307</td>\n",
       "      <td>0.180542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605998</th>\n",
       "      <td>100</td>\n",
       "      <td>64.0</td>\n",
       "      <td>P</td>\n",
       "      <td>1.767578</td>\n",
       "      <td>-0.417480</td>\n",
       "      <td>0.054260</td>\n",
       "      <td>0.137573</td>\n",
       "      <td>0.226440</td>\n",
       "      <td>0.070374</td>\n",
       "      <td>0.365479</td>\n",
       "      <td>0.001135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605999</th>\n",
       "      <td>100</td>\n",
       "      <td>135.0</td>\n",
       "      <td>P</td>\n",
       "      <td>1.183594</td>\n",
       "      <td>-0.541504</td>\n",
       "      <td>0.479980</td>\n",
       "      <td>0.091614</td>\n",
       "      <td>0.104736</td>\n",
       "      <td>0.095215</td>\n",
       "      <td>0.864746</td>\n",
       "      <td>32.093750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>606000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Price  Strike Type     Kappa       Rho     Theta        Xi       V_0  \\\n",
       "0         100    63.0    P  1.877930 -0.603516  0.252441  0.050323  0.364258   \n",
       "1         100   131.0    P  1.459961 -0.262451  0.310059  0.153198  0.338867   \n",
       "2         100   105.0    C  0.247192 -0.742676  0.471924  0.463135  0.268311   \n",
       "3         100    68.0    P  1.594727 -0.576172  0.099670  0.465088  0.366455   \n",
       "4         100    77.0    C  1.563477 -0.328125  0.308838  0.409912  0.241455   \n",
       "...       ...     ...  ...       ...       ...       ...       ...       ...   \n",
       "605995    100    71.0    P  1.039062 -0.757324  0.227661  0.312500  0.445068   \n",
       "605996    100    57.0    C  1.905273 -0.276855  0.322266  0.061432  0.120117   \n",
       "605997    100   135.0    C  0.971680 -0.711426  0.270508  0.438477  0.483887   \n",
       "605998    100    64.0    P  1.767578 -0.417480  0.054260  0.137573  0.226440   \n",
       "605999    100   135.0    P  1.183594 -0.541504  0.479980  0.091614  0.104736   \n",
       "\n",
       "        Interest Rate  Time to Expiration  Option Price  \n",
       "0            0.065308            1.000977      0.002708  \n",
       "1            0.069153            0.363525     28.703125  \n",
       "2            0.040802            1.099609      2.324219  \n",
       "3            0.062683            1.072266      0.060577  \n",
       "4            0.011162            0.940430     24.359375  \n",
       "...               ...                 ...           ...  \n",
       "605995       0.016006            0.487061      1.505859  \n",
       "605996       0.025070            0.947754     41.687500  \n",
       "605997       0.097107            0.289307      0.180542  \n",
       "605998       0.070374            0.365479      0.001135  \n",
       "605999       0.095215            0.864746     32.093750  \n",
       "\n",
       "[606000 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pn28_RUMBAFH",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 515,
     "status": "ok",
     "timestamp": 1650891685322,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "32oPe6XUBCTF",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "synthetic_options = pd.get_dummies(synthetic_options, prefix='', prefix_sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 1032,
     "status": "ok",
     "timestamp": 1650891686346,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "_Tlc7k7xBDPV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_sc = StandardScaler()\n",
    "output_sc = StandardScaler()\n",
    "input_data = input_sc.fit_transform(synthetic_options.drop('Option Price', axis=1))\n",
    "output_data = output_sc.fit_transform(synthetic_options['Option Price'].values.reshape(-1, 1))\n",
    "\n",
    "train_size = 0.8\n",
    "val_size = 0.1\n",
    "\n",
    "last_train_idx = int(np.round(len(input_data) * train_size))\n",
    "last_val_idx = last_train_idx + int(np.round(len(input_data) * val_size))\n",
    "\n",
    "X_train = input_data[0:last_train_idx]\n",
    "X_val = input_data[last_train_idx:last_val_idx]\n",
    "X_test = input_data[last_val_idx:]\n",
    "\n",
    "y_train = output_data[0:last_train_idx]\n",
    "y_val = output_data[last_train_idx:last_val_idx]\n",
    "y_test = output_data[last_val_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1650891686347,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "7nEEoQGvvDpL",
    "outputId": "88b4d863-d037-439b-e625-5ebb52ad41ef",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Price', 'Strike', 'Kappa', 'Rho', 'Theta', 'Xi', 'V_0',\n",
       "       'Interest Rate', 'Time to Expiration', 'C', 'P'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_options.drop('Option Price', axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1650891686349,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "IwMVtvfABIhR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train = Variable(torch.Tensor(X_train))\n",
    "X_val = Variable(torch.Tensor(X_val))\n",
    "X_test = Variable(torch.Tensor(X_test))\n",
    "\n",
    "y_train = Variable(torch.Tensor(y_train))\n",
    "y_val = Variable(torch.Tensor(y_val))\n",
    "y_test = Variable(torch.Tensor(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ra2l5P1nBVCz",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1650891686350,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "xTLMLFoSBWDy",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "CUDA = torch.cuda.is_available()\n",
    "device = 'cuda:0' if CUDA else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1650891686352,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "CQ9Gl3bUBWsj",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "\n",
    "  def __init__(self, module):\n",
    "    super(ResBlock, self).__init__()\n",
    "    self.module = module\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.module(x) + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1650891686353,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "YL3SicQPBYq0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class HiddenLayer(nn.Module):\n",
    "\n",
    "  def __init__(self, layer_size, act_fn):\n",
    "      super(HiddenLayer, self).__init__()\n",
    "      \n",
    "      if act_fn == 'ReLU':\n",
    "        self.layer = nn.Sequential(\n",
    "          nn.Linear(layer_size, layer_size),\n",
    "          nn.ReLU())\n",
    "      elif act_fn == 'LeakyReLU':\n",
    "        self.layer = nn.Sequential(\n",
    "          nn.Linear(layer_size, layer_size),\n",
    "          nn.LeakyReLU())\n",
    "      elif act_fn == 'ELU':\n",
    "        self.layer = nn.Sequential(\n",
    "          nn.Linear(layer_size, layer_size),\n",
    "          nn.ELU())\n",
    "    \n",
    "  def forward(self, x):\n",
    "    return self.layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 455,
     "status": "ok",
     "timestamp": 1650891686792,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "lHUFGf9xBawS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "  def __init__(self, input_size, output_size, hidden_size, num_layers, act_fn):\n",
    "    super(Net, self).__init__()\n",
    "    self.input_size = input_size\n",
    "    self.output_size = output_size\n",
    "    self.hidden_size = hidden_size\n",
    "\n",
    "    if act_fn == 'ReLU':\n",
    "      self.initial_layer = nn.Sequential(\n",
    "          nn.Linear(self.input_size, self.hidden_size),\n",
    "          nn.ReLU())\n",
    "    elif act_fn == 'LeakyReLU':\n",
    "      self.initial_layer = nn.Sequential(\n",
    "          nn.Linear(self.input_size, self.hidden_size),\n",
    "          nn.LeakyReLU())\n",
    "    elif act_fn == 'ELU':\n",
    "      self.initial_layer = nn.Sequential(\n",
    "          nn.Linear(self.input_size, self.hidden_size),\n",
    "          nn.ELU())\n",
    "\n",
    "    self.hidden_layers_list = []\n",
    "\n",
    "    for i in range(num_layers // 2):\n",
    "      self.hidden_layers_list.append(\n",
    "          ResBlock(\n",
    "            nn.Sequential(\n",
    "                HiddenLayer(self.hidden_size, act_fn),\n",
    "                HiddenLayer(self.hidden_size, act_fn)\n",
    "            )\n",
    "        )\n",
    "      )\n",
    "\n",
    "    self.hidden_layers = nn.Sequential(*self.hidden_layers_list)\n",
    "\n",
    "    self.net = nn.Sequential(\n",
    "        self.initial_layer,\n",
    "        self.hidden_layers,\n",
    "        nn.Linear(self.hidden_size, self.output_size)\n",
    "    )\n",
    "  \n",
    "  def forward(self, x):\n",
    "    return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1650891686793,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "zcq_lQrHBdH8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def init_weights(m, init_m: str):\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def init_uniform(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "      torch.nn.init.uniform_(m.weight)\n",
    "      m.bias.data.fill_(0.01)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def init_normal(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "      torch.nn.init.normal_(m.weight)\n",
    "      m.bias.data.fill_(0.01)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def init_xuniform(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "      torch.nn.init.xavier_uniform_(m.weight)\n",
    "      m.bias.data.fill_(0.01)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def init_xnormal(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "      torch.nn.init.xavier_normal_(m.weight)\n",
    "      m.bias.data.fill_(0.01)\n",
    "\n",
    "  if init_m == 'uniform':\n",
    "    m.apply(init_uniform)\n",
    "  elif init_m == 'normal':\n",
    "    m.apply(init_normal)\n",
    "  elif init_m == 'xaiver uniform':\n",
    "    m.apply(init_xuniform)\n",
    "  elif init_m == 'xavier normal':\n",
    "    m.apply(init_xnormal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vuCpyycNCKEZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1650891686794,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "YbCOnCSNCL25",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_size = 11\n",
    "output_size = 1\n",
    "num_layers = 4\n",
    "hidden_size = 800\n",
    "batch_size = 585\n",
    "epochs = 2000\n",
    "lr = 0.000656\n",
    "init_method = 'xaiver uniform'\n",
    "act_fn = 'LeakyReLU'\n",
    "\n",
    "model = Net(input_size, output_size, hidden_size, num_layers, act_fn)\n",
    "init_weights(model, init_method)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 7351,
     "status": "ok",
     "timestamp": 1650891694138,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "QqZbxrppvDpZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "X_train = X_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "\n",
    "X_val = X_val.to(device)\n",
    "y_val = y_val.to(device)\n",
    "\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1650891694142,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "Q-9T0GArCMgp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class OptDataset(Dataset):\n",
    "\n",
    "  def __init__(self, X, y):\n",
    "    self.X = X\n",
    "    self.y = y\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.X[idx], self.y[idx]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6-hCH2ivDpb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Losses Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1650891694144,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "mVaO8TruHW4M",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def MAPELoss(output, target):\n",
    "  return torch.mean(torch.abs((target - output) / target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1650891694149,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "tVLW5dHhvDpe",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, loss_fn, X_val, y_val):\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    out = model(X_val)\n",
    "    loss = loss_fn(out, y_val)\n",
    "    print('\\nVal set: Average loss: {:.8f}\\n'.format(\n",
    "            loss.item()))\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68eF5_EovDpf",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Early Stopping class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1650891694150,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "n2So2ffSvDpg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Code took form: https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, \n",
    "                 patience=10, \n",
    "                 verbose=False, \n",
    "                 delta=0, \n",
    "                 path='../models/final_heston_model.chkpt',\n",
    "                 trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score > self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dL_xmnKXvDph",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1650891694152,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "DrBBTGKJvDph",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    epochs,\n",
    "    batch_size,\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val\n",
    "):\n",
    "\n",
    "  training_losses = []\n",
    "  validation_losses = []\n",
    "\n",
    "  early_stopping = EarlyStopping(patience=20)\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "    i = 0\n",
    "\n",
    "    for batch, batch_labels in DataLoader(OptDataset(X_train, y_train), batch_size=batch_size):\n",
    "      out = model(batch.to(device))\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      loss = loss_fn(out, batch_labels.to(device))\n",
    "      epoch_losses.append(loss.item())\n",
    "      total_loss += loss.item()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      if i > 0 and i % 50 == 0:\n",
    "        avg_loss = total_loss / 50\n",
    "        elapsed = time.time() - start_time\n",
    "        print('| Epoch {:3d} | {:5d}/{:5d} batches | lr {:2.5f} | ms/batch {:5.2f} | '\n",
    "                  'loss {:5.8f}'.format(\n",
    "              epoch, i, len(X_train) // batch_size+1, lr, elapsed * 1000 / 50,\n",
    "              avg_loss))\n",
    "        start_time = time.time()\n",
    "        total_loss = 0\n",
    "\n",
    "      i += 1\n",
    "\n",
    "    training_losses.append(np.array(epoch_losses).mean())\n",
    "    val_loss = evaluate(model, loss_fn, X_val, y_val)\n",
    "    validation_losses.append(val_loss)\n",
    "\n",
    "    early_stopping(val_loss, model)\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(f\"Stopping at Epoch: {epoch}\")\n",
    "        break\n",
    "\n",
    "  return training_losses, validation_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2525796,
     "status": "ok",
     "timestamp": 1650894219916,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "hBETWoCfvDpj",
    "outputId": "30acf99f-3a1e-4d87-d1ff-13068ebe4cd4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch   0 |    50/  829 batches | lr 0.00066 | ms/batch 15.69 | loss 0.32139893\n",
      "| Epoch   0 |   100/  829 batches | lr 0.00066 | ms/batch 11.70 | loss 0.00662611\n",
      "| Epoch   0 |   150/  829 batches | lr 0.00066 | ms/batch 11.60 | loss 0.00276318\n",
      "| Epoch   0 |   200/  829 batches | lr 0.00066 | ms/batch 13.35 | loss 0.00183212\n",
      "| Epoch   0 |   250/  829 batches | lr 0.00066 | ms/batch 11.88 | loss 0.00146399\n",
      "| Epoch   0 |   300/  829 batches | lr 0.00066 | ms/batch 11.99 | loss 0.00138721\n",
      "| Epoch   0 |   350/  829 batches | lr 0.00066 | ms/batch 11.82 | loss 0.00129619\n",
      "| Epoch   0 |   400/  829 batches | lr 0.00066 | ms/batch 13.52 | loss 0.00118205\n",
      "| Epoch   0 |   450/  829 batches | lr 0.00066 | ms/batch 11.91 | loss 0.00110201\n",
      "| Epoch   0 |   500/  829 batches | lr 0.00066 | ms/batch 11.58 | loss 0.00108675\n",
      "| Epoch   0 |   550/  829 batches | lr 0.00066 | ms/batch 13.57 | loss 0.00110702\n",
      "| Epoch   0 |   600/  829 batches | lr 0.00066 | ms/batch 11.97 | loss 0.00103391\n",
      "| Epoch   0 |   650/  829 batches | lr 0.00066 | ms/batch 11.71 | loss 0.00108652\n",
      "| Epoch   0 |   700/  829 batches | lr 0.00066 | ms/batch 11.69 | loss 0.00101335\n",
      "| Epoch   0 |   750/  829 batches | lr 0.00066 | ms/batch 11.74 | loss 0.00101862\n",
      "| Epoch   0 |   800/  829 batches | lr 0.00066 | ms/batch 13.38 | loss 0.00104890\n",
      "\n",
      "Val set: Average loss: 0.00090715\n",
      "\n",
      "| Epoch   1 |    50/  829 batches | lr 0.00066 | ms/batch 12.16 | loss 0.00106536\n",
      "| Epoch   1 |   100/  829 batches | lr 0.00066 | ms/batch 11.71 | loss 0.00107758\n",
      "| Epoch   1 |   150/  829 batches | lr 0.00066 | ms/batch 13.51 | loss 0.00090902\n",
      "| Epoch   1 |   200/  829 batches | lr 0.00066 | ms/batch 11.76 | loss 0.00088441\n",
      "| Epoch   1 |   250/  829 batches | lr 0.00066 | ms/batch 12.14 | loss 0.00088956\n",
      "| Epoch   1 |   300/  829 batches | lr 0.00066 | ms/batch 13.33 | loss 0.00093214\n",
      "| Epoch   1 |   350/  829 batches | lr 0.00066 | ms/batch 11.73 | loss 0.00091761\n",
      "| Epoch   1 |   400/  829 batches | lr 0.00066 | ms/batch 11.70 | loss 0.00096978\n",
      "| Epoch   1 |   450/  829 batches | lr 0.00066 | ms/batch 11.69 | loss 0.00085664\n",
      "| Epoch   1 |   500/  829 batches | lr 0.00066 | ms/batch 11.63 | loss 0.00078801\n",
      "| Epoch   1 |   550/  829 batches | lr 0.00066 | ms/batch 13.26 | loss 0.00095747\n",
      "| Epoch   1 |   600/  829 batches | lr 0.00066 | ms/batch 11.70 | loss 0.00105759\n",
      "| Epoch   1 |   650/  829 batches | lr 0.00066 | ms/batch 14.05 | loss 0.00093311\n",
      "| Epoch   1 |   700/  829 batches | lr 0.00066 | ms/batch 11.71 | loss 0.00098893\n",
      "| Epoch   1 |   750/  829 batches | lr 0.00066 | ms/batch 11.73 | loss 0.00088184\n",
      "| Epoch   1 |   800/  829 batches | lr 0.00066 | ms/batch 11.83 | loss 0.00083311\n",
      "\n",
      "Val set: Average loss: 0.00082133\n",
      "\n",
      "| Epoch   2 |    50/  829 batches | lr 0.00066 | ms/batch 13.88 | loss 0.00082669\n",
      "| Epoch   2 |   100/  829 batches | lr 0.00066 | ms/batch 11.75 | loss 0.00091624\n",
      "| Epoch   2 |   150/  829 batches | lr 0.00066 | ms/batch 11.71 | loss 0.00093566\n",
      "| Epoch   2 |   200/  829 batches | lr 0.00066 | ms/batch 11.82 | loss 0.00078839\n",
      "| Epoch   2 |   250/  829 batches | lr 0.00066 | ms/batch 11.68 | loss 0.00086991\n",
      "| Epoch   2 |   300/  829 batches | lr 0.00066 | ms/batch 13.45 | loss 0.00094022\n",
      "| Epoch   2 |   350/  829 batches | lr 0.00066 | ms/batch 11.82 | loss 0.00095892\n",
      "| Epoch   2 |   400/  829 batches | lr 0.00066 | ms/batch 13.29 | loss 0.00149994\n",
      "| Epoch   2 |   450/  829 batches | lr 0.00066 | ms/batch 11.59 | loss 0.00076704\n",
      "| Epoch   2 |   500/  829 batches | lr 0.00066 | ms/batch 11.73 | loss 0.00075626\n",
      "| Epoch   2 |   550/  829 batches | lr 0.00066 | ms/batch 11.58 | loss 0.00088693\n",
      "| Epoch   2 |   600/  829 batches | lr 0.00066 | ms/batch 11.89 | loss 0.00084979\n",
      "| Epoch   2 |   650/  829 batches | lr 0.00066 | ms/batch 13.24 | loss 0.00079772\n",
      "| Epoch   2 |   700/  829 batches | lr 0.00066 | ms/batch 11.59 | loss 0.00076644\n",
      "| Epoch   2 |   750/  829 batches | lr 0.00066 | ms/batch 11.78 | loss 0.00075503\n",
      "| Epoch   2 |   800/  829 batches | lr 0.00066 | ms/batch 13.15 | loss 0.00070846\n",
      "\n",
      "Val set: Average loss: 0.00071395\n",
      "\n",
      "| Epoch   3 |    50/  829 batches | lr 0.00066 | ms/batch 12.18 | loss 0.00081516\n",
      "| Epoch   3 |   100/  829 batches | lr 0.00066 | ms/batch 11.87 | loss 0.00076730\n",
      "| Epoch   3 |   150/  829 batches | lr 0.00066 | ms/batch 13.45 | loss 0.00095667\n",
      "| Epoch   3 |   200/  829 batches | lr 0.00066 | ms/batch 11.88 | loss 0.00081274\n",
      "| Epoch   3 |   250/  829 batches | lr 0.00066 | ms/batch 11.86 | loss 0.00076512\n",
      "| Epoch   3 |   300/  829 batches | lr 0.00066 | ms/batch 11.95 | loss 0.00075662\n",
      "| Epoch   3 |   350/  829 batches | lr 0.00066 | ms/batch 13.54 | loss 0.00083620\n",
      "| Epoch   3 |   400/  829 batches | lr 0.00066 | ms/batch 11.97 | loss 0.00109174\n",
      "| Epoch   3 |   450/  829 batches | lr 0.00066 | ms/batch 11.88 | loss 0.00067289\n",
      "| Epoch   3 |   500/  829 batches | lr 0.00066 | ms/batch 14.13 | loss 0.00066928\n",
      "| Epoch   3 |   550/  829 batches | lr 0.00066 | ms/batch 11.75 | loss 0.00073991\n",
      "| Epoch   3 |   600/  829 batches | lr 0.00066 | ms/batch 11.98 | loss 0.00086730\n",
      "| Epoch   3 |   650/  829 batches | lr 0.00066 | ms/batch 11.76 | loss 0.00092395\n",
      "| Epoch   3 |   700/  829 batches | lr 0.00066 | ms/batch 11.97 | loss 0.00069741\n",
      "| Epoch   3 |   750/  829 batches | lr 0.00066 | ms/batch 13.60 | loss 0.00072423\n",
      "| Epoch   3 |   800/  829 batches | lr 0.00066 | ms/batch 12.55 | loss 0.00067144\n",
      "\n",
      "Val set: Average loss: 0.00058656\n",
      "\n",
      "| Epoch   4 |    50/  829 batches | lr 0.00066 | ms/batch 13.49 | loss 0.00074599\n",
      "| Epoch   4 |   100/  829 batches | lr 0.00066 | ms/batch 11.69 | loss 0.00064501\n",
      "| Epoch   4 |   150/  829 batches | lr 0.00066 | ms/batch 11.63 | loss 0.00092672\n",
      "| Epoch   4 |   200/  829 batches | lr 0.00066 | ms/batch 13.20 | loss 0.00082655\n",
      "| Epoch   4 |   250/  829 batches | lr 0.00066 | ms/batch 11.55 | loss 0.00068292\n",
      "| Epoch   4 |   300/  829 batches | lr 0.00066 | ms/batch 11.53 | loss 0.00074299\n",
      "| Epoch   4 |   350/  829 batches | lr 0.00066 | ms/batch 12.17 | loss 0.00079227\n",
      "| Epoch   4 |   400/  829 batches | lr 0.00066 | ms/batch 11.83 | loss 0.00079924\n",
      "| Epoch   4 |   450/  829 batches | lr 0.00066 | ms/batch 13.42 | loss 0.00057964\n",
      "| Epoch   4 |   500/  829 batches | lr 0.00066 | ms/batch 11.71 | loss 0.00068408\n",
      "| Epoch   4 |   550/  829 batches | lr 0.00066 | ms/batch 13.37 | loss 0.00066157\n",
      "| Epoch   4 |   600/  829 batches | lr 0.00066 | ms/batch 11.66 | loss 0.00063619\n",
      "| Epoch   4 |   650/  829 batches | lr 0.00066 | ms/batch 11.56 | loss 0.00073524\n",
      "| Epoch   4 |   700/  829 batches | lr 0.00066 | ms/batch 11.63 | loss 0.00069438\n",
      "| Epoch   4 |   750/  829 batches | lr 0.00066 | ms/batch 11.66 | loss 0.00085186\n",
      "| Epoch   4 |   800/  829 batches | lr 0.00066 | ms/batch 13.12 | loss 0.00067926\n",
      "\n",
      "Val set: Average loss: 0.00053552\n",
      "\n",
      "| Epoch   5 |    50/  829 batches | lr 0.00066 | ms/batch 11.92 | loss 0.00061924\n",
      "| Epoch   5 |   100/  829 batches | lr 0.00066 | ms/batch 11.64 | loss 0.00060905\n",
      "| Epoch   5 |   150/  829 batches | lr 0.00066 | ms/batch 13.20 | loss 0.00089934\n",
      "| Epoch   5 |   200/  829 batches | lr 0.00066 | ms/batch 11.69 | loss 0.00079849\n",
      "| Epoch   5 |   250/  829 batches | lr 0.00066 | ms/batch 11.68 | loss 0.00064320\n",
      "| Epoch   5 |   300/  829 batches | lr 0.00066 | ms/batch 13.12 | loss 0.00072990\n",
      "| Epoch   5 |   350/  829 batches | lr 0.00066 | ms/batch 11.73 | loss 0.00055173\n",
      "| Epoch   5 |   400/  829 batches | lr 0.00066 | ms/batch 11.53 | loss 0.00056028\n",
      "| Epoch   5 |   450/  829 batches | lr 0.00066 | ms/batch 11.53 | loss 0.00057482\n",
      "| Epoch   5 |   500/  829 batches | lr 0.00066 | ms/batch 11.56 | loss 0.00072949\n",
      "| Epoch   5 |   550/  829 batches | lr 0.00066 | ms/batch 13.12 | loss 0.00079626\n",
      "| Epoch   5 |   600/  829 batches | lr 0.00066 | ms/batch 11.69 | loss 0.00093315\n",
      "| Epoch   5 |   650/  829 batches | lr 0.00066 | ms/batch 11.68 | loss 0.00104242\n",
      "| Epoch   5 |   700/  829 batches | lr 0.00066 | ms/batch 13.15 | loss 0.00055723\n",
      "| Epoch   5 |   750/  829 batches | lr 0.00066 | ms/batch 13.36 | loss 0.00057680\n",
      "| Epoch   5 |   800/  829 batches | lr 0.00066 | ms/batch 11.57 | loss 0.00058450\n",
      "\n",
      "Val set: Average loss: 0.00046129\n",
      "\n",
      "| Epoch   6 |    50/  829 batches | lr 0.00066 | ms/batch 13.44 | loss 0.00059215\n",
      "| Epoch   6 |   100/  829 batches | lr 0.00066 | ms/batch 11.56 | loss 0.00054490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch   6 |   150/  829 batches | lr 0.00066 | ms/batch 11.66 | loss 0.00081219\n",
      "| Epoch   6 |   200/  829 batches | lr 0.00066 | ms/batch 11.72 | loss 0.00111091\n",
      "| Epoch   6 |   250/  829 batches | lr 0.00066 | ms/batch 11.58 | loss 0.00053354\n",
      "| Epoch   6 |   300/  829 batches | lr 0.00066 | ms/batch 13.53 | loss 0.00052383\n",
      "| Epoch   6 |   350/  829 batches | lr 0.00066 | ms/batch 11.59 | loss 0.00055413\n",
      "| Epoch   6 |   400/  829 batches | lr 0.00066 | ms/batch 11.66 | loss 0.00081964\n",
      "| Epoch   6 |   450/  829 batches | lr 0.00066 | ms/batch 13.28 | loss 0.00051738\n",
      "| Epoch   6 |   500/  829 batches | lr 0.00066 | ms/batch 11.84 | loss 0.00056461\n",
      "| Epoch   6 |   550/  829 batches | lr 0.00066 | ms/batch 11.70 | loss 0.00052019\n",
      "| Epoch   6 |   600/  829 batches | lr 0.00066 | ms/batch 12.18 | loss 0.00056981\n",
      "| Epoch   6 |   650/  829 batches | lr 0.00066 | ms/batch 13.36 | loss 0.00061543\n",
      "| Epoch   6 |   700/  829 batches | lr 0.00066 | ms/batch 11.73 | loss 0.00049931\n",
      "| Epoch   6 |   750/  829 batches | lr 0.00066 | ms/batch 11.75 | loss 0.00052905\n",
      "| Epoch   6 |   800/  829 batches | lr 0.00066 | ms/batch 13.25 | loss 0.00048005\n",
      "\n",
      "Val set: Average loss: 0.00042241\n",
      "\n",
      "| Epoch   7 |    50/  829 batches | lr 0.00066 | ms/batch 11.92 | loss 0.00053076\n",
      "| Epoch   7 |   100/  829 batches | lr 0.00066 | ms/batch 11.63 | loss 0.00049268\n",
      "| Epoch   7 |   150/  829 batches | lr 0.00066 | ms/batch 13.28 | loss 0.00076539\n",
      "| Epoch   7 |   200/  829 batches | lr 0.00066 | ms/batch 11.56 | loss 0.00087902\n",
      "| Epoch   7 |   250/  829 batches | lr 0.00066 | ms/batch 11.63 | loss 0.00048305\n",
      "| Epoch   7 |   300/  829 batches | lr 0.00066 | ms/batch 11.64 | loss 0.00047308\n",
      "| Epoch   7 |   350/  829 batches | lr 0.00066 | ms/batch 13.16 | loss 0.00045085\n",
      "| Epoch   7 |   400/  829 batches | lr 0.00066 | ms/batch 11.60 | loss 0.00052802\n",
      "| Epoch   7 |   450/  829 batches | lr 0.00066 | ms/batch 11.60 | loss 0.00043205\n",
      "| Epoch   7 |   500/  829 batches | lr 0.00066 | ms/batch 13.21 | loss 0.00060533\n",
      "| Epoch   7 |   550/  829 batches | lr 0.00066 | ms/batch 11.68 | loss 0.00062800\n",
      "| Epoch   7 |   600/  829 batches | lr 0.00066 | ms/batch 11.60 | loss 0.00055698\n",
      "| Epoch   7 |   650/  829 batches | lr 0.00066 | ms/batch 11.60 | loss 0.00063120\n",
      "| Epoch   7 |   700/  829 batches | lr 0.00066 | ms/batch 11.60 | loss 0.00051298\n",
      "| Epoch   7 |   750/  829 batches | lr 0.00066 | ms/batch 13.26 | loss 0.00049619\n",
      "| Epoch   7 |   800/  829 batches | lr 0.00066 | ms/batch 11.73 | loss 0.00042036\n",
      "\n",
      "Val set: Average loss: 0.00039012\n",
      "\n",
      "| Epoch   8 |    50/  829 batches | lr 0.00066 | ms/batch 13.44 | loss 0.00054451\n",
      "| Epoch   8 |   100/  829 batches | lr 0.00066 | ms/batch 11.58 | loss 0.00048722\n",
      "| Epoch   8 |   150/  829 batches | lr 0.00066 | ms/batch 11.71 | loss 0.00066476\n",
      "| Epoch   8 |   200/  829 batches | lr 0.00066 | ms/batch 13.18 | loss 0.00080884\n",
      "| Epoch   8 |   250/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00041612\n",
      "| Epoch   8 |   300/  829 batches | lr 0.00066 | ms/batch 11.61 | loss 0.00042617\n",
      "| Epoch   8 |   350/  829 batches | lr 0.00066 | ms/batch 11.57 | loss 0.00040431\n",
      "| Epoch   8 |   400/  829 batches | lr 0.00066 | ms/batch 11.55 | loss 0.00049496\n",
      "| Epoch   8 |   450/  829 batches | lr 0.00066 | ms/batch 13.18 | loss 0.00037850\n",
      "| Epoch   8 |   500/  829 batches | lr 0.00066 | ms/batch 11.57 | loss 0.00052383\n",
      "| Epoch   8 |   550/  829 batches | lr 0.00066 | ms/batch 13.39 | loss 0.00063286\n",
      "| Epoch   8 |   600/  829 batches | lr 0.00066 | ms/batch 11.94 | loss 0.00043232\n",
      "| Epoch   8 |   650/  829 batches | lr 0.00066 | ms/batch 11.89 | loss 0.00044516\n",
      "| Epoch   8 |   700/  829 batches | lr 0.00066 | ms/batch 11.87 | loss 0.00040726\n",
      "| Epoch   8 |   750/  829 batches | lr 0.00066 | ms/batch 11.93 | loss 0.00042400\n",
      "| Epoch   8 |   800/  829 batches | lr 0.00066 | ms/batch 13.33 | loss 0.00040456\n",
      "\n",
      "Val set: Average loss: 0.00040986\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch   9 |    50/  829 batches | lr 0.00066 | ms/batch 12.36 | loss 0.00049630\n",
      "| Epoch   9 |   100/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00045709\n",
      "| Epoch   9 |   150/  829 batches | lr 0.00066 | ms/batch 13.56 | loss 0.00055895\n",
      "| Epoch   9 |   200/  829 batches | lr 0.00066 | ms/batch 11.92 | loss 0.00061339\n",
      "| Epoch   9 |   250/  829 batches | lr 0.00066 | ms/batch 11.86 | loss 0.00036954\n",
      "| Epoch   9 |   300/  829 batches | lr 0.00066 | ms/batch 13.75 | loss 0.00038553\n",
      "| Epoch   9 |   350/  829 batches | lr 0.00066 | ms/batch 11.71 | loss 0.00035407\n",
      "| Epoch   9 |   400/  829 batches | lr 0.00066 | ms/batch 12.10 | loss 0.00039940\n",
      "| Epoch   9 |   450/  829 batches | lr 0.00066 | ms/batch 11.85 | loss 0.00036215\n",
      "| Epoch   9 |   500/  829 batches | lr 0.00066 | ms/batch 11.92 | loss 0.00044590\n",
      "| Epoch   9 |   550/  829 batches | lr 0.00066 | ms/batch 13.31 | loss 0.00051819\n",
      "| Epoch   9 |   600/  829 batches | lr 0.00066 | ms/batch 11.85 | loss 0.00040106\n",
      "| Epoch   9 |   650/  829 batches | lr 0.00066 | ms/batch 11.81 | loss 0.00049726\n",
      "| Epoch   9 |   700/  829 batches | lr 0.00066 | ms/batch 13.26 | loss 0.00044480\n",
      "| Epoch   9 |   750/  829 batches | lr 0.00066 | ms/batch 11.63 | loss 0.00043076\n",
      "| Epoch   9 |   800/  829 batches | lr 0.00066 | ms/batch 11.65 | loss 0.00039034\n",
      "\n",
      "Val set: Average loss: 0.00035390\n",
      "\n",
      "| Epoch  10 |    50/  829 batches | lr 0.00066 | ms/batch 13.75 | loss 0.00041811\n",
      "| Epoch  10 |   100/  829 batches | lr 0.00066 | ms/batch 11.72 | loss 0.00039769\n",
      "| Epoch  10 |   150/  829 batches | lr 0.00066 | ms/batch 12.04 | loss 0.00053643\n",
      "| Epoch  10 |   200/  829 batches | lr 0.00066 | ms/batch 12.02 | loss 0.00046956\n",
      "| Epoch  10 |   250/  829 batches | lr 0.00066 | ms/batch 11.81 | loss 0.00034839\n",
      "| Epoch  10 |   300/  829 batches | lr 0.00066 | ms/batch 13.61 | loss 0.00040059\n",
      "| Epoch  10 |   350/  829 batches | lr 0.00066 | ms/batch 11.78 | loss 0.00039673\n",
      "| Epoch  10 |   400/  829 batches | lr 0.00066 | ms/batch 12.05 | loss 0.00048704\n",
      "| Epoch  10 |   450/  829 batches | lr 0.00066 | ms/batch 13.41 | loss 0.00036350\n",
      "| Epoch  10 |   500/  829 batches | lr 0.00066 | ms/batch 11.76 | loss 0.00051582\n",
      "| Epoch  10 |   550/  829 batches | lr 0.00066 | ms/batch 11.94 | loss 0.00057050\n",
      "| Epoch  10 |   600/  829 batches | lr 0.00066 | ms/batch 13.00 | loss 0.00041446\n",
      "| Epoch  10 |   650/  829 batches | lr 0.00066 | ms/batch 13.63 | loss 0.00036990\n",
      "| Epoch  10 |   700/  829 batches | lr 0.00066 | ms/batch 11.82 | loss 0.00040594\n",
      "| Epoch  10 |   750/  829 batches | lr 0.00066 | ms/batch 11.92 | loss 0.00043703\n",
      "| Epoch  10 |   800/  829 batches | lr 0.00066 | ms/batch 13.18 | loss 0.00035668\n",
      "\n",
      "Val set: Average loss: 0.00032442\n",
      "\n",
      "| Epoch  11 |    50/  829 batches | lr 0.00066 | ms/batch 11.99 | loss 0.00034643\n",
      "| Epoch  11 |   100/  829 batches | lr 0.00066 | ms/batch 11.68 | loss 0.00053776\n",
      "| Epoch  11 |   150/  829 batches | lr 0.00066 | ms/batch 14.29 | loss 0.00037523\n",
      "| Epoch  11 |   200/  829 batches | lr 0.00066 | ms/batch 12.11 | loss 0.00033038\n",
      "| Epoch  11 |   250/  829 batches | lr 0.00066 | ms/batch 11.99 | loss 0.00034125\n",
      "| Epoch  11 |   300/  829 batches | lr 0.00066 | ms/batch 12.39 | loss 0.00040205\n",
      "| Epoch  11 |   350/  829 batches | lr 0.00066 | ms/batch 13.40 | loss 0.00029950\n",
      "| Epoch  11 |   400/  829 batches | lr 0.00066 | ms/batch 12.06 | loss 0.00055125\n",
      "| Epoch  11 |   450/  829 batches | lr 0.00066 | ms/batch 11.95 | loss 0.00034694\n",
      "| Epoch  11 |   500/  829 batches | lr 0.00066 | ms/batch 13.42 | loss 0.00041845\n",
      "| Epoch  11 |   550/  829 batches | lr 0.00066 | ms/batch 12.11 | loss 0.00039920\n",
      "| Epoch  11 |   600/  829 batches | lr 0.00066 | ms/batch 12.00 | loss 0.00028756\n",
      "| Epoch  11 |   650/  829 batches | lr 0.00066 | ms/batch 11.96 | loss 0.00027343\n",
      "| Epoch  11 |   700/  829 batches | lr 0.00066 | ms/batch 12.04 | loss 0.00030025\n",
      "| Epoch  11 |   750/  829 batches | lr 0.00066 | ms/batch 13.74 | loss 0.00030186\n",
      "| Epoch  11 |   800/  829 batches | lr 0.00066 | ms/batch 12.08 | loss 0.00028126\n",
      "\n",
      "Val set: Average loss: 0.00025519\n",
      "\n",
      "| Epoch  12 |    50/  829 batches | lr 0.00066 | ms/batch 14.01 | loss 0.00027775\n",
      "| Epoch  12 |   100/  829 batches | lr 0.00066 | ms/batch 11.75 | loss 0.00027885\n",
      "| Epoch  12 |   150/  829 batches | lr 0.00066 | ms/batch 11.91 | loss 0.00033709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch  12 |   200/  829 batches | lr 0.00066 | ms/batch 13.32 | loss 0.00030630\n",
      "| Epoch  12 |   250/  829 batches | lr 0.00066 | ms/batch 11.68 | loss 0.00031618\n",
      "| Epoch  12 |   300/  829 batches | lr 0.00066 | ms/batch 11.93 | loss 0.00032106\n",
      "| Epoch  12 |   350/  829 batches | lr 0.00066 | ms/batch 12.35 | loss 0.00026898\n",
      "| Epoch  12 |   400/  829 batches | lr 0.00066 | ms/batch 12.26 | loss 0.00026926\n",
      "| Epoch  12 |   450/  829 batches | lr 0.00066 | ms/batch 13.71 | loss 0.00022447\n",
      "| Epoch  12 |   500/  829 batches | lr 0.00066 | ms/batch 12.20 | loss 0.00024463\n",
      "| Epoch  12 |   550/  829 batches | lr 0.00066 | ms/batch 13.76 | loss 0.00028833\n",
      "| Epoch  12 |   600/  829 batches | lr 0.00066 | ms/batch 11.77 | loss 0.00030776\n",
      "| Epoch  12 |   650/  829 batches | lr 0.00066 | ms/batch 11.79 | loss 0.00031427\n",
      "| Epoch  12 |   700/  829 batches | lr 0.00066 | ms/batch 11.78 | loss 0.00024614\n",
      "| Epoch  12 |   750/  829 batches | lr 0.00066 | ms/batch 12.02 | loss 0.00038802\n",
      "| Epoch  12 |   800/  829 batches | lr 0.00066 | ms/batch 14.92 | loss 0.00035226\n",
      "\n",
      "Val set: Average loss: 0.00030367\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  13 |    50/  829 batches | lr 0.00066 | ms/batch 12.03 | loss 0.00028078\n",
      "| Epoch  13 |   100/  829 batches | lr 0.00066 | ms/batch 11.60 | loss 0.00027618\n",
      "| Epoch  13 |   150/  829 batches | lr 0.00066 | ms/batch 13.32 | loss 0.00030267\n",
      "| Epoch  13 |   200/  829 batches | lr 0.00066 | ms/batch 11.61 | loss 0.00026802\n",
      "| Epoch  13 |   250/  829 batches | lr 0.00066 | ms/batch 11.65 | loss 0.00028676\n",
      "| Epoch  13 |   300/  829 batches | lr 0.00066 | ms/batch 13.49 | loss 0.00028781\n",
      "| Epoch  13 |   350/  829 batches | lr 0.00066 | ms/batch 11.64 | loss 0.00025674\n",
      "| Epoch  13 |   400/  829 batches | lr 0.00066 | ms/batch 11.59 | loss 0.00026500\n",
      "| Epoch  13 |   450/  829 batches | lr 0.00066 | ms/batch 11.62 | loss 0.00024901\n",
      "| Epoch  13 |   500/  829 batches | lr 0.00066 | ms/batch 11.56 | loss 0.00024959\n",
      "| Epoch  13 |   550/  829 batches | lr 0.00066 | ms/batch 13.25 | loss 0.00033522\n",
      "| Epoch  13 |   600/  829 batches | lr 0.00066 | ms/batch 11.70 | loss 0.00031317\n",
      "| Epoch  13 |   650/  829 batches | lr 0.00066 | ms/batch 11.87 | loss 0.00036891\n",
      "| Epoch  13 |   700/  829 batches | lr 0.00066 | ms/batch 13.30 | loss 0.00027775\n",
      "| Epoch  13 |   750/  829 batches | lr 0.00066 | ms/batch 11.81 | loss 0.00036940\n",
      "| Epoch  13 |   800/  829 batches | lr 0.00066 | ms/batch 12.36 | loss 0.00031824\n",
      "\n",
      "Val set: Average loss: 0.00023887\n",
      "\n",
      "| Epoch  14 |    50/  829 batches | lr 0.00066 | ms/batch 13.88 | loss 0.00031443\n",
      "| Epoch  14 |   100/  829 batches | lr 0.00066 | ms/batch 11.95 | loss 0.00029281\n",
      "| Epoch  14 |   150/  829 batches | lr 0.00066 | ms/batch 11.84 | loss 0.00035191\n",
      "| Epoch  14 |   200/  829 batches | lr 0.00066 | ms/batch 11.60 | loss 0.00026761\n",
      "| Epoch  14 |   250/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00027622\n",
      "| Epoch  14 |   300/  829 batches | lr 0.00066 | ms/batch 13.49 | loss 0.00031266\n",
      "| Epoch  14 |   350/  829 batches | lr 0.00066 | ms/batch 11.82 | loss 0.00032870\n",
      "| Epoch  14 |   400/  829 batches | lr 0.00066 | ms/batch 11.73 | loss 0.00033095\n",
      "| Epoch  14 |   450/  829 batches | lr 0.00066 | ms/batch 13.19 | loss 0.00026900\n",
      "| Epoch  14 |   500/  829 batches | lr 0.00066 | ms/batch 11.75 | loss 0.00035884\n",
      "| Epoch  14 |   550/  829 batches | lr 0.00066 | ms/batch 11.66 | loss 0.00033325\n",
      "| Epoch  14 |   600/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00023165\n",
      "| Epoch  14 |   650/  829 batches | lr 0.00066 | ms/batch 13.26 | loss 0.00026267\n",
      "| Epoch  14 |   700/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00021731\n",
      "| Epoch  14 |   750/  829 batches | lr 0.00066 | ms/batch 11.90 | loss 0.00026571\n",
      "| Epoch  14 |   800/  829 batches | lr 0.00066 | ms/batch 13.18 | loss 0.00020676\n",
      "\n",
      "Val set: Average loss: 0.00021729\n",
      "\n",
      "| Epoch  15 |    50/  829 batches | lr 0.00066 | ms/batch 11.96 | loss 0.00029425\n",
      "| Epoch  15 |   100/  829 batches | lr 0.00066 | ms/batch 11.78 | loss 0.00033477\n",
      "| Epoch  15 |   150/  829 batches | lr 0.00066 | ms/batch 13.14 | loss 0.00026394\n",
      "| Epoch  15 |   200/  829 batches | lr 0.00066 | ms/batch 11.56 | loss 0.00026976\n",
      "| Epoch  15 |   250/  829 batches | lr 0.00066 | ms/batch 11.61 | loss 0.00025846\n",
      "| Epoch  15 |   300/  829 batches | lr 0.00066 | ms/batch 11.66 | loss 0.00040052\n",
      "| Epoch  15 |   350/  829 batches | lr 0.00066 | ms/batch 13.14 | loss 0.00027167\n",
      "| Epoch  15 |   400/  829 batches | lr 0.00066 | ms/batch 11.62 | loss 0.00029359\n",
      "| Epoch  15 |   450/  829 batches | lr 0.00066 | ms/batch 11.60 | loss 0.00031191\n",
      "| Epoch  15 |   500/  829 batches | lr 0.00066 | ms/batch 13.22 | loss 0.00024830\n",
      "| Epoch  15 |   550/  829 batches | lr 0.00066 | ms/batch 11.66 | loss 0.00025214\n",
      "| Epoch  15 |   600/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00020479\n",
      "| Epoch  15 |   650/  829 batches | lr 0.00066 | ms/batch 11.66 | loss 0.00019568\n",
      "| Epoch  15 |   700/  829 batches | lr 0.00066 | ms/batch 11.71 | loss 0.00020266\n",
      "| Epoch  15 |   750/  829 batches | lr 0.00066 | ms/batch 13.60 | loss 0.00020526\n",
      "| Epoch  15 |   800/  829 batches | lr 0.00066 | ms/batch 11.74 | loss 0.00017890\n",
      "\n",
      "Val set: Average loss: 0.00018943\n",
      "\n",
      "| Epoch  16 |    50/  829 batches | lr 0.00066 | ms/batch 13.49 | loss 0.00020915\n",
      "| Epoch  16 |   100/  829 batches | lr 0.00066 | ms/batch 11.83 | loss 0.00026037\n",
      "| Epoch  16 |   150/  829 batches | lr 0.00066 | ms/batch 11.69 | loss 0.00020301\n",
      "| Epoch  16 |   200/  829 batches | lr 0.00066 | ms/batch 13.21 | loss 0.00020147\n",
      "| Epoch  16 |   250/  829 batches | lr 0.00066 | ms/batch 11.68 | loss 0.00019101\n",
      "| Epoch  16 |   300/  829 batches | lr 0.00066 | ms/batch 11.58 | loss 0.00024330\n",
      "| Epoch  16 |   350/  829 batches | lr 0.00066 | ms/batch 11.62 | loss 0.00019605\n",
      "| Epoch  16 |   400/  829 batches | lr 0.00066 | ms/batch 11.70 | loss 0.00019967\n",
      "| Epoch  16 |   450/  829 batches | lr 0.00066 | ms/batch 13.18 | loss 0.00018357\n",
      "| Epoch  16 |   500/  829 batches | lr 0.00066 | ms/batch 11.62 | loss 0.00025313\n",
      "| Epoch  16 |   550/  829 batches | lr 0.00066 | ms/batch 13.25 | loss 0.00024115\n",
      "| Epoch  16 |   600/  829 batches | lr 0.00066 | ms/batch 11.58 | loss 0.00020867\n",
      "| Epoch  16 |   650/  829 batches | lr 0.00066 | ms/batch 11.59 | loss 0.00018750\n",
      "| Epoch  16 |   700/  829 batches | lr 0.00066 | ms/batch 11.59 | loss 0.00019179\n",
      "| Epoch  16 |   750/  829 batches | lr 0.00066 | ms/batch 11.63 | loss 0.00020958\n",
      "| Epoch  16 |   800/  829 batches | lr 0.00066 | ms/batch 13.16 | loss 0.00024282\n",
      "\n",
      "Val set: Average loss: 0.00023997\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  17 |    50/  829 batches | lr 0.00066 | ms/batch 11.94 | loss 0.00022153\n",
      "| Epoch  17 |   100/  829 batches | lr 0.00066 | ms/batch 11.69 | loss 0.00020420\n",
      "| Epoch  17 |   150/  829 batches | lr 0.00066 | ms/batch 13.60 | loss 0.00021651\n",
      "| Epoch  17 |   200/  829 batches | lr 0.00066 | ms/batch 12.23 | loss 0.00022155\n",
      "| Epoch  17 |   250/  829 batches | lr 0.00066 | ms/batch 11.72 | loss 0.00018453\n",
      "| Epoch  17 |   300/  829 batches | lr 0.00066 | ms/batch 13.42 | loss 0.00021425\n",
      "| Epoch  17 |   350/  829 batches | lr 0.00066 | ms/batch 11.75 | loss 0.00019906\n",
      "| Epoch  17 |   400/  829 batches | lr 0.00066 | ms/batch 12.50 | loss 0.00021005\n",
      "| Epoch  17 |   450/  829 batches | lr 0.00066 | ms/batch 11.82 | loss 0.00019739\n",
      "| Epoch  17 |   500/  829 batches | lr 0.00066 | ms/batch 11.90 | loss 0.00022279\n",
      "| Epoch  17 |   550/  829 batches | lr 0.00066 | ms/batch 14.15 | loss 0.00022488\n",
      "| Epoch  17 |   600/  829 batches | lr 0.00066 | ms/batch 11.83 | loss 0.00022366\n",
      "| Epoch  17 |   650/  829 batches | lr 0.00066 | ms/batch 11.74 | loss 0.00025134\n",
      "| Epoch  17 |   700/  829 batches | lr 0.00066 | ms/batch 13.38 | loss 0.00021953\n",
      "| Epoch  17 |   750/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00023524\n",
      "| Epoch  17 |   800/  829 batches | lr 0.00066 | ms/batch 11.92 | loss 0.00023546\n",
      "\n",
      "Val set: Average loss: 0.00020296\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  18 |    50/  829 batches | lr 0.00066 | ms/batch 13.55 | loss 0.00021710\n",
      "| Epoch  18 |   100/  829 batches | lr 0.00066 | ms/batch 11.74 | loss 0.00020222\n",
      "| Epoch  18 |   150/  829 batches | lr 0.00066 | ms/batch 11.85 | loss 0.00024205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch  18 |   200/  829 batches | lr 0.00066 | ms/batch 11.86 | loss 0.00026103\n",
      "| Epoch  18 |   250/  829 batches | lr 0.00066 | ms/batch 11.77 | loss 0.00026921\n",
      "| Epoch  18 |   300/  829 batches | lr 0.00066 | ms/batch 13.49 | loss 0.00026781\n",
      "| Epoch  18 |   350/  829 batches | lr 0.00066 | ms/batch 11.96 | loss 0.00019309\n",
      "| Epoch  18 |   400/  829 batches | lr 0.00066 | ms/batch 12.02 | loss 0.00025493\n",
      "| Epoch  18 |   450/  829 batches | lr 0.00066 | ms/batch 13.57 | loss 0.00024413\n",
      "| Epoch  18 |   500/  829 batches | lr 0.00066 | ms/batch 12.02 | loss 0.00021870\n",
      "| Epoch  18 |   550/  829 batches | lr 0.00066 | ms/batch 12.04 | loss 0.00024412\n",
      "| Epoch  18 |   600/  829 batches | lr 0.00066 | ms/batch 11.96 | loss 0.00016979\n",
      "| Epoch  18 |   650/  829 batches | lr 0.00066 | ms/batch 13.86 | loss 0.00018294\n",
      "| Epoch  18 |   700/  829 batches | lr 0.00066 | ms/batch 12.23 | loss 0.00016594\n",
      "| Epoch  18 |   750/  829 batches | lr 0.00066 | ms/batch 12.18 | loss 0.00018045\n",
      "| Epoch  18 |   800/  829 batches | lr 0.00066 | ms/batch 13.85 | loss 0.00018290\n",
      "\n",
      "Val set: Average loss: 0.00019258\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  19 |    50/  829 batches | lr 0.00066 | ms/batch 12.15 | loss 0.00024651\n",
      "| Epoch  19 |   100/  829 batches | lr 0.00066 | ms/batch 12.12 | loss 0.00022317\n",
      "| Epoch  19 |   150/  829 batches | lr 0.00066 | ms/batch 13.27 | loss 0.00024378\n",
      "| Epoch  19 |   200/  829 batches | lr 0.00066 | ms/batch 12.33 | loss 0.00024782\n",
      "| Epoch  19 |   250/  829 batches | lr 0.00066 | ms/batch 12.29 | loss 0.00019827\n",
      "| Epoch  19 |   300/  829 batches | lr 0.00066 | ms/batch 11.91 | loss 0.00021631\n",
      "| Epoch  19 |   350/  829 batches | lr 0.00066 | ms/batch 13.63 | loss 0.00018302\n",
      "| Epoch  19 |   400/  829 batches | lr 0.00066 | ms/batch 11.83 | loss 0.00022813\n",
      "| Epoch  19 |   450/  829 batches | lr 0.00066 | ms/batch 11.94 | loss 0.00026527\n",
      "| Epoch  19 |   500/  829 batches | lr 0.00066 | ms/batch 14.29 | loss 0.00019458\n",
      "| Epoch  19 |   550/  829 batches | lr 0.00066 | ms/batch 11.94 | loss 0.00020936\n",
      "| Epoch  19 |   600/  829 batches | lr 0.00066 | ms/batch 12.04 | loss 0.00016404\n",
      "| Epoch  19 |   650/  829 batches | lr 0.00066 | ms/batch 11.72 | loss 0.00016485\n",
      "| Epoch  19 |   700/  829 batches | lr 0.00066 | ms/batch 11.84 | loss 0.00016254\n",
      "| Epoch  19 |   750/  829 batches | lr 0.00066 | ms/batch 13.47 | loss 0.00016753\n",
      "| Epoch  19 |   800/  829 batches | lr 0.00066 | ms/batch 11.77 | loss 0.00015195\n",
      "\n",
      "Val set: Average loss: 0.00015905\n",
      "\n",
      "| Epoch  20 |    50/  829 batches | lr 0.00066 | ms/batch 13.81 | loss 0.00020222\n",
      "| Epoch  20 |   100/  829 batches | lr 0.00066 | ms/batch 11.81 | loss 0.00020322\n",
      "| Epoch  20 |   150/  829 batches | lr 0.00066 | ms/batch 12.01 | loss 0.00017858\n",
      "| Epoch  20 |   200/  829 batches | lr 0.00066 | ms/batch 13.54 | loss 0.00018218\n",
      "| Epoch  20 |   250/  829 batches | lr 0.00066 | ms/batch 11.75 | loss 0.00016103\n",
      "| Epoch  20 |   300/  829 batches | lr 0.00066 | ms/batch 11.79 | loss 0.00015652\n",
      "| Epoch  20 |   350/  829 batches | lr 0.00066 | ms/batch 11.94 | loss 0.00013712\n",
      "| Epoch  20 |   400/  829 batches | lr 0.00066 | ms/batch 11.77 | loss 0.00019296\n",
      "| Epoch  20 |   450/  829 batches | lr 0.00066 | ms/batch 13.49 | loss 0.00017013\n",
      "| Epoch  20 |   500/  829 batches | lr 0.00066 | ms/batch 11.74 | loss 0.00016756\n",
      "| Epoch  20 |   550/  829 batches | lr 0.00066 | ms/batch 13.42 | loss 0.00022006\n",
      "| Epoch  20 |   600/  829 batches | lr 0.00066 | ms/batch 11.81 | loss 0.00016476\n",
      "| Epoch  20 |   650/  829 batches | lr 0.00066 | ms/batch 11.98 | loss 0.00016485\n",
      "| Epoch  20 |   700/  829 batches | lr 0.00066 | ms/batch 11.65 | loss 0.00013864\n",
      "| Epoch  20 |   750/  829 batches | lr 0.00066 | ms/batch 11.66 | loss 0.00014891\n",
      "| Epoch  20 |   800/  829 batches | lr 0.00066 | ms/batch 13.66 | loss 0.00014734\n",
      "\n",
      "Val set: Average loss: 0.00015962\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  21 |    50/  829 batches | lr 0.00066 | ms/batch 12.71 | loss 0.00016340\n",
      "| Epoch  21 |   100/  829 batches | lr 0.00066 | ms/batch 11.88 | loss 0.00015899\n",
      "| Epoch  21 |   150/  829 batches | lr 0.00066 | ms/batch 12.99 | loss 0.00014568\n",
      "| Epoch  21 |   200/  829 batches | lr 0.00066 | ms/batch 14.64 | loss 0.00016207\n",
      "| Epoch  21 |   250/  829 batches | lr 0.00066 | ms/batch 12.09 | loss 0.00023794\n",
      "| Epoch  21 |   300/  829 batches | lr 0.00066 | ms/batch 14.01 | loss 0.00020031\n",
      "| Epoch  21 |   350/  829 batches | lr 0.00066 | ms/batch 13.43 | loss 0.00015604\n",
      "| Epoch  21 |   400/  829 batches | lr 0.00066 | ms/batch 12.25 | loss 0.00015630\n",
      "| Epoch  21 |   450/  829 batches | lr 0.00066 | ms/batch 12.06 | loss 0.00015553\n",
      "| Epoch  21 |   500/  829 batches | lr 0.00066 | ms/batch 11.97 | loss 0.00016003\n",
      "| Epoch  21 |   550/  829 batches | lr 0.00066 | ms/batch 13.39 | loss 0.00018342\n",
      "| Epoch  21 |   600/  829 batches | lr 0.00066 | ms/batch 11.69 | loss 0.00019704\n",
      "| Epoch  21 |   650/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00023201\n",
      "| Epoch  21 |   700/  829 batches | lr 0.00066 | ms/batch 13.18 | loss 0.00018861\n",
      "| Epoch  21 |   750/  829 batches | lr 0.00066 | ms/batch 11.61 | loss 0.00017998\n",
      "| Epoch  21 |   800/  829 batches | lr 0.00066 | ms/batch 11.69 | loss 0.00018000\n",
      "\n",
      "Val set: Average loss: 0.00019581\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  22 |    50/  829 batches | lr 0.00066 | ms/batch 13.64 | loss 0.00018397\n",
      "| Epoch  22 |   100/  829 batches | lr 0.00066 | ms/batch 11.59 | loss 0.00020059\n",
      "| Epoch  22 |   150/  829 batches | lr 0.00066 | ms/batch 11.74 | loss 0.00017847\n",
      "| Epoch  22 |   200/  829 batches | lr 0.00066 | ms/batch 11.60 | loss 0.00018562\n",
      "| Epoch  22 |   250/  829 batches | lr 0.00066 | ms/batch 11.59 | loss 0.00018855\n",
      "| Epoch  22 |   300/  829 batches | lr 0.00066 | ms/batch 13.19 | loss 0.00014865\n",
      "| Epoch  22 |   350/  829 batches | lr 0.00066 | ms/batch 11.63 | loss 0.00015076\n",
      "| Epoch  22 |   400/  829 batches | lr 0.00066 | ms/batch 11.68 | loss 0.00017846\n",
      "| Epoch  22 |   450/  829 batches | lr 0.00066 | ms/batch 13.30 | loss 0.00019226\n",
      "| Epoch  22 |   500/  829 batches | lr 0.00066 | ms/batch 11.59 | loss 0.00018884\n",
      "| Epoch  22 |   550/  829 batches | lr 0.00066 | ms/batch 11.70 | loss 0.00020475\n",
      "| Epoch  22 |   600/  829 batches | lr 0.00066 | ms/batch 11.79 | loss 0.00014606\n",
      "| Epoch  22 |   650/  829 batches | lr 0.00066 | ms/batch 11.66 | loss 0.00017305\n",
      "| Epoch  22 |   700/  829 batches | lr 0.00066 | ms/batch 13.43 | loss 0.00013721\n",
      "| Epoch  22 |   750/  829 batches | lr 0.00066 | ms/batch 11.74 | loss 0.00014994\n",
      "| Epoch  22 |   800/  829 batches | lr 0.00066 | ms/batch 13.17 | loss 0.00012799\n",
      "\n",
      "Val set: Average loss: 0.00013716\n",
      "\n",
      "| Epoch  23 |    50/  829 batches | lr 0.00066 | ms/batch 12.07 | loss 0.00020392\n",
      "| Epoch  23 |   100/  829 batches | lr 0.00066 | ms/batch 11.70 | loss 0.00019167\n",
      "| Epoch  23 |   150/  829 batches | lr 0.00066 | ms/batch 13.20 | loss 0.00019363\n",
      "| Epoch  23 |   200/  829 batches | lr 0.00066 | ms/batch 11.57 | loss 0.00023632\n",
      "| Epoch  23 |   250/  829 batches | lr 0.00066 | ms/batch 11.58 | loss 0.00029695\n",
      "| Epoch  23 |   300/  829 batches | lr 0.00066 | ms/batch 11.60 | loss 0.00025164\n",
      "| Epoch  23 |   350/  829 batches | lr 0.00066 | ms/batch 13.18 | loss 0.00016990\n",
      "| Epoch  23 |   400/  829 batches | lr 0.00066 | ms/batch 11.60 | loss 0.00013632\n",
      "| Epoch  23 |   450/  829 batches | lr 0.00066 | ms/batch 11.63 | loss 0.00014097\n",
      "| Epoch  23 |   500/  829 batches | lr 0.00066 | ms/batch 13.18 | loss 0.00017301\n",
      "| Epoch  23 |   550/  829 batches | lr 0.00066 | ms/batch 11.62 | loss 0.00025652\n",
      "| Epoch  23 |   600/  829 batches | lr 0.00066 | ms/batch 11.58 | loss 0.00020693\n",
      "| Epoch  23 |   650/  829 batches | lr 0.00066 | ms/batch 11.61 | loss 0.00015003\n",
      "| Epoch  23 |   700/  829 batches | lr 0.00066 | ms/batch 11.59 | loss 0.00015116\n",
      "| Epoch  23 |   750/  829 batches | lr 0.00066 | ms/batch 13.17 | loss 0.00015507\n",
      "| Epoch  23 |   800/  829 batches | lr 0.00066 | ms/batch 11.61 | loss 0.00012419\n",
      "\n",
      "Val set: Average loss: 0.00016046\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  24 |    50/  829 batches | lr 0.00066 | ms/batch 13.54 | loss 0.00015731\n",
      "| Epoch  24 |   100/  829 batches | lr 0.00066 | ms/batch 11.73 | loss 0.00013436\n",
      "| Epoch  24 |   150/  829 batches | lr 0.00066 | ms/batch 11.64 | loss 0.00015331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch  24 |   200/  829 batches | lr 0.00066 | ms/batch 13.14 | loss 0.00012931\n",
      "| Epoch  24 |   250/  829 batches | lr 0.00066 | ms/batch 11.56 | loss 0.00014989\n",
      "| Epoch  24 |   300/  829 batches | lr 0.00066 | ms/batch 11.66 | loss 0.00016791\n",
      "| Epoch  24 |   350/  829 batches | lr 0.00066 | ms/batch 11.75 | loss 0.00013368\n",
      "| Epoch  24 |   400/  829 batches | lr 0.00066 | ms/batch 11.69 | loss 0.00011688\n",
      "| Epoch  24 |   450/  829 batches | lr 0.00066 | ms/batch 13.41 | loss 0.00012972\n",
      "| Epoch  24 |   500/  829 batches | lr 0.00066 | ms/batch 11.77 | loss 0.00013732\n",
      "| Epoch  24 |   550/  829 batches | lr 0.00066 | ms/batch 13.35 | loss 0.00014169\n",
      "| Epoch  24 |   600/  829 batches | lr 0.00066 | ms/batch 11.70 | loss 0.00013113\n",
      "| Epoch  24 |   650/  829 batches | lr 0.00066 | ms/batch 11.80 | loss 0.00012416\n",
      "| Epoch  24 |   700/  829 batches | lr 0.00066 | ms/batch 11.72 | loss 0.00011829\n",
      "| Epoch  24 |   750/  829 batches | lr 0.00066 | ms/batch 11.57 | loss 0.00012293\n",
      "| Epoch  24 |   800/  829 batches | lr 0.00066 | ms/batch 13.24 | loss 0.00011461\n",
      "\n",
      "Val set: Average loss: 0.00013798\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  25 |    50/  829 batches | lr 0.00066 | ms/batch 12.00 | loss 0.00012588\n",
      "| Epoch  25 |   100/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00012663\n",
      "| Epoch  25 |   150/  829 batches | lr 0.00066 | ms/batch 11.74 | loss 0.00011759\n",
      "| Epoch  25 |   200/  829 batches | lr 0.00066 | ms/batch 13.36 | loss 0.00011343\n",
      "| Epoch  25 |   250/  829 batches | lr 0.00066 | ms/batch 11.75 | loss 0.00011580\n",
      "| Epoch  25 |   300/  829 batches | lr 0.00066 | ms/batch 13.42 | loss 0.00012928\n",
      "| Epoch  25 |   350/  829 batches | lr 0.00066 | ms/batch 11.68 | loss 0.00012423\n",
      "| Epoch  25 |   400/  829 batches | lr 0.00066 | ms/batch 11.58 | loss 0.00012979\n",
      "| Epoch  25 |   450/  829 batches | lr 0.00066 | ms/batch 11.65 | loss 0.00013533\n",
      "| Epoch  25 |   500/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00019617\n",
      "| Epoch  25 |   550/  829 batches | lr 0.00066 | ms/batch 13.15 | loss 0.00019169\n",
      "| Epoch  25 |   600/  829 batches | lr 0.00066 | ms/batch 11.62 | loss 0.00013279\n",
      "| Epoch  25 |   650/  829 batches | lr 0.00066 | ms/batch 11.65 | loss 0.00012711\n",
      "| Epoch  25 |   700/  829 batches | lr 0.00066 | ms/batch 13.16 | loss 0.00011687\n",
      "| Epoch  25 |   750/  829 batches | lr 0.00066 | ms/batch 11.57 | loss 0.00011408\n",
      "| Epoch  25 |   800/  829 batches | lr 0.00066 | ms/batch 11.57 | loss 0.00011878\n",
      "\n",
      "Val set: Average loss: 0.00016642\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  26 |    50/  829 batches | lr 0.00066 | ms/batch 13.56 | loss 0.00015313\n",
      "| Epoch  26 |   100/  829 batches | lr 0.00066 | ms/batch 11.62 | loss 0.00012747\n",
      "| Epoch  26 |   150/  829 batches | lr 0.00066 | ms/batch 11.60 | loss 0.00011802\n",
      "| Epoch  26 |   200/  829 batches | lr 0.00066 | ms/batch 11.57 | loss 0.00012039\n",
      "| Epoch  26 |   250/  829 batches | lr 0.00066 | ms/batch 11.57 | loss 0.00014616\n",
      "| Epoch  26 |   300/  829 batches | lr 0.00066 | ms/batch 13.19 | loss 0.00017408\n",
      "| Epoch  26 |   350/  829 batches | lr 0.00066 | ms/batch 11.64 | loss 0.00014182\n",
      "| Epoch  26 |   400/  829 batches | lr 0.00066 | ms/batch 11.63 | loss 0.00014077\n",
      "| Epoch  26 |   450/  829 batches | lr 0.00066 | ms/batch 13.22 | loss 0.00015446\n",
      "| Epoch  26 |   500/  829 batches | lr 0.00066 | ms/batch 11.60 | loss 0.00014225\n",
      "| Epoch  26 |   550/  829 batches | lr 0.00066 | ms/batch 11.58 | loss 0.00016553\n",
      "| Epoch  26 |   600/  829 batches | lr 0.00066 | ms/batch 11.56 | loss 0.00014935\n",
      "| Epoch  26 |   650/  829 batches | lr 0.00066 | ms/batch 11.58 | loss 0.00012860\n",
      "| Epoch  26 |   700/  829 batches | lr 0.00066 | ms/batch 13.19 | loss 0.00015601\n",
      "| Epoch  26 |   750/  829 batches | lr 0.00066 | ms/batch 11.64 | loss 0.00013422\n",
      "| Epoch  26 |   800/  829 batches | lr 0.00066 | ms/batch 13.21 | loss 0.00011263\n",
      "\n",
      "Val set: Average loss: 0.00012414\n",
      "\n",
      "| Epoch  27 |    50/  829 batches | lr 0.00066 | ms/batch 12.08 | loss 0.00012287\n",
      "| Epoch  27 |   100/  829 batches | lr 0.00066 | ms/batch 11.88 | loss 0.00011731\n",
      "| Epoch  27 |   150/  829 batches | lr 0.00066 | ms/batch 13.27 | loss 0.00011359\n",
      "| Epoch  27 |   200/  829 batches | lr 0.00066 | ms/batch 11.72 | loss 0.00016948\n",
      "| Epoch  27 |   250/  829 batches | lr 0.00066 | ms/batch 11.72 | loss 0.00020535\n",
      "| Epoch  27 |   300/  829 batches | lr 0.00066 | ms/batch 11.74 | loss 0.00015752\n",
      "| Epoch  27 |   350/  829 batches | lr 0.00066 | ms/batch 13.24 | loss 0.00013618\n",
      "| Epoch  27 |   400/  829 batches | lr 0.00066 | ms/batch 11.69 | loss 0.00013817\n",
      "| Epoch  27 |   450/  829 batches | lr 0.00066 | ms/batch 11.73 | loss 0.00013944\n",
      "| Epoch  27 |   500/  829 batches | lr 0.00066 | ms/batch 13.26 | loss 0.00013125\n",
      "| Epoch  27 |   550/  829 batches | lr 0.00066 | ms/batch 11.57 | loss 0.00019065\n",
      "| Epoch  27 |   600/  829 batches | lr 0.00066 | ms/batch 11.58 | loss 0.00012563\n",
      "| Epoch  27 |   650/  829 batches | lr 0.00066 | ms/batch 11.58 | loss 0.00010947\n",
      "| Epoch  27 |   700/  829 batches | lr 0.00066 | ms/batch 11.59 | loss 0.00012780\n",
      "| Epoch  27 |   750/  829 batches | lr 0.00066 | ms/batch 13.17 | loss 0.00013058\n",
      "| Epoch  27 |   800/  829 batches | lr 0.00066 | ms/batch 11.62 | loss 0.00011339\n",
      "\n",
      "Val set: Average loss: 0.00016568\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  28 |    50/  829 batches | lr 0.00066 | ms/batch 13.53 | loss 0.00016105\n",
      "| Epoch  28 |   100/  829 batches | lr 0.00066 | ms/batch 11.65 | loss 0.00011724\n",
      "| Epoch  28 |   150/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00012725\n",
      "| Epoch  28 |   200/  829 batches | lr 0.00066 | ms/batch 13.15 | loss 0.00013568\n",
      "| Epoch  28 |   250/  829 batches | lr 0.00066 | ms/batch 11.61 | loss 0.00020625\n",
      "| Epoch  28 |   300/  829 batches | lr 0.00066 | ms/batch 11.64 | loss 0.00020258\n",
      "| Epoch  28 |   350/  829 batches | lr 0.00066 | ms/batch 11.62 | loss 0.00014557\n",
      "| Epoch  28 |   400/  829 batches | lr 0.00066 | ms/batch 11.58 | loss 0.00013172\n",
      "| Epoch  28 |   450/  829 batches | lr 0.00066 | ms/batch 13.24 | loss 0.00012396\n",
      "| Epoch  28 |   500/  829 batches | lr 0.00066 | ms/batch 11.75 | loss 0.00012400\n",
      "| Epoch  28 |   550/  829 batches | lr 0.00066 | ms/batch 13.19 | loss 0.00024134\n",
      "| Epoch  28 |   600/  829 batches | lr 0.00066 | ms/batch 11.58 | loss 0.00018068\n",
      "| Epoch  28 |   650/  829 batches | lr 0.00066 | ms/batch 11.58 | loss 0.00011721\n",
      "| Epoch  28 |   700/  829 batches | lr 0.00066 | ms/batch 11.59 | loss 0.00012658\n",
      "| Epoch  28 |   750/  829 batches | lr 0.00066 | ms/batch 11.58 | loss 0.00014399\n",
      "| Epoch  28 |   800/  829 batches | lr 0.00066 | ms/batch 13.15 | loss 0.00011675\n",
      "\n",
      "Val set: Average loss: 0.00016554\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  29 |    50/  829 batches | lr 0.00066 | ms/batch 12.07 | loss 0.00015461\n",
      "| Epoch  29 |   100/  829 batches | lr 0.00066 | ms/batch 11.65 | loss 0.00012904\n",
      "| Epoch  29 |   150/  829 batches | lr 0.00066 | ms/batch 11.60 | loss 0.00013314\n",
      "| Epoch  29 |   200/  829 batches | lr 0.00066 | ms/batch 13.19 | loss 0.00010907\n",
      "| Epoch  29 |   250/  829 batches | lr 0.00066 | ms/batch 11.61 | loss 0.00012869\n",
      "| Epoch  29 |   300/  829 batches | lr 0.00066 | ms/batch 11.62 | loss 0.00010969\n",
      "| Epoch  29 |   350/  829 batches | lr 0.00066 | ms/batch 13.15 | loss 0.00012759\n",
      "| Epoch  29 |   400/  829 batches | lr 0.00066 | ms/batch 11.59 | loss 0.00012116\n",
      "| Epoch  29 |   450/  829 batches | lr 0.00066 | ms/batch 11.59 | loss 0.00011821\n",
      "| Epoch  29 |   500/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00011389\n",
      "| Epoch  29 |   550/  829 batches | lr 0.00066 | ms/batch 13.15 | loss 0.00017865\n",
      "| Epoch  29 |   600/  829 batches | lr 0.00066 | ms/batch 11.64 | loss 0.00014802\n",
      "| Epoch  29 |   650/  829 batches | lr 0.00066 | ms/batch 11.59 | loss 0.00010643\n",
      "| Epoch  29 |   700/  829 batches | lr 0.00066 | ms/batch 13.30 | loss 0.00010750\n",
      "| Epoch  29 |   750/  829 batches | lr 0.00066 | ms/batch 11.61 | loss 0.00012181\n",
      "| Epoch  29 |   800/  829 batches | lr 0.00066 | ms/batch 11.58 | loss 0.00009984\n",
      "\n",
      "Val set: Average loss: 0.00013273\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  30 |    50/  829 batches | lr 0.00066 | ms/batch 13.90 | loss 0.00014033\n",
      "| Epoch  30 |   100/  829 batches | lr 0.00066 | ms/batch 12.74 | loss 0.00010752\n",
      "| Epoch  30 |   150/  829 batches | lr 0.00066 | ms/batch 11.95 | loss 0.00011373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch  30 |   200/  829 batches | lr 0.00066 | ms/batch 12.11 | loss 0.00009906\n",
      "| Epoch  30 |   250/  829 batches | lr 0.00066 | ms/batch 11.79 | loss 0.00010696\n",
      "| Epoch  30 |   300/  829 batches | lr 0.00066 | ms/batch 13.76 | loss 0.00010187\n",
      "| Epoch  30 |   350/  829 batches | lr 0.00066 | ms/batch 11.85 | loss 0.00010223\n",
      "| Epoch  30 |   400/  829 batches | lr 0.00066 | ms/batch 11.72 | loss 0.00010768\n",
      "| Epoch  30 |   450/  829 batches | lr 0.00066 | ms/batch 13.26 | loss 0.00009770\n",
      "| Epoch  30 |   500/  829 batches | lr 0.00066 | ms/batch 11.90 | loss 0.00010331\n",
      "| Epoch  30 |   550/  829 batches | lr 0.00066 | ms/batch 11.71 | loss 0.00010443\n",
      "| Epoch  30 |   600/  829 batches | lr 0.00066 | ms/batch 11.66 | loss 0.00010643\n",
      "| Epoch  30 |   650/  829 batches | lr 0.00066 | ms/batch 12.04 | loss 0.00010195\n",
      "| Epoch  30 |   700/  829 batches | lr 0.00066 | ms/batch 13.72 | loss 0.00009822\n",
      "| Epoch  30 |   750/  829 batches | lr 0.00066 | ms/batch 11.79 | loss 0.00010781\n",
      "| Epoch  30 |   800/  829 batches | lr 0.00066 | ms/batch 13.57 | loss 0.00010397\n",
      "\n",
      "Val set: Average loss: 0.00010775\n",
      "\n",
      "| Epoch  31 |    50/  829 batches | lr 0.00066 | ms/batch 12.52 | loss 0.00010403\n",
      "| Epoch  31 |   100/  829 batches | lr 0.00066 | ms/batch 11.95 | loss 0.00010219\n",
      "| Epoch  31 |   150/  829 batches | lr 0.00066 | ms/batch 13.59 | loss 0.00009591\n",
      "| Epoch  31 |   200/  829 batches | lr 0.00066 | ms/batch 12.18 | loss 0.00009957\n",
      "| Epoch  31 |   250/  829 batches | lr 0.00066 | ms/batch 12.03 | loss 0.00009365\n",
      "| Epoch  31 |   300/  829 batches | lr 0.00066 | ms/batch 11.62 | loss 0.00011582\n",
      "| Epoch  31 |   350/  829 batches | lr 0.00066 | ms/batch 13.17 | loss 0.00011220\n",
      "| Epoch  31 |   400/  829 batches | lr 0.00066 | ms/batch 11.70 | loss 0.00011576\n",
      "| Epoch  31 |   450/  829 batches | lr 0.00066 | ms/batch 11.77 | loss 0.00009883\n",
      "| Epoch  31 |   500/  829 batches | lr 0.00066 | ms/batch 14.47 | loss 0.00009730\n",
      "| Epoch  31 |   550/  829 batches | lr 0.00066 | ms/batch 11.76 | loss 0.00010170\n",
      "| Epoch  31 |   600/  829 batches | lr 0.00066 | ms/batch 11.57 | loss 0.00014498\n",
      "| Epoch  31 |   650/  829 batches | lr 0.00066 | ms/batch 11.62 | loss 0.00021445\n",
      "| Epoch  31 |   700/  829 batches | lr 0.00066 | ms/batch 11.63 | loss 0.00012995\n",
      "| Epoch  31 |   750/  829 batches | lr 0.00066 | ms/batch 13.47 | loss 0.00010929\n",
      "| Epoch  31 |   800/  829 batches | lr 0.00066 | ms/batch 12.22 | loss 0.00010541\n",
      "\n",
      "Val set: Average loss: 0.00010648\n",
      "\n",
      "| Epoch  32 |    50/  829 batches | lr 0.00066 | ms/batch 13.71 | loss 0.00010837\n",
      "| Epoch  32 |   100/  829 batches | lr 0.00066 | ms/batch 11.70 | loss 0.00010105\n",
      "| Epoch  32 |   150/  829 batches | lr 0.00066 | ms/batch 11.71 | loss 0.00010226\n",
      "| Epoch  32 |   200/  829 batches | lr 0.00066 | ms/batch 14.18 | loss 0.00009972\n",
      "| Epoch  32 |   250/  829 batches | lr 0.00066 | ms/batch 12.47 | loss 0.00009076\n",
      "| Epoch  32 |   300/  829 batches | lr 0.00066 | ms/batch 12.02 | loss 0.00010654\n",
      "| Epoch  32 |   350/  829 batches | lr 0.00066 | ms/batch 11.73 | loss 0.00010457\n",
      "| Epoch  32 |   400/  829 batches | lr 0.00066 | ms/batch 11.80 | loss 0.00011784\n",
      "| Epoch  32 |   450/  829 batches | lr 0.00066 | ms/batch 14.11 | loss 0.00012655\n",
      "| Epoch  32 |   500/  829 batches | lr 0.00066 | ms/batch 12.07 | loss 0.00011806\n",
      "| Epoch  32 |   550/  829 batches | lr 0.00066 | ms/batch 13.88 | loss 0.00014079\n",
      "| Epoch  32 |   600/  829 batches | lr 0.00066 | ms/batch 12.05 | loss 0.00013285\n",
      "| Epoch  32 |   650/  829 batches | lr 0.00066 | ms/batch 11.89 | loss 0.00011315\n",
      "| Epoch  32 |   700/  829 batches | lr 0.00066 | ms/batch 11.78 | loss 0.00010180\n",
      "| Epoch  32 |   750/  829 batches | lr 0.00066 | ms/batch 11.77 | loss 0.00011560\n",
      "| Epoch  32 |   800/  829 batches | lr 0.00066 | ms/batch 14.06 | loss 0.00009730\n",
      "\n",
      "Val set: Average loss: 0.00009955\n",
      "\n",
      "| Epoch  33 |    50/  829 batches | lr 0.00066 | ms/batch 13.11 | loss 0.00011137\n",
      "| Epoch  33 |   100/  829 batches | lr 0.00066 | ms/batch 11.96 | loss 0.00011018\n",
      "| Epoch  33 |   150/  829 batches | lr 0.00066 | ms/batch 12.50 | loss 0.00010512\n",
      "| Epoch  33 |   200/  829 batches | lr 0.00066 | ms/batch 15.14 | loss 0.00011095\n",
      "| Epoch  33 |   250/  829 batches | lr 0.00066 | ms/batch 12.60 | loss 0.00015830\n",
      "| Epoch  33 |   300/  829 batches | lr 0.00066 | ms/batch 12.92 | loss 0.00011959\n",
      "| Epoch  33 |   350/  829 batches | lr 0.00066 | ms/batch 14.77 | loss 0.00010896\n",
      "| Epoch  33 |   400/  829 batches | lr 0.00066 | ms/batch 12.43 | loss 0.00012582\n",
      "| Epoch  33 |   450/  829 batches | lr 0.00066 | ms/batch 12.16 | loss 0.00011029\n",
      "| Epoch  33 |   500/  829 batches | lr 0.00066 | ms/batch 11.79 | loss 0.00012372\n",
      "| Epoch  33 |   550/  829 batches | lr 0.00066 | ms/batch 13.53 | loss 0.00013550\n",
      "| Epoch  33 |   600/  829 batches | lr 0.00066 | ms/batch 12.16 | loss 0.00013442\n",
      "| Epoch  33 |   650/  829 batches | lr 0.00066 | ms/batch 12.58 | loss 0.00012724\n",
      "| Epoch  33 |   700/  829 batches | lr 0.00066 | ms/batch 13.48 | loss 0.00012711\n",
      "| Epoch  33 |   750/  829 batches | lr 0.00066 | ms/batch 11.83 | loss 0.00013220\n",
      "| Epoch  33 |   800/  829 batches | lr 0.00066 | ms/batch 12.12 | loss 0.00010809\n",
      "\n",
      "Val set: Average loss: 0.00015731\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  34 |    50/  829 batches | lr 0.00066 | ms/batch 14.33 | loss 0.00014320\n",
      "| Epoch  34 |   100/  829 batches | lr 0.00066 | ms/batch 11.90 | loss 0.00012863\n",
      "| Epoch  34 |   150/  829 batches | lr 0.00066 | ms/batch 12.07 | loss 0.00010509\n",
      "| Epoch  34 |   200/  829 batches | lr 0.00066 | ms/batch 12.90 | loss 0.00009911\n",
      "| Epoch  34 |   250/  829 batches | lr 0.00066 | ms/batch 12.72 | loss 0.00012284\n",
      "| Epoch  34 |   300/  829 batches | lr 0.00066 | ms/batch 13.85 | loss 0.00012037\n",
      "| Epoch  34 |   350/  829 batches | lr 0.00066 | ms/batch 12.38 | loss 0.00011919\n",
      "| Epoch  34 |   400/  829 batches | lr 0.00066 | ms/batch 11.90 | loss 0.00009612\n",
      "| Epoch  34 |   450/  829 batches | lr 0.00066 | ms/batch 13.58 | loss 0.00010962\n",
      "| Epoch  34 |   500/  829 batches | lr 0.00066 | ms/batch 11.89 | loss 0.00010461\n",
      "| Epoch  34 |   550/  829 batches | lr 0.00066 | ms/batch 12.21 | loss 0.00013837\n",
      "| Epoch  34 |   600/  829 batches | lr 0.00066 | ms/batch 11.81 | loss 0.00011242\n",
      "| Epoch  34 |   650/  829 batches | lr 0.00066 | ms/batch 12.02 | loss 0.00009835\n",
      "| Epoch  34 |   700/  829 batches | lr 0.00066 | ms/batch 13.92 | loss 0.00010152\n",
      "| Epoch  34 |   750/  829 batches | lr 0.00066 | ms/batch 12.05 | loss 0.00013548\n",
      "| Epoch  34 |   800/  829 batches | lr 0.00066 | ms/batch 13.83 | loss 0.00011637\n",
      "\n",
      "Val set: Average loss: 0.00014608\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  35 |    50/  829 batches | lr 0.00066 | ms/batch 13.11 | loss 0.00015642\n",
      "| Epoch  35 |   100/  829 batches | lr 0.00066 | ms/batch 12.19 | loss 0.00012384\n",
      "| Epoch  35 |   150/  829 batches | lr 0.00066 | ms/batch 14.10 | loss 0.00010420\n",
      "| Epoch  35 |   200/  829 batches | lr 0.00066 | ms/batch 13.10 | loss 0.00010409\n",
      "| Epoch  35 |   250/  829 batches | lr 0.00066 | ms/batch 12.22 | loss 0.00011968\n",
      "| Epoch  35 |   300/  829 batches | lr 0.00066 | ms/batch 12.72 | loss 0.00011655\n",
      "| Epoch  35 |   350/  829 batches | lr 0.00066 | ms/batch 14.25 | loss 0.00013917\n",
      "| Epoch  35 |   400/  829 batches | lr 0.00066 | ms/batch 12.29 | loss 0.00011212\n",
      "| Epoch  35 |   450/  829 batches | lr 0.00066 | ms/batch 12.18 | loss 0.00010215\n",
      "| Epoch  35 |   500/  829 batches | lr 0.00066 | ms/batch 13.90 | loss 0.00010023\n",
      "| Epoch  35 |   550/  829 batches | lr 0.00066 | ms/batch 12.02 | loss 0.00008597\n",
      "| Epoch  35 |   600/  829 batches | lr 0.00066 | ms/batch 12.01 | loss 0.00008432\n",
      "| Epoch  35 |   650/  829 batches | lr 0.00066 | ms/batch 11.85 | loss 0.00008595\n",
      "| Epoch  35 |   700/  829 batches | lr 0.00066 | ms/batch 11.78 | loss 0.00009874\n",
      "| Epoch  35 |   750/  829 batches | lr 0.00066 | ms/batch 13.40 | loss 0.00012571\n",
      "| Epoch  35 |   800/  829 batches | lr 0.00066 | ms/batch 11.98 | loss 0.00011658\n",
      "\n",
      "Val set: Average loss: 0.00011497\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  36 |    50/  829 batches | lr 0.00066 | ms/batch 13.60 | loss 0.00010872\n",
      "| Epoch  36 |   100/  829 batches | lr 0.00066 | ms/batch 11.83 | loss 0.00009411\n",
      "| Epoch  36 |   150/  829 batches | lr 0.00066 | ms/batch 12.00 | loss 0.00008794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch  36 |   200/  829 batches | lr 0.00066 | ms/batch 13.66 | loss 0.00008818\n",
      "| Epoch  36 |   250/  829 batches | lr 0.00066 | ms/batch 12.00 | loss 0.00009410\n",
      "| Epoch  36 |   300/  829 batches | lr 0.00066 | ms/batch 12.04 | loss 0.00008642\n",
      "| Epoch  36 |   350/  829 batches | lr 0.00066 | ms/batch 11.96 | loss 0.00008950\n",
      "| Epoch  36 |   400/  829 batches | lr 0.00066 | ms/batch 12.11 | loss 0.00009992\n",
      "| Epoch  36 |   450/  829 batches | lr 0.00066 | ms/batch 13.94 | loss 0.00008031\n",
      "| Epoch  36 |   500/  829 batches | lr 0.00066 | ms/batch 11.82 | loss 0.00007660\n",
      "| Epoch  36 |   550/  829 batches | lr 0.00066 | ms/batch 13.46 | loss 0.00007883\n",
      "| Epoch  36 |   600/  829 batches | lr 0.00066 | ms/batch 11.73 | loss 0.00008326\n",
      "| Epoch  36 |   650/  829 batches | lr 0.00066 | ms/batch 11.91 | loss 0.00007927\n",
      "| Epoch  36 |   700/  829 batches | lr 0.00066 | ms/batch 12.10 | loss 0.00008287\n",
      "| Epoch  36 |   750/  829 batches | lr 0.00066 | ms/batch 12.16 | loss 0.00008726\n",
      "| Epoch  36 |   800/  829 batches | lr 0.00066 | ms/batch 14.03 | loss 0.00008608\n",
      "\n",
      "Val set: Average loss: 0.00009607\n",
      "\n",
      "| Epoch  37 |    50/  829 batches | lr 0.00066 | ms/batch 12.45 | loss 0.00008254\n",
      "| Epoch  37 |   100/  829 batches | lr 0.00066 | ms/batch 11.85 | loss 0.00008118\n",
      "| Epoch  37 |   150/  829 batches | lr 0.00066 | ms/batch 12.07 | loss 0.00008380\n",
      "| Epoch  37 |   200/  829 batches | lr 0.00066 | ms/batch 13.45 | loss 0.00008216\n",
      "| Epoch  37 |   250/  829 batches | lr 0.00066 | ms/batch 11.95 | loss 0.00009157\n",
      "| Epoch  37 |   300/  829 batches | lr 0.00066 | ms/batch 12.67 | loss 0.00009971\n",
      "| Epoch  37 |   350/  829 batches | lr 0.00066 | ms/batch 16.18 | loss 0.00008824\n",
      "| Epoch  37 |   400/  829 batches | lr 0.00066 | ms/batch 12.73 | loss 0.00008150\n",
      "| Epoch  37 |   450/  829 batches | lr 0.00066 | ms/batch 14.19 | loss 0.00008432\n",
      "| Epoch  37 |   500/  829 batches | lr 0.00066 | ms/batch 13.38 | loss 0.00008558\n",
      "| Epoch  37 |   550/  829 batches | lr 0.00066 | ms/batch 15.20 | loss 0.00008438\n",
      "| Epoch  37 |   600/  829 batches | lr 0.00066 | ms/batch 12.68 | loss 0.00009242\n",
      "| Epoch  37 |   650/  829 batches | lr 0.00066 | ms/batch 12.73 | loss 0.00010695\n",
      "| Epoch  37 |   700/  829 batches | lr 0.00066 | ms/batch 13.96 | loss 0.00009659\n",
      "| Epoch  37 |   750/  829 batches | lr 0.00066 | ms/batch 12.00 | loss 0.00012294\n",
      "| Epoch  37 |   800/  829 batches | lr 0.00066 | ms/batch 12.46 | loss 0.00011060\n",
      "\n",
      "Val set: Average loss: 0.00010251\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  38 |    50/  829 batches | lr 0.00066 | ms/batch 16.02 | loss 0.00008889\n",
      "| Epoch  38 |   100/  829 batches | lr 0.00066 | ms/batch 14.30 | loss 0.00009180\n",
      "| Epoch  38 |   150/  829 batches | lr 0.00066 | ms/batch 13.87 | loss 0.00009720\n",
      "| Epoch  38 |   200/  829 batches | lr 0.00066 | ms/batch 12.45 | loss 0.00010779\n",
      "| Epoch  38 |   250/  829 batches | lr 0.00066 | ms/batch 12.54 | loss 0.00011198\n",
      "| Epoch  38 |   300/  829 batches | lr 0.00066 | ms/batch 14.96 | loss 0.00010897\n",
      "| Epoch  38 |   350/  829 batches | lr 0.00066 | ms/batch 14.05 | loss 0.00009132\n",
      "| Epoch  38 |   400/  829 batches | lr 0.00066 | ms/batch 13.10 | loss 0.00008632\n",
      "| Epoch  38 |   450/  829 batches | lr 0.00066 | ms/batch 14.31 | loss 0.00008736\n",
      "| Epoch  38 |   500/  829 batches | lr 0.00066 | ms/batch 12.93 | loss 0.00007961\n",
      "| Epoch  38 |   550/  829 batches | lr 0.00066 | ms/batch 12.87 | loss 0.00008698\n",
      "| Epoch  38 |   600/  829 batches | lr 0.00066 | ms/batch 13.46 | loss 0.00009452\n",
      "| Epoch  38 |   650/  829 batches | lr 0.00066 | ms/batch 12.55 | loss 0.00009317\n",
      "| Epoch  38 |   700/  829 batches | lr 0.00066 | ms/batch 14.04 | loss 0.00009535\n",
      "| Epoch  38 |   750/  829 batches | lr 0.00066 | ms/batch 12.51 | loss 0.00010103\n",
      "| Epoch  38 |   800/  829 batches | lr 0.00066 | ms/batch 15.00 | loss 0.00010026\n",
      "\n",
      "Val set: Average loss: 0.00010221\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  39 |    50/  829 batches | lr 0.00066 | ms/batch 14.20 | loss 0.00009358\n",
      "| Epoch  39 |   100/  829 batches | lr 0.00066 | ms/batch 13.95 | loss 0.00009083\n",
      "| Epoch  39 |   150/  829 batches | lr 0.00066 | ms/batch 15.72 | loss 0.00007838\n",
      "| Epoch  39 |   200/  829 batches | lr 0.00066 | ms/batch 13.14 | loss 0.00008717\n",
      "| Epoch  39 |   250/  829 batches | lr 0.00066 | ms/batch 13.89 | loss 0.00010300\n",
      "| Epoch  39 |   300/  829 batches | lr 0.00066 | ms/batch 13.01 | loss 0.00011382\n",
      "| Epoch  39 |   350/  829 batches | lr 0.00066 | ms/batch 14.25 | loss 0.00012311\n",
      "| Epoch  39 |   400/  829 batches | lr 0.00066 | ms/batch 13.19 | loss 0.00011372\n",
      "| Epoch  39 |   450/  829 batches | lr 0.00066 | ms/batch 13.40 | loss 0.00008817\n",
      "| Epoch  39 |   500/  829 batches | lr 0.00066 | ms/batch 16.46 | loss 0.00008623\n",
      "| Epoch  39 |   550/  829 batches | lr 0.00066 | ms/batch 12.54 | loss 0.00010870\n",
      "| Epoch  39 |   600/  829 batches | lr 0.00066 | ms/batch 13.67 | loss 0.00015024\n",
      "| Epoch  39 |   650/  829 batches | lr 0.00066 | ms/batch 12.59 | loss 0.00010821\n",
      "| Epoch  39 |   700/  829 batches | lr 0.00066 | ms/batch 12.29 | loss 0.00010610\n",
      "| Epoch  39 |   750/  829 batches | lr 0.00066 | ms/batch 14.80 | loss 0.00010135\n",
      "| Epoch  39 |   800/  829 batches | lr 0.00066 | ms/batch 12.22 | loss 0.00009136\n",
      "\n",
      "Val set: Average loss: 0.00015808\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  40 |    50/  829 batches | lr 0.00066 | ms/batch 15.48 | loss 0.00009722\n",
      "| Epoch  40 |   100/  829 batches | lr 0.00066 | ms/batch 13.11 | loss 0.00008748\n",
      "| Epoch  40 |   150/  829 batches | lr 0.00066 | ms/batch 13.13 | loss 0.00008645\n",
      "| Epoch  40 |   200/  829 batches | lr 0.00066 | ms/batch 14.54 | loss 0.00008697\n",
      "| Epoch  40 |   250/  829 batches | lr 0.00066 | ms/batch 12.42 | loss 0.00009653\n",
      "| Epoch  40 |   300/  829 batches | lr 0.00066 | ms/batch 12.43 | loss 0.00008623\n",
      "| Epoch  40 |   350/  829 batches | lr 0.00066 | ms/batch 12.90 | loss 0.00010385\n",
      "| Epoch  40 |   400/  829 batches | lr 0.00066 | ms/batch 13.41 | loss 0.00011336\n",
      "| Epoch  40 |   450/  829 batches | lr 0.00066 | ms/batch 14.14 | loss 0.00008697\n",
      "| Epoch  40 |   500/  829 batches | lr 0.00066 | ms/batch 12.68 | loss 0.00009073\n",
      "| Epoch  40 |   550/  829 batches | lr 0.00066 | ms/batch 12.96 | loss 0.00014098\n",
      "| Epoch  40 |   600/  829 batches | lr 0.00066 | ms/batch 15.49 | loss 0.00010921\n",
      "| Epoch  40 |   650/  829 batches | lr 0.00066 | ms/batch 12.59 | loss 0.00010831\n",
      "| Epoch  40 |   700/  829 batches | lr 0.00066 | ms/batch 12.79 | loss 0.00009627\n",
      "| Epoch  40 |   750/  829 batches | lr 0.00066 | ms/batch 12.70 | loss 0.00011129\n",
      "| Epoch  40 |   800/  829 batches | lr 0.00066 | ms/batch 14.65 | loss 0.00010105\n",
      "\n",
      "Val set: Average loss: 0.00013981\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch  41 |    50/  829 batches | lr 0.00066 | ms/batch 13.81 | loss 0.00011208\n",
      "| Epoch  41 |   100/  829 batches | lr 0.00066 | ms/batch 13.26 | loss 0.00008623\n",
      "| Epoch  41 |   150/  829 batches | lr 0.00066 | ms/batch 12.50 | loss 0.00007761\n",
      "| Epoch  41 |   200/  829 batches | lr 0.00066 | ms/batch 14.08 | loss 0.00008747\n",
      "| Epoch  41 |   250/  829 batches | lr 0.00066 | ms/batch 12.30 | loss 0.00009682\n",
      "| Epoch  41 |   300/  829 batches | lr 0.00066 | ms/batch 13.05 | loss 0.00008797\n",
      "| Epoch  41 |   350/  829 batches | lr 0.00066 | ms/batch 14.07 | loss 0.00012238\n",
      "| Epoch  41 |   400/  829 batches | lr 0.00066 | ms/batch 12.16 | loss 0.00008646\n",
      "| Epoch  41 |   450/  829 batches | lr 0.00066 | ms/batch 12.33 | loss 0.00008080\n",
      "| Epoch  41 |   500/  829 batches | lr 0.00066 | ms/batch 12.15 | loss 0.00010209\n",
      "| Epoch  41 |   550/  829 batches | lr 0.00066 | ms/batch 14.15 | loss 0.00009319\n",
      "| Epoch  41 |   600/  829 batches | lr 0.00066 | ms/batch 12.77 | loss 0.00010374\n",
      "| Epoch  41 |   650/  829 batches | lr 0.00066 | ms/batch 13.23 | loss 0.00010128\n",
      "| Epoch  41 |   700/  829 batches | lr 0.00066 | ms/batch 14.95 | loss 0.00010043\n",
      "| Epoch  41 |   750/  829 batches | lr 0.00066 | ms/batch 12.98 | loss 0.00011836\n",
      "| Epoch  41 |   800/  829 batches | lr 0.00066 | ms/batch 12.83 | loss 0.00010699\n",
      "\n",
      "Val set: Average loss: 0.00010667\n",
      "\n",
      "EarlyStopping counter: 5 out of 20\n",
      "| Epoch  42 |    50/  829 batches | lr 0.00066 | ms/batch 15.52 | loss 0.00010879\n",
      "| Epoch  42 |   100/  829 batches | lr 0.00066 | ms/batch 12.91 | loss 0.00007860\n",
      "| Epoch  42 |   150/  829 batches | lr 0.00066 | ms/batch 13.43 | loss 0.00008187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch  42 |   200/  829 batches | lr 0.00066 | ms/batch 12.95 | loss 0.00009282\n",
      "| Epoch  42 |   250/  829 batches | lr 0.00066 | ms/batch 13.59 | loss 0.00008556\n",
      "| Epoch  42 |   300/  829 batches | lr 0.00066 | ms/batch 15.60 | loss 0.00009264\n",
      "| Epoch  42 |   350/  829 batches | lr 0.00066 | ms/batch 15.03 | loss 0.00011838\n",
      "| Epoch  42 |   400/  829 batches | lr 0.00066 | ms/batch 12.72 | loss 0.00010436\n",
      "| Epoch  42 |   450/  829 batches | lr 0.00066 | ms/batch 15.25 | loss 0.00007769\n",
      "| Epoch  42 |   500/  829 batches | lr 0.00066 | ms/batch 12.32 | loss 0.00008677\n",
      "| Epoch  42 |   550/  829 batches | lr 0.00066 | ms/batch 12.85 | loss 0.00010427\n",
      "| Epoch  42 |   600/  829 batches | lr 0.00066 | ms/batch 12.63 | loss 0.00009936\n",
      "| Epoch  42 |   650/  829 batches | lr 0.00066 | ms/batch 13.07 | loss 0.00009623\n",
      "| Epoch  42 |   700/  829 batches | lr 0.00066 | ms/batch 14.37 | loss 0.00009501\n",
      "| Epoch  42 |   750/  829 batches | lr 0.00066 | ms/batch 12.95 | loss 0.00009018\n",
      "| Epoch  42 |   800/  829 batches | lr 0.00066 | ms/batch 15.01 | loss 0.00008022\n",
      "\n",
      "Val set: Average loss: 0.00010957\n",
      "\n",
      "EarlyStopping counter: 6 out of 20\n",
      "| Epoch  43 |    50/  829 batches | lr 0.00066 | ms/batch 12.68 | loss 0.00009289\n",
      "| Epoch  43 |   100/  829 batches | lr 0.00066 | ms/batch 11.98 | loss 0.00007491\n",
      "| Epoch  43 |   150/  829 batches | lr 0.00066 | ms/batch 13.93 | loss 0.00007485\n",
      "| Epoch  43 |   200/  829 batches | lr 0.00066 | ms/batch 12.15 | loss 0.00009085\n",
      "| Epoch  43 |   250/  829 batches | lr 0.00066 | ms/batch 12.19 | loss 0.00008570\n",
      "| Epoch  43 |   300/  829 batches | lr 0.00066 | ms/batch 12.25 | loss 0.00008887\n",
      "| Epoch  43 |   350/  829 batches | lr 0.00066 | ms/batch 12.12 | loss 0.00010468\n",
      "| Epoch  43 |   400/  829 batches | lr 0.00066 | ms/batch 13.89 | loss 0.00010355\n",
      "| Epoch  43 |   450/  829 batches | lr 0.00066 | ms/batch 12.24 | loss 0.00007740\n",
      "| Epoch  43 |   500/  829 batches | lr 0.00066 | ms/batch 13.81 | loss 0.00007851\n",
      "| Epoch  43 |   550/  829 batches | lr 0.00066 | ms/batch 12.28 | loss 0.00009015\n",
      "| Epoch  43 |   600/  829 batches | lr 0.00066 | ms/batch 12.01 | loss 0.00008346\n",
      "| Epoch  43 |   650/  829 batches | lr 0.00066 | ms/batch 12.17 | loss 0.00008354\n",
      "| Epoch  43 |   700/  829 batches | lr 0.00066 | ms/batch 12.47 | loss 0.00007779\n",
      "| Epoch  43 |   750/  829 batches | lr 0.00066 | ms/batch 14.13 | loss 0.00007356\n",
      "| Epoch  43 |   800/  829 batches | lr 0.00066 | ms/batch 12.42 | loss 0.00007074\n",
      "\n",
      "Val set: Average loss: 0.00009607\n",
      "\n",
      "EarlyStopping counter: 7 out of 20\n",
      "| Epoch  44 |    50/  829 batches | lr 0.00066 | ms/batch 14.05 | loss 0.00007808\n",
      "| Epoch  44 |   100/  829 batches | lr 0.00066 | ms/batch 12.12 | loss 0.00006441\n",
      "| Epoch  44 |   150/  829 batches | lr 0.00066 | ms/batch 12.27 | loss 0.00006678\n",
      "| Epoch  44 |   200/  829 batches | lr 0.00066 | ms/batch 13.81 | loss 0.00007505\n",
      "| Epoch  44 |   250/  829 batches | lr 0.00066 | ms/batch 12.16 | loss 0.00007350\n",
      "| Epoch  44 |   300/  829 batches | lr 0.00066 | ms/batch 12.11 | loss 0.00008117\n",
      "| Epoch  44 |   350/  829 batches | lr 0.00066 | ms/batch 11.96 | loss 0.00007907\n",
      "| Epoch  44 |   400/  829 batches | lr 0.00066 | ms/batch 11.87 | loss 0.00007237\n",
      "| Epoch  44 |   450/  829 batches | lr 0.00066 | ms/batch 14.00 | loss 0.00006473\n",
      "| Epoch  44 |   500/  829 batches | lr 0.00066 | ms/batch 12.32 | loss 0.00007459\n",
      "| Epoch  44 |   550/  829 batches | lr 0.00066 | ms/batch 12.10 | loss 0.00008150\n",
      "| Epoch  44 |   600/  829 batches | lr 0.00066 | ms/batch 13.79 | loss 0.00008836\n",
      "| Epoch  44 |   650/  829 batches | lr 0.00066 | ms/batch 11.86 | loss 0.00007670\n",
      "| Epoch  44 |   700/  829 batches | lr 0.00066 | ms/batch 12.33 | loss 0.00007958\n",
      "| Epoch  44 |   750/  829 batches | lr 0.00066 | ms/batch 12.10 | loss 0.00007674\n",
      "| Epoch  44 |   800/  829 batches | lr 0.00066 | ms/batch 13.53 | loss 0.00006970\n",
      "\n",
      "Val set: Average loss: 0.00009523\n",
      "\n",
      "| Epoch  45 |    50/  829 batches | lr 0.00066 | ms/batch 12.27 | loss 0.00007639\n",
      "| Epoch  45 |   100/  829 batches | lr 0.00066 | ms/batch 12.07 | loss 0.00007205\n",
      "| Epoch  45 |   150/  829 batches | lr 0.00066 | ms/batch 12.16 | loss 0.00007383\n",
      "| Epoch  45 |   200/  829 batches | lr 0.00066 | ms/batch 14.18 | loss 0.00008792\n",
      "| Epoch  45 |   250/  829 batches | lr 0.00066 | ms/batch 12.18 | loss 0.00008904\n",
      "| Epoch  45 |   300/  829 batches | lr 0.00066 | ms/batch 12.63 | loss 0.00008849\n",
      "| Epoch  45 |   350/  829 batches | lr 0.00066 | ms/batch 13.84 | loss 0.00008372\n",
      "| Epoch  45 |   400/  829 batches | lr 0.00066 | ms/batch 12.15 | loss 0.00007732\n",
      "| Epoch  45 |   450/  829 batches | lr 0.00066 | ms/batch 12.06 | loss 0.00007143\n",
      "| Epoch  45 |   500/  829 batches | lr 0.00066 | ms/batch 12.71 | loss 0.00007677\n",
      "| Epoch  45 |   550/  829 batches | lr 0.00066 | ms/batch 12.14 | loss 0.00008016\n",
      "| Epoch  45 |   600/  829 batches | lr 0.00066 | ms/batch 14.14 | loss 0.00008775\n",
      "| Epoch  45 |   650/  829 batches | lr 0.00066 | ms/batch 12.17 | loss 0.00008494\n",
      "| Epoch  45 |   700/  829 batches | lr 0.00066 | ms/batch 13.43 | loss 0.00009183\n",
      "| Epoch  45 |   750/  829 batches | lr 0.00066 | ms/batch 12.49 | loss 0.00009611\n",
      "| Epoch  45 |   800/  829 batches | lr 0.00066 | ms/batch 12.58 | loss 0.00008889\n",
      "\n",
      "Val set: Average loss: 0.00011200\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  46 |    50/  829 batches | lr 0.00066 | ms/batch 14.83 | loss 0.00009141\n",
      "| Epoch  46 |   100/  829 batches | lr 0.00066 | ms/batch 12.50 | loss 0.00007869\n",
      "| Epoch  46 |   150/  829 batches | lr 0.00066 | ms/batch 13.40 | loss 0.00009162\n",
      "| Epoch  46 |   200/  829 batches | lr 0.00066 | ms/batch 12.69 | loss 0.00008318\n",
      "| Epoch  46 |   250/  829 batches | lr 0.00066 | ms/batch 12.47 | loss 0.00009001\n",
      "| Epoch  46 |   300/  829 batches | lr 0.00066 | ms/batch 13.60 | loss 0.00008130\n",
      "| Epoch  46 |   350/  829 batches | lr 0.00066 | ms/batch 11.83 | loss 0.00008487\n",
      "| Epoch  46 |   400/  829 batches | lr 0.00066 | ms/batch 11.99 | loss 0.00009337\n",
      "| Epoch  46 |   450/  829 batches | lr 0.00066 | ms/batch 13.43 | loss 0.00007171\n",
      "| Epoch  46 |   500/  829 batches | lr 0.00066 | ms/batch 11.80 | loss 0.00007747\n",
      "| Epoch  46 |   550/  829 batches | lr 0.00066 | ms/batch 12.06 | loss 0.00007262\n",
      "| Epoch  46 |   600/  829 batches | lr 0.00066 | ms/batch 12.17 | loss 0.00009117\n",
      "| Epoch  46 |   650/  829 batches | lr 0.00066 | ms/batch 11.89 | loss 0.00008695\n",
      "| Epoch  46 |   700/  829 batches | lr 0.00066 | ms/batch 13.53 | loss 0.00008456\n",
      "| Epoch  46 |   750/  829 batches | lr 0.00066 | ms/batch 11.86 | loss 0.00008781\n",
      "| Epoch  46 |   800/  829 batches | lr 0.00066 | ms/batch 13.70 | loss 0.00008473\n",
      "\n",
      "Val set: Average loss: 0.00014854\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  47 |    50/  829 batches | lr 0.00066 | ms/batch 12.42 | loss 0.00008594\n",
      "| Epoch  47 |   100/  829 batches | lr 0.00066 | ms/batch 12.27 | loss 0.00007398\n",
      "| Epoch  47 |   150/  829 batches | lr 0.00066 | ms/batch 13.63 | loss 0.00008631\n",
      "| Epoch  47 |   200/  829 batches | lr 0.00066 | ms/batch 12.02 | loss 0.00008698\n",
      "| Epoch  47 |   250/  829 batches | lr 0.00066 | ms/batch 12.03 | loss 0.00008934\n",
      "| Epoch  47 |   300/  829 batches | lr 0.00066 | ms/batch 12.09 | loss 0.00008517\n",
      "| Epoch  47 |   350/  829 batches | lr 0.00066 | ms/batch 12.00 | loss 0.00008452\n",
      "| Epoch  47 |   400/  829 batches | lr 0.00066 | ms/batch 13.77 | loss 0.00008249\n",
      "| Epoch  47 |   450/  829 batches | lr 0.00066 | ms/batch 11.92 | loss 0.00006676\n",
      "| Epoch  47 |   500/  829 batches | lr 0.00066 | ms/batch 14.66 | loss 0.00007456\n",
      "| Epoch  47 |   550/  829 batches | lr 0.00066 | ms/batch 12.36 | loss 0.00009229\n",
      "| Epoch  47 |   600/  829 batches | lr 0.00066 | ms/batch 12.45 | loss 0.00008836\n",
      "| Epoch  47 |   650/  829 batches | lr 0.00066 | ms/batch 13.40 | loss 0.00009441\n",
      "| Epoch  47 |   700/  829 batches | lr 0.00066 | ms/batch 13.47 | loss 0.00009180\n",
      "| Epoch  47 |   750/  829 batches | lr 0.00066 | ms/batch 15.68 | loss 0.00009064\n",
      "| Epoch  47 |   800/  829 batches | lr 0.00066 | ms/batch 13.44 | loss 0.00008028\n",
      "\n",
      "Val set: Average loss: 0.00010794\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  48 |    50/  829 batches | lr 0.00066 | ms/batch 14.55 | loss 0.00009074\n",
      "| Epoch  48 |   100/  829 batches | lr 0.00066 | ms/batch 13.37 | loss 0.00009230\n",
      "| Epoch  48 |   150/  829 batches | lr 0.00066 | ms/batch 13.02 | loss 0.00008140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch  48 |   200/  829 batches | lr 0.00066 | ms/batch 14.05 | loss 0.00008801\n",
      "| Epoch  48 |   250/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00009008\n",
      "| Epoch  48 |   300/  829 batches | lr 0.00066 | ms/batch 11.85 | loss 0.00007988\n",
      "| Epoch  48 |   350/  829 batches | lr 0.00066 | ms/batch 11.74 | loss 0.00008458\n",
      "| Epoch  48 |   400/  829 batches | lr 0.00066 | ms/batch 11.78 | loss 0.00009112\n",
      "| Epoch  48 |   450/  829 batches | lr 0.00066 | ms/batch 13.48 | loss 0.00007525\n",
      "| Epoch  48 |   500/  829 batches | lr 0.00066 | ms/batch 11.93 | loss 0.00007591\n",
      "| Epoch  48 |   550/  829 batches | lr 0.00066 | ms/batch 11.89 | loss 0.00011302\n",
      "| Epoch  48 |   600/  829 batches | lr 0.00066 | ms/batch 13.59 | loss 0.00009387\n",
      "| Epoch  48 |   650/  829 batches | lr 0.00066 | ms/batch 11.68 | loss 0.00010002\n",
      "| Epoch  48 |   700/  829 batches | lr 0.00066 | ms/batch 12.34 | loss 0.00009049\n",
      "| Epoch  48 |   750/  829 batches | lr 0.00066 | ms/batch 11.97 | loss 0.00009299\n",
      "| Epoch  48 |   800/  829 batches | lr 0.00066 | ms/batch 13.96 | loss 0.00008324\n",
      "\n",
      "Val set: Average loss: 0.00009689\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch  49 |    50/  829 batches | lr 0.00066 | ms/batch 11.91 | loss 0.00008144\n",
      "| Epoch  49 |   100/  829 batches | lr 0.00066 | ms/batch 11.83 | loss 0.00007031\n",
      "| Epoch  49 |   150/  829 batches | lr 0.00066 | ms/batch 11.84 | loss 0.00007184\n",
      "| Epoch  49 |   200/  829 batches | lr 0.00066 | ms/batch 13.73 | loss 0.00008477\n",
      "| Epoch  49 |   250/  829 batches | lr 0.00066 | ms/batch 11.84 | loss 0.00010304\n",
      "| Epoch  49 |   300/  829 batches | lr 0.00066 | ms/batch 12.14 | loss 0.00009608\n",
      "| Epoch  49 |   350/  829 batches | lr 0.00066 | ms/batch 13.72 | loss 0.00007674\n",
      "| Epoch  49 |   400/  829 batches | lr 0.00066 | ms/batch 11.97 | loss 0.00008095\n",
      "| Epoch  49 |   450/  829 batches | lr 0.00066 | ms/batch 11.78 | loss 0.00006598\n",
      "| Epoch  49 |   500/  829 batches | lr 0.00066 | ms/batch 11.97 | loss 0.00007275\n",
      "| Epoch  49 |   550/  829 batches | lr 0.00066 | ms/batch 12.52 | loss 0.00008262\n",
      "| Epoch  49 |   600/  829 batches | lr 0.00066 | ms/batch 13.64 | loss 0.00009671\n",
      "| Epoch  49 |   650/  829 batches | lr 0.00066 | ms/batch 12.30 | loss 0.00010087\n",
      "| Epoch  49 |   700/  829 batches | lr 0.00066 | ms/batch 13.45 | loss 0.00008529\n",
      "| Epoch  49 |   750/  829 batches | lr 0.00066 | ms/batch 11.75 | loss 0.00008388\n",
      "| Epoch  49 |   800/  829 batches | lr 0.00066 | ms/batch 12.66 | loss 0.00008022\n",
      "\n",
      "Val set: Average loss: 0.00009198\n",
      "\n",
      "| Epoch  50 |    50/  829 batches | lr 0.00066 | ms/batch 12.19 | loss 0.00006435\n",
      "| Epoch  50 |   100/  829 batches | lr 0.00066 | ms/batch 13.59 | loss 0.00006472\n",
      "| Epoch  50 |   150/  829 batches | lr 0.00066 | ms/batch 13.13 | loss 0.00006857\n",
      "| Epoch  50 |   200/  829 batches | lr 0.00066 | ms/batch 11.69 | loss 0.00007951\n",
      "| Epoch  50 |   250/  829 batches | lr 0.00066 | ms/batch 11.88 | loss 0.00009764\n",
      "| Epoch  50 |   300/  829 batches | lr 0.00066 | ms/batch 13.37 | loss 0.00008676\n",
      "| Epoch  50 |   350/  829 batches | lr 0.00066 | ms/batch 13.03 | loss 0.00007440\n",
      "| Epoch  50 |   400/  829 batches | lr 0.00066 | ms/batch 11.81 | loss 0.00007679\n",
      "| Epoch  50 |   450/  829 batches | lr 0.00066 | ms/batch 13.93 | loss 0.00006691\n",
      "| Epoch  50 |   500/  829 batches | lr 0.00066 | ms/batch 11.90 | loss 0.00007444\n",
      "| Epoch  50 |   550/  829 batches | lr 0.00066 | ms/batch 12.26 | loss 0.00007926\n",
      "| Epoch  50 |   600/  829 batches | lr 0.00066 | ms/batch 11.90 | loss 0.00007730\n",
      "| Epoch  50 |   650/  829 batches | lr 0.00066 | ms/batch 11.79 | loss 0.00007957\n",
      "| Epoch  50 |   700/  829 batches | lr 0.00066 | ms/batch 14.14 | loss 0.00007616\n",
      "| Epoch  50 |   750/  829 batches | lr 0.00066 | ms/batch 12.13 | loss 0.00006798\n",
      "| Epoch  50 |   800/  829 batches | lr 0.00066 | ms/batch 13.51 | loss 0.00006791\n",
      "\n",
      "Val set: Average loss: 0.00008369\n",
      "\n",
      "| Epoch  51 |    50/  829 batches | lr 0.00066 | ms/batch 12.33 | loss 0.00006472\n",
      "| Epoch  51 |   100/  829 batches | lr 0.00066 | ms/batch 12.13 | loss 0.00006303\n",
      "| Epoch  51 |   150/  829 batches | lr 0.00066 | ms/batch 13.41 | loss 0.00006248\n",
      "| Epoch  51 |   200/  829 batches | lr 0.00066 | ms/batch 11.59 | loss 0.00006595\n",
      "| Epoch  51 |   250/  829 batches | lr 0.00066 | ms/batch 11.95 | loss 0.00006747\n",
      "| Epoch  51 |   300/  829 batches | lr 0.00066 | ms/batch 11.87 | loss 0.00005923\n",
      "| Epoch  51 |   350/  829 batches | lr 0.00066 | ms/batch 12.06 | loss 0.00006508\n",
      "| Epoch  51 |   400/  829 batches | lr 0.00066 | ms/batch 13.58 | loss 0.00006347\n",
      "| Epoch  51 |   450/  829 batches | lr 0.00066 | ms/batch 11.76 | loss 0.00007093\n",
      "| Epoch  51 |   500/  829 batches | lr 0.00066 | ms/batch 13.28 | loss 0.00007975\n",
      "| Epoch  51 |   550/  829 batches | lr 0.00066 | ms/batch 11.76 | loss 0.00007594\n",
      "| Epoch  51 |   600/  829 batches | lr 0.00066 | ms/batch 11.63 | loss 0.00007591\n",
      "| Epoch  51 |   650/  829 batches | lr 0.00066 | ms/batch 11.60 | loss 0.00006993\n",
      "| Epoch  51 |   700/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00006309\n",
      "| Epoch  51 |   750/  829 batches | lr 0.00066 | ms/batch 13.37 | loss 0.00007006\n",
      "| Epoch  51 |   800/  829 batches | lr 0.00066 | ms/batch 11.64 | loss 0.00007337\n",
      "\n",
      "Val set: Average loss: 0.00008673\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  52 |    50/  829 batches | lr 0.00066 | ms/batch 11.94 | loss 0.00006312\n",
      "| Epoch  52 |   100/  829 batches | lr 0.00066 | ms/batch 13.25 | loss 0.00006015\n",
      "| Epoch  52 |   150/  829 batches | lr 0.00066 | ms/batch 11.63 | loss 0.00006271\n",
      "| Epoch  52 |   200/  829 batches | lr 0.00066 | ms/batch 13.20 | loss 0.00006932\n",
      "| Epoch  52 |   250/  829 batches | lr 0.00066 | ms/batch 11.69 | loss 0.00007117\n",
      "| Epoch  52 |   300/  829 batches | lr 0.00066 | ms/batch 12.23 | loss 0.00006733\n",
      "| Epoch  52 |   350/  829 batches | lr 0.00066 | ms/batch 12.05 | loss 0.00006816\n",
      "| Epoch  52 |   400/  829 batches | lr 0.00066 | ms/batch 11.63 | loss 0.00006581\n",
      "| Epoch  52 |   450/  829 batches | lr 0.00066 | ms/batch 13.70 | loss 0.00006870\n",
      "| Epoch  52 |   500/  829 batches | lr 0.00066 | ms/batch 11.69 | loss 0.00006747\n",
      "| Epoch  52 |   550/  829 batches | lr 0.00066 | ms/batch 11.60 | loss 0.00007712\n",
      "| Epoch  52 |   600/  829 batches | lr 0.00066 | ms/batch 13.55 | loss 0.00007346\n",
      "| Epoch  52 |   650/  829 batches | lr 0.00066 | ms/batch 11.84 | loss 0.00007556\n",
      "| Epoch  52 |   700/  829 batches | lr 0.00066 | ms/batch 11.92 | loss 0.00007420\n",
      "| Epoch  52 |   750/  829 batches | lr 0.00066 | ms/batch 12.57 | loss 0.00007905\n",
      "| Epoch  52 |   800/  829 batches | lr 0.00066 | ms/batch 13.98 | loss 0.00008805\n",
      "\n",
      "Val set: Average loss: 0.00008962\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  53 |    50/  829 batches | lr 0.00066 | ms/batch 12.34 | loss 0.00007449\n",
      "| Epoch  53 |   100/  829 batches | lr 0.00066 | ms/batch 12.27 | loss 0.00007170\n",
      "| Epoch  53 |   150/  829 batches | lr 0.00066 | ms/batch 11.92 | loss 0.00006850\n",
      "| Epoch  53 |   200/  829 batches | lr 0.00066 | ms/batch 13.94 | loss 0.00006765\n",
      "| Epoch  53 |   250/  829 batches | lr 0.00066 | ms/batch 12.05 | loss 0.00007236\n",
      "| Epoch  53 |   300/  829 batches | lr 0.00066 | ms/batch 12.01 | loss 0.00007398\n",
      "| Epoch  53 |   350/  829 batches | lr 0.00066 | ms/batch 14.02 | loss 0.00007316\n",
      "| Epoch  53 |   400/  829 batches | lr 0.00066 | ms/batch 12.09 | loss 0.00007387\n",
      "| Epoch  53 |   450/  829 batches | lr 0.00066 | ms/batch 12.01 | loss 0.00008059\n",
      "| Epoch  53 |   500/  829 batches | lr 0.00066 | ms/batch 11.99 | loss 0.00008974\n",
      "| Epoch  53 |   550/  829 batches | lr 0.00066 | ms/batch 11.94 | loss 0.00008423\n",
      "| Epoch  53 |   600/  829 batches | lr 0.00066 | ms/batch 13.41 | loss 0.00009647\n",
      "| Epoch  53 |   650/  829 batches | lr 0.00066 | ms/batch 12.40 | loss 0.00008548\n",
      "| Epoch  53 |   700/  829 batches | lr 0.00066 | ms/batch 14.11 | loss 0.00007303\n",
      "| Epoch  53 |   750/  829 batches | lr 0.00066 | ms/batch 12.58 | loss 0.00006698\n",
      "| Epoch  53 |   800/  829 batches | lr 0.00066 | ms/batch 12.84 | loss 0.00007187\n",
      "\n",
      "Val set: Average loss: 0.00008308\n",
      "\n",
      "| Epoch  54 |    50/  829 batches | lr 0.00066 | ms/batch 12.95 | loss 0.00007195\n",
      "| Epoch  54 |   100/  829 batches | lr 0.00066 | ms/batch 14.19 | loss 0.00006310\n",
      "| Epoch  54 |   150/  829 batches | lr 0.00066 | ms/batch 12.22 | loss 0.00006280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch  54 |   200/  829 batches | lr 0.00066 | ms/batch 12.43 | loss 0.00007532\n",
      "| Epoch  54 |   250/  829 batches | lr 0.00066 | ms/batch 12.52 | loss 0.00007308\n",
      "| Epoch  54 |   300/  829 batches | lr 0.00066 | ms/batch 13.82 | loss 0.00006564\n",
      "| Epoch  54 |   350/  829 batches | lr 0.00066 | ms/batch 11.83 | loss 0.00006657\n",
      "| Epoch  54 |   400/  829 batches | lr 0.00066 | ms/batch 11.76 | loss 0.00007386\n",
      "| Epoch  54 |   450/  829 batches | lr 0.00066 | ms/batch 13.95 | loss 0.00007602\n",
      "| Epoch  54 |   500/  829 batches | lr 0.00066 | ms/batch 11.96 | loss 0.00008195\n",
      "| Epoch  54 |   550/  829 batches | lr 0.00066 | ms/batch 12.04 | loss 0.00008012\n",
      "| Epoch  54 |   600/  829 batches | lr 0.00066 | ms/batch 11.82 | loss 0.00007975\n",
      "| Epoch  54 |   650/  829 batches | lr 0.00066 | ms/batch 12.06 | loss 0.00008182\n",
      "| Epoch  54 |   700/  829 batches | lr 0.00066 | ms/batch 14.82 | loss 0.00007162\n",
      "| Epoch  54 |   750/  829 batches | lr 0.00066 | ms/batch 12.71 | loss 0.00006561\n",
      "| Epoch  54 |   800/  829 batches | lr 0.00066 | ms/batch 13.65 | loss 0.00006721\n",
      "\n",
      "Val set: Average loss: 0.00008308\n",
      "\n",
      "| Epoch  55 |    50/  829 batches | lr 0.00066 | ms/batch 12.24 | loss 0.00006484\n",
      "| Epoch  55 |   100/  829 batches | lr 0.00066 | ms/batch 11.93 | loss 0.00006623\n",
      "| Epoch  55 |   150/  829 batches | lr 0.00066 | ms/batch 13.47 | loss 0.00006952\n",
      "| Epoch  55 |   200/  829 batches | lr 0.00066 | ms/batch 11.69 | loss 0.00007333\n",
      "| Epoch  55 |   250/  829 batches | lr 0.00066 | ms/batch 11.88 | loss 0.00007977\n",
      "| Epoch  55 |   300/  829 batches | lr 0.00066 | ms/batch 11.93 | loss 0.00007076\n",
      "| Epoch  55 |   350/  829 batches | lr 0.00066 | ms/batch 11.93 | loss 0.00007592\n",
      "| Epoch  55 |   400/  829 batches | lr 0.00066 | ms/batch 13.67 | loss 0.00007564\n",
      "| Epoch  55 |   450/  829 batches | lr 0.00066 | ms/batch 11.87 | loss 0.00007866\n",
      "| Epoch  55 |   500/  829 batches | lr 0.00066 | ms/batch 13.40 | loss 0.00006959\n",
      "| Epoch  55 |   550/  829 batches | lr 0.00066 | ms/batch 11.63 | loss 0.00008800\n",
      "| Epoch  55 |   600/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00010007\n",
      "| Epoch  55 |   650/  829 batches | lr 0.00066 | ms/batch 12.14 | loss 0.00010542\n",
      "| Epoch  55 |   700/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00007643\n",
      "| Epoch  55 |   750/  829 batches | lr 0.00066 | ms/batch 13.27 | loss 0.00007173\n",
      "| Epoch  55 |   800/  829 batches | lr 0.00066 | ms/batch 11.69 | loss 0.00006945\n",
      "\n",
      "Val set: Average loss: 0.00008333\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  56 |    50/  829 batches | lr 0.00066 | ms/batch 11.93 | loss 0.00007247\n",
      "| Epoch  56 |   100/  829 batches | lr 0.00066 | ms/batch 13.39 | loss 0.00006432\n",
      "| Epoch  56 |   150/  829 batches | lr 0.00066 | ms/batch 11.70 | loss 0.00007215\n",
      "| Epoch  56 |   200/  829 batches | lr 0.00066 | ms/batch 13.36 | loss 0.00008294\n",
      "| Epoch  56 |   250/  829 batches | lr 0.00066 | ms/batch 11.73 | loss 0.00010234\n",
      "| Epoch  56 |   300/  829 batches | lr 0.00066 | ms/batch 11.73 | loss 0.00008244\n",
      "| Epoch  56 |   350/  829 batches | lr 0.00066 | ms/batch 11.60 | loss 0.00007328\n",
      "| Epoch  56 |   400/  829 batches | lr 0.00066 | ms/batch 11.59 | loss 0.00006604\n",
      "| Epoch  56 |   450/  829 batches | lr 0.00066 | ms/batch 13.19 | loss 0.00006175\n",
      "| Epoch  56 |   500/  829 batches | lr 0.00066 | ms/batch 11.74 | loss 0.00008044\n",
      "| Epoch  56 |   550/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00008120\n",
      "| Epoch  56 |   600/  829 batches | lr 0.00066 | ms/batch 13.35 | loss 0.00010542\n",
      "| Epoch  56 |   650/  829 batches | lr 0.00066 | ms/batch 11.74 | loss 0.00011464\n",
      "| Epoch  56 |   700/  829 batches | lr 0.00066 | ms/batch 11.65 | loss 0.00010397\n",
      "| Epoch  56 |   750/  829 batches | lr 0.00066 | ms/batch 11.89 | loss 0.00009085\n",
      "| Epoch  56 |   800/  829 batches | lr 0.00066 | ms/batch 11.64 | loss 0.00007674\n",
      "\n",
      "Val set: Average loss: 0.00011151\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  57 |    50/  829 batches | lr 0.00066 | ms/batch 12.23 | loss 0.00007216\n",
      "| Epoch  57 |   100/  829 batches | lr 0.00066 | ms/batch 11.74 | loss 0.00006596\n",
      "| Epoch  57 |   150/  829 batches | lr 0.00066 | ms/batch 11.96 | loss 0.00007347\n",
      "| Epoch  57 |   200/  829 batches | lr 0.00066 | ms/batch 13.53 | loss 0.00006781\n",
      "| Epoch  57 |   250/  829 batches | lr 0.00066 | ms/batch 11.69 | loss 0.00007315\n",
      "| Epoch  57 |   300/  829 batches | lr 0.00066 | ms/batch 11.71 | loss 0.00010157\n",
      "| Epoch  57 |   350/  829 batches | lr 0.00066 | ms/batch 13.26 | loss 0.00011241\n",
      "| Epoch  57 |   400/  829 batches | lr 0.00066 | ms/batch 11.68 | loss 0.00007267\n",
      "| Epoch  57 |   450/  829 batches | lr 0.00066 | ms/batch 11.72 | loss 0.00006233\n",
      "| Epoch  57 |   500/  829 batches | lr 0.00066 | ms/batch 11.63 | loss 0.00007692\n",
      "| Epoch  57 |   550/  829 batches | lr 0.00066 | ms/batch 11.65 | loss 0.00007582\n",
      "| Epoch  57 |   600/  829 batches | lr 0.00066 | ms/batch 13.35 | loss 0.00008710\n",
      "| Epoch  57 |   650/  829 batches | lr 0.00066 | ms/batch 11.80 | loss 0.00011820\n",
      "| Epoch  57 |   700/  829 batches | lr 0.00066 | ms/batch 11.65 | loss 0.00008106\n",
      "| Epoch  57 |   750/  829 batches | lr 0.00066 | ms/batch 13.21 | loss 0.00007066\n",
      "| Epoch  57 |   800/  829 batches | lr 0.00066 | ms/batch 11.78 | loss 0.00006159\n",
      "\n",
      "Val set: Average loss: 0.00009318\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  58 |    50/  829 batches | lr 0.00066 | ms/batch 12.17 | loss 0.00007323\n",
      "| Epoch  58 |   100/  829 batches | lr 0.00066 | ms/batch 13.74 | loss 0.00006455\n",
      "| Epoch  58 |   150/  829 batches | lr 0.00066 | ms/batch 11.75 | loss 0.00006296\n",
      "| Epoch  58 |   200/  829 batches | lr 0.00066 | ms/batch 11.80 | loss 0.00006701\n",
      "| Epoch  58 |   250/  829 batches | lr 0.00066 | ms/batch 11.73 | loss 0.00006434\n",
      "| Epoch  58 |   300/  829 batches | lr 0.00066 | ms/batch 13.30 | loss 0.00008358\n",
      "| Epoch  58 |   350/  829 batches | lr 0.00066 | ms/batch 11.74 | loss 0.00008356\n",
      "| Epoch  58 |   400/  829 batches | lr 0.00066 | ms/batch 11.69 | loss 0.00005728\n",
      "| Epoch  58 |   450/  829 batches | lr 0.00066 | ms/batch 13.23 | loss 0.00005549\n",
      "| Epoch  58 |   500/  829 batches | lr 0.00066 | ms/batch 11.60 | loss 0.00006026\n",
      "| Epoch  58 |   550/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00006305\n",
      "| Epoch  58 |   600/  829 batches | lr 0.00066 | ms/batch 11.66 | loss 0.00006633\n",
      "| Epoch  58 |   650/  829 batches | lr 0.00066 | ms/batch 11.65 | loss 0.00007659\n",
      "| Epoch  58 |   700/  829 batches | lr 0.00066 | ms/batch 13.20 | loss 0.00006000\n",
      "| Epoch  58 |   750/  829 batches | lr 0.00066 | ms/batch 11.68 | loss 0.00006007\n",
      "| Epoch  58 |   800/  829 batches | lr 0.00066 | ms/batch 11.65 | loss 0.00005538\n",
      "\n",
      "Val set: Average loss: 0.00007755\n",
      "\n",
      "| Epoch  59 |    50/  829 batches | lr 0.00066 | ms/batch 12.32 | loss 0.00005866\n",
      "| Epoch  59 |   100/  829 batches | lr 0.00066 | ms/batch 11.83 | loss 0.00005539\n",
      "| Epoch  59 |   150/  829 batches | lr 0.00066 | ms/batch 13.35 | loss 0.00005567\n",
      "| Epoch  59 |   200/  829 batches | lr 0.00066 | ms/batch 11.85 | loss 0.00005894\n",
      "| Epoch  59 |   250/  829 batches | lr 0.00066 | ms/batch 11.76 | loss 0.00006163\n",
      "| Epoch  59 |   300/  829 batches | lr 0.00066 | ms/batch 11.74 | loss 0.00005917\n",
      "| Epoch  59 |   350/  829 batches | lr 0.00066 | ms/batch 11.75 | loss 0.00007059\n",
      "| Epoch  59 |   400/  829 batches | lr 0.00066 | ms/batch 13.38 | loss 0.00006293\n",
      "| Epoch  59 |   450/  829 batches | lr 0.00066 | ms/batch 11.77 | loss 0.00005460\n",
      "| Epoch  59 |   500/  829 batches | lr 0.00066 | ms/batch 13.31 | loss 0.00005173\n",
      "| Epoch  59 |   550/  829 batches | lr 0.00066 | ms/batch 11.58 | loss 0.00005357\n",
      "| Epoch  59 |   600/  829 batches | lr 0.00066 | ms/batch 11.65 | loss 0.00006527\n",
      "| Epoch  59 |   650/  829 batches | lr 0.00066 | ms/batch 11.63 | loss 0.00007118\n",
      "| Epoch  59 |   700/  829 batches | lr 0.00066 | ms/batch 11.65 | loss 0.00006586\n",
      "| Epoch  59 |   750/  829 batches | lr 0.00066 | ms/batch 13.19 | loss 0.00006306\n",
      "| Epoch  59 |   800/  829 batches | lr 0.00066 | ms/batch 11.71 | loss 0.00006262\n",
      "\n",
      "Val set: Average loss: 0.00007958\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  60 |    50/  829 batches | lr 0.00066 | ms/batch 12.29 | loss 0.00006349\n",
      "| Epoch  60 |   100/  829 batches | lr 0.00066 | ms/batch 13.27 | loss 0.00005983\n",
      "| Epoch  60 |   150/  829 batches | lr 0.00066 | ms/batch 11.65 | loss 0.00006358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch  60 |   200/  829 batches | lr 0.00066 | ms/batch 13.27 | loss 0.00006124\n",
      "| Epoch  60 |   250/  829 batches | lr 0.00066 | ms/batch 11.58 | loss 0.00006515\n",
      "| Epoch  60 |   300/  829 batches | lr 0.00066 | ms/batch 11.63 | loss 0.00006613\n",
      "| Epoch  60 |   350/  829 batches | lr 0.00066 | ms/batch 11.75 | loss 0.00006982\n",
      "| Epoch  60 |   400/  829 batches | lr 0.00066 | ms/batch 11.83 | loss 0.00005898\n",
      "| Epoch  60 |   450/  829 batches | lr 0.00066 | ms/batch 13.45 | loss 0.00005626\n",
      "| Epoch  60 |   500/  829 batches | lr 0.00066 | ms/batch 11.82 | loss 0.00005740\n",
      "| Epoch  60 |   550/  829 batches | lr 0.00066 | ms/batch 11.79 | loss 0.00006102\n",
      "| Epoch  60 |   600/  829 batches | lr 0.00066 | ms/batch 13.37 | loss 0.00006829\n",
      "| Epoch  60 |   650/  829 batches | lr 0.00066 | ms/batch 11.73 | loss 0.00005872\n",
      "| Epoch  60 |   700/  829 batches | lr 0.00066 | ms/batch 12.00 | loss 0.00006030\n",
      "| Epoch  60 |   750/  829 batches | lr 0.00066 | ms/batch 11.63 | loss 0.00006733\n",
      "| Epoch  60 |   800/  829 batches | lr 0.00066 | ms/batch 11.61 | loss 0.00006205\n",
      "\n",
      "Val set: Average loss: 0.00007634\n",
      "\n",
      "| Epoch  61 |    50/  829 batches | lr 0.00066 | ms/batch 12.12 | loss 0.00005684\n",
      "| Epoch  61 |   100/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00006023\n",
      "| Epoch  61 |   150/  829 batches | lr 0.00066 | ms/batch 11.65 | loss 0.00006607\n",
      "| Epoch  61 |   200/  829 batches | lr 0.00066 | ms/batch 13.30 | loss 0.00007332\n",
      "| Epoch  61 |   250/  829 batches | lr 0.00066 | ms/batch 11.65 | loss 0.00007560\n",
      "| Epoch  61 |   300/  829 batches | lr 0.00066 | ms/batch 11.87 | loss 0.00007388\n",
      "| Epoch  61 |   350/  829 batches | lr 0.00066 | ms/batch 13.21 | loss 0.00007592\n",
      "| Epoch  61 |   400/  829 batches | lr 0.00066 | ms/batch 11.58 | loss 0.00007076\n",
      "| Epoch  61 |   450/  829 batches | lr 0.00066 | ms/batch 11.62 | loss 0.00006461\n",
      "| Epoch  61 |   500/  829 batches | lr 0.00066 | ms/batch 11.69 | loss 0.00006660\n",
      "| Epoch  61 |   550/  829 batches | lr 0.00066 | ms/batch 11.72 | loss 0.00005849\n",
      "| Epoch  61 |   600/  829 batches | lr 0.00066 | ms/batch 13.51 | loss 0.00007159\n",
      "| Epoch  61 |   650/  829 batches | lr 0.00066 | ms/batch 11.80 | loss 0.00007274\n",
      "| Epoch  61 |   700/  829 batches | lr 0.00066 | ms/batch 11.62 | loss 0.00007383\n",
      "| Epoch  61 |   750/  829 batches | lr 0.00066 | ms/batch 13.16 | loss 0.00007425\n",
      "| Epoch  61 |   800/  829 batches | lr 0.00066 | ms/batch 11.59 | loss 0.00006438\n",
      "\n",
      "Val set: Average loss: 0.00008106\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  62 |    50/  829 batches | lr 0.00066 | ms/batch 11.93 | loss 0.00006325\n",
      "| Epoch  62 |   100/  829 batches | lr 0.00066 | ms/batch 13.22 | loss 0.00006262\n",
      "| Epoch  62 |   150/  829 batches | lr 0.00066 | ms/batch 11.65 | loss 0.00005787\n",
      "| Epoch  62 |   200/  829 batches | lr 0.00066 | ms/batch 11.64 | loss 0.00006385\n",
      "| Epoch  62 |   250/  829 batches | lr 0.00066 | ms/batch 11.58 | loss 0.00008124\n",
      "| Epoch  62 |   300/  829 batches | lr 0.00066 | ms/batch 13.17 | loss 0.00006905\n",
      "| Epoch  62 |   350/  829 batches | lr 0.00066 | ms/batch 11.66 | loss 0.00006501\n",
      "| Epoch  62 |   400/  829 batches | lr 0.00066 | ms/batch 11.72 | loss 0.00009689\n",
      "| Epoch  62 |   450/  829 batches | lr 0.00066 | ms/batch 13.31 | loss 0.00006638\n",
      "| Epoch  62 |   500/  829 batches | lr 0.00066 | ms/batch 11.63 | loss 0.00006517\n",
      "| Epoch  62 |   550/  829 batches | lr 0.00066 | ms/batch 11.58 | loss 0.00006782\n",
      "| Epoch  62 |   600/  829 batches | lr 0.00066 | ms/batch 11.75 | loss 0.00008101\n",
      "| Epoch  62 |   650/  829 batches | lr 0.00066 | ms/batch 11.60 | loss 0.00007148\n",
      "| Epoch  62 |   700/  829 batches | lr 0.00066 | ms/batch 13.16 | loss 0.00006247\n",
      "| Epoch  62 |   750/  829 batches | lr 0.00066 | ms/batch 11.63 | loss 0.00005987\n",
      "| Epoch  62 |   800/  829 batches | lr 0.00066 | ms/batch 11.61 | loss 0.00005971\n",
      "\n",
      "Val set: Average loss: 0.00010292\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  63 |    50/  829 batches | lr 0.00066 | ms/batch 11.93 | loss 0.00006441\n",
      "| Epoch  63 |   100/  829 batches | lr 0.00066 | ms/batch 11.60 | loss 0.00006539\n",
      "| Epoch  63 |   150/  829 batches | lr 0.00066 | ms/batch 13.16 | loss 0.00005915\n",
      "| Epoch  63 |   200/  829 batches | lr 0.00066 | ms/batch 11.84 | loss 0.00005847\n",
      "| Epoch  63 |   250/  829 batches | lr 0.00066 | ms/batch 11.82 | loss 0.00007368\n",
      "| Epoch  63 |   300/  829 batches | lr 0.00066 | ms/batch 11.92 | loss 0.00006522\n",
      "| Epoch  63 |   350/  829 batches | lr 0.00066 | ms/batch 11.68 | loss 0.00006723\n",
      "| Epoch  63 |   400/  829 batches | lr 0.00066 | ms/batch 13.41 | loss 0.00008052\n",
      "| Epoch  63 |   450/  829 batches | lr 0.00066 | ms/batch 11.91 | loss 0.00006366\n",
      "| Epoch  63 |   500/  829 batches | lr 0.00066 | ms/batch 13.77 | loss 0.00006406\n",
      "| Epoch  63 |   550/  829 batches | lr 0.00066 | ms/batch 12.07 | loss 0.00006304\n",
      "| Epoch  63 |   600/  829 batches | lr 0.00066 | ms/batch 11.85 | loss 0.00007760\n",
      "| Epoch  63 |   650/  829 batches | lr 0.00066 | ms/batch 11.80 | loss 0.00006598\n",
      "| Epoch  63 |   700/  829 batches | lr 0.00066 | ms/batch 11.69 | loss 0.00005919\n",
      "| Epoch  63 |   750/  829 batches | lr 0.00066 | ms/batch 13.27 | loss 0.00005590\n",
      "| Epoch  63 |   800/  829 batches | lr 0.00066 | ms/batch 11.69 | loss 0.00005366\n",
      "\n",
      "Val set: Average loss: 0.00008375\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  64 |    50/  829 batches | lr 0.00066 | ms/batch 11.99 | loss 0.00006028\n",
      "| Epoch  64 |   100/  829 batches | lr 0.00066 | ms/batch 13.28 | loss 0.00005832\n",
      "| Epoch  64 |   150/  829 batches | lr 0.00066 | ms/batch 11.71 | loss 0.00005327\n",
      "| Epoch  64 |   200/  829 batches | lr 0.00066 | ms/batch 13.21 | loss 0.00005859\n",
      "| Epoch  64 |   250/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00006484\n",
      "| Epoch  64 |   300/  829 batches | lr 0.00066 | ms/batch 11.81 | loss 0.00006204\n",
      "| Epoch  64 |   350/  829 batches | lr 0.00066 | ms/batch 11.83 | loss 0.00005928\n",
      "| Epoch  64 |   400/  829 batches | lr 0.00066 | ms/batch 11.87 | loss 0.00006525\n",
      "| Epoch  64 |   450/  829 batches | lr 0.00066 | ms/batch 13.81 | loss 0.00006040\n",
      "| Epoch  64 |   500/  829 batches | lr 0.00066 | ms/batch 12.13 | loss 0.00006077\n",
      "| Epoch  64 |   550/  829 batches | lr 0.00066 | ms/batch 11.91 | loss 0.00006333\n",
      "| Epoch  64 |   600/  829 batches | lr 0.00066 | ms/batch 13.31 | loss 0.00006643\n",
      "| Epoch  64 |   650/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00006348\n",
      "| Epoch  64 |   700/  829 batches | lr 0.00066 | ms/batch 11.83 | loss 0.00005868\n",
      "| Epoch  64 |   750/  829 batches | lr 0.00066 | ms/batch 11.81 | loss 0.00005491\n",
      "| Epoch  64 |   800/  829 batches | lr 0.00066 | ms/batch 11.71 | loss 0.00005436\n",
      "\n",
      "Val set: Average loss: 0.00008296\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch  65 |    50/  829 batches | lr 0.00066 | ms/batch 11.94 | loss 0.00005787\n",
      "| Epoch  65 |   100/  829 batches | lr 0.00066 | ms/batch 11.63 | loss 0.00005444\n",
      "| Epoch  65 |   150/  829 batches | lr 0.00066 | ms/batch 11.89 | loss 0.00006118\n",
      "| Epoch  65 |   200/  829 batches | lr 0.00066 | ms/batch 13.17 | loss 0.00006302\n",
      "| Epoch  65 |   250/  829 batches | lr 0.00066 | ms/batch 11.66 | loss 0.00006315\n",
      "| Epoch  65 |   300/  829 batches | lr 0.00066 | ms/batch 11.72 | loss 0.00006592\n",
      "| Epoch  65 |   350/  829 batches | lr 0.00066 | ms/batch 13.19 | loss 0.00006450\n",
      "| Epoch  65 |   400/  829 batches | lr 0.00066 | ms/batch 11.66 | loss 0.00006478\n",
      "| Epoch  65 |   450/  829 batches | lr 0.00066 | ms/batch 11.66 | loss 0.00005900\n",
      "| Epoch  65 |   500/  829 batches | lr 0.00066 | ms/batch 11.65 | loss 0.00005694\n",
      "| Epoch  65 |   550/  829 batches | lr 0.00066 | ms/batch 11.64 | loss 0.00006150\n",
      "| Epoch  65 |   600/  829 batches | lr 0.00066 | ms/batch 13.21 | loss 0.00006349\n",
      "| Epoch  65 |   650/  829 batches | lr 0.00066 | ms/batch 11.59 | loss 0.00006282\n",
      "| Epoch  65 |   700/  829 batches | lr 0.00066 | ms/batch 11.62 | loss 0.00005542\n",
      "| Epoch  65 |   750/  829 batches | lr 0.00066 | ms/batch 13.19 | loss 0.00005724\n",
      "| Epoch  65 |   800/  829 batches | lr 0.00066 | ms/batch 11.58 | loss 0.00005418\n",
      "\n",
      "Val set: Average loss: 0.00008871\n",
      "\n",
      "EarlyStopping counter: 5 out of 20\n",
      "| Epoch  66 |    50/  829 batches | lr 0.00066 | ms/batch 11.93 | loss 0.00005424\n",
      "| Epoch  66 |   100/  829 batches | lr 0.00066 | ms/batch 13.19 | loss 0.00005153\n",
      "| Epoch  66 |   150/  829 batches | lr 0.00066 | ms/batch 11.63 | loss 0.00005806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch  66 |   200/  829 batches | lr 0.00066 | ms/batch 11.59 | loss 0.00006442\n",
      "| Epoch  66 |   250/  829 batches | lr 0.00066 | ms/batch 11.60 | loss 0.00007376\n",
      "| Epoch  66 |   300/  829 batches | lr 0.00066 | ms/batch 11.61 | loss 0.00006861\n",
      "| Epoch  66 |   350/  829 batches | lr 0.00066 | ms/batch 13.22 | loss 0.00006439\n",
      "| Epoch  66 |   400/  829 batches | lr 0.00066 | ms/batch 11.64 | loss 0.00006040\n",
      "| Epoch  66 |   450/  829 batches | lr 0.00066 | ms/batch 13.28 | loss 0.00006002\n",
      "| Epoch  66 |   500/  829 batches | lr 0.00066 | ms/batch 11.71 | loss 0.00005831\n",
      "| Epoch  66 |   550/  829 batches | lr 0.00066 | ms/batch 11.69 | loss 0.00005912\n",
      "| Epoch  66 |   600/  829 batches | lr 0.00066 | ms/batch 11.85 | loss 0.00006187\n",
      "| Epoch  66 |   650/  829 batches | lr 0.00066 | ms/batch 11.74 | loss 0.00006507\n",
      "| Epoch  66 |   700/  829 batches | lr 0.00066 | ms/batch 13.43 | loss 0.00005755\n",
      "| Epoch  66 |   750/  829 batches | lr 0.00066 | ms/batch 11.78 | loss 0.00005957\n",
      "| Epoch  66 |   800/  829 batches | lr 0.00066 | ms/batch 11.77 | loss 0.00006542\n",
      "\n",
      "Val set: Average loss: 0.00008734\n",
      "\n",
      "EarlyStopping counter: 6 out of 20\n",
      "| Epoch  67 |    50/  829 batches | lr 0.00066 | ms/batch 12.01 | loss 0.00005708\n",
      "| Epoch  67 |   100/  829 batches | lr 0.00066 | ms/batch 11.62 | loss 0.00006496\n",
      "| Epoch  67 |   150/  829 batches | lr 0.00066 | ms/batch 13.20 | loss 0.00006185\n",
      "| Epoch  67 |   200/  829 batches | lr 0.00066 | ms/batch 11.61 | loss 0.00006027\n",
      "| Epoch  67 |   250/  829 batches | lr 0.00066 | ms/batch 11.60 | loss 0.00007051\n",
      "| Epoch  67 |   300/  829 batches | lr 0.00066 | ms/batch 11.58 | loss 0.00007475\n",
      "| Epoch  67 |   350/  829 batches | lr 0.00066 | ms/batch 11.57 | loss 0.00006511\n",
      "| Epoch  67 |   400/  829 batches | lr 0.00066 | ms/batch 13.21 | loss 0.00006548\n",
      "| Epoch  67 |   450/  829 batches | lr 0.00066 | ms/batch 11.62 | loss 0.00007380\n",
      "| Epoch  67 |   500/  829 batches | lr 0.00066 | ms/batch 13.18 | loss 0.00006944\n",
      "| Epoch  67 |   550/  829 batches | lr 0.00066 | ms/batch 11.59 | loss 0.00006839\n",
      "| Epoch  67 |   600/  829 batches | lr 0.00066 | ms/batch 11.68 | loss 0.00007340\n",
      "| Epoch  67 |   650/  829 batches | lr 0.00066 | ms/batch 11.59 | loss 0.00007246\n",
      "| Epoch  67 |   700/  829 batches | lr 0.00066 | ms/batch 11.64 | loss 0.00007053\n",
      "| Epoch  67 |   750/  829 batches | lr 0.00066 | ms/batch 13.39 | loss 0.00006775\n",
      "| Epoch  67 |   800/  829 batches | lr 0.00066 | ms/batch 11.89 | loss 0.00006568\n",
      "\n",
      "Val set: Average loss: 0.00012473\n",
      "\n",
      "EarlyStopping counter: 7 out of 20\n",
      "| Epoch  68 |    50/  829 batches | lr 0.00066 | ms/batch 12.19 | loss 0.00008235\n",
      "| Epoch  68 |   100/  829 batches | lr 0.00066 | ms/batch 13.37 | loss 0.00006458\n",
      "| Epoch  68 |   150/  829 batches | lr 0.00066 | ms/batch 11.76 | loss 0.00005943\n",
      "| Epoch  68 |   200/  829 batches | lr 0.00066 | ms/batch 13.20 | loss 0.00006151\n",
      "| Epoch  68 |   250/  829 batches | lr 0.00066 | ms/batch 11.68 | loss 0.00007621\n",
      "| Epoch  68 |   300/  829 batches | lr 0.00066 | ms/batch 11.73 | loss 0.00007853\n",
      "| Epoch  68 |   350/  829 batches | lr 0.00066 | ms/batch 11.72 | loss 0.00007174\n",
      "| Epoch  68 |   400/  829 batches | lr 0.00066 | ms/batch 11.66 | loss 0.00008586\n",
      "| Epoch  68 |   450/  829 batches | lr 0.00066 | ms/batch 13.25 | loss 0.00006887\n",
      "| Epoch  68 |   500/  829 batches | lr 0.00066 | ms/batch 11.62 | loss 0.00006670\n",
      "| Epoch  68 |   550/  829 batches | lr 0.00066 | ms/batch 11.70 | loss 0.00007384\n",
      "| Epoch  68 |   600/  829 batches | lr 0.00066 | ms/batch 13.27 | loss 0.00007880\n",
      "| Epoch  68 |   650/  829 batches | lr 0.00066 | ms/batch 11.63 | loss 0.00010315\n",
      "| Epoch  68 |   700/  829 batches | lr 0.00066 | ms/batch 11.61 | loss 0.00007344\n",
      "| Epoch  68 |   750/  829 batches | lr 0.00066 | ms/batch 11.66 | loss 0.00006410\n",
      "| Epoch  68 |   800/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00005832\n",
      "\n",
      "Val set: Average loss: 0.00011552\n",
      "\n",
      "EarlyStopping counter: 8 out of 20\n",
      "| Epoch  69 |    50/  829 batches | lr 0.00066 | ms/batch 11.93 | loss 0.00007205\n",
      "| Epoch  69 |   100/  829 batches | lr 0.00066 | ms/batch 11.58 | loss 0.00005711\n",
      "| Epoch  69 |   150/  829 batches | lr 0.00066 | ms/batch 11.61 | loss 0.00007313\n",
      "| Epoch  69 |   200/  829 batches | lr 0.00066 | ms/batch 11.63 | loss 0.00006362\n",
      "| Epoch  69 |   250/  829 batches | lr 0.00066 | ms/batch 13.21 | loss 0.00006754\n",
      "| Epoch  69 |   300/  829 batches | lr 0.00066 | ms/batch 11.75 | loss 0.00007638\n",
      "| Epoch  69 |   350/  829 batches | lr 0.00066 | ms/batch 13.32 | loss 0.00007894\n",
      "| Epoch  69 |   400/  829 batches | lr 0.00066 | ms/batch 11.65 | loss 0.00005821\n",
      "| Epoch  69 |   450/  829 batches | lr 0.00066 | ms/batch 11.61 | loss 0.00005487\n",
      "| Epoch  69 |   500/  829 batches | lr 0.00066 | ms/batch 11.68 | loss 0.00005970\n",
      "| Epoch  69 |   550/  829 batches | lr 0.00066 | ms/batch 11.71 | loss 0.00006684\n",
      "| Epoch  69 |   600/  829 batches | lr 0.00066 | ms/batch 13.23 | loss 0.00006529\n",
      "| Epoch  69 |   650/  829 batches | lr 0.00066 | ms/batch 11.65 | loss 0.00007591\n",
      "| Epoch  69 |   700/  829 batches | lr 0.00066 | ms/batch 11.70 | loss 0.00006459\n",
      "| Epoch  69 |   750/  829 batches | lr 0.00066 | ms/batch 13.30 | loss 0.00005621\n",
      "| Epoch  69 |   800/  829 batches | lr 0.00066 | ms/batch 11.66 | loss 0.00005409\n",
      "\n",
      "Val set: Average loss: 0.00010092\n",
      "\n",
      "EarlyStopping counter: 9 out of 20\n",
      "| Epoch  70 |    50/  829 batches | lr 0.00066 | ms/batch 11.96 | loss 0.00006207\n",
      "| Epoch  70 |   100/  829 batches | lr 0.00066 | ms/batch 13.16 | loss 0.00005596\n",
      "| Epoch  70 |   150/  829 batches | lr 0.00066 | ms/batch 11.63 | loss 0.00006159\n",
      "| Epoch  70 |   200/  829 batches | lr 0.00066 | ms/batch 11.62 | loss 0.00005333\n",
      "| Epoch  70 |   250/  829 batches | lr 0.00066 | ms/batch 11.69 | loss 0.00005828\n",
      "| Epoch  70 |   300/  829 batches | lr 0.00066 | ms/batch 11.75 | loss 0.00006166\n",
      "| Epoch  70 |   350/  829 batches | lr 0.00066 | ms/batch 13.48 | loss 0.00006346\n",
      "| Epoch  70 |   400/  829 batches | lr 0.00066 | ms/batch 11.77 | loss 0.00006072\n",
      "| Epoch  70 |   450/  829 batches | lr 0.00066 | ms/batch 13.33 | loss 0.00004945\n",
      "| Epoch  70 |   500/  829 batches | lr 0.00066 | ms/batch 11.78 | loss 0.00004987\n",
      "| Epoch  70 |   550/  829 batches | lr 0.00066 | ms/batch 11.68 | loss 0.00005285\n",
      "| Epoch  70 |   600/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00005776\n",
      "| Epoch  70 |   650/  829 batches | lr 0.00066 | ms/batch 11.62 | loss 0.00005427\n",
      "| Epoch  70 |   700/  829 batches | lr 0.00066 | ms/batch 13.22 | loss 0.00005061\n",
      "| Epoch  70 |   750/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00004654\n",
      "| Epoch  70 |   800/  829 batches | lr 0.00066 | ms/batch 11.65 | loss 0.00004607\n",
      "\n",
      "Val set: Average loss: 0.00008439\n",
      "\n",
      "EarlyStopping counter: 10 out of 20\n",
      "| Epoch  71 |    50/  829 batches | lr 0.00066 | ms/batch 11.90 | loss 0.00005346\n",
      "| Epoch  71 |   100/  829 batches | lr 0.00066 | ms/batch 11.60 | loss 0.00005200\n",
      "| Epoch  71 |   150/  829 batches | lr 0.00066 | ms/batch 13.45 | loss 0.00004788\n",
      "| Epoch  71 |   200/  829 batches | lr 0.00066 | ms/batch 11.62 | loss 0.00004935\n",
      "| Epoch  71 |   250/  829 batches | lr 0.00066 | ms/batch 11.86 | loss 0.00005631\n",
      "| Epoch  71 |   300/  829 batches | lr 0.00066 | ms/batch 11.95 | loss 0.00005355\n",
      "| Epoch  71 |   350/  829 batches | lr 0.00066 | ms/batch 11.87 | loss 0.00005898\n",
      "| Epoch  71 |   400/  829 batches | lr 0.00066 | ms/batch 13.35 | loss 0.00005248\n",
      "| Epoch  71 |   450/  829 batches | lr 0.00066 | ms/batch 11.80 | loss 0.00005142\n",
      "| Epoch  71 |   500/  829 batches | lr 0.00066 | ms/batch 13.31 | loss 0.00005047\n",
      "| Epoch  71 |   550/  829 batches | lr 0.00066 | ms/batch 11.66 | loss 0.00005229\n",
      "| Epoch  71 |   600/  829 batches | lr 0.00066 | ms/batch 11.77 | loss 0.00005065\n",
      "| Epoch  71 |   650/  829 batches | lr 0.00066 | ms/batch 11.71 | loss 0.00005396\n",
      "| Epoch  71 |   700/  829 batches | lr 0.00066 | ms/batch 11.64 | loss 0.00005345\n",
      "| Epoch  71 |   750/  829 batches | lr 0.00066 | ms/batch 13.32 | loss 0.00005333\n",
      "| Epoch  71 |   800/  829 batches | lr 0.00066 | ms/batch 11.64 | loss 0.00005758\n",
      "\n",
      "Val set: Average loss: 0.00009187\n",
      "\n",
      "EarlyStopping counter: 11 out of 20\n",
      "| Epoch  72 |    50/  829 batches | lr 0.00066 | ms/batch 11.89 | loss 0.00006197\n",
      "| Epoch  72 |   100/  829 batches | lr 0.00066 | ms/batch 13.18 | loss 0.00006221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch  72 |   150/  829 batches | lr 0.00066 | ms/batch 11.75 | loss 0.00005624\n",
      "| Epoch  72 |   200/  829 batches | lr 0.00066 | ms/batch 13.19 | loss 0.00005694\n",
      "| Epoch  72 |   250/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00006288\n",
      "| Epoch  72 |   300/  829 batches | lr 0.00066 | ms/batch 11.70 | loss 0.00005627\n",
      "| Epoch  72 |   350/  829 batches | lr 0.00066 | ms/batch 11.65 | loss 0.00005580\n",
      "| Epoch  72 |   400/  829 batches | lr 0.00066 | ms/batch 11.69 | loss 0.00005467\n",
      "| Epoch  72 |   450/  829 batches | lr 0.00066 | ms/batch 13.26 | loss 0.00005467\n",
      "| Epoch  72 |   500/  829 batches | lr 0.00066 | ms/batch 11.66 | loss 0.00005713\n",
      "| Epoch  72 |   550/  829 batches | lr 0.00066 | ms/batch 11.62 | loss 0.00005719\n",
      "| Epoch  72 |   600/  829 batches | lr 0.00066 | ms/batch 13.25 | loss 0.00006002\n",
      "| Epoch  72 |   650/  829 batches | lr 0.00066 | ms/batch 11.60 | loss 0.00006468\n",
      "| Epoch  72 |   700/  829 batches | lr 0.00066 | ms/batch 11.63 | loss 0.00005950\n",
      "| Epoch  72 |   750/  829 batches | lr 0.00066 | ms/batch 11.58 | loss 0.00006470\n",
      "| Epoch  72 |   800/  829 batches | lr 0.00066 | ms/batch 11.69 | loss 0.00006174\n",
      "\n",
      "Val set: Average loss: 0.00009319\n",
      "\n",
      "EarlyStopping counter: 12 out of 20\n",
      "| Epoch  73 |    50/  829 batches | lr 0.00066 | ms/batch 12.04 | loss 0.00006283\n",
      "| Epoch  73 |   100/  829 batches | lr 0.00066 | ms/batch 11.72 | loss 0.00005716\n",
      "| Epoch  73 |   150/  829 batches | lr 0.00066 | ms/batch 11.75 | loss 0.00005271\n",
      "| Epoch  73 |   200/  829 batches | lr 0.00066 | ms/batch 13.30 | loss 0.00005342\n",
      "| Epoch  73 |   250/  829 batches | lr 0.00066 | ms/batch 11.73 | loss 0.00005766\n",
      "| Epoch  73 |   300/  829 batches | lr 0.00066 | ms/batch 11.68 | loss 0.00005749\n",
      "| Epoch  73 |   350/  829 batches | lr 0.00066 | ms/batch 13.20 | loss 0.00005762\n",
      "| Epoch  73 |   400/  829 batches | lr 0.00066 | ms/batch 11.60 | loss 0.00006846\n",
      "| Epoch  73 |   450/  829 batches | lr 0.00066 | ms/batch 11.69 | loss 0.00006180\n",
      "| Epoch  73 |   500/  829 batches | lr 0.00066 | ms/batch 11.57 | loss 0.00006209\n",
      "| Epoch  73 |   550/  829 batches | lr 0.00066 | ms/batch 11.64 | loss 0.00007457\n",
      "| Epoch  73 |   600/  829 batches | lr 0.00066 | ms/batch 13.17 | loss 0.00006571\n",
      "| Epoch  73 |   650/  829 batches | lr 0.00066 | ms/batch 11.65 | loss 0.00006473\n",
      "| Epoch  73 |   700/  829 batches | lr 0.00066 | ms/batch 11.65 | loss 0.00005933\n",
      "| Epoch  73 |   750/  829 batches | lr 0.00066 | ms/batch 13.16 | loss 0.00006112\n",
      "| Epoch  73 |   800/  829 batches | lr 0.00066 | ms/batch 11.59 | loss 0.00006973\n",
      "\n",
      "Val set: Average loss: 0.00009842\n",
      "\n",
      "EarlyStopping counter: 13 out of 20\n",
      "| Epoch  74 |    50/  829 batches | lr 0.00066 | ms/batch 11.92 | loss 0.00006873\n",
      "| Epoch  74 |   100/  829 batches | lr 0.00066 | ms/batch 13.17 | loss 0.00005762\n",
      "| Epoch  74 |   150/  829 batches | lr 0.00066 | ms/batch 11.64 | loss 0.00005630\n",
      "| Epoch  74 |   200/  829 batches | lr 0.00066 | ms/batch 11.63 | loss 0.00005605\n",
      "| Epoch  74 |   250/  829 batches | lr 0.00066 | ms/batch 11.56 | loss 0.00006251\n",
      "| Epoch  74 |   300/  829 batches | lr 0.00066 | ms/batch 11.56 | loss 0.00005958\n",
      "| Epoch  74 |   350/  829 batches | lr 0.00066 | ms/batch 13.38 | loss 0.00007250\n",
      "| Epoch  74 |   400/  829 batches | lr 0.00066 | ms/batch 11.62 | loss 0.00008267\n",
      "| Epoch  74 |   450/  829 batches | lr 0.00066 | ms/batch 13.23 | loss 0.00005878\n",
      "| Epoch  74 |   500/  829 batches | lr 0.00066 | ms/batch 11.59 | loss 0.00005867\n",
      "| Epoch  74 |   550/  829 batches | lr 0.00066 | ms/batch 11.63 | loss 0.00006401\n",
      "| Epoch  74 |   600/  829 batches | lr 0.00066 | ms/batch 11.64 | loss 0.00007261\n",
      "| Epoch  74 |   650/  829 batches | lr 0.00066 | ms/batch 11.60 | loss 0.00006298\n",
      "| Epoch  74 |   700/  829 batches | lr 0.00066 | ms/batch 13.18 | loss 0.00007038\n",
      "| Epoch  74 |   750/  829 batches | lr 0.00066 | ms/batch 11.69 | loss 0.00005896\n",
      "| Epoch  74 |   800/  829 batches | lr 0.00066 | ms/batch 11.69 | loss 0.00005724\n",
      "\n",
      "Val set: Average loss: 0.00010193\n",
      "\n",
      "EarlyStopping counter: 14 out of 20\n",
      "| Epoch  75 |    50/  829 batches | lr 0.00066 | ms/batch 11.94 | loss 0.00006184\n",
      "| Epoch  75 |   100/  829 batches | lr 0.00066 | ms/batch 11.61 | loss 0.00005289\n",
      "| Epoch  75 |   150/  829 batches | lr 0.00066 | ms/batch 13.32 | loss 0.00005607\n",
      "| Epoch  75 |   200/  829 batches | lr 0.00066 | ms/batch 11.58 | loss 0.00005273\n",
      "| Epoch  75 |   250/  829 batches | lr 0.00066 | ms/batch 11.56 | loss 0.00006700\n",
      "| Epoch  75 |   300/  829 batches | lr 0.00066 | ms/batch 11.59 | loss 0.00006442\n",
      "| Epoch  75 |   350/  829 batches | lr 0.00066 | ms/batch 11.56 | loss 0.00007758\n",
      "| Epoch  75 |   400/  829 batches | lr 0.00066 | ms/batch 13.56 | loss 0.00006768\n",
      "| Epoch  75 |   450/  829 batches | lr 0.00066 | ms/batch 11.99 | loss 0.00006051\n",
      "| Epoch  75 |   500/  829 batches | lr 0.00066 | ms/batch 13.36 | loss 0.00005919\n",
      "| Epoch  75 |   550/  829 batches | lr 0.00066 | ms/batch 11.80 | loss 0.00006716\n",
      "| Epoch  75 |   600/  829 batches | lr 0.00066 | ms/batch 11.68 | loss 0.00006828\n",
      "| Epoch  75 |   650/  829 batches | lr 0.00066 | ms/batch 11.62 | loss 0.00006535\n",
      "| Epoch  75 |   700/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00005860\n",
      "| Epoch  75 |   750/  829 batches | lr 0.00066 | ms/batch 13.32 | loss 0.00006133\n",
      "| Epoch  75 |   800/  829 batches | lr 0.00066 | ms/batch 11.80 | loss 0.00005453\n",
      "\n",
      "Val set: Average loss: 0.00010657\n",
      "\n",
      "EarlyStopping counter: 15 out of 20\n",
      "| Epoch  76 |    50/  829 batches | lr 0.00066 | ms/batch 12.32 | loss 0.00007288\n",
      "| Epoch  76 |   100/  829 batches | lr 0.00066 | ms/batch 13.44 | loss 0.00006112\n",
      "| Epoch  76 |   150/  829 batches | lr 0.00066 | ms/batch 11.78 | loss 0.00007334\n",
      "| Epoch  76 |   200/  829 batches | lr 0.00066 | ms/batch 13.26 | loss 0.00006122\n",
      "| Epoch  76 |   250/  829 batches | lr 0.00066 | ms/batch 11.77 | loss 0.00007342\n",
      "| Epoch  76 |   300/  829 batches | lr 0.00066 | ms/batch 11.59 | loss 0.00007436\n",
      "| Epoch  76 |   350/  829 batches | lr 0.00066 | ms/batch 11.60 | loss 0.00006367\n",
      "| Epoch  76 |   400/  829 batches | lr 0.00066 | ms/batch 11.58 | loss 0.00005982\n",
      "| Epoch  76 |   450/  829 batches | lr 0.00066 | ms/batch 13.36 | loss 0.00005534\n",
      "| Epoch  76 |   500/  829 batches | lr 0.00066 | ms/batch 11.77 | loss 0.00005678\n",
      "| Epoch  76 |   550/  829 batches | lr 0.00066 | ms/batch 11.81 | loss 0.00006684\n",
      "| Epoch  76 |   600/  829 batches | lr 0.00066 | ms/batch 13.53 | loss 0.00005916\n",
      "| Epoch  76 |   650/  829 batches | lr 0.00066 | ms/batch 11.95 | loss 0.00007163\n",
      "| Epoch  76 |   700/  829 batches | lr 0.00066 | ms/batch 11.81 | loss 0.00005725\n",
      "| Epoch  76 |   750/  829 batches | lr 0.00066 | ms/batch 11.76 | loss 0.00005674\n",
      "| Epoch  76 |   800/  829 batches | lr 0.00066 | ms/batch 11.83 | loss 0.00005155\n",
      "\n",
      "Val set: Average loss: 0.00008014\n",
      "\n",
      "EarlyStopping counter: 16 out of 20\n",
      "| Epoch  77 |    50/  829 batches | lr 0.00066 | ms/batch 12.00 | loss 0.00006713\n",
      "| Epoch  77 |   100/  829 batches | lr 0.00066 | ms/batch 11.71 | loss 0.00006423\n",
      "| Epoch  77 |   150/  829 batches | lr 0.00066 | ms/batch 11.65 | loss 0.00006585\n",
      "| Epoch  77 |   200/  829 batches | lr 0.00066 | ms/batch 11.61 | loss 0.00006301\n",
      "| Epoch  77 |   250/  829 batches | lr 0.00066 | ms/batch 13.32 | loss 0.00006490\n",
      "| Epoch  77 |   300/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00006252\n",
      "| Epoch  77 |   350/  829 batches | lr 0.00066 | ms/batch 13.29 | loss 0.00006534\n",
      "| Epoch  77 |   400/  829 batches | lr 0.00066 | ms/batch 11.65 | loss 0.00005123\n",
      "| Epoch  77 |   450/  829 batches | lr 0.00066 | ms/batch 11.92 | loss 0.00005048\n",
      "| Epoch  77 |   500/  829 batches | lr 0.00066 | ms/batch 11.84 | loss 0.00005346\n",
      "| Epoch  77 |   550/  829 batches | lr 0.00066 | ms/batch 11.66 | loss 0.00005873\n",
      "| Epoch  77 |   600/  829 batches | lr 0.00066 | ms/batch 13.25 | loss 0.00005402\n",
      "| Epoch  77 |   650/  829 batches | lr 0.00066 | ms/batch 11.66 | loss 0.00005753\n",
      "| Epoch  77 |   700/  829 batches | lr 0.00066 | ms/batch 11.61 | loss 0.00004834\n",
      "| Epoch  77 |   750/  829 batches | lr 0.00066 | ms/batch 13.23 | loss 0.00005249\n",
      "| Epoch  77 |   800/  829 batches | lr 0.00066 | ms/batch 11.81 | loss 0.00004938\n",
      "\n",
      "Val set: Average loss: 0.00008042\n",
      "\n",
      "EarlyStopping counter: 17 out of 20\n",
      "| Epoch  78 |    50/  829 batches | lr 0.00066 | ms/batch 12.00 | loss 0.00005204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch  78 |   100/  829 batches | lr 0.00066 | ms/batch 13.30 | loss 0.00004881\n",
      "| Epoch  78 |   150/  829 batches | lr 0.00066 | ms/batch 11.61 | loss 0.00004592\n",
      "| Epoch  78 |   200/  829 batches | lr 0.00066 | ms/batch 11.65 | loss 0.00004738\n",
      "| Epoch  78 |   250/  829 batches | lr 0.00066 | ms/batch 11.63 | loss 0.00004772\n",
      "| Epoch  78 |   300/  829 batches | lr 0.00066 | ms/batch 11.66 | loss 0.00004711\n",
      "| Epoch  78 |   350/  829 batches | lr 0.00066 | ms/batch 13.19 | loss 0.00004994\n",
      "| Epoch  78 |   400/  829 batches | lr 0.00066 | ms/batch 11.63 | loss 0.00004522\n",
      "| Epoch  78 |   450/  829 batches | lr 0.00066 | ms/batch 13.18 | loss 0.00004614\n",
      "| Epoch  78 |   500/  829 batches | lr 0.00066 | ms/batch 11.62 | loss 0.00004442\n",
      "| Epoch  78 |   550/  829 batches | lr 0.00066 | ms/batch 11.66 | loss 0.00005038\n",
      "| Epoch  78 |   600/  829 batches | lr 0.00066 | ms/batch 11.60 | loss 0.00005425\n",
      "| Epoch  78 |   650/  829 batches | lr 0.00066 | ms/batch 11.60 | loss 0.00005101\n",
      "| Epoch  78 |   700/  829 batches | lr 0.00066 | ms/batch 13.14 | loss 0.00005508\n",
      "| Epoch  78 |   750/  829 batches | lr 0.00066 | ms/batch 11.64 | loss 0.00005352\n",
      "| Epoch  78 |   800/  829 batches | lr 0.00066 | ms/batch 11.61 | loss 0.00005118\n",
      "\n",
      "Val set: Average loss: 0.00007816\n",
      "\n",
      "EarlyStopping counter: 18 out of 20\n",
      "| Epoch  79 |    50/  829 batches | lr 0.00066 | ms/batch 12.07 | loss 0.00005360\n",
      "| Epoch  79 |   100/  829 batches | lr 0.00066 | ms/batch 11.98 | loss 0.00005220\n",
      "| Epoch  79 |   150/  829 batches | lr 0.00066 | ms/batch 13.37 | loss 0.00005552\n",
      "| Epoch  79 |   200/  829 batches | lr 0.00066 | ms/batch 12.06 | loss 0.00005538\n",
      "| Epoch  79 |   250/  829 batches | lr 0.00066 | ms/batch 11.78 | loss 0.00005915\n",
      "| Epoch  79 |   300/  829 batches | lr 0.00066 | ms/batch 11.84 | loss 0.00005715\n",
      "| Epoch  79 |   350/  829 batches | lr 0.00066 | ms/batch 11.99 | loss 0.00005313\n",
      "| Epoch  79 |   400/  829 batches | lr 0.00066 | ms/batch 13.45 | loss 0.00006114\n",
      "| Epoch  79 |   450/  829 batches | lr 0.00066 | ms/batch 12.00 | loss 0.00004884\n",
      "| Epoch  79 |   500/  829 batches | lr 0.00066 | ms/batch 13.49 | loss 0.00004796\n",
      "| Epoch  79 |   550/  829 batches | lr 0.00066 | ms/batch 11.99 | loss 0.00005420\n",
      "| Epoch  79 |   600/  829 batches | lr 0.00066 | ms/batch 11.76 | loss 0.00006447\n",
      "| Epoch  79 |   650/  829 batches | lr 0.00066 | ms/batch 11.83 | loss 0.00005693\n",
      "| Epoch  79 |   700/  829 batches | lr 0.00066 | ms/batch 11.75 | loss 0.00005719\n",
      "| Epoch  79 |   750/  829 batches | lr 0.00066 | ms/batch 13.59 | loss 0.00005879\n",
      "| Epoch  79 |   800/  829 batches | lr 0.00066 | ms/batch 11.80 | loss 0.00005310\n",
      "\n",
      "Val set: Average loss: 0.00007723\n",
      "\n",
      "EarlyStopping counter: 19 out of 20\n",
      "| Epoch  80 |    50/  829 batches | lr 0.00066 | ms/batch 12.10 | loss 0.00005738\n",
      "| Epoch  80 |   100/  829 batches | lr 0.00066 | ms/batch 13.36 | loss 0.00004971\n",
      "| Epoch  80 |   150/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00004985\n",
      "| Epoch  80 |   200/  829 batches | lr 0.00066 | ms/batch 13.19 | loss 0.00005075\n",
      "| Epoch  80 |   250/  829 batches | lr 0.00066 | ms/batch 11.61 | loss 0.00005721\n",
      "| Epoch  80 |   300/  829 batches | lr 0.00066 | ms/batch 11.74 | loss 0.00006305\n",
      "| Epoch  80 |   350/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00005886\n",
      "| Epoch  80 |   400/  829 batches | lr 0.00066 | ms/batch 11.66 | loss 0.00005291\n",
      "| Epoch  80 |   450/  829 batches | lr 0.00066 | ms/batch 13.53 | loss 0.00005178\n",
      "| Epoch  80 |   500/  829 batches | lr 0.00066 | ms/batch 11.86 | loss 0.00005703\n",
      "| Epoch  80 |   550/  829 batches | lr 0.00066 | ms/batch 11.81 | loss 0.00005970\n",
      "| Epoch  80 |   600/  829 batches | lr 0.00066 | ms/batch 13.37 | loss 0.00006782\n",
      "| Epoch  80 |   650/  829 batches | lr 0.00066 | ms/batch 11.89 | loss 0.00005934\n",
      "| Epoch  80 |   700/  829 batches | lr 0.00066 | ms/batch 11.99 | loss 0.00005529\n",
      "| Epoch  80 |   750/  829 batches | lr 0.00066 | ms/batch 11.68 | loss 0.00005569\n",
      "| Epoch  80 |   800/  829 batches | lr 0.00066 | ms/batch 11.77 | loss 0.00005767\n",
      "\n",
      "Val set: Average loss: 0.00007587\n",
      "\n",
      "| Epoch  81 |    50/  829 batches | lr 0.00066 | ms/batch 11.99 | loss 0.00005473\n",
      "| Epoch  81 |   100/  829 batches | lr 0.00066 | ms/batch 11.73 | loss 0.00005986\n",
      "| Epoch  81 |   150/  829 batches | lr 0.00066 | ms/batch 11.81 | loss 0.00005171\n",
      "| Epoch  81 |   200/  829 batches | lr 0.00066 | ms/batch 11.77 | loss 0.00005078\n",
      "| Epoch  81 |   250/  829 batches | lr 0.00066 | ms/batch 13.48 | loss 0.00005801\n",
      "| Epoch  81 |   300/  829 batches | lr 0.00066 | ms/batch 11.69 | loss 0.00007360\n",
      "| Epoch  81 |   350/  829 batches | lr 0.00066 | ms/batch 13.49 | loss 0.00005953\n",
      "| Epoch  81 |   400/  829 batches | lr 0.00066 | ms/batch 11.80 | loss 0.00006073\n",
      "| Epoch  81 |   450/  829 batches | lr 0.00066 | ms/batch 11.82 | loss 0.00005485\n",
      "| Epoch  81 |   500/  829 batches | lr 0.00066 | ms/batch 11.91 | loss 0.00005885\n",
      "| Epoch  81 |   550/  829 batches | lr 0.00066 | ms/batch 11.91 | loss 0.00005545\n",
      "| Epoch  81 |   600/  829 batches | lr 0.00066 | ms/batch 13.40 | loss 0.00007230\n",
      "| Epoch  81 |   650/  829 batches | lr 0.00066 | ms/batch 11.71 | loss 0.00006041\n",
      "| Epoch  81 |   700/  829 batches | lr 0.00066 | ms/batch 11.82 | loss 0.00005442\n",
      "| Epoch  81 |   750/  829 batches | lr 0.00066 | ms/batch 13.51 | loss 0.00005440\n",
      "| Epoch  81 |   800/  829 batches | lr 0.00066 | ms/batch 11.81 | loss 0.00005025\n",
      "\n",
      "Val set: Average loss: 0.00007837\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  82 |    50/  829 batches | lr 0.00066 | ms/batch 12.05 | loss 0.00005239\n",
      "| Epoch  82 |   100/  829 batches | lr 0.00066 | ms/batch 13.45 | loss 0.00004922\n",
      "| Epoch  82 |   150/  829 batches | lr 0.00066 | ms/batch 11.78 | loss 0.00004765\n",
      "| Epoch  82 |   200/  829 batches | lr 0.00066 | ms/batch 12.11 | loss 0.00004820\n",
      "| Epoch  82 |   250/  829 batches | lr 0.00066 | ms/batch 12.05 | loss 0.00005304\n",
      "| Epoch  82 |   300/  829 batches | lr 0.00066 | ms/batch 11.93 | loss 0.00006404\n",
      "| Epoch  82 |   350/  829 batches | lr 0.00066 | ms/batch 13.82 | loss 0.00006616\n",
      "| Epoch  82 |   400/  829 batches | lr 0.00066 | ms/batch 11.97 | loss 0.00006220\n",
      "| Epoch  82 |   450/  829 batches | lr 0.00066 | ms/batch 13.75 | loss 0.00005258\n",
      "| Epoch  82 |   500/  829 batches | lr 0.00066 | ms/batch 12.01 | loss 0.00004960\n",
      "| Epoch  82 |   550/  829 batches | lr 0.00066 | ms/batch 12.23 | loss 0.00005110\n",
      "| Epoch  82 |   600/  829 batches | lr 0.00066 | ms/batch 12.20 | loss 0.00005627\n",
      "| Epoch  82 |   650/  829 batches | lr 0.00066 | ms/batch 11.94 | loss 0.00005048\n",
      "| Epoch  82 |   700/  829 batches | lr 0.00066 | ms/batch 13.67 | loss 0.00005000\n",
      "| Epoch  82 |   750/  829 batches | lr 0.00066 | ms/batch 11.81 | loss 0.00004798\n",
      "| Epoch  82 |   800/  829 batches | lr 0.00066 | ms/batch 11.83 | loss 0.00004556\n",
      "\n",
      "Val set: Average loss: 0.00007133\n",
      "\n",
      "| Epoch  83 |    50/  829 batches | lr 0.00066 | ms/batch 12.12 | loss 0.00004750\n",
      "| Epoch  83 |   100/  829 batches | lr 0.00066 | ms/batch 11.71 | loss 0.00004585\n",
      "| Epoch  83 |   150/  829 batches | lr 0.00066 | ms/batch 13.23 | loss 0.00004584\n",
      "| Epoch  83 |   200/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00004624\n",
      "| Epoch  83 |   250/  829 batches | lr 0.00066 | ms/batch 11.69 | loss 0.00004805\n",
      "| Epoch  83 |   300/  829 batches | lr 0.00066 | ms/batch 11.76 | loss 0.00005422\n",
      "| Epoch  83 |   350/  829 batches | lr 0.00066 | ms/batch 11.62 | loss 0.00005455\n",
      "| Epoch  83 |   400/  829 batches | lr 0.00066 | ms/batch 13.18 | loss 0.00005325\n",
      "| Epoch  83 |   450/  829 batches | lr 0.00066 | ms/batch 11.71 | loss 0.00004903\n",
      "| Epoch  83 |   500/  829 batches | lr 0.00066 | ms/batch 13.17 | loss 0.00004505\n",
      "| Epoch  83 |   550/  829 batches | lr 0.00066 | ms/batch 11.75 | loss 0.00004807\n",
      "| Epoch  83 |   600/  829 batches | lr 0.00066 | ms/batch 11.69 | loss 0.00005315\n",
      "| Epoch  83 |   650/  829 batches | lr 0.00066 | ms/batch 11.64 | loss 0.00004924\n",
      "| Epoch  83 |   700/  829 batches | lr 0.00066 | ms/batch 11.58 | loss 0.00004767\n",
      "| Epoch  83 |   750/  829 batches | lr 0.00066 | ms/batch 13.21 | loss 0.00005039\n",
      "| Epoch  83 |   800/  829 batches | lr 0.00066 | ms/batch 11.61 | loss 0.00005133\n",
      "\n",
      "Val set: Average loss: 0.00007634\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  84 |    50/  829 batches | lr 0.00066 | ms/batch 12.00 | loss 0.00005290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch  84 |   100/  829 batches | lr 0.00066 | ms/batch 13.17 | loss 0.00004982\n",
      "| Epoch  84 |   150/  829 batches | lr 0.00066 | ms/batch 11.62 | loss 0.00004970\n",
      "| Epoch  84 |   200/  829 batches | lr 0.00066 | ms/batch 11.61 | loss 0.00005276\n",
      "| Epoch  84 |   250/  829 batches | lr 0.00066 | ms/batch 13.22 | loss 0.00005733\n",
      "| Epoch  84 |   300/  829 batches | lr 0.00066 | ms/batch 11.70 | loss 0.00005360\n",
      "| Epoch  84 |   350/  829 batches | lr 0.00066 | ms/batch 11.64 | loss 0.00005488\n",
      "| Epoch  84 |   400/  829 batches | lr 0.00066 | ms/batch 11.60 | loss 0.00005411\n",
      "| Epoch  84 |   450/  829 batches | lr 0.00066 | ms/batch 13.36 | loss 0.00004733\n",
      "| Epoch  84 |   500/  829 batches | lr 0.00066 | ms/batch 11.60 | loss 0.00004502\n",
      "| Epoch  84 |   550/  829 batches | lr 0.00066 | ms/batch 11.62 | loss 0.00005069\n",
      "| Epoch  84 |   600/  829 batches | lr 0.00066 | ms/batch 13.51 | loss 0.00005115\n",
      "| Epoch  84 |   650/  829 batches | lr 0.00066 | ms/batch 11.59 | loss 0.00004760\n",
      "| Epoch  84 |   700/  829 batches | lr 0.00066 | ms/batch 11.58 | loss 0.00004793\n",
      "| Epoch  84 |   750/  829 batches | lr 0.00066 | ms/batch 11.60 | loss 0.00005356\n",
      "| Epoch  84 |   800/  829 batches | lr 0.00066 | ms/batch 11.57 | loss 0.00005975\n",
      "\n",
      "Val set: Average loss: 0.00008091\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  85 |    50/  829 batches | lr 0.00066 | ms/batch 11.86 | loss 0.00005773\n",
      "| Epoch  85 |   100/  829 batches | lr 0.00066 | ms/batch 11.64 | loss 0.00005984\n",
      "| Epoch  85 |   150/  829 batches | lr 0.00066 | ms/batch 11.56 | loss 0.00005100\n",
      "| Epoch  85 |   200/  829 batches | lr 0.00066 | ms/batch 11.56 | loss 0.00004958\n",
      "| Epoch  85 |   250/  829 batches | lr 0.00066 | ms/batch 13.18 | loss 0.00005748\n",
      "| Epoch  85 |   300/  829 batches | lr 0.00066 | ms/batch 11.71 | loss 0.00005523\n",
      "| Epoch  85 |   350/  829 batches | lr 0.00066 | ms/batch 13.19 | loss 0.00006772\n",
      "| Epoch  85 |   400/  829 batches | lr 0.00066 | ms/batch 11.63 | loss 0.00006813\n",
      "| Epoch  85 |   450/  829 batches | lr 0.00066 | ms/batch 11.73 | loss 0.00005103\n",
      "| Epoch  85 |   500/  829 batches | lr 0.00066 | ms/batch 11.62 | loss 0.00005009\n",
      "| Epoch  85 |   550/  829 batches | lr 0.00066 | ms/batch 11.60 | loss 0.00005670\n",
      "| Epoch  85 |   600/  829 batches | lr 0.00066 | ms/batch 13.21 | loss 0.00006338\n",
      "| Epoch  85 |   650/  829 batches | lr 0.00066 | ms/batch 11.66 | loss 0.00005647\n",
      "| Epoch  85 |   700/  829 batches | lr 0.00066 | ms/batch 11.68 | loss 0.00006094\n",
      "| Epoch  85 |   750/  829 batches | lr 0.00066 | ms/batch 13.24 | loss 0.00006137\n",
      "| Epoch  85 |   800/  829 batches | lr 0.00066 | ms/batch 11.57 | loss 0.00005457\n",
      "\n",
      "Val set: Average loss: 0.00007652\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  86 |    50/  829 batches | lr 0.00066 | ms/batch 12.26 | loss 0.00005504\n",
      "| Epoch  86 |   100/  829 batches | lr 0.00066 | ms/batch 13.18 | loss 0.00004942\n",
      "| Epoch  86 |   150/  829 batches | lr 0.00066 | ms/batch 11.57 | loss 0.00005166\n",
      "| Epoch  86 |   200/  829 batches | lr 0.00066 | ms/batch 11.62 | loss 0.00005315\n",
      "| Epoch  86 |   250/  829 batches | lr 0.00066 | ms/batch 11.57 | loss 0.00005655\n",
      "| Epoch  86 |   300/  829 batches | lr 0.00066 | ms/batch 11.65 | loss 0.00005658\n",
      "| Epoch  86 |   350/  829 batches | lr 0.00066 | ms/batch 13.18 | loss 0.00005929\n",
      "| Epoch  86 |   400/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00005608\n",
      "| Epoch  86 |   450/  829 batches | lr 0.00066 | ms/batch 13.21 | loss 0.00004855\n",
      "| Epoch  86 |   500/  829 batches | lr 0.00066 | ms/batch 11.58 | loss 0.00004897\n",
      "| Epoch  86 |   550/  829 batches | lr 0.00066 | ms/batch 11.59 | loss 0.00005673\n",
      "| Epoch  86 |   600/  829 batches | lr 0.00066 | ms/batch 11.64 | loss 0.00006488\n",
      "| Epoch  86 |   650/  829 batches | lr 0.00066 | ms/batch 11.59 | loss 0.00005057\n",
      "| Epoch  86 |   700/  829 batches | lr 0.00066 | ms/batch 13.26 | loss 0.00004738\n",
      "| Epoch  86 |   750/  829 batches | lr 0.00066 | ms/batch 11.63 | loss 0.00005873\n",
      "| Epoch  86 |   800/  829 batches | lr 0.00066 | ms/batch 11.61 | loss 0.00005181\n",
      "\n",
      "Val set: Average loss: 0.00009744\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch  87 |    50/  829 batches | lr 0.00066 | ms/batch 12.01 | loss 0.00005610\n",
      "| Epoch  87 |   100/  829 batches | lr 0.00066 | ms/batch 11.61 | loss 0.00005607\n",
      "| Epoch  87 |   150/  829 batches | lr 0.00066 | ms/batch 13.18 | loss 0.00005652\n",
      "| Epoch  87 |   200/  829 batches | lr 0.00066 | ms/batch 11.70 | loss 0.00006046\n",
      "| Epoch  87 |   250/  829 batches | lr 0.00066 | ms/batch 11.76 | loss 0.00005753\n",
      "| Epoch  87 |   300/  829 batches | lr 0.00066 | ms/batch 11.77 | loss 0.00006164\n",
      "| Epoch  87 |   350/  829 batches | lr 0.00066 | ms/batch 11.85 | loss 0.00006994\n",
      "| Epoch  87 |   400/  829 batches | lr 0.00066 | ms/batch 13.42 | loss 0.00007002\n",
      "| Epoch  87 |   450/  829 batches | lr 0.00066 | ms/batch 11.96 | loss 0.00006377\n",
      "| Epoch  87 |   500/  829 batches | lr 0.00066 | ms/batch 13.48 | loss 0.00005135\n",
      "| Epoch  87 |   550/  829 batches | lr 0.00066 | ms/batch 11.85 | loss 0.00005199\n",
      "| Epoch  87 |   600/  829 batches | lr 0.00066 | ms/batch 11.68 | loss 0.00005839\n",
      "| Epoch  87 |   650/  829 batches | lr 0.00066 | ms/batch 11.73 | loss 0.00005419\n",
      "| Epoch  87 |   700/  829 batches | lr 0.00066 | ms/batch 11.68 | loss 0.00004947\n",
      "| Epoch  87 |   750/  829 batches | lr 0.00066 | ms/batch 13.26 | loss 0.00005126\n",
      "| Epoch  87 |   800/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00004963\n",
      "\n",
      "Val set: Average loss: 0.00007577\n",
      "\n",
      "EarlyStopping counter: 5 out of 20\n",
      "| Epoch  88 |    50/  829 batches | lr 0.00066 | ms/batch 12.22 | loss 0.00005905\n",
      "| Epoch  88 |   100/  829 batches | lr 0.00066 | ms/batch 13.73 | loss 0.00005364\n",
      "| Epoch  88 |   150/  829 batches | lr 0.00066 | ms/batch 11.90 | loss 0.00006984\n",
      "| Epoch  88 |   200/  829 batches | lr 0.00066 | ms/batch 11.96 | loss 0.00005125\n",
      "| Epoch  88 |   250/  829 batches | lr 0.00066 | ms/batch 13.69 | loss 0.00005180\n",
      "| Epoch  88 |   300/  829 batches | lr 0.00066 | ms/batch 11.96 | loss 0.00007528\n",
      "| Epoch  88 |   350/  829 batches | lr 0.00066 | ms/batch 12.22 | loss 0.00006586\n",
      "| Epoch  88 |   400/  829 batches | lr 0.00066 | ms/batch 11.81 | loss 0.00005462\n",
      "| Epoch  88 |   450/  829 batches | lr 0.00066 | ms/batch 13.90 | loss 0.00005147\n",
      "| Epoch  88 |   500/  829 batches | lr 0.00066 | ms/batch 12.19 | loss 0.00005445\n",
      "| Epoch  88 |   550/  829 batches | lr 0.00066 | ms/batch 12.36 | loss 0.00006000\n",
      "| Epoch  88 |   600/  829 batches | lr 0.00066 | ms/batch 13.60 | loss 0.00005539\n",
      "| Epoch  88 |   650/  829 batches | lr 0.00066 | ms/batch 11.98 | loss 0.00005490\n",
      "| Epoch  88 |   700/  829 batches | lr 0.00066 | ms/batch 12.09 | loss 0.00005148\n",
      "| Epoch  88 |   750/  829 batches | lr 0.00066 | ms/batch 11.86 | loss 0.00005981\n",
      "| Epoch  88 |   800/  829 batches | lr 0.00066 | ms/batch 11.87 | loss 0.00005284\n",
      "\n",
      "Val set: Average loss: 0.00007302\n",
      "\n",
      "EarlyStopping counter: 6 out of 20\n",
      "| Epoch  89 |    50/  829 batches | lr 0.00066 | ms/batch 12.02 | loss 0.00005582\n",
      "| Epoch  89 |   100/  829 batches | lr 0.00066 | ms/batch 11.72 | loss 0.00006155\n",
      "| Epoch  89 |   150/  829 batches | lr 0.00066 | ms/batch 11.74 | loss 0.00006716\n",
      "| Epoch  89 |   200/  829 batches | lr 0.00066 | ms/batch 11.88 | loss 0.00004937\n",
      "| Epoch  89 |   250/  829 batches | lr 0.00066 | ms/batch 13.63 | loss 0.00005948\n",
      "| Epoch  89 |   300/  829 batches | lr 0.00066 | ms/batch 12.14 | loss 0.00006832\n",
      "| Epoch  89 |   350/  829 batches | lr 0.00066 | ms/batch 13.48 | loss 0.00007772\n",
      "| Epoch  89 |   400/  829 batches | lr 0.00066 | ms/batch 11.96 | loss 0.00006072\n",
      "| Epoch  89 |   450/  829 batches | lr 0.00066 | ms/batch 12.15 | loss 0.00005373\n",
      "| Epoch  89 |   500/  829 batches | lr 0.00066 | ms/batch 11.68 | loss 0.00005365\n",
      "| Epoch  89 |   550/  829 batches | lr 0.00066 | ms/batch 12.26 | loss 0.00005882\n",
      "| Epoch  89 |   600/  829 batches | lr 0.00066 | ms/batch 13.39 | loss 0.00006343\n",
      "| Epoch  89 |   650/  829 batches | lr 0.00066 | ms/batch 11.79 | loss 0.00005579\n",
      "| Epoch  89 |   700/  829 batches | lr 0.00066 | ms/batch 12.02 | loss 0.00004876\n",
      "| Epoch  89 |   750/  829 batches | lr 0.00066 | ms/batch 13.36 | loss 0.00004974\n",
      "| Epoch  89 |   800/  829 batches | lr 0.00066 | ms/batch 12.17 | loss 0.00004860\n",
      "\n",
      "Val set: Average loss: 0.00008406\n",
      "\n",
      "EarlyStopping counter: 7 out of 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch  90 |    50/  829 batches | lr 0.00066 | ms/batch 12.46 | loss 0.00006118\n",
      "| Epoch  90 |   100/  829 batches | lr 0.00066 | ms/batch 13.62 | loss 0.00006563\n",
      "| Epoch  90 |   150/  829 batches | lr 0.00066 | ms/batch 11.94 | loss 0.00005759\n",
      "| Epoch  90 |   200/  829 batches | lr 0.00066 | ms/batch 11.71 | loss 0.00005119\n",
      "| Epoch  90 |   250/  829 batches | lr 0.00066 | ms/batch 11.76 | loss 0.00005465\n",
      "| Epoch  90 |   300/  829 batches | lr 0.00066 | ms/batch 11.68 | loss 0.00005825\n",
      "| Epoch  90 |   350/  829 batches | lr 0.00066 | ms/batch 13.34 | loss 0.00006524\n",
      "| Epoch  90 |   400/  829 batches | lr 0.00066 | ms/batch 11.99 | loss 0.00005429\n",
      "| Epoch  90 |   450/  829 batches | lr 0.00066 | ms/batch 13.78 | loss 0.00004740\n",
      "| Epoch  90 |   500/  829 batches | lr 0.00066 | ms/batch 11.94 | loss 0.00004764\n",
      "| Epoch  90 |   550/  829 batches | lr 0.00066 | ms/batch 11.77 | loss 0.00005418\n",
      "| Epoch  90 |   600/  829 batches | lr 0.00066 | ms/batch 12.03 | loss 0.00005408\n",
      "| Epoch  90 |   650/  829 batches | lr 0.00066 | ms/batch 11.81 | loss 0.00005040\n",
      "| Epoch  90 |   700/  829 batches | lr 0.00066 | ms/batch 13.37 | loss 0.00004164\n",
      "| Epoch  90 |   750/  829 batches | lr 0.00066 | ms/batch 12.36 | loss 0.00004210\n",
      "| Epoch  90 |   800/  829 batches | lr 0.00066 | ms/batch 12.61 | loss 0.00004175\n",
      "\n",
      "Val set: Average loss: 0.00007408\n",
      "\n",
      "EarlyStopping counter: 8 out of 20\n",
      "| Epoch  91 |    50/  829 batches | lr 0.00066 | ms/batch 12.12 | loss 0.00004911\n",
      "| Epoch  91 |   100/  829 batches | lr 0.00066 | ms/batch 11.90 | loss 0.00004667\n",
      "| Epoch  91 |   150/  829 batches | lr 0.00066 | ms/batch 13.52 | loss 0.00004591\n",
      "| Epoch  91 |   200/  829 batches | lr 0.00066 | ms/batch 11.82 | loss 0.00004377\n",
      "| Epoch  91 |   250/  829 batches | lr 0.00066 | ms/batch 11.62 | loss 0.00004629\n",
      "| Epoch  91 |   300/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00004390\n",
      "| Epoch  91 |   350/  829 batches | lr 0.00066 | ms/batch 11.58 | loss 0.00004425\n",
      "| Epoch  91 |   400/  829 batches | lr 0.00066 | ms/batch 13.30 | loss 0.00004291\n",
      "| Epoch  91 |   450/  829 batches | lr 0.00066 | ms/batch 12.06 | loss 0.00004129\n",
      "| Epoch  91 |   500/  829 batches | lr 0.00066 | ms/batch 13.89 | loss 0.00004520\n",
      "| Epoch  91 |   550/  829 batches | lr 0.00066 | ms/batch 12.00 | loss 0.00004461\n",
      "| Epoch  91 |   600/  829 batches | lr 0.00066 | ms/batch 11.77 | loss 0.00004866\n",
      "| Epoch  91 |   650/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00004333\n",
      "| Epoch  91 |   700/  829 batches | lr 0.00066 | ms/batch 11.71 | loss 0.00004415\n",
      "| Epoch  91 |   750/  829 batches | lr 0.00066 | ms/batch 13.21 | loss 0.00004603\n",
      "| Epoch  91 |   800/  829 batches | lr 0.00066 | ms/batch 12.09 | loss 0.00004494\n",
      "\n",
      "Val set: Average loss: 0.00006808\n",
      "\n",
      "| Epoch  92 |    50/  829 batches | lr 0.00066 | ms/batch 12.42 | loss 0.00005253\n",
      "| Epoch  92 |   100/  829 batches | lr 0.00066 | ms/batch 13.71 | loss 0.00004754\n",
      "| Epoch  92 |   150/  829 batches | lr 0.00066 | ms/batch 11.87 | loss 0.00004732\n",
      "| Epoch  92 |   200/  829 batches | lr 0.00066 | ms/batch 14.57 | loss 0.00004750\n",
      "| Epoch  92 |   250/  829 batches | lr 0.00066 | ms/batch 12.39 | loss 0.00005181\n",
      "| Epoch  92 |   300/  829 batches | lr 0.00066 | ms/batch 12.41 | loss 0.00004746\n",
      "| Epoch  92 |   350/  829 batches | lr 0.00066 | ms/batch 12.52 | loss 0.00004412\n",
      "| Epoch  92 |   400/  829 batches | lr 0.00066 | ms/batch 12.50 | loss 0.00004428\n",
      "| Epoch  92 |   450/  829 batches | lr 0.00066 | ms/batch 15.37 | loss 0.00004305\n",
      "| Epoch  92 |   500/  829 batches | lr 0.00066 | ms/batch 13.24 | loss 0.00004319\n",
      "| Epoch  92 |   550/  829 batches | lr 0.00066 | ms/batch 12.94 | loss 0.00004901\n",
      "| Epoch  92 |   600/  829 batches | lr 0.00066 | ms/batch 14.64 | loss 0.00005501\n",
      "| Epoch  92 |   650/  829 batches | lr 0.00066 | ms/batch 13.25 | loss 0.00005178\n",
      "| Epoch  92 |   700/  829 batches | lr 0.00066 | ms/batch 13.16 | loss 0.00004771\n",
      "| Epoch  92 |   750/  829 batches | lr 0.00066 | ms/batch 14.87 | loss 0.00004915\n",
      "| Epoch  92 |   800/  829 batches | lr 0.00066 | ms/batch 13.18 | loss 0.00004969\n",
      "\n",
      "Val set: Average loss: 0.00007738\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  93 |    50/  829 batches | lr 0.00066 | ms/batch 13.07 | loss 0.00006203\n",
      "| Epoch  93 |   100/  829 batches | lr 0.00066 | ms/batch 11.91 | loss 0.00005146\n",
      "| Epoch  93 |   150/  829 batches | lr 0.00066 | ms/batch 12.41 | loss 0.00004758\n",
      "| Epoch  93 |   200/  829 batches | lr 0.00066 | ms/batch 12.23 | loss 0.00005388\n",
      "| Epoch  93 |   250/  829 batches | lr 0.00066 | ms/batch 13.44 | loss 0.00006209\n",
      "| Epoch  93 |   300/  829 batches | lr 0.00066 | ms/batch 13.69 | loss 0.00005126\n",
      "| Epoch  93 |   350/  829 batches | lr 0.00066 | ms/batch 13.80 | loss 0.00005493\n",
      "| Epoch  93 |   400/  829 batches | lr 0.00066 | ms/batch 12.70 | loss 0.00004555\n",
      "| Epoch  93 |   450/  829 batches | lr 0.00066 | ms/batch 12.59 | loss 0.00004329\n",
      "| Epoch  93 |   500/  829 batches | lr 0.00066 | ms/batch 12.33 | loss 0.00004471\n",
      "| Epoch  93 |   550/  829 batches | lr 0.00066 | ms/batch 12.21 | loss 0.00004795\n",
      "| Epoch  93 |   600/  829 batches | lr 0.00066 | ms/batch 14.09 | loss 0.00005488\n",
      "| Epoch  93 |   650/  829 batches | lr 0.00066 | ms/batch 13.06 | loss 0.00005185\n",
      "| Epoch  93 |   700/  829 batches | lr 0.00066 | ms/batch 13.42 | loss 0.00004448\n",
      "| Epoch  93 |   750/  829 batches | lr 0.00066 | ms/batch 14.59 | loss 0.00004556\n",
      "| Epoch  93 |   800/  829 batches | lr 0.00066 | ms/batch 12.69 | loss 0.00005249\n",
      "\n",
      "Val set: Average loss: 0.00007476\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  94 |    50/  829 batches | lr 0.00066 | ms/batch 13.74 | loss 0.00004785\n",
      "| Epoch  94 |   100/  829 batches | lr 0.00066 | ms/batch 14.97 | loss 0.00005572\n",
      "| Epoch  94 |   150/  829 batches | lr 0.00066 | ms/batch 12.62 | loss 0.00005381\n",
      "| Epoch  94 |   200/  829 batches | lr 0.00066 | ms/batch 13.37 | loss 0.00005353\n",
      "| Epoch  94 |   250/  829 batches | lr 0.00066 | ms/batch 12.87 | loss 0.00005561\n",
      "| Epoch  94 |   300/  829 batches | lr 0.00066 | ms/batch 11.95 | loss 0.00005006\n",
      "| Epoch  94 |   350/  829 batches | lr 0.00066 | ms/batch 13.66 | loss 0.00005234\n",
      "| Epoch  94 |   400/  829 batches | lr 0.00066 | ms/batch 12.27 | loss 0.00004979\n",
      "| Epoch  94 |   450/  829 batches | lr 0.00066 | ms/batch 14.30 | loss 0.00004651\n",
      "| Epoch  94 |   500/  829 batches | lr 0.00066 | ms/batch 12.26 | loss 0.00004687\n",
      "| Epoch  94 |   550/  829 batches | lr 0.00066 | ms/batch 12.30 | loss 0.00005406\n",
      "| Epoch  94 |   600/  829 batches | lr 0.00066 | ms/batch 12.57 | loss 0.00006384\n",
      "| Epoch  94 |   650/  829 batches | lr 0.00066 | ms/batch 13.31 | loss 0.00005166\n",
      "| Epoch  94 |   700/  829 batches | lr 0.00066 | ms/batch 14.19 | loss 0.00004620\n",
      "| Epoch  94 |   750/  829 batches | lr 0.00066 | ms/batch 12.01 | loss 0.00004895\n",
      "| Epoch  94 |   800/  829 batches | lr 0.00066 | ms/batch 11.85 | loss 0.00004247\n",
      "\n",
      "Val set: Average loss: 0.00007295\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch  95 |    50/  829 batches | lr 0.00066 | ms/batch 12.28 | loss 0.00004477\n",
      "| Epoch  95 |   100/  829 batches | lr 0.00066 | ms/batch 12.04 | loss 0.00005120\n",
      "| Epoch  95 |   150/  829 batches | lr 0.00066 | ms/batch 14.48 | loss 0.00004564\n",
      "| Epoch  95 |   200/  829 batches | lr 0.00066 | ms/batch 12.23 | loss 0.00004432\n",
      "| Epoch  95 |   250/  829 batches | lr 0.00066 | ms/batch 12.16 | loss 0.00005180\n",
      "| Epoch  95 |   300/  829 batches | lr 0.00066 | ms/batch 12.14 | loss 0.00005203\n",
      "| Epoch  95 |   350/  829 batches | lr 0.00066 | ms/batch 12.03 | loss 0.00005955\n",
      "| Epoch  95 |   400/  829 batches | lr 0.00066 | ms/batch 13.82 | loss 0.00004991\n",
      "| Epoch  95 |   450/  829 batches | lr 0.00066 | ms/batch 12.12 | loss 0.00004970\n",
      "| Epoch  95 |   500/  829 batches | lr 0.00066 | ms/batch 13.80 | loss 0.00005090\n",
      "| Epoch  95 |   550/  829 batches | lr 0.00066 | ms/batch 11.94 | loss 0.00005090\n",
      "| Epoch  95 |   600/  829 batches | lr 0.00066 | ms/batch 11.98 | loss 0.00005800\n",
      "| Epoch  95 |   650/  829 batches | lr 0.00066 | ms/batch 11.84 | loss 0.00004904\n",
      "| Epoch  95 |   700/  829 batches | lr 0.00066 | ms/batch 11.83 | loss 0.00004629\n",
      "| Epoch  95 |   750/  829 batches | lr 0.00066 | ms/batch 13.71 | loss 0.00004971\n",
      "| Epoch  95 |   800/  829 batches | lr 0.00066 | ms/batch 12.56 | loss 0.00004296\n",
      "\n",
      "Val set: Average loss: 0.00007083\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch  96 |    50/  829 batches | lr 0.00066 | ms/batch 12.73 | loss 0.00004588\n",
      "| Epoch  96 |   100/  829 batches | lr 0.00066 | ms/batch 13.83 | loss 0.00004593\n",
      "| Epoch  96 |   150/  829 batches | lr 0.00066 | ms/batch 12.02 | loss 0.00004473\n",
      "| Epoch  96 |   200/  829 batches | lr 0.00066 | ms/batch 13.44 | loss 0.00004505\n",
      "| Epoch  96 |   250/  829 batches | lr 0.00066 | ms/batch 11.78 | loss 0.00005271\n",
      "| Epoch  96 |   300/  829 batches | lr 0.00066 | ms/batch 11.77 | loss 0.00004849\n",
      "| Epoch  96 |   350/  829 batches | lr 0.00066 | ms/batch 11.80 | loss 0.00005351\n",
      "| Epoch  96 |   400/  829 batches | lr 0.00066 | ms/batch 12.35 | loss 0.00004615\n",
      "| Epoch  96 |   450/  829 batches | lr 0.00066 | ms/batch 13.58 | loss 0.00004188\n",
      "| Epoch  96 |   500/  829 batches | lr 0.00066 | ms/batch 12.89 | loss 0.00004137\n",
      "| Epoch  96 |   550/  829 batches | lr 0.00066 | ms/batch 12.87 | loss 0.00004826\n",
      "| Epoch  96 |   600/  829 batches | lr 0.00066 | ms/batch 13.51 | loss 0.00004570\n",
      "| Epoch  96 |   650/  829 batches | lr 0.00066 | ms/batch 12.42 | loss 0.00004435\n",
      "| Epoch  96 |   700/  829 batches | lr 0.00066 | ms/batch 11.79 | loss 0.00004339\n",
      "| Epoch  96 |   750/  829 batches | lr 0.00066 | ms/batch 11.71 | loss 0.00004246\n",
      "| Epoch  96 |   800/  829 batches | lr 0.00066 | ms/batch 11.65 | loss 0.00004186\n",
      "\n",
      "Val set: Average loss: 0.00007335\n",
      "\n",
      "EarlyStopping counter: 5 out of 20\n",
      "| Epoch  97 |    50/  829 batches | lr 0.00066 | ms/batch 12.04 | loss 0.00004448\n",
      "| Epoch  97 |   100/  829 batches | lr 0.00066 | ms/batch 12.29 | loss 0.00004827\n",
      "| Epoch  97 |   150/  829 batches | lr 0.00066 | ms/batch 11.84 | loss 0.00004938\n",
      "| Epoch  97 |   200/  829 batches | lr 0.00066 | ms/batch 13.54 | loss 0.00004664\n",
      "| Epoch  97 |   250/  829 batches | lr 0.00066 | ms/batch 12.02 | loss 0.00004970\n",
      "| Epoch  97 |   300/  829 batches | lr 0.00066 | ms/batch 12.03 | loss 0.00004586\n",
      "| Epoch  97 |   350/  829 batches | lr 0.00066 | ms/batch 13.75 | loss 0.00004669\n",
      "| Epoch  97 |   400/  829 batches | lr 0.00066 | ms/batch 12.27 | loss 0.00004782\n",
      "| Epoch  97 |   450/  829 batches | lr 0.00066 | ms/batch 12.58 | loss 0.00004141\n",
      "| Epoch  97 |   500/  829 batches | lr 0.00066 | ms/batch 12.55 | loss 0.00004098\n",
      "| Epoch  97 |   550/  829 batches | lr 0.00066 | ms/batch 12.94 | loss 0.00004300\n",
      "| Epoch  97 |   600/  829 batches | lr 0.00066 | ms/batch 14.46 | loss 0.00004666\n",
      "| Epoch  97 |   650/  829 batches | lr 0.00066 | ms/batch 12.39 | loss 0.00004592\n",
      "| Epoch  97 |   700/  829 batches | lr 0.00066 | ms/batch 12.35 | loss 0.00004252\n",
      "| Epoch  97 |   750/  829 batches | lr 0.00066 | ms/batch 13.72 | loss 0.00004547\n",
      "| Epoch  97 |   800/  829 batches | lr 0.00066 | ms/batch 12.12 | loss 0.00004534\n",
      "\n",
      "Val set: Average loss: 0.00007681\n",
      "\n",
      "EarlyStopping counter: 6 out of 20\n",
      "| Epoch  98 |    50/  829 batches | lr 0.00066 | ms/batch 12.36 | loss 0.00005314\n",
      "| Epoch  98 |   100/  829 batches | lr 0.00066 | ms/batch 14.45 | loss 0.00004729\n",
      "| Epoch  98 |   150/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00004684\n",
      "| Epoch  98 |   200/  829 batches | lr 0.00066 | ms/batch 11.79 | loss 0.00004657\n",
      "| Epoch  98 |   250/  829 batches | lr 0.00066 | ms/batch 12.31 | loss 0.00005009\n",
      "| Epoch  98 |   300/  829 batches | lr 0.00066 | ms/batch 11.86 | loss 0.00005073\n",
      "| Epoch  98 |   350/  829 batches | lr 0.00066 | ms/batch 13.78 | loss 0.00004861\n",
      "| Epoch  98 |   400/  829 batches | lr 0.00066 | ms/batch 11.82 | loss 0.00005613\n",
      "| Epoch  98 |   450/  829 batches | lr 0.00066 | ms/batch 13.70 | loss 0.00004646\n",
      "| Epoch  98 |   500/  829 batches | lr 0.00066 | ms/batch 12.08 | loss 0.00004268\n",
      "| Epoch  98 |   550/  829 batches | lr 0.00066 | ms/batch 11.85 | loss 0.00004333\n",
      "| Epoch  98 |   600/  829 batches | lr 0.00066 | ms/batch 11.98 | loss 0.00004998\n",
      "| Epoch  98 |   650/  829 batches | lr 0.00066 | ms/batch 11.86 | loss 0.00004643\n",
      "| Epoch  98 |   700/  829 batches | lr 0.00066 | ms/batch 13.79 | loss 0.00005817\n",
      "| Epoch  98 |   750/  829 batches | lr 0.00066 | ms/batch 12.00 | loss 0.00004845\n",
      "| Epoch  98 |   800/  829 batches | lr 0.00066 | ms/batch 11.90 | loss 0.00004810\n",
      "\n",
      "Val set: Average loss: 0.00007700\n",
      "\n",
      "EarlyStopping counter: 7 out of 20\n",
      "| Epoch  99 |    50/  829 batches | lr 0.00066 | ms/batch 12.16 | loss 0.00005401\n",
      "| Epoch  99 |   100/  829 batches | lr 0.00066 | ms/batch 11.82 | loss 0.00004665\n",
      "| Epoch  99 |   150/  829 batches | lr 0.00066 | ms/batch 13.38 | loss 0.00005001\n",
      "| Epoch  99 |   200/  829 batches | lr 0.00066 | ms/batch 11.94 | loss 0.00004614\n",
      "| Epoch  99 |   250/  829 batches | lr 0.00066 | ms/batch 11.95 | loss 0.00005046\n",
      "| Epoch  99 |   300/  829 batches | lr 0.00066 | ms/batch 12.23 | loss 0.00004865\n",
      "| Epoch  99 |   350/  829 batches | lr 0.00066 | ms/batch 11.81 | loss 0.00004963\n",
      "| Epoch  99 |   400/  829 batches | lr 0.00066 | ms/batch 13.73 | loss 0.00004920\n",
      "| Epoch  99 |   450/  829 batches | lr 0.00066 | ms/batch 12.00 | loss 0.00004649\n",
      "| Epoch  99 |   500/  829 batches | lr 0.00066 | ms/batch 14.50 | loss 0.00004580\n",
      "| Epoch  99 |   550/  829 batches | lr 0.00066 | ms/batch 12.05 | loss 0.00004728\n",
      "| Epoch  99 |   600/  829 batches | lr 0.00066 | ms/batch 12.06 | loss 0.00005334\n",
      "| Epoch  99 |   650/  829 batches | lr 0.00066 | ms/batch 12.02 | loss 0.00004925\n",
      "| Epoch  99 |   700/  829 batches | lr 0.00066 | ms/batch 12.04 | loss 0.00004808\n",
      "| Epoch  99 |   750/  829 batches | lr 0.00066 | ms/batch 13.68 | loss 0.00005017\n",
      "| Epoch  99 |   800/  829 batches | lr 0.00066 | ms/batch 12.03 | loss 0.00004520\n",
      "\n",
      "Val set: Average loss: 0.00007016\n",
      "\n",
      "EarlyStopping counter: 8 out of 20\n",
      "| Epoch 100 |    50/  829 batches | lr 0.00066 | ms/batch 14.07 | loss 0.00005444\n",
      "| Epoch 100 |   100/  829 batches | lr 0.00066 | ms/batch 13.92 | loss 0.00005156\n",
      "| Epoch 100 |   150/  829 batches | lr 0.00066 | ms/batch 12.78 | loss 0.00004785\n",
      "| Epoch 100 |   200/  829 batches | lr 0.00066 | ms/batch 14.47 | loss 0.00004519\n",
      "| Epoch 100 |   250/  829 batches | lr 0.00066 | ms/batch 12.64 | loss 0.00005217\n",
      "| Epoch 100 |   300/  829 batches | lr 0.00066 | ms/batch 12.72 | loss 0.00005062\n",
      "| Epoch 100 |   350/  829 batches | lr 0.00066 | ms/batch 13.05 | loss 0.00005073\n",
      "| Epoch 100 |   400/  829 batches | lr 0.00066 | ms/batch 13.15 | loss 0.00005021\n",
      "| Epoch 100 |   450/  829 batches | lr 0.00066 | ms/batch 15.50 | loss 0.00004367\n",
      "| Epoch 100 |   500/  829 batches | lr 0.00066 | ms/batch 12.21 | loss 0.00005214\n",
      "| Epoch 100 |   550/  829 batches | lr 0.00066 | ms/batch 11.92 | loss 0.00005208\n",
      "| Epoch 100 |   600/  829 batches | lr 0.00066 | ms/batch 13.46 | loss 0.00007620\n",
      "| Epoch 100 |   650/  829 batches | lr 0.00066 | ms/batch 11.94 | loss 0.00005704\n",
      "| Epoch 100 |   700/  829 batches | lr 0.00066 | ms/batch 11.78 | loss 0.00005198\n",
      "| Epoch 100 |   750/  829 batches | lr 0.00066 | ms/batch 11.90 | loss 0.00004938\n",
      "| Epoch 100 |   800/  829 batches | lr 0.00066 | ms/batch 12.13 | loss 0.00004524\n",
      "\n",
      "Val set: Average loss: 0.00010102\n",
      "\n",
      "EarlyStopping counter: 9 out of 20\n",
      "| Epoch 101 |    50/  829 batches | lr 0.00066 | ms/batch 12.51 | loss 0.00005418\n",
      "| Epoch 101 |   100/  829 batches | lr 0.00066 | ms/batch 12.03 | loss 0.00004929\n",
      "| Epoch 101 |   150/  829 batches | lr 0.00066 | ms/batch 12.00 | loss 0.00005275\n",
      "| Epoch 101 |   200/  829 batches | lr 0.00066 | ms/batch 11.68 | loss 0.00004822\n",
      "| Epoch 101 |   250/  829 batches | lr 0.00066 | ms/batch 13.26 | loss 0.00005377\n",
      "| Epoch 101 |   300/  829 batches | lr 0.00066 | ms/batch 11.68 | loss 0.00005464\n",
      "| Epoch 101 |   350/  829 batches | lr 0.00066 | ms/batch 13.63 | loss 0.00005679\n",
      "| Epoch 101 |   400/  829 batches | lr 0.00066 | ms/batch 11.59 | loss 0.00005793\n",
      "| Epoch 101 |   450/  829 batches | lr 0.00066 | ms/batch 12.06 | loss 0.00005253\n",
      "| Epoch 101 |   500/  829 batches | lr 0.00066 | ms/batch 11.73 | loss 0.00006471\n",
      "| Epoch 101 |   550/  829 batches | lr 0.00066 | ms/batch 12.34 | loss 0.00006065\n",
      "| Epoch 101 |   600/  829 batches | lr 0.00066 | ms/batch 14.98 | loss 0.00005526\n",
      "| Epoch 101 |   650/  829 batches | lr 0.00066 | ms/batch 12.91 | loss 0.00004888\n",
      "| Epoch 101 |   700/  829 batches | lr 0.00066 | ms/batch 12.67 | loss 0.00004860\n",
      "| Epoch 101 |   750/  829 batches | lr 0.00066 | ms/batch 13.52 | loss 0.00004874\n",
      "| Epoch 101 |   800/  829 batches | lr 0.00066 | ms/batch 12.16 | loss 0.00004950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Val set: Average loss: 0.00007906\n",
      "\n",
      "EarlyStopping counter: 10 out of 20\n",
      "| Epoch 102 |    50/  829 batches | lr 0.00066 | ms/batch 13.51 | loss 0.00005779\n",
      "| Epoch 102 |   100/  829 batches | lr 0.00066 | ms/batch 15.57 | loss 0.00005214\n",
      "| Epoch 102 |   150/  829 batches | lr 0.00066 | ms/batch 14.28 | loss 0.00005180\n",
      "| Epoch 102 |   200/  829 batches | lr 0.00066 | ms/batch 13.23 | loss 0.00004500\n",
      "| Epoch 102 |   250/  829 batches | lr 0.00066 | ms/batch 12.80 | loss 0.00004994\n",
      "| Epoch 102 |   300/  829 batches | lr 0.00066 | ms/batch 12.57 | loss 0.00005154\n",
      "| Epoch 102 |   350/  829 batches | lr 0.00066 | ms/batch 15.52 | loss 0.00005481\n",
      "| Epoch 102 |   400/  829 batches | lr 0.00066 | ms/batch 12.66 | loss 0.00005096\n",
      "| Epoch 102 |   450/  829 batches | lr 0.00066 | ms/batch 14.24 | loss 0.00004595\n",
      "| Epoch 102 |   500/  829 batches | lr 0.00066 | ms/batch 11.77 | loss 0.00004915\n",
      "| Epoch 102 |   550/  829 batches | lr 0.00066 | ms/batch 11.76 | loss 0.00005445\n",
      "| Epoch 102 |   600/  829 batches | lr 0.00066 | ms/batch 11.78 | loss 0.00005518\n",
      "| Epoch 102 |   650/  829 batches | lr 0.00066 | ms/batch 11.76 | loss 0.00004350\n",
      "| Epoch 102 |   700/  829 batches | lr 0.00066 | ms/batch 13.36 | loss 0.00004265\n",
      "| Epoch 102 |   750/  829 batches | lr 0.00066 | ms/batch 11.99 | loss 0.00004826\n",
      "| Epoch 102 |   800/  829 batches | lr 0.00066 | ms/batch 11.98 | loss 0.00004608\n",
      "\n",
      "Val set: Average loss: 0.00007839\n",
      "\n",
      "EarlyStopping counter: 11 out of 20\n",
      "| Epoch 103 |    50/  829 batches | lr 0.00066 | ms/batch 12.07 | loss 0.00005009\n",
      "| Epoch 103 |   100/  829 batches | lr 0.00066 | ms/batch 11.83 | loss 0.00004955\n",
      "| Epoch 103 |   150/  829 batches | lr 0.00066 | ms/batch 13.35 | loss 0.00004958\n",
      "| Epoch 103 |   200/  829 batches | lr 0.00066 | ms/batch 11.79 | loss 0.00004213\n",
      "| Epoch 103 |   250/  829 batches | lr 0.00066 | ms/batch 12.42 | loss 0.00004614\n",
      "| Epoch 103 |   300/  829 batches | lr 0.00066 | ms/batch 12.22 | loss 0.00004831\n",
      "| Epoch 103 |   350/  829 batches | lr 0.00066 | ms/batch 12.14 | loss 0.00004988\n",
      "| Epoch 103 |   400/  829 batches | lr 0.00066 | ms/batch 13.94 | loss 0.00004776\n",
      "| Epoch 103 |   450/  829 batches | lr 0.00066 | ms/batch 12.11 | loss 0.00004458\n",
      "| Epoch 103 |   500/  829 batches | lr 0.00066 | ms/batch 13.69 | loss 0.00004443\n",
      "| Epoch 103 |   550/  829 batches | lr 0.00066 | ms/batch 11.92 | loss 0.00004677\n",
      "| Epoch 103 |   600/  829 batches | lr 0.00066 | ms/batch 11.73 | loss 0.00004389\n",
      "| Epoch 103 |   650/  829 batches | lr 0.00066 | ms/batch 11.74 | loss 0.00004356\n",
      "| Epoch 103 |   700/  829 batches | lr 0.00066 | ms/batch 11.69 | loss 0.00003976\n",
      "| Epoch 103 |   750/  829 batches | lr 0.00066 | ms/batch 13.47 | loss 0.00003935\n",
      "| Epoch 103 |   800/  829 batches | lr 0.00066 | ms/batch 11.91 | loss 0.00004274\n",
      "\n",
      "Val set: Average loss: 0.00007478\n",
      "\n",
      "EarlyStopping counter: 12 out of 20\n",
      "| Epoch 104 |    50/  829 batches | lr 0.00066 | ms/batch 13.02 | loss 0.00004460\n",
      "| Epoch 104 |   100/  829 batches | lr 0.00066 | ms/batch 13.86 | loss 0.00004252\n",
      "| Epoch 104 |   150/  829 batches | lr 0.00066 | ms/batch 11.84 | loss 0.00004199\n",
      "| Epoch 104 |   200/  829 batches | lr 0.00066 | ms/batch 13.50 | loss 0.00004012\n",
      "| Epoch 104 |   250/  829 batches | lr 0.00066 | ms/batch 11.82 | loss 0.00004044\n",
      "| Epoch 104 |   300/  829 batches | lr 0.00066 | ms/batch 11.85 | loss 0.00004106\n",
      "| Epoch 104 |   350/  829 batches | lr 0.00066 | ms/batch 11.99 | loss 0.00004180\n",
      "| Epoch 104 |   400/  829 batches | lr 0.00066 | ms/batch 11.78 | loss 0.00004033\n",
      "| Epoch 104 |   450/  829 batches | lr 0.00066 | ms/batch 13.55 | loss 0.00003934\n",
      "| Epoch 104 |   500/  829 batches | lr 0.00066 | ms/batch 12.03 | loss 0.00003889\n",
      "| Epoch 104 |   550/  829 batches | lr 0.00066 | ms/batch 12.08 | loss 0.00004107\n",
      "| Epoch 104 |   600/  829 batches | lr 0.00066 | ms/batch 13.55 | loss 0.00004318\n",
      "| Epoch 104 |   650/  829 batches | lr 0.00066 | ms/batch 12.07 | loss 0.00004314\n",
      "| Epoch 104 |   700/  829 batches | lr 0.00066 | ms/batch 12.07 | loss 0.00004064\n",
      "| Epoch 104 |   750/  829 batches | lr 0.00066 | ms/batch 11.99 | loss 0.00004611\n",
      "| Epoch 104 |   800/  829 batches | lr 0.00066 | ms/batch 12.02 | loss 0.00004577\n",
      "\n",
      "Val set: Average loss: 0.00007130\n",
      "\n",
      "EarlyStopping counter: 13 out of 20\n",
      "| Epoch 105 |    50/  829 batches | lr 0.00066 | ms/batch 12.31 | loss 0.00004191\n",
      "| Epoch 105 |   100/  829 batches | lr 0.00066 | ms/batch 12.03 | loss 0.00004353\n",
      "| Epoch 105 |   150/  829 batches | lr 0.00066 | ms/batch 11.87 | loss 0.00004436\n",
      "| Epoch 105 |   200/  829 batches | lr 0.00066 | ms/batch 12.00 | loss 0.00004581\n",
      "| Epoch 105 |   250/  829 batches | lr 0.00066 | ms/batch 13.70 | loss 0.00004438\n",
      "| Epoch 105 |   300/  829 batches | lr 0.00066 | ms/batch 11.88 | loss 0.00004491\n",
      "| Epoch 105 |   350/  829 batches | lr 0.00066 | ms/batch 13.61 | loss 0.00004033\n",
      "| Epoch 105 |   400/  829 batches | lr 0.00066 | ms/batch 11.95 | loss 0.00004473\n",
      "| Epoch 105 |   450/  829 batches | lr 0.00066 | ms/batch 12.05 | loss 0.00004098\n",
      "| Epoch 105 |   500/  829 batches | lr 0.00066 | ms/batch 11.81 | loss 0.00004355\n",
      "| Epoch 105 |   550/  829 batches | lr 0.00066 | ms/batch 12.00 | loss 0.00004344\n",
      "| Epoch 105 |   600/  829 batches | lr 0.00066 | ms/batch 13.72 | loss 0.00004712\n",
      "| Epoch 105 |   650/  829 batches | lr 0.00066 | ms/batch 11.87 | loss 0.00004867\n",
      "| Epoch 105 |   700/  829 batches | lr 0.00066 | ms/batch 12.14 | loss 0.00004567\n",
      "| Epoch 105 |   750/  829 batches | lr 0.00066 | ms/batch 13.83 | loss 0.00004940\n",
      "| Epoch 105 |   800/  829 batches | lr 0.00066 | ms/batch 11.80 | loss 0.00004840\n",
      "\n",
      "Val set: Average loss: 0.00007602\n",
      "\n",
      "EarlyStopping counter: 14 out of 20\n",
      "| Epoch 106 |    50/  829 batches | lr 0.00066 | ms/batch 12.33 | loss 0.00004720\n",
      "| Epoch 106 |   100/  829 batches | lr 0.00066 | ms/batch 13.31 | loss 0.00004681\n",
      "| Epoch 106 |   150/  829 batches | lr 0.00066 | ms/batch 11.71 | loss 0.00004454\n",
      "| Epoch 106 |   200/  829 batches | lr 0.00066 | ms/batch 11.72 | loss 0.00004929\n",
      "| Epoch 106 |   250/  829 batches | lr 0.00066 | ms/batch 11.86 | loss 0.00004429\n",
      "| Epoch 106 |   300/  829 batches | lr 0.00066 | ms/batch 11.78 | loss 0.00004647\n",
      "| Epoch 106 |   350/  829 batches | lr 0.00066 | ms/batch 13.50 | loss 0.00004337\n",
      "| Epoch 106 |   400/  829 batches | lr 0.00066 | ms/batch 11.87 | loss 0.00004189\n",
      "| Epoch 106 |   450/  829 batches | lr 0.00066 | ms/batch 13.27 | loss 0.00004058\n",
      "| Epoch 106 |   500/  829 batches | lr 0.00066 | ms/batch 11.68 | loss 0.00004223\n",
      "| Epoch 106 |   550/  829 batches | lr 0.00066 | ms/batch 11.78 | loss 0.00004526\n",
      "| Epoch 106 |   600/  829 batches | lr 0.00066 | ms/batch 12.06 | loss 0.00004388\n",
      "| Epoch 106 |   650/  829 batches | lr 0.00066 | ms/batch 11.84 | loss 0.00004533\n",
      "| Epoch 106 |   700/  829 batches | lr 0.00066 | ms/batch 13.54 | loss 0.00004362\n",
      "| Epoch 106 |   750/  829 batches | lr 0.00066 | ms/batch 12.08 | loss 0.00004949\n",
      "| Epoch 106 |   800/  829 batches | lr 0.00066 | ms/batch 11.91 | loss 0.00005780\n",
      "\n",
      "Val set: Average loss: 0.00009335\n",
      "\n",
      "EarlyStopping counter: 15 out of 20\n",
      "| Epoch 107 |    50/  829 batches | lr 0.00066 | ms/batch 12.16 | loss 0.00005206\n",
      "| Epoch 107 |   100/  829 batches | lr 0.00066 | ms/batch 11.70 | loss 0.00004480\n",
      "| Epoch 107 |   150/  829 batches | lr 0.00066 | ms/batch 13.28 | loss 0.00004348\n",
      "| Epoch 107 |   200/  829 batches | lr 0.00066 | ms/batch 11.68 | loss 0.00004672\n",
      "| Epoch 107 |   250/  829 batches | lr 0.00066 | ms/batch 11.64 | loss 0.00004682\n",
      "| Epoch 107 |   300/  829 batches | lr 0.00066 | ms/batch 11.71 | loss 0.00004364\n",
      "| Epoch 107 |   350/  829 batches | lr 0.00066 | ms/batch 11.63 | loss 0.00004359\n",
      "| Epoch 107 |   400/  829 batches | lr 0.00066 | ms/batch 13.27 | loss 0.00004041\n",
      "| Epoch 107 |   450/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00004086\n",
      "| Epoch 107 |   500/  829 batches | lr 0.00066 | ms/batch 13.23 | loss 0.00004273\n",
      "| Epoch 107 |   550/  829 batches | lr 0.00066 | ms/batch 11.61 | loss 0.00004836\n",
      "| Epoch 107 |   600/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00004940\n",
      "| Epoch 107 |   650/  829 batches | lr 0.00066 | ms/batch 11.62 | loss 0.00005189\n",
      "| Epoch 107 |   700/  829 batches | lr 0.00066 | ms/batch 11.88 | loss 0.00004329\n",
      "| Epoch 107 |   750/  829 batches | lr 0.00066 | ms/batch 13.32 | loss 0.00004381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch 107 |   800/  829 batches | lr 0.00066 | ms/batch 11.71 | loss 0.00004705\n",
      "\n",
      "Val set: Average loss: 0.00007191\n",
      "\n",
      "EarlyStopping counter: 16 out of 20\n",
      "| Epoch 108 |    50/  829 batches | lr 0.00066 | ms/batch 12.00 | loss 0.00004935\n",
      "| Epoch 108 |   100/  829 batches | lr 0.00066 | ms/batch 13.31 | loss 0.00005180\n",
      "| Epoch 108 |   150/  829 batches | lr 0.00066 | ms/batch 11.87 | loss 0.00004601\n",
      "| Epoch 108 |   200/  829 batches | lr 0.00066 | ms/batch 11.81 | loss 0.00004348\n",
      "| Epoch 108 |   250/  829 batches | lr 0.00066 | ms/batch 13.39 | loss 0.00004127\n",
      "| Epoch 108 |   300/  829 batches | lr 0.00066 | ms/batch 11.84 | loss 0.00003963\n",
      "| Epoch 108 |   350/  829 batches | lr 0.00066 | ms/batch 11.81 | loss 0.00004429\n",
      "| Epoch 108 |   400/  829 batches | lr 0.00066 | ms/batch 11.72 | loss 0.00004269\n",
      "| Epoch 108 |   450/  829 batches | lr 0.00066 | ms/batch 13.29 | loss 0.00004040\n",
      "| Epoch 108 |   500/  829 batches | lr 0.00066 | ms/batch 11.70 | loss 0.00004099\n",
      "| Epoch 108 |   550/  829 batches | lr 0.00066 | ms/batch 11.73 | loss 0.00004420\n",
      "| Epoch 108 |   600/  829 batches | lr 0.00066 | ms/batch 13.43 | loss 0.00004963\n",
      "| Epoch 108 |   650/  829 batches | lr 0.00066 | ms/batch 11.66 | loss 0.00004697\n",
      "| Epoch 108 |   700/  829 batches | lr 0.00066 | ms/batch 11.69 | loss 0.00004675\n",
      "| Epoch 108 |   750/  829 batches | lr 0.00066 | ms/batch 11.86 | loss 0.00004662\n",
      "| Epoch 108 |   800/  829 batches | lr 0.00066 | ms/batch 11.67 | loss 0.00004479\n",
      "\n",
      "Val set: Average loss: 0.00008296\n",
      "\n",
      "EarlyStopping counter: 17 out of 20\n",
      "| Epoch 109 |    50/  829 batches | lr 0.00066 | ms/batch 12.02 | loss 0.00005167\n",
      "| Epoch 109 |   100/  829 batches | lr 0.00066 | ms/batch 11.91 | loss 0.00005570\n",
      "| Epoch 109 |   150/  829 batches | lr 0.00066 | ms/batch 11.89 | loss 0.00005090\n",
      "| Epoch 109 |   200/  829 batches | lr 0.00066 | ms/batch 11.76 | loss 0.00004939\n",
      "| Epoch 109 |   250/  829 batches | lr 0.00066 | ms/batch 13.57 | loss 0.00004335\n",
      "| Epoch 109 |   300/  829 batches | lr 0.00066 | ms/batch 12.09 | loss 0.00004212\n",
      "| Epoch 109 |   350/  829 batches | lr 0.00066 | ms/batch 13.44 | loss 0.00004343\n",
      "| Epoch 109 |   400/  829 batches | lr 0.00066 | ms/batch 11.73 | loss 0.00004772\n",
      "| Epoch 109 |   450/  829 batches | lr 0.00066 | ms/batch 11.87 | loss 0.00004658\n",
      "| Epoch 109 |   500/  829 batches | lr 0.00066 | ms/batch 11.63 | loss 0.00004238\n",
      "| Epoch 109 |   550/  829 batches | lr 0.00066 | ms/batch 12.01 | loss 0.00004567\n",
      "| Epoch 109 |   600/  829 batches | lr 0.00066 | ms/batch 13.68 | loss 0.00004864\n",
      "| Epoch 109 |   650/  829 batches | lr 0.00066 | ms/batch 12.02 | loss 0.00004831\n",
      "| Epoch 109 |   700/  829 batches | lr 0.00066 | ms/batch 12.15 | loss 0.00004560\n",
      "| Epoch 109 |   750/  829 batches | lr 0.00066 | ms/batch 13.52 | loss 0.00004606\n",
      "| Epoch 109 |   800/  829 batches | lr 0.00066 | ms/batch 12.02 | loss 0.00004536\n",
      "\n",
      "Val set: Average loss: 0.00007403\n",
      "\n",
      "EarlyStopping counter: 18 out of 20\n",
      "| Epoch 110 |    50/  829 batches | lr 0.00066 | ms/batch 12.01 | loss 0.00006652\n",
      "| Epoch 110 |   100/  829 batches | lr 0.00066 | ms/batch 13.72 | loss 0.00006745\n",
      "| Epoch 110 |   150/  829 batches | lr 0.00066 | ms/batch 12.08 | loss 0.00005383\n",
      "| Epoch 110 |   200/  829 batches | lr 0.00066 | ms/batch 11.92 | loss 0.00005153\n",
      "| Epoch 110 |   250/  829 batches | lr 0.00066 | ms/batch 11.91 | loss 0.00004417\n",
      "| Epoch 110 |   300/  829 batches | lr 0.00066 | ms/batch 11.90 | loss 0.00004507\n",
      "| Epoch 110 |   350/  829 batches | lr 0.00066 | ms/batch 13.30 | loss 0.00004695\n",
      "| Epoch 110 |   400/  829 batches | lr 0.00066 | ms/batch 11.97 | loss 0.00004637\n",
      "| Epoch 110 |   450/  829 batches | lr 0.00066 | ms/batch 13.24 | loss 0.00004716\n",
      "| Epoch 110 |   500/  829 batches | lr 0.00066 | ms/batch 12.02 | loss 0.00005188\n",
      "| Epoch 110 |   550/  829 batches | lr 0.00066 | ms/batch 11.96 | loss 0.00005213\n",
      "| Epoch 110 |   600/  829 batches | lr 0.00066 | ms/batch 11.78 | loss 0.00005341\n",
      "| Epoch 110 |   650/  829 batches | lr 0.00066 | ms/batch 11.70 | loss 0.00004439\n",
      "| Epoch 110 |   700/  829 batches | lr 0.00066 | ms/batch 13.64 | loss 0.00004515\n",
      "| Epoch 110 |   750/  829 batches | lr 0.00066 | ms/batch 11.91 | loss 0.00004668\n",
      "| Epoch 110 |   800/  829 batches | lr 0.00066 | ms/batch 11.83 | loss 0.00004772\n",
      "\n",
      "Val set: Average loss: 0.00007807\n",
      "\n",
      "EarlyStopping counter: 19 out of 20\n",
      "| Epoch 111 |    50/  829 batches | lr 0.00066 | ms/batch 12.01 | loss 0.00005248\n",
      "| Epoch 111 |   100/  829 batches | lr 0.00066 | ms/batch 12.01 | loss 0.00005508\n",
      "| Epoch 111 |   150/  829 batches | lr 0.00066 | ms/batch 13.61 | loss 0.00004912\n",
      "| Epoch 111 |   200/  829 batches | lr 0.00066 | ms/batch 12.03 | loss 0.00004349\n",
      "| Epoch 111 |   250/  829 batches | lr 0.00066 | ms/batch 12.13 | loss 0.00004552\n",
      "| Epoch 111 |   300/  829 batches | lr 0.00066 | ms/batch 11.82 | loss 0.00004738\n",
      "| Epoch 111 |   350/  829 batches | lr 0.00066 | ms/batch 12.05 | loss 0.00004734\n",
      "| Epoch 111 |   400/  829 batches | lr 0.00066 | ms/batch 13.71 | loss 0.00004291\n",
      "| Epoch 111 |   450/  829 batches | lr 0.00066 | ms/batch 11.99 | loss 0.00004466\n",
      "| Epoch 111 |   500/  829 batches | lr 0.00066 | ms/batch 14.24 | loss 0.00005034\n",
      "| Epoch 111 |   550/  829 batches | lr 0.00066 | ms/batch 12.28 | loss 0.00005296\n",
      "| Epoch 111 |   600/  829 batches | lr 0.00066 | ms/batch 12.41 | loss 0.00005389\n",
      "| Epoch 111 |   650/  829 batches | lr 0.00066 | ms/batch 12.21 | loss 0.00004623\n",
      "| Epoch 111 |   700/  829 batches | lr 0.00066 | ms/batch 12.24 | loss 0.00004266\n",
      "| Epoch 111 |   750/  829 batches | lr 0.00066 | ms/batch 13.70 | loss 0.00004527\n",
      "| Epoch 111 |   800/  829 batches | lr 0.00066 | ms/batch 12.18 | loss 0.00005396\n",
      "\n",
      "Val set: Average loss: 0.00006909\n",
      "\n",
      "EarlyStopping counter: 20 out of 20\n",
      "Stopping at Epoch: 111\n"
     ]
    }
   ],
   "source": [
    "load = False\n",
    "save_model_path = '../models/final_heston_model.chkpt'\n",
    "val_err_df_path = '../results/val_final_heston_model.csv'\n",
    "\n",
    "if not load:\n",
    "  train_losses, val_losses = train(\n",
    "      epochs,\n",
    "      batch_size,\n",
    "      model,\n",
    "      optimizer,\n",
    "      loss_fn,\n",
    "      X_train,\n",
    "      y_train,\n",
    "      X_val,\n",
    "      y_val)\n",
    "  val_err_df = pd.DataFrame({\n",
    "      'Training': train_losses,\n",
    "      'Validation': val_losses})\n",
    "  val_err_df.to_csv(val_err_df_path)\n",
    "  torch.save(model.state_dict(), save_model_path)\n",
    "else:\n",
    "  model = Net(input_size, output_size, hidden_size, num_layers, act_fn)\n",
    "  model.load_state_dict(torch.load(save_model_path, map_location=device))\n",
    "  model = model.to(device)\n",
    "  val_err_df = pd.read_csv(val_err_df_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1650894219921,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "KkenWSRYvDpl",
    "outputId": "37746aa5-0b46-4a80-d14d-397868e89361",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_err_df[1:].plot(xlabel='epoch', ylabel='MSE')\n",
    "plt.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FlG5Ky25vDpm",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1650894219922,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "TBZ4eHAdvDpn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_size = 30\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_out = model(X_test[0:test_size])\n",
    "\n",
    "test_out = output_sc.inverse_transform(test_out.cpu().detach().numpy())\n",
    "real_out = output_sc.inverse_transform(y_test[0:test_size].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1650894219926,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "wK1WeGIZvDpo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['Price', 'Strike', 'Kappa', 'Rho', 'Theta', 'Xi', 'V_0',\n",
    "       'Interest Rate', 'Time to Expiration', 'C', 'P', 'Prediction', 'Real']\n",
    "test_options = pd.DataFrame(columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 68,
     "status": "ok",
     "timestamp": 1650894220542,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "_dvE5LGXvDpq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i, item in enumerate(input_sc.inverse_transform(X_test[0:test_size].cpu().detach().numpy())):\n",
    "  opt = {\n",
    "      'Price': item[0],\n",
    "      'Strike': item[1],\n",
    "      'Kappa': item[2],\n",
    "      'Rho': item[3],\n",
    "      'Theta': item[4],\n",
    "      'Xi': item[5],\n",
    "      'V_0': item[6],\n",
    "      'Interest Rate': item[7],\n",
    "      'Time to Expiration': item[8],\n",
    "      'C': item[9],\n",
    "      'P': item[10],\n",
    "      'Prediction': test_out[i][0],\n",
    "      'Real': real_out[i][0]\n",
    "  }\n",
    "  test_options = test_options.append(opt, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 67,
     "status": "ok",
     "timestamp": 1650894220545,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "TNw5-1jgvDpr",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_options['Moneyness'] = test_options.Price / test_options.Strike\n",
    "test_options['Abs Error'] = np.abs(test_options.Prediction - test_options.Real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 990
    },
    "executionInfo": {
     "elapsed": 65,
     "status": "ok",
     "timestamp": 1650894220546,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "lAC6AdeVvDpr",
    "outputId": "78bd13cc-c5a0-4746-f402-9e84d8b78696",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Strike</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>Rho</th>\n",
       "      <th>Theta</th>\n",
       "      <th>Xi</th>\n",
       "      <th>V_0</th>\n",
       "      <th>Interest Rate</th>\n",
       "      <th>Time to Expiration</th>\n",
       "      <th>C</th>\n",
       "      <th>P</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Real</th>\n",
       "      <th>Moneyness</th>\n",
       "      <th>Abs Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100.0</td>\n",
       "      <td>59.997620</td>\n",
       "      <td>1.071289</td>\n",
       "      <td>-0.051914</td>\n",
       "      <td>0.226319</td>\n",
       "      <td>0.450437</td>\n",
       "      <td>0.493193</td>\n",
       "      <td>0.058075</td>\n",
       "      <td>0.652823</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.064157</td>\n",
       "      <td>0.061618</td>\n",
       "      <td>1.666733</td>\n",
       "      <td>0.002540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>119.004692</td>\n",
       "      <td>0.459027</td>\n",
       "      <td>-0.607435</td>\n",
       "      <td>0.077329</td>\n",
       "      <td>0.265382</td>\n",
       "      <td>0.277832</td>\n",
       "      <td>0.073559</td>\n",
       "      <td>0.116525</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.330068</td>\n",
       "      <td>0.333941</td>\n",
       "      <td>0.840303</td>\n",
       "      <td>0.003873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100.0</td>\n",
       "      <td>50.004143</td>\n",
       "      <td>0.162745</td>\n",
       "      <td>-0.759794</td>\n",
       "      <td>0.204118</td>\n",
       "      <td>0.282966</td>\n",
       "      <td>0.213250</td>\n",
       "      <td>0.037848</td>\n",
       "      <td>0.950695</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.004867</td>\n",
       "      <td>0.002737</td>\n",
       "      <td>1.999834</td>\n",
       "      <td>0.007604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100.0</td>\n",
       "      <td>69.991096</td>\n",
       "      <td>0.894499</td>\n",
       "      <td>-0.839463</td>\n",
       "      <td>0.263179</td>\n",
       "      <td>0.219730</td>\n",
       "      <td>0.277832</td>\n",
       "      <td>0.033243</td>\n",
       "      <td>1.093623</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.121912</td>\n",
       "      <td>0.113138</td>\n",
       "      <td>1.428753</td>\n",
       "      <td>0.008774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100.0</td>\n",
       "      <td>135.987915</td>\n",
       "      <td>1.279229</td>\n",
       "      <td>-0.703722</td>\n",
       "      <td>0.254393</td>\n",
       "      <td>0.129273</td>\n",
       "      <td>0.361071</td>\n",
       "      <td>0.040284</td>\n",
       "      <td>1.020327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.538937</td>\n",
       "      <td>34.551037</td>\n",
       "      <td>0.735359</td>\n",
       "      <td>0.012100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100.0</td>\n",
       "      <td>64.012093</td>\n",
       "      <td>0.910638</td>\n",
       "      <td>-0.466795</td>\n",
       "      <td>0.011080</td>\n",
       "      <td>0.016862</td>\n",
       "      <td>0.121881</td>\n",
       "      <td>0.011792</td>\n",
       "      <td>0.147253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.014970</td>\n",
       "      <td>0.002737</td>\n",
       "      <td>1.562205</td>\n",
       "      <td>0.012233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100.0</td>\n",
       "      <td>69.991096</td>\n",
       "      <td>0.683705</td>\n",
       "      <td>-0.383527</td>\n",
       "      <td>0.421824</td>\n",
       "      <td>0.168669</td>\n",
       "      <td>0.347116</td>\n",
       "      <td>0.086563</td>\n",
       "      <td>0.258607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.017609</td>\n",
       "      <td>0.032177</td>\n",
       "      <td>1.428753</td>\n",
       "      <td>0.014567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>87.002785</td>\n",
       "      <td>0.549236</td>\n",
       "      <td>-0.723259</td>\n",
       "      <td>0.234988</td>\n",
       "      <td>0.453115</td>\n",
       "      <td>0.458942</td>\n",
       "      <td>0.068231</td>\n",
       "      <td>1.049646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.063344</td>\n",
       "      <td>1.047870</td>\n",
       "      <td>1.149388</td>\n",
       "      <td>0.015473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.0</td>\n",
       "      <td>79.998810</td>\n",
       "      <td>0.503286</td>\n",
       "      <td>-0.404776</td>\n",
       "      <td>0.419709</td>\n",
       "      <td>0.261232</td>\n",
       "      <td>0.160762</td>\n",
       "      <td>0.028943</td>\n",
       "      <td>0.409147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.340980</td>\n",
       "      <td>0.363381</td>\n",
       "      <td>1.250019</td>\n",
       "      <td>0.022401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100.0</td>\n",
       "      <td>78.005814</td>\n",
       "      <td>1.897587</td>\n",
       "      <td>-0.499509</td>\n",
       "      <td>0.404486</td>\n",
       "      <td>0.260008</td>\n",
       "      <td>0.170277</td>\n",
       "      <td>0.072278</td>\n",
       "      <td>1.038087</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052030</td>\n",
       "      <td>0.024817</td>\n",
       "      <td>1.281956</td>\n",
       "      <td>0.027213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100.0</td>\n",
       "      <td>79.002312</td>\n",
       "      <td>0.856442</td>\n",
       "      <td>-0.619741</td>\n",
       "      <td>0.093257</td>\n",
       "      <td>0.112922</td>\n",
       "      <td>0.475814</td>\n",
       "      <td>0.093692</td>\n",
       "      <td>0.248459</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.292013</td>\n",
       "      <td>19.264114</td>\n",
       "      <td>1.265786</td>\n",
       "      <td>0.027899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>100.0</td>\n",
       "      <td>139.005875</td>\n",
       "      <td>0.798299</td>\n",
       "      <td>-0.315530</td>\n",
       "      <td>0.376436</td>\n",
       "      <td>0.194464</td>\n",
       "      <td>0.166344</td>\n",
       "      <td>0.039485</td>\n",
       "      <td>0.687039</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074044</td>\n",
       "      <td>0.039537</td>\n",
       "      <td>0.719394</td>\n",
       "      <td>0.034507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.0</td>\n",
       "      <td>141.995377</td>\n",
       "      <td>1.385648</td>\n",
       "      <td>-0.217086</td>\n",
       "      <td>0.353742</td>\n",
       "      <td>0.094105</td>\n",
       "      <td>0.426973</td>\n",
       "      <td>0.037874</td>\n",
       "      <td>0.866122</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397763</td>\n",
       "      <td>0.436983</td>\n",
       "      <td>0.704248</td>\n",
       "      <td>0.039220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100.0</td>\n",
       "      <td>65.008591</td>\n",
       "      <td>0.097906</td>\n",
       "      <td>-0.385240</td>\n",
       "      <td>0.157603</td>\n",
       "      <td>0.163102</td>\n",
       "      <td>0.308108</td>\n",
       "      <td>0.084609</td>\n",
       "      <td>0.263682</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.076435</td>\n",
       "      <td>32.122204</td>\n",
       "      <td>1.538258</td>\n",
       "      <td>0.045769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100.0</td>\n",
       "      <td>64.012093</td>\n",
       "      <td>1.026378</td>\n",
       "      <td>-0.784659</td>\n",
       "      <td>0.051253</td>\n",
       "      <td>0.303457</td>\n",
       "      <td>0.401856</td>\n",
       "      <td>0.081057</td>\n",
       "      <td>0.972120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.793530</td>\n",
       "      <td>32.843494</td>\n",
       "      <td>1.562205</td>\n",
       "      <td>0.049965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>100.0</td>\n",
       "      <td>75.998573</td>\n",
       "      <td>0.371918</td>\n",
       "      <td>-0.520473</td>\n",
       "      <td>0.366922</td>\n",
       "      <td>0.006149</td>\n",
       "      <td>0.382573</td>\n",
       "      <td>0.026228</td>\n",
       "      <td>0.335287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.804845</td>\n",
       "      <td>0.753466</td>\n",
       "      <td>1.315814</td>\n",
       "      <td>0.051378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>71.998337</td>\n",
       "      <td>0.652695</td>\n",
       "      <td>-0.054705</td>\n",
       "      <td>0.007979</td>\n",
       "      <td>0.175506</td>\n",
       "      <td>0.292235</td>\n",
       "      <td>0.089658</td>\n",
       "      <td>0.860202</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.809189</td>\n",
       "      <td>24.865149</td>\n",
       "      <td>1.388921</td>\n",
       "      <td>0.055960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>100.0</td>\n",
       "      <td>139.005875</td>\n",
       "      <td>0.122714</td>\n",
       "      <td>-0.755481</td>\n",
       "      <td>0.344510</td>\n",
       "      <td>0.490186</td>\n",
       "      <td>0.120866</td>\n",
       "      <td>0.081615</td>\n",
       "      <td>0.357980</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.054377</td>\n",
       "      <td>0.002737</td>\n",
       "      <td>0.719394</td>\n",
       "      <td>0.057114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.0</td>\n",
       "      <td>57.008118</td>\n",
       "      <td>1.241171</td>\n",
       "      <td>-0.819926</td>\n",
       "      <td>0.266843</td>\n",
       "      <td>0.491455</td>\n",
       "      <td>0.424309</td>\n",
       "      <td>0.048768</td>\n",
       "      <td>0.333595</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.558548</td>\n",
       "      <td>40.615757</td>\n",
       "      <td>1.754136</td>\n",
       "      <td>0.057209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100.0</td>\n",
       "      <td>82.006042</td>\n",
       "      <td>1.389594</td>\n",
       "      <td>-0.474121</td>\n",
       "      <td>0.182376</td>\n",
       "      <td>0.283441</td>\n",
       "      <td>0.188100</td>\n",
       "      <td>0.092956</td>\n",
       "      <td>0.947030</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.303118</td>\n",
       "      <td>16.360556</td>\n",
       "      <td>1.219422</td>\n",
       "      <td>0.057438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100.0</td>\n",
       "      <td>79.002312</td>\n",
       "      <td>1.801739</td>\n",
       "      <td>-0.378897</td>\n",
       "      <td>0.410829</td>\n",
       "      <td>0.456357</td>\n",
       "      <td>0.480254</td>\n",
       "      <td>0.055267</td>\n",
       "      <td>0.558594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.574808</td>\n",
       "      <td>0.503223</td>\n",
       "      <td>1.265786</td>\n",
       "      <td>0.071585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>100.0</td>\n",
       "      <td>59.001118</td>\n",
       "      <td>0.579118</td>\n",
       "      <td>-0.159492</td>\n",
       "      <td>0.101855</td>\n",
       "      <td>0.353742</td>\n",
       "      <td>0.424309</td>\n",
       "      <td>0.024097</td>\n",
       "      <td>0.446077</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.190308</td>\n",
       "      <td>40.115273</td>\n",
       "      <td>1.694883</td>\n",
       "      <td>0.075035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100.0</td>\n",
       "      <td>69.991096</td>\n",
       "      <td>0.798299</td>\n",
       "      <td>-0.764108</td>\n",
       "      <td>0.466366</td>\n",
       "      <td>0.192138</td>\n",
       "      <td>0.268556</td>\n",
       "      <td>0.030681</td>\n",
       "      <td>0.763225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.359753</td>\n",
       "      <td>0.267700</td>\n",
       "      <td>1.428753</td>\n",
       "      <td>0.092053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>100.0</td>\n",
       "      <td>93.999641</td>\n",
       "      <td>1.946074</td>\n",
       "      <td>-0.552251</td>\n",
       "      <td>0.120391</td>\n",
       "      <td>0.499207</td>\n",
       "      <td>0.088136</td>\n",
       "      <td>0.099731</td>\n",
       "      <td>0.385044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.774727</td>\n",
       "      <td>5.673692</td>\n",
       "      <td>1.063834</td>\n",
       "      <td>0.101035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>100.0</td>\n",
       "      <td>130.008911</td>\n",
       "      <td>1.031258</td>\n",
       "      <td>-0.283688</td>\n",
       "      <td>0.103124</td>\n",
       "      <td>0.075076</td>\n",
       "      <td>0.127843</td>\n",
       "      <td>0.071111</td>\n",
       "      <td>1.025401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.880854</td>\n",
       "      <td>27.765026</td>\n",
       "      <td>0.769178</td>\n",
       "      <td>0.115828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>100.0</td>\n",
       "      <td>114.000832</td>\n",
       "      <td>1.831057</td>\n",
       "      <td>-0.492436</td>\n",
       "      <td>0.039130</td>\n",
       "      <td>0.267822</td>\n",
       "      <td>0.428496</td>\n",
       "      <td>0.044737</td>\n",
       "      <td>0.360095</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.137464</td>\n",
       "      <td>2.012044</td>\n",
       "      <td>0.877187</td>\n",
       "      <td>0.125421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>100.0</td>\n",
       "      <td>127.005165</td>\n",
       "      <td>1.735210</td>\n",
       "      <td>-0.227743</td>\n",
       "      <td>0.030814</td>\n",
       "      <td>0.399412</td>\n",
       "      <td>0.451203</td>\n",
       "      <td>0.039827</td>\n",
       "      <td>1.084884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.181662</td>\n",
       "      <td>26.050123</td>\n",
       "      <td>0.787370</td>\n",
       "      <td>0.131538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>100.0</td>\n",
       "      <td>131.005402</td>\n",
       "      <td>0.392779</td>\n",
       "      <td>-0.482414</td>\n",
       "      <td>0.237058</td>\n",
       "      <td>0.081983</td>\n",
       "      <td>0.393039</td>\n",
       "      <td>0.079725</td>\n",
       "      <td>0.719248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.575813</td>\n",
       "      <td>29.737534</td>\n",
       "      <td>0.763327</td>\n",
       "      <td>0.161720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>100.0</td>\n",
       "      <td>71.001831</td>\n",
       "      <td>0.709358</td>\n",
       "      <td>-0.811553</td>\n",
       "      <td>0.423092</td>\n",
       "      <td>0.093400</td>\n",
       "      <td>0.460971</td>\n",
       "      <td>0.028334</td>\n",
       "      <td>0.205890</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.181561</td>\n",
       "      <td>28.972084</td>\n",
       "      <td>1.408414</td>\n",
       "      <td>0.209476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100.0</td>\n",
       "      <td>101.000061</td>\n",
       "      <td>1.015630</td>\n",
       "      <td>-0.353271</td>\n",
       "      <td>0.302717</td>\n",
       "      <td>0.203626</td>\n",
       "      <td>0.473911</td>\n",
       "      <td>0.037455</td>\n",
       "      <td>0.101866</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.036759</td>\n",
       "      <td>6.273540</td>\n",
       "      <td>0.990098</td>\n",
       "      <td>0.236781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Price      Strike     Kappa       Rho     Theta        Xi       V_0  \\\n",
       "6   100.0   59.997620  1.071289 -0.051914  0.226319  0.450437  0.493193   \n",
       "2   100.0  119.004692  0.459027 -0.607435  0.077329  0.265382  0.277832   \n",
       "16  100.0   50.004143  0.162745 -0.759794  0.204118  0.282966  0.213250   \n",
       "11  100.0   69.991096  0.894499 -0.839463  0.263179  0.219730  0.277832   \n",
       "10  100.0  135.987915  1.279229 -0.703722  0.254393  0.129273  0.361071   \n",
       "19  100.0   64.012093  0.910638 -0.466795  0.011080  0.016862  0.121881   \n",
       "9   100.0   69.991096  0.683705 -0.383527  0.421824  0.168669  0.347116   \n",
       "0   100.0   87.002785  0.549236 -0.723259  0.234988  0.453115  0.458942   \n",
       "3   100.0   79.998810  0.503286 -0.404776  0.419709  0.261232  0.160762   \n",
       "18  100.0   78.005814  1.897587 -0.499509  0.404486  0.260008  0.170277   \n",
       "13  100.0   79.002312  0.856442 -0.619741  0.093257  0.112922  0.475814   \n",
       "24  100.0  139.005875  0.798299 -0.315530  0.376436  0.194464  0.166344   \n",
       "4   100.0  141.995377  1.385648 -0.217086  0.353742  0.094105  0.426973   \n",
       "15  100.0   65.008591  0.097906 -0.385240  0.157603  0.163102  0.308108   \n",
       "7   100.0   64.012093  1.026378 -0.784659  0.051253  0.303457  0.401856   \n",
       "29  100.0   75.998573  0.371918 -0.520473  0.366922  0.006149  0.382573   \n",
       "1   100.0   71.998337  0.652695 -0.054705  0.007979  0.175506  0.292235   \n",
       "27  100.0  139.005875  0.122714 -0.755481  0.344510  0.490186  0.120866   \n",
       "5   100.0   57.008118  1.241171 -0.819926  0.266843  0.491455  0.424309   \n",
       "17  100.0   82.006042  1.389594 -0.474121  0.182376  0.283441  0.188100   \n",
       "8   100.0   79.002312  1.801739 -0.378897  0.410829  0.456357  0.480254   \n",
       "26  100.0   59.001118  0.579118 -0.159492  0.101855  0.353742  0.424309   \n",
       "14  100.0   69.991096  0.798299 -0.764108  0.466366  0.192138  0.268556   \n",
       "23  100.0   93.999641  1.946074 -0.552251  0.120391  0.499207  0.088136   \n",
       "21  100.0  130.008911  1.031258 -0.283688  0.103124  0.075076  0.127843   \n",
       "25  100.0  114.000832  1.831057 -0.492436  0.039130  0.267822  0.428496   \n",
       "28  100.0  127.005165  1.735210 -0.227743  0.030814  0.399412  0.451203   \n",
       "22  100.0  131.005402  0.392779 -0.482414  0.237058  0.081983  0.393039   \n",
       "20  100.0   71.001831  0.709358 -0.811553  0.423092  0.093400  0.460971   \n",
       "12  100.0  101.000061  1.015630 -0.353271  0.302717  0.203626  0.473911   \n",
       "\n",
       "    Interest Rate  Time to Expiration    C    P  Prediction       Real  \\\n",
       "6        0.058075            0.652823  0.0  1.0    0.064157   0.061618   \n",
       "2        0.073559            0.116525  1.0  0.0    0.330068   0.333941   \n",
       "16       0.037848            0.950695  0.0  1.0   -0.004867   0.002737   \n",
       "11       0.033243            1.093623  0.0  1.0    0.121912   0.113138   \n",
       "10       0.040284            1.020327  0.0  1.0   34.538937  34.551037   \n",
       "19       0.011792            0.147253  0.0  1.0    0.014970   0.002737   \n",
       "9        0.086563            0.258607  0.0  1.0    0.017609   0.032177   \n",
       "0        0.068231            1.049646  0.0  1.0    1.063344   1.047870   \n",
       "3        0.028943            0.409147  0.0  1.0    0.340980   0.363381   \n",
       "18       0.072278            1.038087  0.0  1.0    0.052030   0.024817   \n",
       "13       0.093692            0.248459  1.0  0.0   19.292013  19.264114   \n",
       "24       0.039485            0.687039  1.0  0.0    0.074044   0.039537   \n",
       "4        0.037874            0.866122  1.0  0.0    0.397763   0.436983   \n",
       "15       0.084609            0.263682  1.0  0.0   32.076435  32.122204   \n",
       "7        0.081057            0.972120  1.0  0.0   32.793530  32.843494   \n",
       "29       0.026228            0.335287  0.0  1.0    0.804845   0.753466   \n",
       "1        0.089658            0.860202  1.0  0.0   24.809189  24.865149   \n",
       "27       0.081615            0.357980  1.0  0.0   -0.054377   0.002737   \n",
       "5        0.048768            0.333595  1.0  0.0   40.558548  40.615757   \n",
       "17       0.092956            0.947030  1.0  0.0   16.303118  16.360556   \n",
       "8        0.055267            0.558594  0.0  1.0    0.574808   0.503223   \n",
       "26       0.024097            0.446077  1.0  0.0   40.190308  40.115273   \n",
       "14       0.030681            0.763225  0.0  1.0    0.359753   0.267700   \n",
       "23       0.099731            0.385044  1.0  0.0    5.774727   5.673692   \n",
       "21       0.071111            1.025401  0.0  1.0   27.880854  27.765026   \n",
       "25       0.044737            0.360095  1.0  0.0    2.137464   2.012044   \n",
       "28       0.039827            1.084884  0.0  1.0   26.181662  26.050123   \n",
       "22       0.079725            0.719248  0.0  1.0   29.575813  29.737534   \n",
       "20       0.028334            0.205890  1.0  0.0   29.181561  28.972084   \n",
       "12       0.037455            0.101866  1.0  0.0    6.036759   6.273540   \n",
       "\n",
       "    Moneyness  Abs Error  \n",
       "6    1.666733   0.002540  \n",
       "2    0.840303   0.003873  \n",
       "16   1.999834   0.007604  \n",
       "11   1.428753   0.008774  \n",
       "10   0.735359   0.012100  \n",
       "19   1.562205   0.012233  \n",
       "9    1.428753   0.014567  \n",
       "0    1.149388   0.015473  \n",
       "3    1.250019   0.022401  \n",
       "18   1.281956   0.027213  \n",
       "13   1.265786   0.027899  \n",
       "24   0.719394   0.034507  \n",
       "4    0.704248   0.039220  \n",
       "15   1.538258   0.045769  \n",
       "7    1.562205   0.049965  \n",
       "29   1.315814   0.051378  \n",
       "1    1.388921   0.055960  \n",
       "27   0.719394   0.057114  \n",
       "5    1.754136   0.057209  \n",
       "17   1.219422   0.057438  \n",
       "8    1.265786   0.071585  \n",
       "26   1.694883   0.075035  \n",
       "14   1.428753   0.092053  \n",
       "23   1.063834   0.101035  \n",
       "21   0.769178   0.115828  \n",
       "25   0.877187   0.125421  \n",
       "28   0.787370   0.131538  \n",
       "22   0.763327   0.161720  \n",
       "20   1.408414   0.209476  \n",
       "12   0.990098   0.236781  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_options.sort_values('Abs Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fDJ-hkrSAqVh",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### MSE on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 276,
     "status": "ok",
     "timestamp": 1650895213041,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "GG64Xp3vAib-",
    "outputId": "f846ee65-029d-4a76-b006-d65e4ac07a48",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE on the test set is:  7.078811177052557e-05\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(X_test)\n",
    "    loss = loss_fn(out, y_test)\n",
    "    print('The MSE on the test set is: ', loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCLf2KQJAvoE",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### MAE on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1650895213494,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "mZohsEyLAu7S",
    "outputId": "4d6bfba3-5751-478d-d53e-73751702414e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAE on the test set is:  0.005437219515442848\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "mae_loss = nn.L1Loss()\n",
    "with torch.no_grad():\n",
    "    out = model(X_test)\n",
    "    loss = mae_loss(out, y_test)\n",
    "    print('The MAE on the test set is: ', loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmsZ4aPaA1SJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### RSME on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1650895213496,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "f01KkBxRA0t7",
    "outputId": "6492967a-db0c-49f4-fee1-8eb52ef33119",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE on the test set is:  0.008413567125216603\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(X_test)\n",
    "    loss = loss_fn(out, y_test)\n",
    "    print('The RMSE on the test set is: ', np.sqrt(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8Jxp0L4A5zb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### MAPE on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 335,
     "status": "ok",
     "timestamp": 1650895213818,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "fHghkyflA79o",
    "outputId": "37838323-11f0-4eb9-d7d7-50303bf4e9ce",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MAPE on the test set is:  0.029158182442188263\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(X_test)\n",
    "    loss = MAPELoss(out, y_test).item()\n",
    "    print('The MAPE on the test set is: ', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLLLqkX6BEle",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1650895213820,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "sf8FmLxxBGcu",
    "outputId": "764313a9-78fc-46ca-dd08-9fb8834e4374",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the R^2 score is:  0.9999291839786597\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(X_test).squeeze().cpu().detach().numpy()\n",
    "\n",
    "y_true = y_test.cpu().squeeze().detach().numpy()\n",
    "\n",
    "r2 = r2_score(y_pred=out, y_true=y_true)\n",
    "\n",
    "print('the R^2 score is: ', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "executionInfo": {
     "elapsed": 744,
     "status": "ok",
     "timestamp": 1650895214553,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "awvWu7WxBIHB",
    "outputId": "1b3dccd3-90ef-47d5-9895-267fdf93020c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(9, 6))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "ax.scatter(\n",
    "    y=output_sc.inverse_transform(out.reshape(-1, 1)),\n",
    "    x=output_sc.inverse_transform(y_true.squeeze().reshape(-1, 1))\n",
    ")\n",
    "ax.set_xlabel('Actual Value')\n",
    "ax.set_ylabel('Predicted Value')\n",
    "\n",
    "ax.text(20, 80, f'$R^2$ = {np.round(r2, 6)}', fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Model-Testing-Heston.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
