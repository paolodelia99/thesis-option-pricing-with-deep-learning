{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ju-WUaXnY5cr",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Models Testing on Heston data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 824,
     "status": "ok",
     "timestamp": 1650891681415,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "hH3-v8y-AuXg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1650891681417,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "QXEzFQ3iAyj_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set seeds\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1650891681418,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "gsH02HCWA0gC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "options_path = '../data/real_options_tot.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1650891681421,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "jT4n95T6A4S6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 3413,
     "status": "ok",
     "timestamp": 1650891684820,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "7H8lEQPCA5IS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "options_df = pd.read_csv(options_path, index_col=0)\n",
    "options_df = reduce_mem_usage(options_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1650891684821,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "9TKRgvuOA8pC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "options_df = shuffle(options_df, random_state=0)\n",
    "options_df = options_df.reset_index()\n",
    "options_df['r'] = options_df['r'] / 100\n",
    "options_df = options_df.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1650891684822,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "3HXliAsq132p",
    "outputId": "09bc2eb1-d20d-4471-ed50-5fa0eba727fb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "             contractSymbol        lastTradeDate  strike    lastPrice  \\\n0       TSLA220916P00304000  2022-04-13 15:39:13   304.0     1.679688   \n1       TSLA230915C00375000  2022-03-29 15:21:57   375.0   752.000000   \n2        AMD221021P00090000  2022-05-02 19:41:36    90.0    13.398438   \n3       TSLA230120C01750000  2022-05-24 16:39:03  1750.0     5.769531   \n4       AMZN240119C03850000  2022-04-26 18:58:31  3850.0   228.500000   \n...                     ...                  ...     ...          ...   \n636030  TSLA230915P01425000  2022-05-19 16:13:22  1425.0   734.500000   \n636031  TSLA220520P00580000  2022-05-04 19:53:41   580.0     0.830078   \n636032  MSFT220916C00185000  2022-05-02 17:52:36   185.0    96.625000   \n636033  AMZN230317P03300000  2022-05-24 16:20:29  3300.0  1226.000000   \n636034  NFLX230616P00090000  2022-05-13 18:38:35    90.0     6.199219   \n\n                bid          ask     change  percentChange  volume  \\\n0          1.419922     1.990234  -0.770020     -31.421875     1.0   \n1        503.250000   518.500000   0.000000       0.000000     4.0   \n2         12.898438    13.101562  -1.349609      -9.156250    30.0   \n3          5.000000     6.101562  -1.259766     -17.921875    13.0   \n4         80.000000    98.000000   0.000000       0.000000     2.0   \n...             ...          ...        ...            ...     ...   \n636030   736.500000   754.500000  59.750000       8.851562     2.0   \n636031     0.660156     0.859863  -1.080078     -56.531250   271.0   \n636032    97.375000   100.875000   0.000000       0.000000     2.0   \n636033  1167.000000  1186.000000   0.000000       0.000000    17.0   \n636034     4.800781     5.851562   0.000000       0.000000     2.0   \n\n        openInterest  ...  contractSize  currency  type  expiryDate  \\\n0              153.0  ...       REGULAR       USD   put  2022-09-16   \n1                4.0  ...       REGULAR       USD  call  2023-09-15   \n2             4328.0  ...       REGULAR       USD   put  2022-10-21   \n3              518.0  ...       REGULAR       USD  call  2023-01-20   \n4               54.0  ...       REGULAR       USD  call  2024-01-19   \n...              ...  ...           ...       ...   ...         ...   \n636030          80.0  ...       REGULAR       USD   put  2023-09-15   \n636031         590.0  ...       REGULAR       USD   put  2022-05-20   \n636032        2600.0  ...       REGULAR       USD  call  2022-09-16   \n636033         107.0  ...       REGULAR       USD   put  2023-03-17   \n636034         192.0  ...       REGULAR       USD   put  2023-06-16   \n\n       downloadDate      close       vol  moneyness       tau         r  \n0        2022-04-13  1022.5000  0.581055   0.297363  0.428467  0.007851  \n1        2022-05-04   952.5000  0.653809   2.539062  1.371094  0.008331  \n2        2022-05-02    89.8125  0.541504   1.001953  0.472412  0.009323  \n3        2022-05-24   628.0000  0.859375   0.358887  0.662109  0.010880  \n4        2022-05-05  2328.0000  0.671387   0.604492  1.713867  0.008530  \n...             ...        ...       ...        ...       ...       ...  \n636030   2022-05-19   709.5000  0.834473   2.007812  1.330078  0.010323  \n636031   2022-05-04   952.5000  0.653809   0.608887  0.043945  0.008331  \n636032   2022-05-03   281.7500  0.407227   1.523438  0.373535  0.008812  \n636033   2022-05-25  2136.0000  0.752930   1.544922  0.812988  0.010719  \n636034   2022-05-17   190.5000  1.629883   0.472412  1.084961  0.010437  \n\n[636035 rows x 22 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>contractSymbol</th>\n      <th>lastTradeDate</th>\n      <th>strike</th>\n      <th>lastPrice</th>\n      <th>bid</th>\n      <th>ask</th>\n      <th>change</th>\n      <th>percentChange</th>\n      <th>volume</th>\n      <th>openInterest</th>\n      <th>...</th>\n      <th>contractSize</th>\n      <th>currency</th>\n      <th>type</th>\n      <th>expiryDate</th>\n      <th>downloadDate</th>\n      <th>close</th>\n      <th>vol</th>\n      <th>moneyness</th>\n      <th>tau</th>\n      <th>r</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TSLA220916P00304000</td>\n      <td>2022-04-13 15:39:13</td>\n      <td>304.0</td>\n      <td>1.679688</td>\n      <td>1.419922</td>\n      <td>1.990234</td>\n      <td>-0.770020</td>\n      <td>-31.421875</td>\n      <td>1.0</td>\n      <td>153.0</td>\n      <td>...</td>\n      <td>REGULAR</td>\n      <td>USD</td>\n      <td>put</td>\n      <td>2022-09-16</td>\n      <td>2022-04-13</td>\n      <td>1022.5000</td>\n      <td>0.581055</td>\n      <td>0.297363</td>\n      <td>0.428467</td>\n      <td>0.007851</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TSLA230915C00375000</td>\n      <td>2022-03-29 15:21:57</td>\n      <td>375.0</td>\n      <td>752.000000</td>\n      <td>503.250000</td>\n      <td>518.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>REGULAR</td>\n      <td>USD</td>\n      <td>call</td>\n      <td>2023-09-15</td>\n      <td>2022-05-04</td>\n      <td>952.5000</td>\n      <td>0.653809</td>\n      <td>2.539062</td>\n      <td>1.371094</td>\n      <td>0.008331</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AMD221021P00090000</td>\n      <td>2022-05-02 19:41:36</td>\n      <td>90.0</td>\n      <td>13.398438</td>\n      <td>12.898438</td>\n      <td>13.101562</td>\n      <td>-1.349609</td>\n      <td>-9.156250</td>\n      <td>30.0</td>\n      <td>4328.0</td>\n      <td>...</td>\n      <td>REGULAR</td>\n      <td>USD</td>\n      <td>put</td>\n      <td>2022-10-21</td>\n      <td>2022-05-02</td>\n      <td>89.8125</td>\n      <td>0.541504</td>\n      <td>1.001953</td>\n      <td>0.472412</td>\n      <td>0.009323</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TSLA230120C01750000</td>\n      <td>2022-05-24 16:39:03</td>\n      <td>1750.0</td>\n      <td>5.769531</td>\n      <td>5.000000</td>\n      <td>6.101562</td>\n      <td>-1.259766</td>\n      <td>-17.921875</td>\n      <td>13.0</td>\n      <td>518.0</td>\n      <td>...</td>\n      <td>REGULAR</td>\n      <td>USD</td>\n      <td>call</td>\n      <td>2023-01-20</td>\n      <td>2022-05-24</td>\n      <td>628.0000</td>\n      <td>0.859375</td>\n      <td>0.358887</td>\n      <td>0.662109</td>\n      <td>0.010880</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AMZN240119C03850000</td>\n      <td>2022-04-26 18:58:31</td>\n      <td>3850.0</td>\n      <td>228.500000</td>\n      <td>80.000000</td>\n      <td>98.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.0</td>\n      <td>54.0</td>\n      <td>...</td>\n      <td>REGULAR</td>\n      <td>USD</td>\n      <td>call</td>\n      <td>2024-01-19</td>\n      <td>2022-05-05</td>\n      <td>2328.0000</td>\n      <td>0.671387</td>\n      <td>0.604492</td>\n      <td>1.713867</td>\n      <td>0.008530</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>636030</th>\n      <td>TSLA230915P01425000</td>\n      <td>2022-05-19 16:13:22</td>\n      <td>1425.0</td>\n      <td>734.500000</td>\n      <td>736.500000</td>\n      <td>754.500000</td>\n      <td>59.750000</td>\n      <td>8.851562</td>\n      <td>2.0</td>\n      <td>80.0</td>\n      <td>...</td>\n      <td>REGULAR</td>\n      <td>USD</td>\n      <td>put</td>\n      <td>2023-09-15</td>\n      <td>2022-05-19</td>\n      <td>709.5000</td>\n      <td>0.834473</td>\n      <td>2.007812</td>\n      <td>1.330078</td>\n      <td>0.010323</td>\n    </tr>\n    <tr>\n      <th>636031</th>\n      <td>TSLA220520P00580000</td>\n      <td>2022-05-04 19:53:41</td>\n      <td>580.0</td>\n      <td>0.830078</td>\n      <td>0.660156</td>\n      <td>0.859863</td>\n      <td>-1.080078</td>\n      <td>-56.531250</td>\n      <td>271.0</td>\n      <td>590.0</td>\n      <td>...</td>\n      <td>REGULAR</td>\n      <td>USD</td>\n      <td>put</td>\n      <td>2022-05-20</td>\n      <td>2022-05-04</td>\n      <td>952.5000</td>\n      <td>0.653809</td>\n      <td>0.608887</td>\n      <td>0.043945</td>\n      <td>0.008331</td>\n    </tr>\n    <tr>\n      <th>636032</th>\n      <td>MSFT220916C00185000</td>\n      <td>2022-05-02 17:52:36</td>\n      <td>185.0</td>\n      <td>96.625000</td>\n      <td>97.375000</td>\n      <td>100.875000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.0</td>\n      <td>2600.0</td>\n      <td>...</td>\n      <td>REGULAR</td>\n      <td>USD</td>\n      <td>call</td>\n      <td>2022-09-16</td>\n      <td>2022-05-03</td>\n      <td>281.7500</td>\n      <td>0.407227</td>\n      <td>1.523438</td>\n      <td>0.373535</td>\n      <td>0.008812</td>\n    </tr>\n    <tr>\n      <th>636033</th>\n      <td>AMZN230317P03300000</td>\n      <td>2022-05-24 16:20:29</td>\n      <td>3300.0</td>\n      <td>1226.000000</td>\n      <td>1167.000000</td>\n      <td>1186.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>17.0</td>\n      <td>107.0</td>\n      <td>...</td>\n      <td>REGULAR</td>\n      <td>USD</td>\n      <td>put</td>\n      <td>2023-03-17</td>\n      <td>2022-05-25</td>\n      <td>2136.0000</td>\n      <td>0.752930</td>\n      <td>1.544922</td>\n      <td>0.812988</td>\n      <td>0.010719</td>\n    </tr>\n    <tr>\n      <th>636034</th>\n      <td>NFLX230616P00090000</td>\n      <td>2022-05-13 18:38:35</td>\n      <td>90.0</td>\n      <td>6.199219</td>\n      <td>4.800781</td>\n      <td>5.851562</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.0</td>\n      <td>192.0</td>\n      <td>...</td>\n      <td>REGULAR</td>\n      <td>USD</td>\n      <td>put</td>\n      <td>2023-06-16</td>\n      <td>2022-05-17</td>\n      <td>190.5000</td>\n      <td>1.629883</td>\n      <td>0.472412</td>\n      <td>1.084961</td>\n      <td>0.010437</td>\n    </tr>\n  </tbody>\n</table>\n<p>636035 rows Ã— 22 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pn28_RUMBAFH",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 515,
     "status": "ok",
     "timestamp": 1650891685322,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "32oPe6XUBCTF",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cols_to_drop = ['impliedVolatility',\n",
    "                  'inTheMoney',\n",
    "                  'change',\n",
    "                  'percentChange',\n",
    "                  'bid',\n",
    "                  'ask',\n",
    "                  'volume',\n",
    "                  'openInterest',\n",
    "                  'contractSymbol',\n",
    "                  'lastTradeDate',\n",
    "                  'contractSize',\n",
    "                  'currency',\n",
    "                  'expiryDate',\n",
    "                  'downloadDate']\n",
    "options_df = options_df.drop(cols_to_drop, axis=1)\n",
    "options_df = pd.get_dummies(options_df, prefix='', prefix_sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 1032,
     "status": "ok",
     "timestamp": 1650891686346,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "_Tlc7k7xBDPV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_sc = StandardScaler()\n",
    "output_sc = StandardScaler()\n",
    "input_data = input_sc.fit_transform(options_df.drop(['lastPrice'], axis=1))\n",
    "output_data = output_sc.fit_transform(options_df['lastPrice'].values.reshape(-1, 1))\n",
    "\n",
    "train_size = 0.8\n",
    "val_size = 0.1\n",
    "\n",
    "last_train_idx = int(np.round(len(input_data) * train_size))\n",
    "last_val_idx = last_train_idx + int(np.round(len(input_data) * val_size))\n",
    "\n",
    "X_train = input_data[0:last_train_idx]\n",
    "X_val = input_data[last_train_idx:last_val_idx]\n",
    "X_test = input_data[last_val_idx:]\n",
    "\n",
    "y_train = output_data[0:last_train_idx]\n",
    "y_val = output_data[last_train_idx:last_val_idx]\n",
    "y_test = output_data[last_val_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1650891686347,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "7nEEoQGvvDpL",
    "outputId": "88b4d863-d037-439b-e625-5ebb52ad41ef",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['strike', 'lastPrice', 'close', 'vol', 'moneyness', 'tau', 'r', 'call',\n       'put'],\n      dtype='object')"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cols = options_df.columns\n",
    "df_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1650891686349,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "IwMVtvfABIhR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train = Variable(torch.Tensor(X_train))\n",
    "X_val = Variable(torch.Tensor(X_val))\n",
    "X_test = Variable(torch.Tensor(X_test))\n",
    "\n",
    "y_train = Variable(torch.Tensor(y_train))\n",
    "y_val = Variable(torch.Tensor(y_val))\n",
    "y_test = Variable(torch.Tensor(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ra2l5P1nBVCz",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1650891686350,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "xTLMLFoSBWDy",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "CUDA = torch.cuda.is_available()\n",
    "device = 'cuda:0' if CUDA else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1650891686352,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "CQ9Gl3bUBWsj",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "\n",
    "  def __init__(self, module):\n",
    "    super(ResBlock, self).__init__()\n",
    "    self.module = module\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.module(x) + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1650891686353,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "YL3SicQPBYq0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class HiddenLayer(nn.Module):\n",
    "\n",
    "  def __init__(self, layer_size, act_fn):\n",
    "      super(HiddenLayer, self).__init__()\n",
    "      \n",
    "      if act_fn == 'ReLU':\n",
    "        self.layer = nn.Sequential(\n",
    "          nn.Linear(layer_size, layer_size),\n",
    "          nn.ReLU())\n",
    "      elif act_fn == 'LeakyReLU':\n",
    "        self.layer = nn.Sequential(\n",
    "          nn.Linear(layer_size, layer_size),\n",
    "          nn.LeakyReLU())\n",
    "      elif act_fn == 'ELU':\n",
    "        self.layer = nn.Sequential(\n",
    "          nn.Linear(layer_size, layer_size),\n",
    "          nn.ELU())\n",
    "    \n",
    "  def forward(self, x):\n",
    "    return self.layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 455,
     "status": "ok",
     "timestamp": 1650891686792,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "lHUFGf9xBawS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "  def __init__(self, input_size, output_size, hidden_size, num_layers, act_fn):\n",
    "    super(Net, self).__init__()\n",
    "    self.input_size = input_size\n",
    "    self.output_size = output_size\n",
    "    self.hidden_size = hidden_size\n",
    "\n",
    "    if act_fn == 'ReLU':\n",
    "      self.initial_layer = nn.Sequential(\n",
    "          nn.Linear(self.input_size, self.hidden_size),\n",
    "          nn.ReLU())\n",
    "    elif act_fn == 'LeakyReLU':\n",
    "      self.initial_layer = nn.Sequential(\n",
    "          nn.Linear(self.input_size, self.hidden_size),\n",
    "          nn.LeakyReLU())\n",
    "    elif act_fn == 'ELU':\n",
    "      self.initial_layer = nn.Sequential(\n",
    "          nn.Linear(self.input_size, self.hidden_size),\n",
    "          nn.ELU())\n",
    "\n",
    "    self.hidden_layers_list = []\n",
    "\n",
    "    for i in range(num_layers // 2):\n",
    "      self.hidden_layers_list.append(\n",
    "          ResBlock(\n",
    "            nn.Sequential(\n",
    "                HiddenLayer(self.hidden_size, act_fn),\n",
    "                HiddenLayer(self.hidden_size, act_fn)\n",
    "            )\n",
    "        )\n",
    "      )\n",
    "\n",
    "    self.hidden_layers = nn.Sequential(*self.hidden_layers_list)\n",
    "\n",
    "    self.net = nn.Sequential(\n",
    "        self.initial_layer,\n",
    "        self.hidden_layers,\n",
    "        nn.Linear(self.hidden_size, self.output_size)\n",
    "    )\n",
    "  \n",
    "  def forward(self, x):\n",
    "    return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1650891686793,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "zcq_lQrHBdH8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def init_weights(m, init_m: str):\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def init_uniform(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "      torch.nn.init.uniform_(m.weight)\n",
    "      m.bias.data.fill_(0.01)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def init_normal(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "      torch.nn.init.normal_(m.weight)\n",
    "      m.bias.data.fill_(0.01)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def init_xuniform(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "      torch.nn.init.xavier_uniform_(m.weight)\n",
    "      m.bias.data.fill_(0.01)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def init_xnormal(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "      torch.nn.init.xavier_normal_(m.weight)\n",
    "      m.bias.data.fill_(0.01)\n",
    "\n",
    "  if init_m == 'uniform':\n",
    "    m.apply(init_uniform)\n",
    "  elif init_m == 'normal':\n",
    "    m.apply(init_normal)\n",
    "  elif init_m == 'xaiver uniform':\n",
    "    m.apply(init_xuniform)\n",
    "  elif init_m == 'xavier normal':\n",
    "    m.apply(init_xnormal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vuCpyycNCKEZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1650891686794,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "YbCOnCSNCL25",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_size = 8\n",
    "output_size = 1\n",
    "num_layers = 4\n",
    "hidden_size = 800\n",
    "batch_size = 774\n",
    "epochs = 2000\n",
    "lr = 5.973524887918111e-05\n",
    "init_method = 'xaiver uniform'\n",
    "act_fn = 'LeakyReLU'\n",
    "\n",
    "model = Net(input_size, output_size, hidden_size, num_layers, act_fn)\n",
    "init_weights(model, init_method)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 7351,
     "status": "ok",
     "timestamp": 1650891694138,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "QqZbxrppvDpZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1650891694142,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "Q-9T0GArCMgp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class OptDataset(Dataset):\n",
    "\n",
    "  def __init__(self, X, y):\n",
    "    self.X = X\n",
    "    self.y = y\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.X[idx], self.y[idx]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6-hCH2ivDpb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Losses Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1650891694144,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "mVaO8TruHW4M",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def MAPELoss(output, target):\n",
    "  return torch.mean(torch.abs((target - output) / target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1650891694149,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "tVLW5dHhvDpe",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, loss_fn, X_val, y_val):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for batch, batch_labels in DataLoader(OptDataset(X_val, y_val), batch_size=batch_size):\n",
    "            out = model(batch.to(device))\n",
    "            loss = loss_fn(out, batch_labels.to(device))\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    losses = np.array(losses)\n",
    "    print('\\nVal set: Average loss: {:.8f}\\n'.format(\n",
    "                losses.mean()))\n",
    "    return losses.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68eF5_EovDpf",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Early Stopping class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1650891694150,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "n2So2ffSvDpg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Code took form: https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, \n",
    "                 patience=10, \n",
    "                 verbose=False, \n",
    "                 delta=0, \n",
    "                 path='../models/final_heston_model.chkpt',\n",
    "                 trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score > self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dL_xmnKXvDph",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1650891694152,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "DrBBTGKJvDph",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    epochs,\n",
    "    batch_size,\n",
    "    model,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val\n",
    "):\n",
    "\n",
    "  training_losses = []\n",
    "  validation_losses = []\n",
    "\n",
    "  early_stopping = EarlyStopping(patience=20)\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "    i = 0\n",
    "\n",
    "    for batch, batch_labels in DataLoader(OptDataset(X_train, y_train), batch_size=batch_size):\n",
    "      out = model(batch.to(device))\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      loss = loss_fn(out, batch_labels.to(device))\n",
    "      epoch_losses.append(loss.item())\n",
    "      total_loss += loss.item()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      if i > 0 and i % 50 == 0:\n",
    "        avg_loss = total_loss / 50\n",
    "        elapsed = time.time() - start_time\n",
    "        print('| Epoch {:3d} | {:5d}/{:5d} batches | lr {:2.5f} | ms/batch {:5.2f} | '\n",
    "                  'loss {:5.8f}'.format(\n",
    "              epoch, i, len(X_train) // batch_size+1, lr, elapsed * 1000 / 50,\n",
    "              avg_loss))\n",
    "        start_time = time.time()\n",
    "        total_loss = 0\n",
    "\n",
    "      i += 1\n",
    "\n",
    "    training_losses.append(np.array(epoch_losses).mean())\n",
    "    val_loss = evaluate(model, loss_fn, X_val, y_val)\n",
    "    validation_losses.append(val_loss)\n",
    "\n",
    "    early_stopping(val_loss, model)\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(f\"Stopping at Epoch: {epoch}\")\n",
    "        break\n",
    "\n",
    "  return training_losses, validation_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2525796,
     "status": "ok",
     "timestamp": 1650894219916,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "hBETWoCfvDpj",
    "outputId": "30acf99f-3a1e-4d87-d1ff-13068ebe4cd4",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch   0 |    50/  658 batches | lr 0.00006 | ms/batch 21.94 | loss 0.49702895\n",
      "| Epoch   0 |   100/  658 batches | lr 0.00006 | ms/batch 17.26 | loss 0.18200452\n",
      "| Epoch   0 |   150/  658 batches | lr 0.00006 | ms/batch 15.24 | loss 0.13740353\n",
      "| Epoch   0 |   200/  658 batches | lr 0.00006 | ms/batch 14.95 | loss 0.12140823\n",
      "| Epoch   0 |   250/  658 batches | lr 0.00006 | ms/batch 17.55 | loss 0.11612058\n",
      "| Epoch   0 |   300/  658 batches | lr 0.00006 | ms/batch 15.02 | loss 0.11127010\n",
      "| Epoch   0 |   350/  658 batches | lr 0.00006 | ms/batch 16.27 | loss 0.11121804\n",
      "| Epoch   0 |   400/  658 batches | lr 0.00006 | ms/batch 16.46 | loss 0.10380239\n",
      "| Epoch   0 |   450/  658 batches | lr 0.00006 | ms/batch 14.60 | loss 0.10421183\n",
      "| Epoch   0 |   500/  658 batches | lr 0.00006 | ms/batch 14.77 | loss 0.10745940\n",
      "| Epoch   0 |   550/  658 batches | lr 0.00006 | ms/batch 16.58 | loss 0.10395367\n",
      "| Epoch   0 |   600/  658 batches | lr 0.00006 | ms/batch 14.70 | loss 0.09775824\n",
      "| Epoch   0 |   650/  658 batches | lr 0.00006 | ms/batch 16.18 | loss 0.10072356\n",
      "\n",
      "Val set: Average loss: 0.09959791\n",
      "\n",
      "| Epoch   1 |    50/  658 batches | lr 0.00006 | ms/batch 16.20 | loss 0.10939499\n",
      "| Epoch   1 |   100/  658 batches | lr 0.00006 | ms/batch 14.27 | loss 0.10068620\n",
      "| Epoch   1 |   150/  658 batches | lr 0.00006 | ms/batch 14.31 | loss 0.09847772\n",
      "| Epoch   1 |   200/  658 batches | lr 0.00006 | ms/batch 16.07 | loss 0.09730328\n",
      "| Epoch   1 |   250/  658 batches | lr 0.00006 | ms/batch 15.98 | loss 0.10128118\n",
      "| Epoch   1 |   300/  658 batches | lr 0.00006 | ms/batch 14.37 | loss 0.09796730\n",
      "| Epoch   1 |   350/  658 batches | lr 0.00006 | ms/batch 15.88 | loss 0.10022298\n",
      "| Epoch   1 |   400/  658 batches | lr 0.00006 | ms/batch 14.25 | loss 0.09438841\n",
      "| Epoch   1 |   450/  658 batches | lr 0.00006 | ms/batch 14.28 | loss 0.09487912\n",
      "| Epoch   1 |   500/  658 batches | lr 0.00006 | ms/batch 16.19 | loss 0.09766465\n",
      "| Epoch   1 |   550/  658 batches | lr 0.00006 | ms/batch 16.12 | loss 0.09350728\n",
      "| Epoch   1 |   600/  658 batches | lr 0.00006 | ms/batch 14.34 | loss 0.09048439\n",
      "| Epoch   1 |   650/  658 batches | lr 0.00006 | ms/batch 16.05 | loss 0.09374886\n",
      "\n",
      "Val set: Average loss: 0.10031340\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch   2 |    50/  658 batches | lr 0.00006 | ms/batch 14.55 | loss 0.10443973\n",
      "| Epoch   2 |   100/  658 batches | lr 0.00006 | ms/batch 14.31 | loss 0.09484247\n",
      "| Epoch   2 |   150/  658 batches | lr 0.00006 | ms/batch 15.93 | loss 0.09028227\n",
      "| Epoch   2 |   200/  658 batches | lr 0.00006 | ms/batch 14.42 | loss 0.09069541\n",
      "| Epoch   2 |   250/  658 batches | lr 0.00006 | ms/batch 16.04 | loss 0.09493117\n",
      "| Epoch   2 |   300/  658 batches | lr 0.00006 | ms/batch 16.00 | loss 0.09265461\n",
      "| Epoch   2 |   350/  658 batches | lr 0.00006 | ms/batch 14.30 | loss 0.09498413\n",
      "| Epoch   2 |   400/  658 batches | lr 0.00006 | ms/batch 14.40 | loss 0.08974214\n",
      "| Epoch   2 |   450/  658 batches | lr 0.00006 | ms/batch 15.97 | loss 0.09046535\n",
      "| Epoch   2 |   500/  658 batches | lr 0.00006 | ms/batch 14.40 | loss 0.09290390\n",
      "| Epoch   2 |   550/  658 batches | lr 0.00006 | ms/batch 16.04 | loss 0.08843467\n",
      "| Epoch   2 |   600/  658 batches | lr 0.00006 | ms/batch 15.93 | loss 0.08677732\n",
      "| Epoch   2 |   650/  658 batches | lr 0.00006 | ms/batch 14.35 | loss 0.08982116\n",
      "\n",
      "Val set: Average loss: 0.09440942\n",
      "\n",
      "| Epoch   3 |    50/  658 batches | lr 0.00006 | ms/batch 14.62 | loss 0.09854622\n",
      "| Epoch   3 |   100/  658 batches | lr 0.00006 | ms/batch 14.40 | loss 0.09161691\n",
      "| Epoch   3 |   150/  658 batches | lr 0.00006 | ms/batch 16.02 | loss 0.08698816\n",
      "| Epoch   3 |   200/  658 batches | lr 0.00006 | ms/batch 16.03 | loss 0.08728724\n",
      "| Epoch   3 |   250/  658 batches | lr 0.00006 | ms/batch 16.04 | loss 0.09091396\n",
      "| Epoch   3 |   300/  658 batches | lr 0.00006 | ms/batch 14.52 | loss 0.08940634\n",
      "| Epoch   3 |   350/  658 batches | lr 0.00006 | ms/batch 14.24 | loss 0.09164677\n",
      "| Epoch   3 |   400/  658 batches | lr 0.00006 | ms/batch 14.40 | loss 0.08648319\n",
      "| Epoch   3 |   450/  658 batches | lr 0.00006 | ms/batch 15.90 | loss 0.08721145\n",
      "| Epoch   3 |   500/  658 batches | lr 0.00006 | ms/batch 16.14 | loss 0.08990916\n",
      "| Epoch   3 |   550/  658 batches | lr 0.00006 | ms/batch 16.08 | loss 0.08536557\n",
      "| Epoch   3 |   600/  658 batches | lr 0.00006 | ms/batch 14.40 | loss 0.08432776\n",
      "| Epoch   3 |   650/  658 batches | lr 0.00006 | ms/batch 14.33 | loss 0.08699440\n",
      "\n",
      "Val set: Average loss: 0.08893968\n",
      "\n",
      "| Epoch   4 |    50/  658 batches | lr 0.00006 | ms/batch 14.59 | loss 0.09487998\n",
      "| Epoch   4 |   100/  658 batches | lr 0.00006 | ms/batch 16.26 | loss 0.08913387\n",
      "| Epoch   4 |   150/  658 batches | lr 0.00006 | ms/batch 14.35 | loss 0.08511785\n",
      "| Epoch   4 |   200/  658 batches | lr 0.00006 | ms/batch 15.95 | loss 0.08594679\n",
      "| Epoch   4 |   250/  658 batches | lr 0.00006 | ms/batch 16.24 | loss 0.08844184\n",
      "| Epoch   4 |   300/  658 batches | lr 0.00006 | ms/batch 14.32 | loss 0.08719490\n",
      "| Epoch   4 |   350/  658 batches | lr 0.00006 | ms/batch 14.25 | loss 0.08923537\n",
      "| Epoch   4 |   400/  658 batches | lr 0.00006 | ms/batch 16.02 | loss 0.08398027\n",
      "| Epoch   4 |   450/  658 batches | lr 0.00006 | ms/batch 14.35 | loss 0.08459947\n",
      "| Epoch   4 |   500/  658 batches | lr 0.00006 | ms/batch 15.95 | loss 0.08753251\n",
      "| Epoch   4 |   550/  658 batches | lr 0.00006 | ms/batch 16.00 | loss 0.08336347\n",
      "| Epoch   4 |   600/  658 batches | lr 0.00006 | ms/batch 14.30 | loss 0.08229598\n",
      "| Epoch   4 |   650/  658 batches | lr 0.00006 | ms/batch 14.40 | loss 0.08402747\n",
      "\n",
      "Val set: Average loss: 0.08512304\n",
      "\n",
      "| Epoch   5 |    50/  658 batches | lr 0.00006 | ms/batch 14.62 | loss 0.09214299\n",
      "| Epoch   5 |   100/  658 batches | lr 0.00006 | ms/batch 16.01 | loss 0.08701890\n",
      "| Epoch   5 |   150/  658 batches | lr 0.00006 | ms/batch 14.28 | loss 0.08241154\n",
      "| Epoch   5 |   200/  658 batches | lr 0.00006 | ms/batch 16.24 | loss 0.08230886\n",
      "| Epoch   5 |   250/  658 batches | lr 0.00006 | ms/batch 15.97 | loss 0.08634883\n",
      "| Epoch   5 |   300/  658 batches | lr 0.00006 | ms/batch 14.35 | loss 0.08522335\n",
      "| Epoch   5 |   350/  658 batches | lr 0.00006 | ms/batch 14.30 | loss 0.08724196\n",
      "| Epoch   5 |   400/  658 batches | lr 0.00006 | ms/batch 16.08 | loss 0.08184595\n",
      "| Epoch   5 |   450/  658 batches | lr 0.00006 | ms/batch 14.35 | loss 0.08233592\n",
      "| Epoch   5 |   500/  658 batches | lr 0.00006 | ms/batch 15.96 | loss 0.08549300\n",
      "| Epoch   5 |   550/  658 batches | lr 0.00006 | ms/batch 15.98 | loss 0.08164698\n",
      "| Epoch   5 |   600/  658 batches | lr 0.00006 | ms/batch 14.30 | loss 0.08075697\n",
      "| Epoch   5 |   650/  658 batches | lr 0.00006 | ms/batch 14.41 | loss 0.08198982\n",
      "\n",
      "Val set: Average loss: 0.08399223\n",
      "\n",
      "| Epoch   6 |    50/  658 batches | lr 0.00006 | ms/batch 14.59 | loss 0.09056771\n",
      "| Epoch   6 |   100/  658 batches | lr 0.00006 | ms/batch 15.92 | loss 0.08521011\n",
      "| Epoch   6 |   150/  658 batches | lr 0.00006 | ms/batch 14.47 | loss 0.07942718\n",
      "| Epoch   6 |   200/  658 batches | lr 0.00006 | ms/batch 16.00 | loss 0.07983552\n",
      "| Epoch   6 |   250/  658 batches | lr 0.00006 | ms/batch 16.18 | loss 0.08442456\n",
      "| Epoch   6 |   300/  658 batches | lr 0.00006 | ms/batch 15.04 | loss 0.08339657\n",
      "| Epoch   6 |   350/  658 batches | lr 0.00006 | ms/batch 14.38 | loss 0.08530878\n",
      "| Epoch   6 |   400/  658 batches | lr 0.00006 | ms/batch 16.03 | loss 0.07976225\n",
      "| Epoch   6 |   450/  658 batches | lr 0.00006 | ms/batch 14.45 | loss 0.08013108\n",
      "| Epoch   6 |   500/  658 batches | lr 0.00006 | ms/batch 16.16 | loss 0.08359193\n",
      "| Epoch   6 |   550/  658 batches | lr 0.00006 | ms/batch 16.01 | loss 0.08006916\n",
      "| Epoch   6 |   600/  658 batches | lr 0.00006 | ms/batch 14.27 | loss 0.07959518\n",
      "| Epoch   6 |   650/  658 batches | lr 0.00006 | ms/batch 14.28 | loss 0.08032423\n",
      "\n",
      "Val set: Average loss: 0.08329011\n",
      "\n",
      "| Epoch   7 |    50/  658 batches | lr 0.00006 | ms/batch 14.67 | loss 0.08922556\n",
      "| Epoch   7 |   100/  658 batches | lr 0.00006 | ms/batch 16.10 | loss 0.08383464\n",
      "| Epoch   7 |   150/  658 batches | lr 0.00006 | ms/batch 14.47 | loss 0.07747311\n",
      "| Epoch   7 |   200/  658 batches | lr 0.00006 | ms/batch 16.12 | loss 0.07913971\n",
      "| Epoch   7 |   250/  658 batches | lr 0.00006 | ms/batch 17.82 | loss 0.08271456\n",
      "| Epoch   7 |   300/  658 batches | lr 0.00006 | ms/batch 15.79 | loss 0.08178675\n",
      "| Epoch   7 |   350/  658 batches | lr 0.00006 | ms/batch 14.70 | loss 0.08368183\n",
      "| Epoch   7 |   400/  658 batches | lr 0.00006 | ms/batch 17.38 | loss 0.07777051\n",
      "| Epoch   7 |   450/  658 batches | lr 0.00006 | ms/batch 15.00 | loss 0.07808018\n",
      "| Epoch   7 |   500/  658 batches | lr 0.00006 | ms/batch 17.20 | loss 0.08191525\n",
      "| Epoch   7 |   550/  658 batches | lr 0.00006 | ms/batch 16.50 | loss 0.07855505\n",
      "| Epoch   7 |   600/  658 batches | lr 0.00006 | ms/batch 15.22 | loss 0.07867264\n",
      "| Epoch   7 |   650/  658 batches | lr 0.00006 | ms/batch 14.85 | loss 0.07875702\n",
      "\n",
      "Val set: Average loss: 0.08143526\n",
      "\n",
      "| Epoch   8 |    50/  658 batches | lr 0.00006 | ms/batch 15.13 | loss 0.08735201\n",
      "| Epoch   8 |   100/  658 batches | lr 0.00006 | ms/batch 16.29 | loss 0.08253070\n",
      "| Epoch   8 |   150/  658 batches | lr 0.00006 | ms/batch 15.01 | loss 0.07581077\n",
      "| Epoch   8 |   200/  658 batches | lr 0.00006 | ms/batch 16.53 | loss 0.07767433\n",
      "| Epoch   8 |   250/  658 batches | lr 0.00006 | ms/batch 16.49 | loss 0.08141275\n",
      "| Epoch   8 |   300/  658 batches | lr 0.00006 | ms/batch 14.57 | loss 0.08042812\n",
      "| Epoch   8 |   350/  658 batches | lr 0.00006 | ms/batch 17.04 | loss 0.08245046\n",
      "| Epoch   8 |   400/  658 batches | lr 0.00006 | ms/batch 21.69 | loss 0.07594427\n",
      "| Epoch   8 |   450/  658 batches | lr 0.00006 | ms/batch 16.40 | loss 0.07638136\n",
      "| Epoch   8 |   500/  658 batches | lr 0.00006 | ms/batch 17.73 | loss 0.08056459\n",
      "| Epoch   8 |   550/  658 batches | lr 0.00006 | ms/batch 17.39 | loss 0.07687629\n",
      "| Epoch   8 |   600/  658 batches | lr 0.00006 | ms/batch 16.39 | loss 0.07756373\n",
      "| Epoch   8 |   650/  658 batches | lr 0.00006 | ms/batch 15.53 | loss 0.07725264\n",
      "\n",
      "Val set: Average loss: 0.07899390\n",
      "\n",
      "| Epoch   9 |    50/  658 batches | lr 0.00006 | ms/batch 15.27 | loss 0.08563449\n",
      "| Epoch   9 |   100/  658 batches | lr 0.00006 | ms/batch 16.31 | loss 0.08135361\n",
      "| Epoch   9 |   150/  658 batches | lr 0.00006 | ms/batch 15.24 | loss 0.07441679\n",
      "| Epoch   9 |   200/  658 batches | lr 0.00006 | ms/batch 16.95 | loss 0.07715289\n",
      "| Epoch   9 |   250/  658 batches | lr 0.00006 | ms/batch 17.78 | loss 0.08018533\n",
      "| Epoch   9 |   300/  658 batches | lr 0.00006 | ms/batch 15.22 | loss 0.07909995\n",
      "| Epoch   9 |   350/  658 batches | lr 0.00006 | ms/batch 14.54 | loss 0.08106412\n",
      "| Epoch   9 |   400/  658 batches | lr 0.00006 | ms/batch 17.16 | loss 0.07430783\n",
      "| Epoch   9 |   450/  658 batches | lr 0.00006 | ms/batch 14.89 | loss 0.07476410\n",
      "| Epoch   9 |   500/  658 batches | lr 0.00006 | ms/batch 16.12 | loss 0.07923989\n",
      "| Epoch   9 |   550/  658 batches | lr 0.00006 | ms/batch 16.04 | loss 0.07533087\n",
      "| Epoch   9 |   600/  658 batches | lr 0.00006 | ms/batch 14.37 | loss 0.07637010\n",
      "| Epoch   9 |   650/  658 batches | lr 0.00006 | ms/batch 14.34 | loss 0.07569458\n",
      "\n",
      "Val set: Average loss: 0.07668606\n",
      "\n",
      "| Epoch  10 |    50/  658 batches | lr 0.00006 | ms/batch 14.63 | loss 0.08375979\n",
      "| Epoch  10 |   100/  658 batches | lr 0.00006 | ms/batch 15.90 | loss 0.07993004\n",
      "| Epoch  10 |   150/  658 batches | lr 0.00006 | ms/batch 14.43 | loss 0.07279026\n",
      "| Epoch  10 |   200/  658 batches | lr 0.00006 | ms/batch 16.27 | loss 0.07471802\n",
      "| Epoch  10 |   250/  658 batches | lr 0.00006 | ms/batch 16.07 | loss 0.07862309\n",
      "| Epoch  10 |   300/  658 batches | lr 0.00006 | ms/batch 14.33 | loss 0.07783886\n",
      "| Epoch  10 |   350/  658 batches | lr 0.00006 | ms/batch 14.40 | loss 0.07967767\n",
      "| Epoch  10 |   400/  658 batches | lr 0.00006 | ms/batch 15.94 | loss 0.07257234\n",
      "| Epoch  10 |   450/  658 batches | lr 0.00006 | ms/batch 14.43 | loss 0.07305658\n",
      "| Epoch  10 |   500/  658 batches | lr 0.00006 | ms/batch 16.04 | loss 0.07782484\n",
      "| Epoch  10 |   550/  658 batches | lr 0.00006 | ms/batch 16.53 | loss 0.07361822\n",
      "| Epoch  10 |   600/  658 batches | lr 0.00006 | ms/batch 14.45 | loss 0.07518523\n",
      "| Epoch  10 |   650/  658 batches | lr 0.00006 | ms/batch 14.35 | loss 0.07425852\n",
      "\n",
      "Val set: Average loss: 0.07609874\n",
      "\n",
      "| Epoch  11 |    50/  658 batches | lr 0.00006 | ms/batch 14.64 | loss 0.08287177\n",
      "| Epoch  11 |   100/  658 batches | lr 0.00006 | ms/batch 16.31 | loss 0.07861783\n",
      "| Epoch  11 |   150/  658 batches | lr 0.00006 | ms/batch 14.63 | loss 0.07157232\n",
      "| Epoch  11 |   200/  658 batches | lr 0.00006 | ms/batch 16.07 | loss 0.07366211\n",
      "| Epoch  11 |   250/  658 batches | lr 0.00006 | ms/batch 16.16 | loss 0.07737412\n",
      "| Epoch  11 |   300/  658 batches | lr 0.00006 | ms/batch 14.46 | loss 0.07651479\n",
      "| Epoch  11 |   350/  658 batches | lr 0.00006 | ms/batch 14.43 | loss 0.07814900\n",
      "| Epoch  11 |   400/  658 batches | lr 0.00006 | ms/batch 15.95 | loss 0.07101557\n",
      "| Epoch  11 |   450/  658 batches | lr 0.00006 | ms/batch 14.43 | loss 0.07138037\n",
      "| Epoch  11 |   500/  658 batches | lr 0.00006 | ms/batch 16.10 | loss 0.07634750\n",
      "| Epoch  11 |   550/  658 batches | lr 0.00006 | ms/batch 15.93 | loss 0.07209961\n",
      "| Epoch  11 |   600/  658 batches | lr 0.00006 | ms/batch 14.39 | loss 0.07410793\n",
      "| Epoch  11 |   650/  658 batches | lr 0.00006 | ms/batch 14.32 | loss 0.07275304\n",
      "\n",
      "Val set: Average loss: 0.07409537\n",
      "\n",
      "| Epoch  12 |    50/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.08101893\n",
      "| Epoch  12 |   100/  658 batches | lr 0.00006 | ms/batch 16.44 | loss 0.07702429\n",
      "| Epoch  12 |   150/  658 batches | lr 0.00006 | ms/batch 14.42 | loss 0.07041572\n",
      "| Epoch  12 |   200/  658 batches | lr 0.00006 | ms/batch 16.06 | loss 0.07210264\n",
      "| Epoch  12 |   250/  658 batches | lr 0.00006 | ms/batch 16.28 | loss 0.07606078\n",
      "| Epoch  12 |   300/  658 batches | lr 0.00006 | ms/batch 14.43 | loss 0.07520498\n",
      "| Epoch  12 |   350/  658 batches | lr 0.00006 | ms/batch 14.39 | loss 0.07682702\n",
      "| Epoch  12 |   400/  658 batches | lr 0.00006 | ms/batch 15.96 | loss 0.06977873\n",
      "| Epoch  12 |   450/  658 batches | lr 0.00006 | ms/batch 14.47 | loss 0.06995258\n",
      "| Epoch  12 |   500/  658 batches | lr 0.00006 | ms/batch 16.03 | loss 0.07524154\n",
      "| Epoch  12 |   550/  658 batches | lr 0.00006 | ms/batch 16.08 | loss 0.07075826\n",
      "| Epoch  12 |   600/  658 batches | lr 0.00006 | ms/batch 14.32 | loss 0.07318287\n",
      "| Epoch  12 |   650/  658 batches | lr 0.00006 | ms/batch 14.45 | loss 0.07162371\n",
      "\n",
      "Val set: Average loss: 0.07310485\n",
      "\n",
      "| Epoch  13 |    50/  658 batches | lr 0.00006 | ms/batch 14.77 | loss 0.07998662\n",
      "| Epoch  13 |   100/  658 batches | lr 0.00006 | ms/batch 16.02 | loss 0.07570115\n",
      "| Epoch  13 |   150/  658 batches | lr 0.00006 | ms/batch 14.49 | loss 0.06949450\n",
      "| Epoch  13 |   200/  658 batches | lr 0.00006 | ms/batch 16.09 | loss 0.07115696\n",
      "| Epoch  13 |   250/  658 batches | lr 0.00006 | ms/batch 16.05 | loss 0.07524869\n",
      "| Epoch  13 |   300/  658 batches | lr 0.00006 | ms/batch 14.41 | loss 0.07404409\n",
      "| Epoch  13 |   350/  658 batches | lr 0.00006 | ms/batch 14.43 | loss 0.07577585\n",
      "| Epoch  13 |   400/  658 batches | lr 0.00006 | ms/batch 15.99 | loss 0.06862816\n",
      "| Epoch  13 |   450/  658 batches | lr 0.00006 | ms/batch 14.45 | loss 0.06877744\n",
      "| Epoch  13 |   500/  658 batches | lr 0.00006 | ms/batch 16.10 | loss 0.07353650\n",
      "| Epoch  13 |   550/  658 batches | lr 0.00006 | ms/batch 16.14 | loss 0.06949592\n",
      "| Epoch  13 |   600/  658 batches | lr 0.00006 | ms/batch 14.35 | loss 0.07203027\n",
      "| Epoch  13 |   650/  658 batches | lr 0.00006 | ms/batch 14.39 | loss 0.07098853\n",
      "\n",
      "Val set: Average loss: 0.07218971\n",
      "\n",
      "| Epoch  14 |    50/  658 batches | lr 0.00006 | ms/batch 14.68 | loss 0.07908787\n",
      "| Epoch  14 |   100/  658 batches | lr 0.00006 | ms/batch 16.02 | loss 0.07472909\n",
      "| Epoch  14 |   150/  658 batches | lr 0.00006 | ms/batch 14.55 | loss 0.06877320\n",
      "| Epoch  14 |   200/  658 batches | lr 0.00006 | ms/batch 16.22 | loss 0.07026499\n",
      "| Epoch  14 |   250/  658 batches | lr 0.00006 | ms/batch 16.73 | loss 0.07446504\n",
      "| Epoch  14 |   300/  658 batches | lr 0.00006 | ms/batch 14.67 | loss 0.07326709\n",
      "| Epoch  14 |   350/  658 batches | lr 0.00006 | ms/batch 15.64 | loss 0.07539597\n",
      "| Epoch  14 |   400/  658 batches | lr 0.00006 | ms/batch 17.99 | loss 0.06787661\n",
      "| Epoch  14 |   450/  658 batches | lr 0.00006 | ms/batch 16.90 | loss 0.06807056\n",
      "| Epoch  14 |   500/  658 batches | lr 0.00006 | ms/batch 17.86 | loss 0.07246336\n",
      "| Epoch  14 |   550/  658 batches | lr 0.00006 | ms/batch 16.81 | loss 0.06857433\n",
      "| Epoch  14 |   600/  658 batches | lr 0.00006 | ms/batch 14.96 | loss 0.07128796\n",
      "| Epoch  14 |   650/  658 batches | lr 0.00006 | ms/batch 15.28 | loss 0.07029738\n",
      "\n",
      "Val set: Average loss: 0.07153063\n",
      "\n",
      "| Epoch  15 |    50/  658 batches | lr 0.00006 | ms/batch 15.64 | loss 0.07842517\n",
      "| Epoch  15 |   100/  658 batches | lr 0.00006 | ms/batch 16.71 | loss 0.07381787\n",
      "| Epoch  15 |   150/  658 batches | lr 0.00006 | ms/batch 14.96 | loss 0.06809329\n",
      "| Epoch  15 |   200/  658 batches | lr 0.00006 | ms/batch 16.97 | loss 0.06927387\n",
      "| Epoch  15 |   250/  658 batches | lr 0.00006 | ms/batch 16.59 | loss 0.07382333\n",
      "| Epoch  15 |   300/  658 batches | lr 0.00006 | ms/batch 14.67 | loss 0.07258482\n",
      "| Epoch  15 |   350/  658 batches | lr 0.00006 | ms/batch 14.58 | loss 0.07442286\n",
      "| Epoch  15 |   400/  658 batches | lr 0.00006 | ms/batch 16.25 | loss 0.06723116\n",
      "| Epoch  15 |   450/  658 batches | lr 0.00006 | ms/batch 14.68 | loss 0.06735006\n",
      "| Epoch  15 |   500/  658 batches | lr 0.00006 | ms/batch 16.35 | loss 0.07144734\n",
      "| Epoch  15 |   550/  658 batches | lr 0.00006 | ms/batch 16.30 | loss 0.06795939\n",
      "| Epoch  15 |   600/  658 batches | lr 0.00006 | ms/batch 14.63 | loss 0.07081166\n",
      "| Epoch  15 |   650/  658 batches | lr 0.00006 | ms/batch 14.64 | loss 0.06993684\n",
      "\n",
      "Val set: Average loss: 0.07116498\n",
      "\n",
      "| Epoch  16 |    50/  658 batches | lr 0.00006 | ms/batch 14.81 | loss 0.07801093\n",
      "| Epoch  16 |   100/  658 batches | lr 0.00006 | ms/batch 16.38 | loss 0.07332924\n",
      "| Epoch  16 |   150/  658 batches | lr 0.00006 | ms/batch 14.72 | loss 0.06774060\n",
      "| Epoch  16 |   200/  658 batches | lr 0.00006 | ms/batch 16.36 | loss 0.06909787\n",
      "| Epoch  16 |   250/  658 batches | lr 0.00006 | ms/batch 16.41 | loss 0.07326079\n",
      "| Epoch  16 |   300/  658 batches | lr 0.00006 | ms/batch 14.90 | loss 0.07210715\n",
      "| Epoch  16 |   350/  658 batches | lr 0.00006 | ms/batch 15.80 | loss 0.07416989\n",
      "| Epoch  16 |   400/  658 batches | lr 0.00006 | ms/batch 16.49 | loss 0.06681983\n",
      "| Epoch  16 |   450/  658 batches | lr 0.00006 | ms/batch 14.70 | loss 0.06676977\n",
      "| Epoch  16 |   500/  658 batches | lr 0.00006 | ms/batch 17.04 | loss 0.07066293\n",
      "| Epoch  16 |   550/  658 batches | lr 0.00006 | ms/batch 16.77 | loss 0.06749528\n",
      "| Epoch  16 |   600/  658 batches | lr 0.00006 | ms/batch 14.69 | loss 0.07038524\n",
      "| Epoch  16 |   650/  658 batches | lr 0.00006 | ms/batch 14.55 | loss 0.06952060\n",
      "\n",
      "Val set: Average loss: 0.07085083\n",
      "\n",
      "| Epoch  17 |    50/  658 batches | lr 0.00006 | ms/batch 14.82 | loss 0.07737939\n",
      "| Epoch  17 |   100/  658 batches | lr 0.00006 | ms/batch 16.69 | loss 0.07281913\n",
      "| Epoch  17 |   150/  658 batches | lr 0.00006 | ms/batch 15.17 | loss 0.06720954\n",
      "| Epoch  17 |   200/  658 batches | lr 0.00006 | ms/batch 16.34 | loss 0.06842463\n",
      "| Epoch  17 |   250/  658 batches | lr 0.00006 | ms/batch 16.28 | loss 0.07283478\n",
      "| Epoch  17 |   300/  658 batches | lr 0.00006 | ms/batch 14.66 | loss 0.07168651\n",
      "| Epoch  17 |   350/  658 batches | lr 0.00006 | ms/batch 14.69 | loss 0.07361077\n",
      "| Epoch  17 |   400/  658 batches | lr 0.00006 | ms/batch 16.15 | loss 0.06639048\n",
      "| Epoch  17 |   450/  658 batches | lr 0.00006 | ms/batch 14.87 | loss 0.06632372\n",
      "| Epoch  17 |   500/  658 batches | lr 0.00006 | ms/batch 16.45 | loss 0.07001940\n",
      "| Epoch  17 |   550/  658 batches | lr 0.00006 | ms/batch 16.34 | loss 0.06697004\n",
      "| Epoch  17 |   600/  658 batches | lr 0.00006 | ms/batch 14.63 | loss 0.06992749\n",
      "| Epoch  17 |   650/  658 batches | lr 0.00006 | ms/batch 14.71 | loss 0.06913749\n",
      "\n",
      "Val set: Average loss: 0.07008131\n",
      "\n",
      "| Epoch  18 |    50/  658 batches | lr 0.00006 | ms/batch 14.90 | loss 0.07700511\n",
      "| Epoch  18 |   100/  658 batches | lr 0.00006 | ms/batch 16.39 | loss 0.07212584\n",
      "| Epoch  18 |   150/  658 batches | lr 0.00006 | ms/batch 14.63 | loss 0.06665368\n",
      "| Epoch  18 |   200/  658 batches | lr 0.00006 | ms/batch 16.34 | loss 0.06780999\n",
      "| Epoch  18 |   250/  658 batches | lr 0.00006 | ms/batch 16.29 | loss 0.07249271\n",
      "| Epoch  18 |   300/  658 batches | lr 0.00006 | ms/batch 14.81 | loss 0.07136113\n",
      "| Epoch  18 |   350/  658 batches | lr 0.00006 | ms/batch 14.66 | loss 0.07313211\n",
      "| Epoch  18 |   400/  658 batches | lr 0.00006 | ms/batch 16.38 | loss 0.06605409\n",
      "| Epoch  18 |   450/  658 batches | lr 0.00006 | ms/batch 14.68 | loss 0.06592947\n",
      "| Epoch  18 |   500/  658 batches | lr 0.00006 | ms/batch 16.37 | loss 0.06963563\n",
      "| Epoch  18 |   550/  658 batches | lr 0.00006 | ms/batch 16.29 | loss 0.06674688\n",
      "| Epoch  18 |   600/  658 batches | lr 0.00006 | ms/batch 14.58 | loss 0.06942933\n",
      "| Epoch  18 |   650/  658 batches | lr 0.00006 | ms/batch 14.77 | loss 0.06878695\n",
      "\n",
      "Val set: Average loss: 0.06995070\n",
      "\n",
      "| Epoch  19 |    50/  658 batches | lr 0.00006 | ms/batch 14.97 | loss 0.07672880\n",
      "| Epoch  19 |   100/  658 batches | lr 0.00006 | ms/batch 16.20 | loss 0.07176636\n",
      "| Epoch  19 |   150/  658 batches | lr 0.00006 | ms/batch 14.84 | loss 0.06624204\n",
      "| Epoch  19 |   200/  658 batches | lr 0.00006 | ms/batch 16.50 | loss 0.06739325\n",
      "| Epoch  19 |   250/  658 batches | lr 0.00006 | ms/batch 16.34 | loss 0.07205898\n",
      "| Epoch  19 |   300/  658 batches | lr 0.00006 | ms/batch 14.70 | loss 0.07105293\n",
      "| Epoch  19 |   350/  658 batches | lr 0.00006 | ms/batch 14.84 | loss 0.07273586\n",
      "| Epoch  19 |   400/  658 batches | lr 0.00006 | ms/batch 16.55 | loss 0.06576396\n",
      "| Epoch  19 |   450/  658 batches | lr 0.00006 | ms/batch 14.92 | loss 0.06555169\n",
      "| Epoch  19 |   500/  658 batches | lr 0.00006 | ms/batch 16.46 | loss 0.06903270\n",
      "| Epoch  19 |   550/  658 batches | lr 0.00006 | ms/batch 16.42 | loss 0.06643712\n",
      "| Epoch  19 |   600/  658 batches | lr 0.00006 | ms/batch 14.74 | loss 0.06921982\n",
      "| Epoch  19 |   650/  658 batches | lr 0.00006 | ms/batch 14.76 | loss 0.06866415\n",
      "\n",
      "Val set: Average loss: 0.06960054\n",
      "\n",
      "| Epoch  20 |    50/  658 batches | lr 0.00006 | ms/batch 14.91 | loss 0.07632376\n",
      "| Epoch  20 |   100/  658 batches | lr 0.00006 | ms/batch 16.32 | loss 0.07139160\n",
      "| Epoch  20 |   150/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.06608043\n",
      "| Epoch  20 |   200/  658 batches | lr 0.00006 | ms/batch 16.27 | loss 0.06716761\n",
      "| Epoch  20 |   250/  658 batches | lr 0.00006 | ms/batch 16.23 | loss 0.07159327\n",
      "| Epoch  20 |   300/  658 batches | lr 0.00006 | ms/batch 14.76 | loss 0.07084736\n",
      "| Epoch  20 |   350/  658 batches | lr 0.00006 | ms/batch 14.68 | loss 0.07251272\n",
      "| Epoch  20 |   400/  658 batches | lr 0.00006 | ms/batch 16.26 | loss 0.06548808\n",
      "| Epoch  20 |   450/  658 batches | lr 0.00006 | ms/batch 14.63 | loss 0.06514796\n",
      "| Epoch  20 |   500/  658 batches | lr 0.00006 | ms/batch 16.70 | loss 0.06838682\n",
      "| Epoch  20 |   550/  658 batches | lr 0.00006 | ms/batch 17.39 | loss 0.06616332\n",
      "| Epoch  20 |   600/  658 batches | lr 0.00006 | ms/batch 16.87 | loss 0.06869031\n",
      "| Epoch  20 |   650/  658 batches | lr 0.00006 | ms/batch 16.29 | loss 0.06802067\n",
      "\n",
      "Val set: Average loss: 0.06942386\n",
      "\n",
      "| Epoch  21 |    50/  658 batches | lr 0.00006 | ms/batch 15.08 | loss 0.07605328\n",
      "| Epoch  21 |   100/  658 batches | lr 0.00006 | ms/batch 16.79 | loss 0.07075212\n",
      "| Epoch  21 |   150/  658 batches | lr 0.00006 | ms/batch 15.27 | loss 0.06567585\n",
      "| Epoch  21 |   200/  658 batches | lr 0.00006 | ms/batch 16.59 | loss 0.06666611\n",
      "| Epoch  21 |   250/  658 batches | lr 0.00006 | ms/batch 16.45 | loss 0.07136681\n",
      "| Epoch  21 |   300/  658 batches | lr 0.00006 | ms/batch 14.64 | loss 0.07069341\n",
      "| Epoch  21 |   350/  658 batches | lr 0.00006 | ms/batch 14.60 | loss 0.07195992\n",
      "| Epoch  21 |   400/  658 batches | lr 0.00006 | ms/batch 16.30 | loss 0.06532047\n",
      "| Epoch  21 |   450/  658 batches | lr 0.00006 | ms/batch 14.68 | loss 0.06477040\n",
      "| Epoch  21 |   500/  658 batches | lr 0.00006 | ms/batch 18.16 | loss 0.06801100\n",
      "| Epoch  21 |   550/  658 batches | lr 0.00006 | ms/batch 17.18 | loss 0.06598318\n",
      "| Epoch  21 |   600/  658 batches | lr 0.00006 | ms/batch 14.97 | loss 0.06859587\n",
      "| Epoch  21 |   650/  658 batches | lr 0.00006 | ms/batch 14.68 | loss 0.06774923\n",
      "\n",
      "Val set: Average loss: 0.06897062\n",
      "\n",
      "| Epoch  22 |    50/  658 batches | lr 0.00006 | ms/batch 15.26 | loss 0.07577262\n",
      "| Epoch  22 |   100/  658 batches | lr 0.00006 | ms/batch 16.70 | loss 0.07040145\n",
      "| Epoch  22 |   150/  658 batches | lr 0.00006 | ms/batch 14.98 | loss 0.06528124\n",
      "| Epoch  22 |   200/  658 batches | lr 0.00006 | ms/batch 17.60 | loss 0.06654542\n",
      "| Epoch  22 |   250/  658 batches | lr 0.00006 | ms/batch 16.57 | loss 0.07109162\n",
      "| Epoch  22 |   300/  658 batches | lr 0.00006 | ms/batch 14.98 | loss 0.07034248\n",
      "| Epoch  22 |   350/  658 batches | lr 0.00006 | ms/batch 14.88 | loss 0.07168513\n",
      "| Epoch  22 |   400/  658 batches | lr 0.00006 | ms/batch 16.66 | loss 0.06512483\n",
      "| Epoch  22 |   450/  658 batches | lr 0.00006 | ms/batch 15.30 | loss 0.06448460\n",
      "| Epoch  22 |   500/  658 batches | lr 0.00006 | ms/batch 16.55 | loss 0.06750110\n",
      "| Epoch  22 |   550/  658 batches | lr 0.00006 | ms/batch 16.49 | loss 0.06574626\n",
      "| Epoch  22 |   600/  658 batches | lr 0.00006 | ms/batch 14.72 | loss 0.06844533\n",
      "| Epoch  22 |   650/  658 batches | lr 0.00006 | ms/batch 14.77 | loss 0.06749737\n",
      "\n",
      "Val set: Average loss: 0.06872874\n",
      "\n",
      "| Epoch  23 |    50/  658 batches | lr 0.00006 | ms/batch 15.28 | loss 0.07563411\n",
      "| Epoch  23 |   100/  658 batches | lr 0.00006 | ms/batch 16.36 | loss 0.07009540\n",
      "| Epoch  23 |   150/  658 batches | lr 0.00006 | ms/batch 14.80 | loss 0.06509428\n",
      "| Epoch  23 |   200/  658 batches | lr 0.00006 | ms/batch 16.32 | loss 0.06625135\n",
      "| Epoch  23 |   250/  658 batches | lr 0.00006 | ms/batch 16.40 | loss 0.07056252\n",
      "| Epoch  23 |   300/  658 batches | lr 0.00006 | ms/batch 14.58 | loss 0.06991721\n",
      "| Epoch  23 |   350/  658 batches | lr 0.00006 | ms/batch 14.66 | loss 0.07136726\n",
      "| Epoch  23 |   400/  658 batches | lr 0.00006 | ms/batch 16.27 | loss 0.06501995\n",
      "| Epoch  23 |   450/  658 batches | lr 0.00006 | ms/batch 14.78 | loss 0.06420854\n",
      "| Epoch  23 |   500/  658 batches | lr 0.00006 | ms/batch 16.61 | loss 0.06727723\n",
      "| Epoch  23 |   550/  658 batches | lr 0.00006 | ms/batch 16.32 | loss 0.06554653\n",
      "| Epoch  23 |   600/  658 batches | lr 0.00006 | ms/batch 14.77 | loss 0.06794900\n",
      "| Epoch  23 |   650/  658 batches | lr 0.00006 | ms/batch 14.64 | loss 0.06757083\n",
      "\n",
      "Val set: Average loss: 0.06850808\n",
      "\n",
      "| Epoch  24 |    50/  658 batches | lr 0.00006 | ms/batch 15.03 | loss 0.07523690\n",
      "| Epoch  24 |   100/  658 batches | lr 0.00006 | ms/batch 16.36 | loss 0.06977156\n",
      "| Epoch  24 |   150/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.06485654\n",
      "| Epoch  24 |   200/  658 batches | lr 0.00006 | ms/batch 16.55 | loss 0.06585455\n",
      "| Epoch  24 |   250/  658 batches | lr 0.00006 | ms/batch 16.36 | loss 0.07036286\n",
      "| Epoch  24 |   300/  658 batches | lr 0.00006 | ms/batch 14.85 | loss 0.06976919\n",
      "| Epoch  24 |   350/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.07089672\n",
      "| Epoch  24 |   400/  658 batches | lr 0.00006 | ms/batch 16.41 | loss 0.06480358\n",
      "| Epoch  24 |   450/  658 batches | lr 0.00006 | ms/batch 14.90 | loss 0.06396526\n",
      "| Epoch  24 |   500/  658 batches | lr 0.00006 | ms/batch 16.40 | loss 0.06714177\n",
      "| Epoch  24 |   550/  658 batches | lr 0.00006 | ms/batch 16.41 | loss 0.06549454\n",
      "| Epoch  24 |   600/  658 batches | lr 0.00006 | ms/batch 14.71 | loss 0.06767615\n",
      "| Epoch  24 |   650/  658 batches | lr 0.00006 | ms/batch 14.73 | loss 0.06706201\n",
      "\n",
      "Val set: Average loss: 0.06805894\n",
      "\n",
      "| Epoch  25 |    50/  658 batches | lr 0.00006 | ms/batch 14.92 | loss 0.07507435\n",
      "| Epoch  25 |   100/  658 batches | lr 0.00006 | ms/batch 16.41 | loss 0.06943565\n",
      "| Epoch  25 |   150/  658 batches | lr 0.00006 | ms/batch 14.69 | loss 0.06476220\n",
      "| Epoch  25 |   200/  658 batches | lr 0.00006 | ms/batch 16.39 | loss 0.06554322\n",
      "| Epoch  25 |   250/  658 batches | lr 0.00006 | ms/batch 16.33 | loss 0.07006381\n",
      "| Epoch  25 |   300/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.06958360\n",
      "| Epoch  25 |   350/  658 batches | lr 0.00006 | ms/batch 14.67 | loss 0.07063913\n",
      "| Epoch  25 |   400/  658 batches | lr 0.00006 | ms/batch 16.42 | loss 0.06462084\n",
      "| Epoch  25 |   450/  658 batches | lr 0.00006 | ms/batch 14.80 | loss 0.06368006\n",
      "| Epoch  25 |   500/  658 batches | lr 0.00006 | ms/batch 16.34 | loss 0.06681506\n",
      "| Epoch  25 |   550/  658 batches | lr 0.00006 | ms/batch 16.37 | loss 0.06509198\n",
      "| Epoch  25 |   600/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.06780703\n",
      "| Epoch  25 |   650/  658 batches | lr 0.00006 | ms/batch 14.68 | loss 0.06706996\n",
      "\n",
      "Val set: Average loss: 0.06779812\n",
      "\n",
      "| Epoch  26 |    50/  658 batches | lr 0.00006 | ms/batch 14.98 | loss 0.07500661\n",
      "| Epoch  26 |   100/  658 batches | lr 0.00006 | ms/batch 16.76 | loss 0.06931503\n",
      "| Epoch  26 |   150/  658 batches | lr 0.00006 | ms/batch 16.99 | loss 0.06434477\n",
      "| Epoch  26 |   200/  658 batches | lr 0.00006 | ms/batch 16.82 | loss 0.06523192\n",
      "| Epoch  26 |   250/  658 batches | lr 0.00006 | ms/batch 16.48 | loss 0.06981057\n",
      "| Epoch  26 |   300/  658 batches | lr 0.00006 | ms/batch 15.03 | loss 0.06925960\n",
      "| Epoch  26 |   350/  658 batches | lr 0.00006 | ms/batch 14.84 | loss 0.07029503\n",
      "| Epoch  26 |   400/  658 batches | lr 0.00006 | ms/batch 16.33 | loss 0.06460786\n",
      "| Epoch  26 |   450/  658 batches | lr 0.00006 | ms/batch 15.09 | loss 0.06353112\n",
      "| Epoch  26 |   500/  658 batches | lr 0.00006 | ms/batch 17.11 | loss 0.06635454\n",
      "| Epoch  26 |   550/  658 batches | lr 0.00006 | ms/batch 16.91 | loss 0.06490060\n",
      "| Epoch  26 |   600/  658 batches | lr 0.00006 | ms/batch 15.26 | loss 0.06725869\n",
      "| Epoch  26 |   650/  658 batches | lr 0.00006 | ms/batch 14.83 | loss 0.06686197\n",
      "\n",
      "Val set: Average loss: 0.06758328\n",
      "\n",
      "| Epoch  27 |    50/  658 batches | lr 0.00006 | ms/batch 15.25 | loss 0.07480547\n",
      "| Epoch  27 |   100/  658 batches | lr 0.00006 | ms/batch 16.32 | loss 0.06904364\n",
      "| Epoch  27 |   150/  658 batches | lr 0.00006 | ms/batch 14.92 | loss 0.06411273\n",
      "| Epoch  27 |   200/  658 batches | lr 0.00006 | ms/batch 16.33 | loss 0.06517740\n",
      "| Epoch  27 |   250/  658 batches | lr 0.00006 | ms/batch 16.31 | loss 0.06956013\n",
      "| Epoch  27 |   300/  658 batches | lr 0.00006 | ms/batch 14.68 | loss 0.06917891\n",
      "| Epoch  27 |   350/  658 batches | lr 0.00006 | ms/batch 14.70 | loss 0.07007368\n",
      "| Epoch  27 |   400/  658 batches | lr 0.00006 | ms/batch 16.34 | loss 0.06446080\n",
      "| Epoch  27 |   450/  658 batches | lr 0.00006 | ms/batch 14.88 | loss 0.06318716\n",
      "| Epoch  27 |   500/  658 batches | lr 0.00006 | ms/batch 16.64 | loss 0.06606497\n",
      "| Epoch  27 |   550/  658 batches | lr 0.00006 | ms/batch 16.52 | loss 0.06474784\n",
      "| Epoch  27 |   600/  658 batches | lr 0.00006 | ms/batch 15.02 | loss 0.06710226\n",
      "| Epoch  27 |   650/  658 batches | lr 0.00006 | ms/batch 14.73 | loss 0.06658632\n",
      "\n",
      "Val set: Average loss: 0.06746346\n",
      "\n",
      "| Epoch  28 |    50/  658 batches | lr 0.00006 | ms/batch 15.73 | loss 0.07444157\n",
      "| Epoch  28 |   100/  658 batches | lr 0.00006 | ms/batch 17.66 | loss 0.06878487\n",
      "| Epoch  28 |   150/  658 batches | lr 0.00006 | ms/batch 15.82 | loss 0.06377897\n",
      "| Epoch  28 |   200/  658 batches | lr 0.00006 | ms/batch 17.09 | loss 0.06488734\n",
      "| Epoch  28 |   250/  658 batches | lr 0.00006 | ms/batch 17.60 | loss 0.06935390\n",
      "| Epoch  28 |   300/  658 batches | lr 0.00006 | ms/batch 15.32 | loss 0.06901935\n",
      "| Epoch  28 |   350/  658 batches | lr 0.00006 | ms/batch 15.10 | loss 0.06961614\n",
      "| Epoch  28 |   400/  658 batches | lr 0.00006 | ms/batch 19.15 | loss 0.06421435\n",
      "| Epoch  28 |   450/  658 batches | lr 0.00006 | ms/batch 15.54 | loss 0.06305410\n",
      "| Epoch  28 |   500/  658 batches | lr 0.00006 | ms/batch 17.73 | loss 0.06574398\n",
      "| Epoch  28 |   550/  658 batches | lr 0.00006 | ms/batch 17.40 | loss 0.06462728\n",
      "| Epoch  28 |   600/  658 batches | lr 0.00006 | ms/batch 16.47 | loss 0.06697173\n",
      "| Epoch  28 |   650/  658 batches | lr 0.00006 | ms/batch 17.07 | loss 0.06639850\n",
      "\n",
      "Val set: Average loss: 0.06722475\n",
      "\n",
      "| Epoch  29 |    50/  658 batches | lr 0.00006 | ms/batch 16.28 | loss 0.07423224\n",
      "| Epoch  29 |   100/  658 batches | lr 0.00006 | ms/batch 17.50 | loss 0.06865274\n",
      "| Epoch  29 |   150/  658 batches | lr 0.00006 | ms/batch 16.05 | loss 0.06362420\n",
      "| Epoch  29 |   200/  658 batches | lr 0.00006 | ms/batch 17.93 | loss 0.06458263\n",
      "| Epoch  29 |   250/  658 batches | lr 0.00006 | ms/batch 19.28 | loss 0.06916033\n",
      "| Epoch  29 |   300/  658 batches | lr 0.00006 | ms/batch 15.88 | loss 0.06868823\n",
      "| Epoch  29 |   350/  658 batches | lr 0.00006 | ms/batch 15.15 | loss 0.06954820\n",
      "| Epoch  29 |   400/  658 batches | lr 0.00006 | ms/batch 16.88 | loss 0.06424009\n",
      "| Epoch  29 |   450/  658 batches | lr 0.00006 | ms/batch 14.25 | loss 0.06282136\n",
      "| Epoch  29 |   500/  658 batches | lr 0.00006 | ms/batch 16.19 | loss 0.06563947\n",
      "| Epoch  29 |   550/  658 batches | lr 0.00006 | ms/batch 15.91 | loss 0.06435961\n",
      "| Epoch  29 |   600/  658 batches | lr 0.00006 | ms/batch 16.45 | loss 0.06671050\n",
      "| Epoch  29 |   650/  658 batches | lr 0.00006 | ms/batch 15.20 | loss 0.06643962\n",
      "\n",
      "Val set: Average loss: 0.06683541\n",
      "\n",
      "| Epoch  30 |    50/  658 batches | lr 0.00006 | ms/batch 14.65 | loss 0.07378553\n",
      "| Epoch  30 |   100/  658 batches | lr 0.00006 | ms/batch 16.22 | loss 0.06832708\n",
      "| Epoch  30 |   150/  658 batches | lr 0.00006 | ms/batch 14.69 | loss 0.06342406\n",
      "| Epoch  30 |   200/  658 batches | lr 0.00006 | ms/batch 16.64 | loss 0.06440565\n",
      "| Epoch  30 |   250/  658 batches | lr 0.00006 | ms/batch 15.85 | loss 0.06899448\n",
      "| Epoch  30 |   300/  658 batches | lr 0.00006 | ms/batch 14.02 | loss 0.06850511\n",
      "| Epoch  30 |   350/  658 batches | lr 0.00006 | ms/batch 13.96 | loss 0.06935222\n",
      "| Epoch  30 |   400/  658 batches | lr 0.00006 | ms/batch 15.53 | loss 0.06402102\n",
      "| Epoch  30 |   450/  658 batches | lr 0.00006 | ms/batch 14.08 | loss 0.06260386\n",
      "| Epoch  30 |   500/  658 batches | lr 0.00006 | ms/batch 15.96 | loss 0.06546601\n",
      "| Epoch  30 |   550/  658 batches | lr 0.00006 | ms/batch 16.15 | loss 0.06416746\n",
      "| Epoch  30 |   600/  658 batches | lr 0.00006 | ms/batch 14.18 | loss 0.06661840\n",
      "| Epoch  30 |   650/  658 batches | lr 0.00006 | ms/batch 14.16 | loss 0.06607682\n",
      "\n",
      "Val set: Average loss: 0.06654821\n",
      "\n",
      "| Epoch  31 |    50/  658 batches | lr 0.00006 | ms/batch 16.15 | loss 0.07370074\n",
      "| Epoch  31 |   100/  658 batches | lr 0.00006 | ms/batch 17.91 | loss 0.06803622\n",
      "| Epoch  31 |   150/  658 batches | lr 0.00006 | ms/batch 15.14 | loss 0.06319953\n",
      "| Epoch  31 |   200/  658 batches | lr 0.00006 | ms/batch 17.46 | loss 0.06424928\n",
      "| Epoch  31 |   250/  658 batches | lr 0.00006 | ms/batch 16.25 | loss 0.06884762\n",
      "| Epoch  31 |   300/  658 batches | lr 0.00006 | ms/batch 13.95 | loss 0.06822186\n",
      "| Epoch  31 |   350/  658 batches | lr 0.00006 | ms/batch 13.88 | loss 0.06903551\n",
      "| Epoch  31 |   400/  658 batches | lr 0.00006 | ms/batch 15.81 | loss 0.06384185\n",
      "| Epoch  31 |   450/  658 batches | lr 0.00006 | ms/batch 14.46 | loss 0.06239100\n",
      "| Epoch  31 |   500/  658 batches | lr 0.00006 | ms/batch 17.91 | loss 0.06521390\n",
      "| Epoch  31 |   550/  658 batches | lr 0.00006 | ms/batch 16.14 | loss 0.06402237\n",
      "| Epoch  31 |   600/  658 batches | lr 0.00006 | ms/batch 14.38 | loss 0.06657507\n",
      "| Epoch  31 |   650/  658 batches | lr 0.00006 | ms/batch 14.47 | loss 0.06585785\n",
      "\n",
      "Val set: Average loss: 0.06630954\n",
      "\n",
      "| Epoch  32 |    50/  658 batches | lr 0.00006 | ms/batch 14.88 | loss 0.07352997\n",
      "| Epoch  32 |   100/  658 batches | lr 0.00006 | ms/batch 15.73 | loss 0.06777150\n",
      "| Epoch  32 |   150/  658 batches | lr 0.00006 | ms/batch 13.92 | loss 0.06306509\n",
      "| Epoch  32 |   200/  658 batches | lr 0.00006 | ms/batch 15.55 | loss 0.06384740\n",
      "| Epoch  32 |   250/  658 batches | lr 0.00006 | ms/batch 15.56 | loss 0.06854219\n",
      "| Epoch  32 |   300/  658 batches | lr 0.00006 | ms/batch 13.92 | loss 0.06817208\n",
      "| Epoch  32 |   350/  658 batches | lr 0.00006 | ms/batch 14.28 | loss 0.06872446\n",
      "| Epoch  32 |   400/  658 batches | lr 0.00006 | ms/batch 15.68 | loss 0.06377800\n",
      "| Epoch  32 |   450/  658 batches | lr 0.00006 | ms/batch 14.15 | loss 0.06210734\n",
      "| Epoch  32 |   500/  658 batches | lr 0.00006 | ms/batch 16.06 | loss 0.06503306\n",
      "| Epoch  32 |   550/  658 batches | lr 0.00006 | ms/batch 16.37 | loss 0.06368078\n",
      "| Epoch  32 |   600/  658 batches | lr 0.00006 | ms/batch 14.49 | loss 0.06625423\n",
      "| Epoch  32 |   650/  658 batches | lr 0.00006 | ms/batch 14.88 | loss 0.06587179\n",
      "\n",
      "Val set: Average loss: 0.06628524\n",
      "\n",
      "| Epoch  33 |    50/  658 batches | lr 0.00006 | ms/batch 17.02 | loss 0.07331977\n",
      "| Epoch  33 |   100/  658 batches | lr 0.00006 | ms/batch 18.84 | loss 0.06771751\n",
      "| Epoch  33 |   150/  658 batches | lr 0.00006 | ms/batch 16.04 | loss 0.06282647\n",
      "| Epoch  33 |   200/  658 batches | lr 0.00006 | ms/batch 18.26 | loss 0.06384538\n",
      "| Epoch  33 |   250/  658 batches | lr 0.00006 | ms/batch 17.34 | loss 0.06837275\n",
      "| Epoch  33 |   300/  658 batches | lr 0.00006 | ms/batch 14.78 | loss 0.06766796\n",
      "| Epoch  33 |   350/  658 batches | lr 0.00006 | ms/batch 15.13 | loss 0.06857598\n",
      "| Epoch  33 |   400/  658 batches | lr 0.00006 | ms/batch 17.28 | loss 0.06343476\n",
      "| Epoch  33 |   450/  658 batches | lr 0.00006 | ms/batch 15.33 | loss 0.06195885\n",
      "| Epoch  33 |   500/  658 batches | lr 0.00006 | ms/batch 17.05 | loss 0.06481849\n",
      "| Epoch  33 |   550/  658 batches | lr 0.00006 | ms/batch 16.41 | loss 0.06376353\n",
      "| Epoch  33 |   600/  658 batches | lr 0.00006 | ms/batch 14.66 | loss 0.06613456\n",
      "| Epoch  33 |   650/  658 batches | lr 0.00006 | ms/batch 14.64 | loss 0.06576796\n",
      "\n",
      "Val set: Average loss: 0.06607420\n",
      "\n",
      "| Epoch  34 |    50/  658 batches | lr 0.00006 | ms/batch 15.05 | loss 0.07323981\n",
      "| Epoch  34 |   100/  658 batches | lr 0.00006 | ms/batch 16.38 | loss 0.06759779\n",
      "| Epoch  34 |   150/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.06269442\n",
      "| Epoch  34 |   200/  658 batches | lr 0.00006 | ms/batch 16.34 | loss 0.06358827\n",
      "| Epoch  34 |   250/  658 batches | lr 0.00006 | ms/batch 16.57 | loss 0.06809785\n",
      "| Epoch  34 |   300/  658 batches | lr 0.00006 | ms/batch 14.87 | loss 0.06764149\n",
      "| Epoch  34 |   350/  658 batches | lr 0.00006 | ms/batch 14.62 | loss 0.06839655\n",
      "| Epoch  34 |   400/  658 batches | lr 0.00006 | ms/batch 16.28 | loss 0.06338207\n",
      "| Epoch  34 |   450/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.06184166\n",
      "| Epoch  34 |   500/  658 batches | lr 0.00006 | ms/batch 16.39 | loss 0.06468096\n",
      "| Epoch  34 |   550/  658 batches | lr 0.00006 | ms/batch 16.34 | loss 0.06357307\n",
      "| Epoch  34 |   600/  658 batches | lr 0.00006 | ms/batch 14.72 | loss 0.06614349\n",
      "| Epoch  34 |   650/  658 batches | lr 0.00006 | ms/batch 14.69 | loss 0.06558908\n",
      "\n",
      "Val set: Average loss: 0.06592599\n",
      "\n",
      "| Epoch  35 |    50/  658 batches | lr 0.00006 | ms/batch 15.01 | loss 0.07323486\n",
      "| Epoch  35 |   100/  658 batches | lr 0.00006 | ms/batch 16.37 | loss 0.06736867\n",
      "| Epoch  35 |   150/  658 batches | lr 0.00006 | ms/batch 14.77 | loss 0.06247367\n",
      "| Epoch  35 |   200/  658 batches | lr 0.00006 | ms/batch 16.30 | loss 0.06352018\n",
      "| Epoch  35 |   250/  658 batches | lr 0.00006 | ms/batch 16.54 | loss 0.06799645\n",
      "| Epoch  35 |   300/  658 batches | lr 0.00006 | ms/batch 14.66 | loss 0.06751380\n",
      "| Epoch  35 |   350/  658 batches | lr 0.00006 | ms/batch 14.66 | loss 0.06796032\n",
      "| Epoch  35 |   400/  658 batches | lr 0.00006 | ms/batch 16.27 | loss 0.06337010\n",
      "| Epoch  35 |   450/  658 batches | lr 0.00006 | ms/batch 14.78 | loss 0.06160654\n",
      "| Epoch  35 |   500/  658 batches | lr 0.00006 | ms/batch 16.28 | loss 0.06452831\n",
      "| Epoch  35 |   550/  658 batches | lr 0.00006 | ms/batch 16.34 | loss 0.06371051\n",
      "| Epoch  35 |   600/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.06596102\n",
      "| Epoch  35 |   650/  658 batches | lr 0.00006 | ms/batch 14.66 | loss 0.06551294\n",
      "\n",
      "Val set: Average loss: 0.06579965\n",
      "\n",
      "| Epoch  36 |    50/  658 batches | lr 0.00006 | ms/batch 15.03 | loss 0.07272218\n",
      "| Epoch  36 |   100/  658 batches | lr 0.00006 | ms/batch 16.64 | loss 0.06720635\n",
      "| Epoch  36 |   150/  658 batches | lr 0.00006 | ms/batch 14.73 | loss 0.06247183\n",
      "| Epoch  36 |   200/  658 batches | lr 0.00006 | ms/batch 16.44 | loss 0.06335392\n",
      "| Epoch  36 |   250/  658 batches | lr 0.00006 | ms/batch 16.48 | loss 0.06782352\n",
      "| Epoch  36 |   300/  658 batches | lr 0.00006 | ms/batch 14.62 | loss 0.06716937\n",
      "| Epoch  36 |   350/  658 batches | lr 0.00006 | ms/batch 14.74 | loss 0.06800356\n",
      "| Epoch  36 |   400/  658 batches | lr 0.00006 | ms/batch 16.35 | loss 0.06326370\n",
      "| Epoch  36 |   450/  658 batches | lr 0.00006 | ms/batch 14.69 | loss 0.06139272\n",
      "| Epoch  36 |   500/  658 batches | lr 0.00006 | ms/batch 16.32 | loss 0.06445658\n",
      "| Epoch  36 |   550/  658 batches | lr 0.00006 | ms/batch 16.47 | loss 0.06353378\n",
      "| Epoch  36 |   600/  658 batches | lr 0.00006 | ms/batch 14.71 | loss 0.06574317\n",
      "| Epoch  36 |   650/  658 batches | lr 0.00006 | ms/batch 14.65 | loss 0.06526410\n",
      "\n",
      "Val set: Average loss: 0.06534705\n",
      "\n",
      "| Epoch  37 |    50/  658 batches | lr 0.00006 | ms/batch 14.96 | loss 0.07247961\n",
      "| Epoch  37 |   100/  658 batches | lr 0.00006 | ms/batch 16.33 | loss 0.06715802\n",
      "| Epoch  37 |   150/  658 batches | lr 0.00006 | ms/batch 14.76 | loss 0.06218308\n",
      "| Epoch  37 |   200/  658 batches | lr 0.00006 | ms/batch 16.37 | loss 0.06321847\n",
      "| Epoch  37 |   250/  658 batches | lr 0.00006 | ms/batch 16.32 | loss 0.06761379\n",
      "| Epoch  37 |   300/  658 batches | lr 0.00006 | ms/batch 14.82 | loss 0.06710053\n",
      "| Epoch  37 |   350/  658 batches | lr 0.00006 | ms/batch 14.68 | loss 0.06764172\n",
      "| Epoch  37 |   400/  658 batches | lr 0.00006 | ms/batch 16.31 | loss 0.06297335\n",
      "| Epoch  37 |   450/  658 batches | lr 0.00006 | ms/batch 14.68 | loss 0.06125965\n",
      "| Epoch  37 |   500/  658 batches | lr 0.00006 | ms/batch 16.23 | loss 0.06422361\n",
      "| Epoch  37 |   550/  658 batches | lr 0.00006 | ms/batch 16.42 | loss 0.06327592\n",
      "| Epoch  37 |   600/  658 batches | lr 0.00006 | ms/batch 14.64 | loss 0.06569536\n",
      "| Epoch  37 |   650/  658 batches | lr 0.00006 | ms/batch 14.63 | loss 0.06521096\n",
      "\n",
      "Val set: Average loss: 0.06505994\n",
      "\n",
      "| Epoch  38 |    50/  658 batches | lr 0.00006 | ms/batch 15.05 | loss 0.07226166\n",
      "| Epoch  38 |   100/  658 batches | lr 0.00006 | ms/batch 16.64 | loss 0.06684572\n",
      "| Epoch  38 |   150/  658 batches | lr 0.00006 | ms/batch 14.78 | loss 0.06217047\n",
      "| Epoch  38 |   200/  658 batches | lr 0.00006 | ms/batch 16.32 | loss 0.06281715\n",
      "| Epoch  38 |   250/  658 batches | lr 0.00006 | ms/batch 16.44 | loss 0.06735001\n",
      "| Epoch  38 |   300/  658 batches | lr 0.00006 | ms/batch 14.71 | loss 0.06671914\n",
      "| Epoch  38 |   350/  658 batches | lr 0.00006 | ms/batch 14.58 | loss 0.06745756\n",
      "| Epoch  38 |   400/  658 batches | lr 0.00006 | ms/batch 16.43 | loss 0.06285017\n",
      "| Epoch  38 |   450/  658 batches | lr 0.00006 | ms/batch 14.74 | loss 0.06117529\n",
      "| Epoch  38 |   500/  658 batches | lr 0.00006 | ms/batch 16.35 | loss 0.06402116\n",
      "| Epoch  38 |   550/  658 batches | lr 0.00006 | ms/batch 16.28 | loss 0.06316247\n",
      "| Epoch  38 |   600/  658 batches | lr 0.00006 | ms/batch 14.65 | loss 0.06545698\n",
      "| Epoch  38 |   650/  658 batches | lr 0.00006 | ms/batch 14.72 | loss 0.06478748\n",
      "\n",
      "Val set: Average loss: 0.06526345\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  39 |    50/  658 batches | lr 0.00006 | ms/batch 14.91 | loss 0.07190284\n",
      "| Epoch  39 |   100/  658 batches | lr 0.00006 | ms/batch 16.25 | loss 0.06665543\n",
      "| Epoch  39 |   150/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.06219995\n",
      "| Epoch  39 |   200/  658 batches | lr 0.00006 | ms/batch 16.36 | loss 0.06287090\n",
      "| Epoch  39 |   250/  658 batches | lr 0.00006 | ms/batch 16.35 | loss 0.06716916\n",
      "| Epoch  39 |   300/  658 batches | lr 0.00006 | ms/batch 14.69 | loss 0.06651746\n",
      "| Epoch  39 |   350/  658 batches | lr 0.00006 | ms/batch 14.77 | loss 0.06708556\n",
      "| Epoch  39 |   400/  658 batches | lr 0.00006 | ms/batch 16.31 | loss 0.06276542\n",
      "| Epoch  39 |   450/  658 batches | lr 0.00006 | ms/batch 14.69 | loss 0.06097313\n",
      "| Epoch  39 |   500/  658 batches | lr 0.00006 | ms/batch 16.43 | loss 0.06395812\n",
      "| Epoch  39 |   550/  658 batches | lr 0.00006 | ms/batch 16.28 | loss 0.06311355\n",
      "| Epoch  39 |   600/  658 batches | lr 0.00006 | ms/batch 14.71 | loss 0.06523064\n",
      "| Epoch  39 |   650/  658 batches | lr 0.00006 | ms/batch 14.65 | loss 0.06480686\n",
      "\n",
      "Val set: Average loss: 0.06497019\n",
      "\n",
      "| Epoch  40 |    50/  658 batches | lr 0.00006 | ms/batch 14.93 | loss 0.07167085\n",
      "| Epoch  40 |   100/  658 batches | lr 0.00006 | ms/batch 16.35 | loss 0.06639941\n",
      "| Epoch  40 |   150/  658 batches | lr 0.00006 | ms/batch 14.82 | loss 0.06199594\n",
      "| Epoch  40 |   200/  658 batches | lr 0.00006 | ms/batch 16.53 | loss 0.06279228\n",
      "| Epoch  40 |   250/  658 batches | lr 0.00006 | ms/batch 16.34 | loss 0.06710030\n",
      "| Epoch  40 |   300/  658 batches | lr 0.00006 | ms/batch 14.71 | loss 0.06657843\n",
      "| Epoch  40 |   350/  658 batches | lr 0.00006 | ms/batch 14.71 | loss 0.06709204\n",
      "| Epoch  40 |   400/  658 batches | lr 0.00006 | ms/batch 16.37 | loss 0.06262766\n",
      "| Epoch  40 |   450/  658 batches | lr 0.00006 | ms/batch 14.76 | loss 0.06086310\n",
      "| Epoch  40 |   500/  658 batches | lr 0.00006 | ms/batch 16.37 | loss 0.06396931\n",
      "| Epoch  40 |   550/  658 batches | lr 0.00006 | ms/batch 16.28 | loss 0.06287324\n",
      "| Epoch  40 |   600/  658 batches | lr 0.00006 | ms/batch 14.64 | loss 0.06523428\n",
      "| Epoch  40 |   650/  658 batches | lr 0.00006 | ms/batch 14.69 | loss 0.06468873\n",
      "\n",
      "Val set: Average loss: 0.06469460\n",
      "\n",
      "| Epoch  41 |    50/  658 batches | lr 0.00006 | ms/batch 15.02 | loss 0.07139197\n",
      "| Epoch  41 |   100/  658 batches | lr 0.00006 | ms/batch 16.46 | loss 0.06629037\n",
      "| Epoch  41 |   150/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.06175283\n",
      "| Epoch  41 |   200/  658 batches | lr 0.00006 | ms/batch 16.50 | loss 0.06250619\n",
      "| Epoch  41 |   250/  658 batches | lr 0.00006 | ms/batch 16.47 | loss 0.06692641\n",
      "| Epoch  41 |   300/  658 batches | lr 0.00006 | ms/batch 14.70 | loss 0.06632809\n",
      "| Epoch  41 |   350/  658 batches | lr 0.00006 | ms/batch 14.69 | loss 0.06690254\n",
      "| Epoch  41 |   400/  658 batches | lr 0.00006 | ms/batch 16.21 | loss 0.06252784\n",
      "| Epoch  41 |   450/  658 batches | lr 0.00006 | ms/batch 14.68 | loss 0.06067061\n",
      "| Epoch  41 |   500/  658 batches | lr 0.00006 | ms/batch 16.50 | loss 0.06385140\n",
      "| Epoch  41 |   550/  658 batches | lr 0.00006 | ms/batch 16.33 | loss 0.06276039\n",
      "| Epoch  41 |   600/  658 batches | lr 0.00006 | ms/batch 14.68 | loss 0.06504087\n",
      "| Epoch  41 |   650/  658 batches | lr 0.00006 | ms/batch 14.68 | loss 0.06438707\n",
      "\n",
      "Val set: Average loss: 0.06448656\n",
      "\n",
      "| Epoch  42 |    50/  658 batches | lr 0.00006 | ms/batch 15.00 | loss 0.07127426\n",
      "| Epoch  42 |   100/  658 batches | lr 0.00006 | ms/batch 16.41 | loss 0.06615748\n",
      "| Epoch  42 |   150/  658 batches | lr 0.00006 | ms/batch 14.69 | loss 0.06175978\n",
      "| Epoch  42 |   200/  658 batches | lr 0.00006 | ms/batch 16.41 | loss 0.06229141\n",
      "| Epoch  42 |   250/  658 batches | lr 0.00006 | ms/batch 16.27 | loss 0.06668387\n",
      "| Epoch  42 |   300/  658 batches | lr 0.00006 | ms/batch 14.70 | loss 0.06625105\n",
      "| Epoch  42 |   350/  658 batches | lr 0.00006 | ms/batch 14.58 | loss 0.06687065\n",
      "| Epoch  42 |   400/  658 batches | lr 0.00006 | ms/batch 16.39 | loss 0.06246472\n",
      "| Epoch  42 |   450/  658 batches | lr 0.00006 | ms/batch 14.61 | loss 0.06051085\n",
      "| Epoch  42 |   500/  658 batches | lr 0.00006 | ms/batch 16.31 | loss 0.06374395\n",
      "| Epoch  42 |   550/  658 batches | lr 0.00006 | ms/batch 16.33 | loss 0.06270394\n",
      "| Epoch  42 |   600/  658 batches | lr 0.00006 | ms/batch 14.66 | loss 0.06508486\n",
      "| Epoch  42 |   650/  658 batches | lr 0.00006 | ms/batch 14.79 | loss 0.06436951\n",
      "\n",
      "Val set: Average loss: 0.06437164\n",
      "\n",
      "| Epoch  43 |    50/  658 batches | lr 0.00006 | ms/batch 15.08 | loss 0.07114192\n",
      "| Epoch  43 |   100/  658 batches | lr 0.00006 | ms/batch 16.76 | loss 0.06604814\n",
      "| Epoch  43 |   150/  658 batches | lr 0.00006 | ms/batch 14.71 | loss 0.06155359\n",
      "| Epoch  43 |   200/  658 batches | lr 0.00006 | ms/batch 16.35 | loss 0.06206254\n",
      "| Epoch  43 |   250/  658 batches | lr 0.00006 | ms/batch 16.27 | loss 0.06643720\n",
      "| Epoch  43 |   300/  658 batches | lr 0.00006 | ms/batch 14.65 | loss 0.06619350\n",
      "| Epoch  43 |   350/  658 batches | lr 0.00006 | ms/batch 14.63 | loss 0.06678017\n",
      "| Epoch  43 |   400/  658 batches | lr 0.00006 | ms/batch 16.30 | loss 0.06247171\n",
      "| Epoch  43 |   450/  658 batches | lr 0.00006 | ms/batch 14.70 | loss 0.06024893\n",
      "| Epoch  43 |   500/  658 batches | lr 0.00006 | ms/batch 16.38 | loss 0.06351817\n",
      "| Epoch  43 |   550/  658 batches | lr 0.00006 | ms/batch 16.36 | loss 0.06250286\n",
      "| Epoch  43 |   600/  658 batches | lr 0.00006 | ms/batch 14.71 | loss 0.06493091\n",
      "| Epoch  43 |   650/  658 batches | lr 0.00006 | ms/batch 14.67 | loss 0.06407723\n",
      "\n",
      "Val set: Average loss: 0.06406632\n",
      "\n",
      "| Epoch  44 |    50/  658 batches | lr 0.00006 | ms/batch 15.08 | loss 0.07096081\n",
      "| Epoch  44 |   100/  658 batches | lr 0.00006 | ms/batch 16.37 | loss 0.06599537\n",
      "| Epoch  44 |   150/  658 batches | lr 0.00006 | ms/batch 14.74 | loss 0.06144728\n",
      "| Epoch  44 |   200/  658 batches | lr 0.00006 | ms/batch 16.32 | loss 0.06199589\n",
      "| Epoch  44 |   250/  658 batches | lr 0.00006 | ms/batch 16.33 | loss 0.06645968\n",
      "| Epoch  44 |   300/  658 batches | lr 0.00006 | ms/batch 14.67 | loss 0.06561074\n",
      "| Epoch  44 |   350/  658 batches | lr 0.00006 | ms/batch 14.76 | loss 0.06604237\n",
      "| Epoch  44 |   400/  658 batches | lr 0.00006 | ms/batch 16.40 | loss 0.06231461\n",
      "| Epoch  44 |   450/  658 batches | lr 0.00006 | ms/batch 14.76 | loss 0.06023187\n",
      "| Epoch  44 |   500/  658 batches | lr 0.00006 | ms/batch 16.35 | loss 0.06341806\n",
      "| Epoch  44 |   550/  658 batches | lr 0.00006 | ms/batch 16.28 | loss 0.06236026\n",
      "| Epoch  44 |   600/  658 batches | lr 0.00006 | ms/batch 14.71 | loss 0.06473639\n",
      "| Epoch  44 |   650/  658 batches | lr 0.00006 | ms/batch 14.69 | loss 0.06390770\n",
      "\n",
      "Val set: Average loss: 0.06402301\n",
      "\n",
      "| Epoch  45 |    50/  658 batches | lr 0.00006 | ms/batch 14.95 | loss 0.07086920\n",
      "| Epoch  45 |   100/  658 batches | lr 0.00006 | ms/batch 16.21 | loss 0.06595842\n",
      "| Epoch  45 |   150/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.06144785\n",
      "| Epoch  45 |   200/  658 batches | lr 0.00006 | ms/batch 16.34 | loss 0.06185926\n",
      "| Epoch  45 |   250/  658 batches | lr 0.00006 | ms/batch 16.29 | loss 0.06621583\n",
      "| Epoch  45 |   300/  658 batches | lr 0.00006 | ms/batch 14.76 | loss 0.06552547\n",
      "| Epoch  45 |   350/  658 batches | lr 0.00006 | ms/batch 14.63 | loss 0.06636743\n",
      "| Epoch  45 |   400/  658 batches | lr 0.00006 | ms/batch 16.21 | loss 0.06210224\n",
      "| Epoch  45 |   450/  658 batches | lr 0.00006 | ms/batch 14.82 | loss 0.06008666\n",
      "| Epoch  45 |   500/  658 batches | lr 0.00006 | ms/batch 16.33 | loss 0.06325330\n",
      "| Epoch  45 |   550/  658 batches | lr 0.00006 | ms/batch 16.33 | loss 0.06221061\n",
      "| Epoch  45 |   600/  658 batches | lr 0.00006 | ms/batch 14.79 | loss 0.06465856\n",
      "| Epoch  45 |   650/  658 batches | lr 0.00006 | ms/batch 14.71 | loss 0.06392258\n",
      "\n",
      "Val set: Average loss: 0.06389302\n",
      "\n",
      "| Epoch  46 |    50/  658 batches | lr 0.00006 | ms/batch 15.02 | loss 0.07068319\n",
      "| Epoch  46 |   100/  658 batches | lr 0.00006 | ms/batch 16.38 | loss 0.06576146\n",
      "| Epoch  46 |   150/  658 batches | lr 0.00006 | ms/batch 14.69 | loss 0.06128770\n",
      "| Epoch  46 |   200/  658 batches | lr 0.00006 | ms/batch 16.33 | loss 0.06183523\n",
      "| Epoch  46 |   250/  658 batches | lr 0.00006 | ms/batch 16.45 | loss 0.06610541\n",
      "| Epoch  46 |   300/  658 batches | lr 0.00006 | ms/batch 14.66 | loss 0.06543500\n",
      "| Epoch  46 |   350/  658 batches | lr 0.00006 | ms/batch 14.71 | loss 0.06577297\n",
      "| Epoch  46 |   400/  658 batches | lr 0.00006 | ms/batch 16.47 | loss 0.06213381\n",
      "| Epoch  46 |   450/  658 batches | lr 0.00006 | ms/batch 14.83 | loss 0.05999255\n",
      "| Epoch  46 |   500/  658 batches | lr 0.00006 | ms/batch 16.54 | loss 0.06317488\n",
      "| Epoch  46 |   550/  658 batches | lr 0.00006 | ms/batch 16.48 | loss 0.06209057\n",
      "| Epoch  46 |   600/  658 batches | lr 0.00006 | ms/batch 14.90 | loss 0.06464507\n",
      "| Epoch  46 |   650/  658 batches | lr 0.00006 | ms/batch 14.88 | loss 0.06379876\n",
      "\n",
      "Val set: Average loss: 0.06370850\n",
      "\n",
      "| Epoch  47 |    50/  658 batches | lr 0.00006 | ms/batch 14.95 | loss 0.07043590\n",
      "| Epoch  47 |   100/  658 batches | lr 0.00006 | ms/batch 16.40 | loss 0.06553593\n",
      "| Epoch  47 |   150/  658 batches | lr 0.00006 | ms/batch 14.84 | loss 0.06124963\n",
      "| Epoch  47 |   200/  658 batches | lr 0.00006 | ms/batch 16.56 | loss 0.06165197\n",
      "| Epoch  47 |   250/  658 batches | lr 0.00006 | ms/batch 16.23 | loss 0.06590294\n",
      "| Epoch  47 |   300/  658 batches | lr 0.00006 | ms/batch 14.79 | loss 0.06511968\n",
      "| Epoch  47 |   350/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.06588058\n",
      "| Epoch  47 |   400/  658 batches | lr 0.00006 | ms/batch 16.23 | loss 0.06209993\n",
      "| Epoch  47 |   450/  658 batches | lr 0.00006 | ms/batch 14.76 | loss 0.05990684\n",
      "| Epoch  47 |   500/  658 batches | lr 0.00006 | ms/batch 16.27 | loss 0.06312614\n",
      "| Epoch  47 |   550/  658 batches | lr 0.00006 | ms/batch 16.33 | loss 0.06218986\n",
      "| Epoch  47 |   600/  658 batches | lr 0.00006 | ms/batch 14.67 | loss 0.06445233\n",
      "| Epoch  47 |   650/  658 batches | lr 0.00006 | ms/batch 14.80 | loss 0.06359840\n",
      "\n",
      "Val set: Average loss: 0.06358458\n",
      "\n",
      "| Epoch  48 |    50/  658 batches | lr 0.00006 | ms/batch 14.99 | loss 0.07017827\n",
      "| Epoch  48 |   100/  658 batches | lr 0.00006 | ms/batch 16.33 | loss 0.06529900\n",
      "| Epoch  48 |   150/  658 batches | lr 0.00006 | ms/batch 14.82 | loss 0.06111106\n",
      "| Epoch  48 |   200/  658 batches | lr 0.00006 | ms/batch 17.14 | loss 0.06139699\n",
      "| Epoch  48 |   250/  658 batches | lr 0.00006 | ms/batch 16.57 | loss 0.06577979\n",
      "| Epoch  48 |   300/  658 batches | lr 0.00006 | ms/batch 14.87 | loss 0.06560021\n",
      "| Epoch  48 |   350/  658 batches | lr 0.00006 | ms/batch 15.92 | loss 0.06578853\n",
      "| Epoch  48 |   400/  658 batches | lr 0.00006 | ms/batch 16.90 | loss 0.06187323\n",
      "| Epoch  48 |   450/  658 batches | lr 0.00006 | ms/batch 15.40 | loss 0.05978271\n",
      "| Epoch  48 |   500/  658 batches | lr 0.00006 | ms/batch 16.81 | loss 0.06309763\n",
      "| Epoch  48 |   550/  658 batches | lr 0.00006 | ms/batch 16.56 | loss 0.06191227\n",
      "| Epoch  48 |   600/  658 batches | lr 0.00006 | ms/batch 14.72 | loss 0.06443092\n",
      "| Epoch  48 |   650/  658 batches | lr 0.00006 | ms/batch 14.58 | loss 0.06343678\n",
      "\n",
      "Val set: Average loss: 0.06348630\n",
      "\n",
      "| Epoch  49 |    50/  658 batches | lr 0.00006 | ms/batch 15.06 | loss 0.07019169\n",
      "| Epoch  49 |   100/  658 batches | lr 0.00006 | ms/batch 16.31 | loss 0.06532325\n",
      "| Epoch  49 |   150/  658 batches | lr 0.00006 | ms/batch 14.67 | loss 0.06108032\n",
      "| Epoch  49 |   200/  658 batches | lr 0.00006 | ms/batch 16.39 | loss 0.06134690\n",
      "| Epoch  49 |   250/  658 batches | lr 0.00006 | ms/batch 16.26 | loss 0.06573611\n",
      "| Epoch  49 |   300/  658 batches | lr 0.00006 | ms/batch 14.63 | loss 0.06481583\n",
      "| Epoch  49 |   350/  658 batches | lr 0.00006 | ms/batch 14.62 | loss 0.06508411\n",
      "| Epoch  49 |   400/  658 batches | lr 0.00006 | ms/batch 16.41 | loss 0.06191837\n",
      "| Epoch  49 |   450/  658 batches | lr 0.00006 | ms/batch 14.67 | loss 0.05961908\n",
      "| Epoch  49 |   500/  658 batches | lr 0.00006 | ms/batch 16.36 | loss 0.06279644\n",
      "| Epoch  49 |   550/  658 batches | lr 0.00006 | ms/batch 16.36 | loss 0.06194919\n",
      "| Epoch  49 |   600/  658 batches | lr 0.00006 | ms/batch 14.62 | loss 0.06438229\n",
      "| Epoch  49 |   650/  658 batches | lr 0.00006 | ms/batch 14.70 | loss 0.06336306\n",
      "\n",
      "Val set: Average loss: 0.06349036\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  50 |    50/  658 batches | lr 0.00006 | ms/batch 14.99 | loss 0.06984843\n",
      "| Epoch  50 |   100/  658 batches | lr 0.00006 | ms/batch 16.27 | loss 0.06532763\n",
      "| Epoch  50 |   150/  658 batches | lr 0.00006 | ms/batch 14.62 | loss 0.06103546\n",
      "| Epoch  50 |   200/  658 batches | lr 0.00006 | ms/batch 16.37 | loss 0.06123391\n",
      "| Epoch  50 |   250/  658 batches | lr 0.00006 | ms/batch 16.33 | loss 0.06559444\n",
      "| Epoch  50 |   300/  658 batches | lr 0.00006 | ms/batch 14.59 | loss 0.06497174\n",
      "| Epoch  50 |   350/  658 batches | lr 0.00006 | ms/batch 14.72 | loss 0.06547523\n",
      "| Epoch  50 |   400/  658 batches | lr 0.00006 | ms/batch 16.25 | loss 0.06168743\n",
      "| Epoch  50 |   450/  658 batches | lr 0.00006 | ms/batch 14.78 | loss 0.05948873\n",
      "| Epoch  50 |   500/  658 batches | lr 0.00006 | ms/batch 16.26 | loss 0.06283872\n",
      "| Epoch  50 |   550/  658 batches | lr 0.00006 | ms/batch 16.53 | loss 0.06191738\n",
      "| Epoch  50 |   600/  658 batches | lr 0.00006 | ms/batch 14.64 | loss 0.06406579\n",
      "| Epoch  50 |   650/  658 batches | lr 0.00006 | ms/batch 14.67 | loss 0.06316354\n",
      "\n",
      "Val set: Average loss: 0.06320584\n",
      "\n",
      "| Epoch  51 |    50/  658 batches | lr 0.00006 | ms/batch 15.04 | loss 0.06972419\n",
      "| Epoch  51 |   100/  658 batches | lr 0.00006 | ms/batch 16.34 | loss 0.06496844\n",
      "| Epoch  51 |   150/  658 batches | lr 0.00006 | ms/batch 14.71 | loss 0.06080144\n",
      "| Epoch  51 |   200/  658 batches | lr 0.00006 | ms/batch 16.34 | loss 0.06104351\n",
      "| Epoch  51 |   250/  658 batches | lr 0.00006 | ms/batch 16.49 | loss 0.06530924\n",
      "| Epoch  51 |   300/  658 batches | lr 0.00006 | ms/batch 14.71 | loss 0.06458774\n",
      "| Epoch  51 |   350/  658 batches | lr 0.00006 | ms/batch 14.77 | loss 0.06480186\n",
      "| Epoch  51 |   400/  658 batches | lr 0.00006 | ms/batch 16.32 | loss 0.06171105\n",
      "| Epoch  51 |   450/  658 batches | lr 0.00006 | ms/batch 14.68 | loss 0.05932637\n",
      "| Epoch  51 |   500/  658 batches | lr 0.00006 | ms/batch 16.39 | loss 0.06274179\n",
      "| Epoch  51 |   550/  658 batches | lr 0.00006 | ms/batch 16.35 | loss 0.06172081\n",
      "| Epoch  51 |   600/  658 batches | lr 0.00006 | ms/batch 14.72 | loss 0.06413968\n",
      "| Epoch  51 |   650/  658 batches | lr 0.00006 | ms/batch 14.82 | loss 0.06300155\n",
      "\n",
      "Val set: Average loss: 0.06320371\n",
      "\n",
      "| Epoch  52 |    50/  658 batches | lr 0.00006 | ms/batch 15.05 | loss 0.06952103\n",
      "| Epoch  52 |   100/  658 batches | lr 0.00006 | ms/batch 16.27 | loss 0.06491762\n",
      "| Epoch  52 |   150/  658 batches | lr 0.00006 | ms/batch 14.68 | loss 0.06073738\n",
      "| Epoch  52 |   200/  658 batches | lr 0.00006 | ms/batch 16.41 | loss 0.06087610\n",
      "| Epoch  52 |   250/  658 batches | lr 0.00006 | ms/batch 16.35 | loss 0.06515826\n",
      "| Epoch  52 |   300/  658 batches | lr 0.00006 | ms/batch 14.69 | loss 0.06440908\n",
      "| Epoch  52 |   350/  658 batches | lr 0.00006 | ms/batch 14.76 | loss 0.06505847\n",
      "| Epoch  52 |   400/  658 batches | lr 0.00006 | ms/batch 16.31 | loss 0.06153636\n",
      "| Epoch  52 |   450/  658 batches | lr 0.00006 | ms/batch 14.80 | loss 0.05917948\n",
      "| Epoch  52 |   500/  658 batches | lr 0.00006 | ms/batch 16.32 | loss 0.06265556\n",
      "| Epoch  52 |   550/  658 batches | lr 0.00006 | ms/batch 16.46 | loss 0.06154167\n",
      "| Epoch  52 |   600/  658 batches | lr 0.00006 | ms/batch 14.64 | loss 0.06398573\n",
      "| Epoch  52 |   650/  658 batches | lr 0.00006 | ms/batch 14.67 | loss 0.06278767\n",
      "\n",
      "Val set: Average loss: 0.06317780\n",
      "\n",
      "| Epoch  53 |    50/  658 batches | lr 0.00006 | ms/batch 15.01 | loss 0.06949737\n",
      "| Epoch  53 |   100/  658 batches | lr 0.00006 | ms/batch 16.36 | loss 0.06501897\n",
      "| Epoch  53 |   150/  658 batches | lr 0.00006 | ms/batch 15.02 | loss 0.06071480\n",
      "| Epoch  53 |   200/  658 batches | lr 0.00006 | ms/batch 16.95 | loss 0.06081229\n",
      "| Epoch  53 |   250/  658 batches | lr 0.00006 | ms/batch 16.43 | loss 0.06512596\n",
      "| Epoch  53 |   300/  658 batches | lr 0.00006 | ms/batch 14.80 | loss 0.06422322\n",
      "| Epoch  53 |   350/  658 batches | lr 0.00006 | ms/batch 14.76 | loss 0.06462231\n",
      "| Epoch  53 |   400/  658 batches | lr 0.00006 | ms/batch 16.39 | loss 0.06153938\n",
      "| Epoch  53 |   450/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.05906970\n",
      "| Epoch  53 |   500/  658 batches | lr 0.00006 | ms/batch 16.36 | loss 0.06266162\n",
      "| Epoch  53 |   550/  658 batches | lr 0.00006 | ms/batch 16.35 | loss 0.06141156\n",
      "| Epoch  53 |   600/  658 batches | lr 0.00006 | ms/batch 14.98 | loss 0.06397588\n",
      "| Epoch  53 |   650/  658 batches | lr 0.00006 | ms/batch 14.67 | loss 0.06275890\n",
      "\n",
      "Val set: Average loss: 0.06302191\n",
      "\n",
      "| Epoch  54 |    50/  658 batches | lr 0.00006 | ms/batch 15.00 | loss 0.06940299\n",
      "| Epoch  54 |   100/  658 batches | lr 0.00006 | ms/batch 16.44 | loss 0.06492007\n",
      "| Epoch  54 |   150/  658 batches | lr 0.00006 | ms/batch 14.87 | loss 0.06060355\n",
      "| Epoch  54 |   200/  658 batches | lr 0.00006 | ms/batch 16.37 | loss 0.06064093\n",
      "| Epoch  54 |   250/  658 batches | lr 0.00006 | ms/batch 16.41 | loss 0.06487274\n",
      "| Epoch  54 |   300/  658 batches | lr 0.00006 | ms/batch 14.83 | loss 0.06408253\n",
      "| Epoch  54 |   350/  658 batches | lr 0.00006 | ms/batch 14.70 | loss 0.06453458\n",
      "| Epoch  54 |   400/  658 batches | lr 0.00006 | ms/batch 16.43 | loss 0.06144623\n",
      "| Epoch  54 |   450/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.05889649\n",
      "| Epoch  54 |   500/  658 batches | lr 0.00006 | ms/batch 16.52 | loss 0.06265769\n",
      "| Epoch  54 |   550/  658 batches | lr 0.00006 | ms/batch 16.39 | loss 0.06129810\n",
      "| Epoch  54 |   600/  658 batches | lr 0.00006 | ms/batch 14.81 | loss 0.06376599\n",
      "| Epoch  54 |   650/  658 batches | lr 0.00006 | ms/batch 14.83 | loss 0.06276400\n",
      "\n",
      "Val set: Average loss: 0.06296608\n",
      "\n",
      "| Epoch  55 |    50/  658 batches | lr 0.00006 | ms/batch 15.04 | loss 0.06924531\n",
      "| Epoch  55 |   100/  658 batches | lr 0.00006 | ms/batch 16.52 | loss 0.06482474\n",
      "| Epoch  55 |   150/  658 batches | lr 0.00006 | ms/batch 14.83 | loss 0.06060850\n",
      "| Epoch  55 |   200/  658 batches | lr 0.00006 | ms/batch 16.55 | loss 0.06047210\n",
      "| Epoch  55 |   250/  658 batches | lr 0.00006 | ms/batch 16.48 | loss 0.06475663\n",
      "| Epoch  55 |   300/  658 batches | lr 0.00006 | ms/batch 14.98 | loss 0.06392713\n",
      "| Epoch  55 |   350/  658 batches | lr 0.00006 | ms/batch 14.81 | loss 0.06431926\n",
      "| Epoch  55 |   400/  658 batches | lr 0.00006 | ms/batch 16.36 | loss 0.06148643\n",
      "| Epoch  55 |   450/  658 batches | lr 0.00006 | ms/batch 14.72 | loss 0.05891874\n",
      "| Epoch  55 |   500/  658 batches | lr 0.00006 | ms/batch 16.50 | loss 0.06238716\n",
      "| Epoch  55 |   550/  658 batches | lr 0.00006 | ms/batch 16.31 | loss 0.06143378\n",
      "| Epoch  55 |   600/  658 batches | lr 0.00006 | ms/batch 14.79 | loss 0.06379747\n",
      "| Epoch  55 |   650/  658 batches | lr 0.00006 | ms/batch 14.81 | loss 0.06249229\n",
      "\n",
      "Val set: Average loss: 0.06272159\n",
      "\n",
      "| Epoch  56 |    50/  658 batches | lr 0.00006 | ms/batch 14.99 | loss 0.06906805\n",
      "| Epoch  56 |   100/  658 batches | lr 0.00006 | ms/batch 16.62 | loss 0.06468579\n",
      "| Epoch  56 |   150/  658 batches | lr 0.00006 | ms/batch 14.70 | loss 0.06044885\n",
      "| Epoch  56 |   200/  658 batches | lr 0.00006 | ms/batch 16.50 | loss 0.06045255\n",
      "| Epoch  56 |   250/  658 batches | lr 0.00006 | ms/batch 16.31 | loss 0.06463630\n",
      "| Epoch  56 |   300/  658 batches | lr 0.00006 | ms/batch 14.93 | loss 0.06372065\n",
      "| Epoch  56 |   350/  658 batches | lr 0.00006 | ms/batch 14.73 | loss 0.06434810\n",
      "| Epoch  56 |   400/  658 batches | lr 0.00006 | ms/batch 16.43 | loss 0.06143783\n",
      "| Epoch  56 |   450/  658 batches | lr 0.00006 | ms/batch 14.76 | loss 0.05883825\n",
      "| Epoch  56 |   500/  658 batches | lr 0.00006 | ms/batch 16.47 | loss 0.06210488\n",
      "| Epoch  56 |   550/  658 batches | lr 0.00006 | ms/batch 16.38 | loss 0.06110372\n",
      "| Epoch  56 |   600/  658 batches | lr 0.00006 | ms/batch 14.80 | loss 0.06361064\n",
      "| Epoch  56 |   650/  658 batches | lr 0.00006 | ms/batch 14.76 | loss 0.06241862\n",
      "\n",
      "Val set: Average loss: 0.06268948\n",
      "\n",
      "| Epoch  57 |    50/  658 batches | lr 0.00006 | ms/batch 14.97 | loss 0.06888724\n",
      "| Epoch  57 |   100/  658 batches | lr 0.00006 | ms/batch 16.35 | loss 0.06448014\n",
      "| Epoch  57 |   150/  658 batches | lr 0.00006 | ms/batch 14.80 | loss 0.06039738\n",
      "| Epoch  57 |   200/  658 batches | lr 0.00006 | ms/batch 16.48 | loss 0.06051631\n",
      "| Epoch  57 |   250/  658 batches | lr 0.00006 | ms/batch 16.39 | loss 0.06445282\n",
      "| Epoch  57 |   300/  658 batches | lr 0.00006 | ms/batch 14.72 | loss 0.06358241\n",
      "| Epoch  57 |   350/  658 batches | lr 0.00006 | ms/batch 14.74 | loss 0.06417474\n",
      "| Epoch  57 |   400/  658 batches | lr 0.00006 | ms/batch 16.38 | loss 0.06117244\n",
      "| Epoch  57 |   450/  658 batches | lr 0.00006 | ms/batch 14.80 | loss 0.05866928\n",
      "| Epoch  57 |   500/  658 batches | lr 0.00006 | ms/batch 16.38 | loss 0.06241305\n",
      "| Epoch  57 |   550/  658 batches | lr 0.00006 | ms/batch 16.52 | loss 0.06104351\n",
      "| Epoch  57 |   600/  658 batches | lr 0.00006 | ms/batch 14.74 | loss 0.06343876\n",
      "| Epoch  57 |   650/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.06219479\n",
      "\n",
      "Val set: Average loss: 0.06261352\n",
      "\n",
      "| Epoch  58 |    50/  658 batches | lr 0.00006 | ms/batch 14.95 | loss 0.06873378\n",
      "| Epoch  58 |   100/  658 batches | lr 0.00006 | ms/batch 16.43 | loss 0.06438967\n",
      "| Epoch  58 |   150/  658 batches | lr 0.00006 | ms/batch 14.99 | loss 0.06021565\n",
      "| Epoch  58 |   200/  658 batches | lr 0.00006 | ms/batch 16.47 | loss 0.06022123\n",
      "| Epoch  58 |   250/  658 batches | lr 0.00006 | ms/batch 16.37 | loss 0.06435538\n",
      "| Epoch  58 |   300/  658 batches | lr 0.00006 | ms/batch 14.74 | loss 0.06354263\n",
      "| Epoch  58 |   350/  658 batches | lr 0.00006 | ms/batch 14.76 | loss 0.06403954\n",
      "| Epoch  58 |   400/  658 batches | lr 0.00006 | ms/batch 16.48 | loss 0.06104194\n",
      "| Epoch  58 |   450/  658 batches | lr 0.00006 | ms/batch 14.74 | loss 0.05861409\n",
      "| Epoch  58 |   500/  658 batches | lr 0.00006 | ms/batch 16.63 | loss 0.06175679\n",
      "| Epoch  58 |   550/  658 batches | lr 0.00006 | ms/batch 16.33 | loss 0.06099885\n",
      "| Epoch  58 |   600/  658 batches | lr 0.00006 | ms/batch 14.72 | loss 0.06352153\n",
      "| Epoch  58 |   650/  658 batches | lr 0.00006 | ms/batch 14.93 | loss 0.06224093\n",
      "\n",
      "Val set: Average loss: 0.06252176\n",
      "\n",
      "| Epoch  59 |    50/  658 batches | lr 0.00006 | ms/batch 15.02 | loss 0.06862135\n",
      "| Epoch  59 |   100/  658 batches | lr 0.00006 | ms/batch 16.66 | loss 0.06430206\n",
      "| Epoch  59 |   150/  658 batches | lr 0.00006 | ms/batch 14.78 | loss 0.06018701\n",
      "| Epoch  59 |   200/  658 batches | lr 0.00006 | ms/batch 16.38 | loss 0.06019178\n",
      "| Epoch  59 |   250/  658 batches | lr 0.00006 | ms/batch 16.39 | loss 0.06424012\n",
      "| Epoch  59 |   300/  658 batches | lr 0.00006 | ms/batch 14.73 | loss 0.06355533\n",
      "| Epoch  59 |   350/  658 batches | lr 0.00006 | ms/batch 14.85 | loss 0.06415922\n",
      "| Epoch  59 |   400/  658 batches | lr 0.00006 | ms/batch 16.67 | loss 0.06088714\n",
      "| Epoch  59 |   450/  658 batches | lr 0.00006 | ms/batch 14.98 | loss 0.05849632\n",
      "| Epoch  59 |   500/  658 batches | lr 0.00006 | ms/batch 16.34 | loss 0.06232286\n",
      "| Epoch  59 |   550/  658 batches | lr 0.00006 | ms/batch 16.62 | loss 0.06105975\n",
      "| Epoch  59 |   600/  658 batches | lr 0.00006 | ms/batch 14.88 | loss 0.06344457\n",
      "| Epoch  59 |   650/  658 batches | lr 0.00006 | ms/batch 14.76 | loss 0.06210683\n",
      "\n",
      "Val set: Average loss: 0.06246340\n",
      "\n",
      "| Epoch  60 |    50/  658 batches | lr 0.00006 | ms/batch 15.19 | loss 0.06858472\n",
      "| Epoch  60 |   100/  658 batches | lr 0.00006 | ms/batch 16.33 | loss 0.06422518\n",
      "| Epoch  60 |   150/  658 batches | lr 0.00006 | ms/batch 14.79 | loss 0.06011295\n",
      "| Epoch  60 |   200/  658 batches | lr 0.00006 | ms/batch 16.48 | loss 0.06003537\n",
      "| Epoch  60 |   250/  658 batches | lr 0.00006 | ms/batch 16.48 | loss 0.06411062\n",
      "| Epoch  60 |   300/  658 batches | lr 0.00006 | ms/batch 14.80 | loss 0.06329453\n",
      "| Epoch  60 |   350/  658 batches | lr 0.00006 | ms/batch 14.74 | loss 0.06375053\n",
      "| Epoch  60 |   400/  658 batches | lr 0.00006 | ms/batch 16.38 | loss 0.06096151\n",
      "| Epoch  60 |   450/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.05840087\n",
      "| Epoch  60 |   500/  658 batches | lr 0.00006 | ms/batch 16.46 | loss 0.06220625\n",
      "| Epoch  60 |   550/  658 batches | lr 0.00006 | ms/batch 16.48 | loss 0.06086363\n",
      "| Epoch  60 |   600/  658 batches | lr 0.00006 | ms/batch 14.80 | loss 0.06329507\n",
      "| Epoch  60 |   650/  658 batches | lr 0.00006 | ms/batch 14.81 | loss 0.06183477\n",
      "\n",
      "Val set: Average loss: 0.06225322\n",
      "\n",
      "| Epoch  61 |    50/  658 batches | lr 0.00006 | ms/batch 15.15 | loss 0.06844299\n",
      "| Epoch  61 |   100/  658 batches | lr 0.00006 | ms/batch 16.37 | loss 0.06412973\n",
      "| Epoch  61 |   150/  658 batches | lr 0.00006 | ms/batch 14.84 | loss 0.06002241\n",
      "| Epoch  61 |   200/  658 batches | lr 0.00006 | ms/batch 16.43 | loss 0.05984877\n",
      "| Epoch  61 |   250/  658 batches | lr 0.00006 | ms/batch 16.43 | loss 0.06399339\n",
      "| Epoch  61 |   300/  658 batches | lr 0.00006 | ms/batch 15.07 | loss 0.06324078\n",
      "| Epoch  61 |   350/  658 batches | lr 0.00006 | ms/batch 14.73 | loss 0.06369093\n",
      "| Epoch  61 |   400/  658 batches | lr 0.00006 | ms/batch 16.32 | loss 0.06097505\n",
      "| Epoch  61 |   450/  658 batches | lr 0.00006 | ms/batch 14.74 | loss 0.05822594\n",
      "| Epoch  61 |   500/  658 batches | lr 0.00006 | ms/batch 16.48 | loss 0.06201661\n",
      "| Epoch  61 |   550/  658 batches | lr 0.00006 | ms/batch 16.37 | loss 0.06073618\n",
      "| Epoch  61 |   600/  658 batches | lr 0.00006 | ms/batch 14.73 | loss 0.06314870\n",
      "| Epoch  61 |   650/  658 batches | lr 0.00006 | ms/batch 14.77 | loss 0.06197422\n",
      "\n",
      "Val set: Average loss: 0.06220047\n",
      "\n",
      "| Epoch  62 |    50/  658 batches | lr 0.00006 | ms/batch 15.09 | loss 0.06833257\n",
      "| Epoch  62 |   100/  658 batches | lr 0.00006 | ms/batch 16.45 | loss 0.06407133\n",
      "| Epoch  62 |   150/  658 batches | lr 0.00006 | ms/batch 14.94 | loss 0.05991633\n",
      "| Epoch  62 |   200/  658 batches | lr 0.00006 | ms/batch 16.58 | loss 0.05974102\n",
      "| Epoch  62 |   250/  658 batches | lr 0.00006 | ms/batch 16.37 | loss 0.06388764\n",
      "| Epoch  62 |   300/  658 batches | lr 0.00006 | ms/batch 14.78 | loss 0.06314915\n",
      "| Epoch  62 |   350/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.06371231\n",
      "| Epoch  62 |   400/  658 batches | lr 0.00006 | ms/batch 16.46 | loss 0.06079326\n",
      "| Epoch  62 |   450/  658 batches | lr 0.00006 | ms/batch 14.84 | loss 0.05809371\n",
      "| Epoch  62 |   500/  658 batches | lr 0.00006 | ms/batch 16.52 | loss 0.06185006\n",
      "| Epoch  62 |   550/  658 batches | lr 0.00006 | ms/batch 16.39 | loss 0.06057439\n",
      "| Epoch  62 |   600/  658 batches | lr 0.00006 | ms/batch 14.74 | loss 0.06306214\n",
      "| Epoch  62 |   650/  658 batches | lr 0.00006 | ms/batch 14.76 | loss 0.06178484\n",
      "\n",
      "Val set: Average loss: 0.06219606\n",
      "\n",
      "| Epoch  63 |    50/  658 batches | lr 0.00006 | ms/batch 15.02 | loss 0.06818074\n",
      "| Epoch  63 |   100/  658 batches | lr 0.00006 | ms/batch 16.33 | loss 0.06402458\n",
      "| Epoch  63 |   150/  658 batches | lr 0.00006 | ms/batch 14.91 | loss 0.05980166\n",
      "| Epoch  63 |   200/  658 batches | lr 0.00006 | ms/batch 16.49 | loss 0.05972624\n",
      "| Epoch  63 |   250/  658 batches | lr 0.00006 | ms/batch 16.41 | loss 0.06389600\n",
      "| Epoch  63 |   300/  658 batches | lr 0.00006 | ms/batch 14.74 | loss 0.06289646\n",
      "| Epoch  63 |   350/  658 batches | lr 0.00006 | ms/batch 14.83 | loss 0.06348329\n",
      "| Epoch  63 |   400/  658 batches | lr 0.00006 | ms/batch 16.37 | loss 0.06066983\n",
      "| Epoch  63 |   450/  658 batches | lr 0.00006 | ms/batch 14.79 | loss 0.05800278\n",
      "| Epoch  63 |   500/  658 batches | lr 0.00006 | ms/batch 16.54 | loss 0.06159478\n",
      "| Epoch  63 |   550/  658 batches | lr 0.00006 | ms/batch 16.43 | loss 0.06071335\n",
      "| Epoch  63 |   600/  658 batches | lr 0.00006 | ms/batch 14.78 | loss 0.06294414\n",
      "| Epoch  63 |   650/  658 batches | lr 0.00006 | ms/batch 14.74 | loss 0.06169116\n",
      "\n",
      "Val set: Average loss: 0.06211857\n",
      "\n",
      "| Epoch  64 |    50/  658 batches | lr 0.00006 | ms/batch 15.04 | loss 0.06816474\n",
      "| Epoch  64 |   100/  658 batches | lr 0.00006 | ms/batch 16.87 | loss 0.06396489\n",
      "| Epoch  64 |   150/  658 batches | lr 0.00006 | ms/batch 14.79 | loss 0.05986149\n",
      "| Epoch  64 |   200/  658 batches | lr 0.00006 | ms/batch 16.48 | loss 0.05955834\n",
      "| Epoch  64 |   250/  658 batches | lr 0.00006 | ms/batch 16.34 | loss 0.06364079\n",
      "| Epoch  64 |   300/  658 batches | lr 0.00006 | ms/batch 14.89 | loss 0.06278148\n",
      "| Epoch  64 |   350/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.06338968\n",
      "| Epoch  64 |   400/  658 batches | lr 0.00006 | ms/batch 16.36 | loss 0.06086764\n",
      "| Epoch  64 |   450/  658 batches | lr 0.00006 | ms/batch 14.79 | loss 0.05794062\n",
      "| Epoch  64 |   500/  658 batches | lr 0.00006 | ms/batch 16.51 | loss 0.06125106\n",
      "| Epoch  64 |   550/  658 batches | lr 0.00006 | ms/batch 16.48 | loss 0.06054730\n",
      "| Epoch  64 |   600/  658 batches | lr 0.00006 | ms/batch 14.84 | loss 0.06278515\n",
      "| Epoch  64 |   650/  658 batches | lr 0.00006 | ms/batch 14.72 | loss 0.06161423\n",
      "\n",
      "Val set: Average loss: 0.06197164\n",
      "\n",
      "| Epoch  65 |    50/  658 batches | lr 0.00006 | ms/batch 15.10 | loss 0.06798836\n",
      "| Epoch  65 |   100/  658 batches | lr 0.00006 | ms/batch 16.38 | loss 0.06398034\n",
      "| Epoch  65 |   150/  658 batches | lr 0.00006 | ms/batch 14.78 | loss 0.05961446\n",
      "| Epoch  65 |   200/  658 batches | lr 0.00006 | ms/batch 16.46 | loss 0.05942835\n",
      "| Epoch  65 |   250/  658 batches | lr 0.00006 | ms/batch 16.57 | loss 0.06348654\n",
      "| Epoch  65 |   300/  658 batches | lr 0.00006 | ms/batch 14.90 | loss 0.06287201\n",
      "| Epoch  65 |   350/  658 batches | lr 0.00006 | ms/batch 14.81 | loss 0.06344497\n",
      "| Epoch  65 |   400/  658 batches | lr 0.00006 | ms/batch 16.40 | loss 0.06060788\n",
      "| Epoch  65 |   450/  658 batches | lr 0.00006 | ms/batch 14.85 | loss 0.05773681\n",
      "| Epoch  65 |   500/  658 batches | lr 0.00006 | ms/batch 16.37 | loss 0.06142055\n",
      "| Epoch  65 |   550/  658 batches | lr 0.00006 | ms/batch 16.39 | loss 0.06056858\n",
      "| Epoch  65 |   600/  658 batches | lr 0.00006 | ms/batch 14.78 | loss 0.06277144\n",
      "| Epoch  65 |   650/  658 batches | lr 0.00006 | ms/batch 14.85 | loss 0.06141134\n",
      "\n",
      "Val set: Average loss: 0.06183635\n",
      "\n",
      "| Epoch  66 |    50/  658 batches | lr 0.00006 | ms/batch 15.04 | loss 0.06773971\n",
      "| Epoch  66 |   100/  658 batches | lr 0.00006 | ms/batch 16.35 | loss 0.06367725\n",
      "| Epoch  66 |   150/  658 batches | lr 0.00006 | ms/batch 14.88 | loss 0.05967451\n",
      "| Epoch  66 |   200/  658 batches | lr 0.00006 | ms/batch 16.49 | loss 0.05946124\n",
      "| Epoch  66 |   250/  658 batches | lr 0.00006 | ms/batch 16.44 | loss 0.06344440\n",
      "| Epoch  66 |   300/  658 batches | lr 0.00006 | ms/batch 15.03 | loss 0.06273005\n",
      "| Epoch  66 |   350/  658 batches | lr 0.00006 | ms/batch 14.81 | loss 0.06335480\n",
      "| Epoch  66 |   400/  658 batches | lr 0.00006 | ms/batch 16.30 | loss 0.06055138\n",
      "| Epoch  66 |   450/  658 batches | lr 0.00006 | ms/batch 14.82 | loss 0.05760596\n",
      "| Epoch  66 |   500/  658 batches | lr 0.00006 | ms/batch 16.41 | loss 0.06111659\n",
      "| Epoch  66 |   550/  658 batches | lr 0.00006 | ms/batch 16.50 | loss 0.06038837\n",
      "| Epoch  66 |   600/  658 batches | lr 0.00006 | ms/batch 14.86 | loss 0.06259843\n",
      "| Epoch  66 |   650/  658 batches | lr 0.00006 | ms/batch 14.72 | loss 0.06146637\n",
      "\n",
      "Val set: Average loss: 0.06191436\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  67 |    50/  658 batches | lr 0.00006 | ms/batch 15.14 | loss 0.06778627\n",
      "| Epoch  67 |   100/  658 batches | lr 0.00006 | ms/batch 16.41 | loss 0.06381087\n",
      "| Epoch  67 |   150/  658 batches | lr 0.00006 | ms/batch 14.84 | loss 0.05946912\n",
      "| Epoch  67 |   200/  658 batches | lr 0.00006 | ms/batch 16.50 | loss 0.05928937\n",
      "| Epoch  67 |   250/  658 batches | lr 0.00006 | ms/batch 16.53 | loss 0.06343311\n",
      "| Epoch  67 |   300/  658 batches | lr 0.00006 | ms/batch 14.85 | loss 0.06268528\n",
      "| Epoch  67 |   350/  658 batches | lr 0.00006 | ms/batch 14.83 | loss 0.06334964\n",
      "| Epoch  67 |   400/  658 batches | lr 0.00006 | ms/batch 16.37 | loss 0.06049133\n",
      "| Epoch  67 |   450/  658 batches | lr 0.00006 | ms/batch 14.83 | loss 0.05761515\n",
      "| Epoch  67 |   500/  658 batches | lr 0.00006 | ms/batch 16.48 | loss 0.06110981\n",
      "| Epoch  67 |   550/  658 batches | lr 0.00006 | ms/batch 16.45 | loss 0.06033315\n",
      "| Epoch  67 |   600/  658 batches | lr 0.00006 | ms/batch 14.82 | loss 0.06273916\n",
      "| Epoch  67 |   650/  658 batches | lr 0.00006 | ms/batch 14.81 | loss 0.06127255\n",
      "\n",
      "Val set: Average loss: 0.06175539\n",
      "\n",
      "| Epoch  68 |    50/  658 batches | lr 0.00006 | ms/batch 15.13 | loss 0.06783431\n",
      "| Epoch  68 |   100/  658 batches | lr 0.00006 | ms/batch 16.34 | loss 0.06374097\n",
      "| Epoch  68 |   150/  658 batches | lr 0.00006 | ms/batch 14.74 | loss 0.05930573\n",
      "| Epoch  68 |   200/  658 batches | lr 0.00006 | ms/batch 16.49 | loss 0.05908734\n",
      "| Epoch  68 |   250/  658 batches | lr 0.00006 | ms/batch 16.38 | loss 0.06326219\n",
      "| Epoch  68 |   300/  658 batches | lr 0.00006 | ms/batch 14.83 | loss 0.06250976\n",
      "| Epoch  68 |   350/  658 batches | lr 0.00006 | ms/batch 14.83 | loss 0.06322880\n",
      "| Epoch  68 |   400/  658 batches | lr 0.00006 | ms/batch 16.34 | loss 0.06041956\n",
      "| Epoch  68 |   450/  658 batches | lr 0.00006 | ms/batch 14.79 | loss 0.05748511\n",
      "| Epoch  68 |   500/  658 batches | lr 0.00006 | ms/batch 16.48 | loss 0.06133651\n",
      "| Epoch  68 |   550/  658 batches | lr 0.00006 | ms/batch 16.43 | loss 0.06009698\n",
      "| Epoch  68 |   600/  658 batches | lr 0.00006 | ms/batch 14.73 | loss 0.06266966\n",
      "| Epoch  68 |   650/  658 batches | lr 0.00006 | ms/batch 14.86 | loss 0.06110380\n",
      "\n",
      "Val set: Average loss: 0.06172975\n",
      "\n",
      "| Epoch  69 |    50/  658 batches | lr 0.00006 | ms/batch 15.07 | loss 0.06752605\n",
      "| Epoch  69 |   100/  658 batches | lr 0.00006 | ms/batch 16.52 | loss 0.06364987\n",
      "| Epoch  69 |   150/  658 batches | lr 0.00006 | ms/batch 14.85 | loss 0.05926788\n",
      "| Epoch  69 |   200/  658 batches | lr 0.00006 | ms/batch 16.58 | loss 0.05903206\n",
      "| Epoch  69 |   250/  658 batches | lr 0.00006 | ms/batch 16.54 | loss 0.06316666\n",
      "| Epoch  69 |   300/  658 batches | lr 0.00006 | ms/batch 14.72 | loss 0.06243011\n",
      "| Epoch  69 |   350/  658 batches | lr 0.00006 | ms/batch 14.74 | loss 0.06304221\n",
      "| Epoch  69 |   400/  658 batches | lr 0.00006 | ms/batch 16.31 | loss 0.06049520\n",
      "| Epoch  69 |   450/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.05735842\n",
      "| Epoch  69 |   500/  658 batches | lr 0.00006 | ms/batch 16.57 | loss 0.06097382\n",
      "| Epoch  69 |   550/  658 batches | lr 0.00006 | ms/batch 16.43 | loss 0.06012124\n",
      "| Epoch  69 |   600/  658 batches | lr 0.00006 | ms/batch 14.84 | loss 0.06245633\n",
      "| Epoch  69 |   650/  658 batches | lr 0.00006 | ms/batch 14.76 | loss 0.06101617\n",
      "\n",
      "Val set: Average loss: 0.06165796\n",
      "\n",
      "| Epoch  70 |    50/  658 batches | lr 0.00006 | ms/batch 15.15 | loss 0.06748102\n",
      "| Epoch  70 |   100/  658 batches | lr 0.00006 | ms/batch 16.32 | loss 0.06354564\n",
      "| Epoch  70 |   150/  658 batches | lr 0.00006 | ms/batch 14.83 | loss 0.05929436\n",
      "| Epoch  70 |   200/  658 batches | lr 0.00006 | ms/batch 16.36 | loss 0.05892605\n",
      "| Epoch  70 |   250/  658 batches | lr 0.00006 | ms/batch 16.29 | loss 0.06306714\n",
      "| Epoch  70 |   300/  658 batches | lr 0.00006 | ms/batch 14.72 | loss 0.06241755\n",
      "| Epoch  70 |   350/  658 batches | lr 0.00006 | ms/batch 14.86 | loss 0.06313153\n",
      "| Epoch  70 |   400/  658 batches | lr 0.00006 | ms/batch 16.48 | loss 0.06025575\n",
      "| Epoch  70 |   450/  658 batches | lr 0.00006 | ms/batch 15.05 | loss 0.05732597\n",
      "| Epoch  70 |   500/  658 batches | lr 0.00006 | ms/batch 16.63 | loss 0.06112790\n",
      "| Epoch  70 |   550/  658 batches | lr 0.00006 | ms/batch 16.61 | loss 0.06014222\n",
      "| Epoch  70 |   600/  658 batches | lr 0.00006 | ms/batch 14.65 | loss 0.06244373\n",
      "| Epoch  70 |   650/  658 batches | lr 0.00006 | ms/batch 14.78 | loss 0.06096099\n",
      "\n",
      "Val set: Average loss: 0.06158793\n",
      "\n",
      "| Epoch  71 |    50/  658 batches | lr 0.00006 | ms/batch 15.05 | loss 0.06718209\n",
      "| Epoch  71 |   100/  658 batches | lr 0.00006 | ms/batch 16.53 | loss 0.06340832\n",
      "| Epoch  71 |   150/  658 batches | lr 0.00006 | ms/batch 14.78 | loss 0.05910242\n",
      "| Epoch  71 |   200/  658 batches | lr 0.00006 | ms/batch 16.59 | loss 0.05890011\n",
      "| Epoch  71 |   250/  658 batches | lr 0.00006 | ms/batch 16.48 | loss 0.06296694\n",
      "| Epoch  71 |   300/  658 batches | lr 0.00006 | ms/batch 14.92 | loss 0.06252919\n",
      "| Epoch  71 |   350/  658 batches | lr 0.00006 | ms/batch 14.82 | loss 0.06361284\n",
      "| Epoch  71 |   400/  658 batches | lr 0.00006 | ms/batch 16.33 | loss 0.06020098\n",
      "| Epoch  71 |   450/  658 batches | lr 0.00006 | ms/batch 14.92 | loss 0.05721759\n",
      "| Epoch  71 |   500/  658 batches | lr 0.00006 | ms/batch 16.54 | loss 0.06066645\n",
      "| Epoch  71 |   550/  658 batches | lr 0.00006 | ms/batch 16.31 | loss 0.06002172\n",
      "| Epoch  71 |   600/  658 batches | lr 0.00006 | ms/batch 14.88 | loss 0.06240142\n",
      "| Epoch  71 |   650/  658 batches | lr 0.00006 | ms/batch 14.84 | loss 0.06072840\n",
      "\n",
      "Val set: Average loss: 0.06140099\n",
      "\n",
      "| Epoch  72 |    50/  658 batches | lr 0.00006 | ms/batch 15.18 | loss 0.06739655\n",
      "| Epoch  72 |   100/  658 batches | lr 0.00006 | ms/batch 16.45 | loss 0.06353196\n",
      "| Epoch  72 |   150/  658 batches | lr 0.00006 | ms/batch 14.83 | loss 0.05903753\n",
      "| Epoch  72 |   200/  658 batches | lr 0.00006 | ms/batch 16.60 | loss 0.05884069\n",
      "| Epoch  72 |   250/  658 batches | lr 0.00006 | ms/batch 16.45 | loss 0.06297838\n",
      "| Epoch  72 |   300/  658 batches | lr 0.00006 | ms/batch 14.72 | loss 0.06260229\n",
      "| Epoch  72 |   350/  658 batches | lr 0.00006 | ms/batch 14.70 | loss 0.06327097\n",
      "| Epoch  72 |   400/  658 batches | lr 0.00006 | ms/batch 16.38 | loss 0.06017311\n",
      "| Epoch  72 |   450/  658 batches | lr 0.00006 | ms/batch 14.87 | loss 0.05706261\n",
      "| Epoch  72 |   500/  658 batches | lr 0.00006 | ms/batch 16.45 | loss 0.06106734\n",
      "| Epoch  72 |   550/  658 batches | lr 0.00006 | ms/batch 16.47 | loss 0.05988347\n",
      "| Epoch  72 |   600/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.06230247\n",
      "| Epoch  72 |   650/  658 batches | lr 0.00006 | ms/batch 14.78 | loss 0.06074003\n",
      "\n",
      "Val set: Average loss: 0.06149881\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  73 |    50/  658 batches | lr 0.00006 | ms/batch 15.01 | loss 0.06734625\n",
      "| Epoch  73 |   100/  658 batches | lr 0.00006 | ms/batch 16.42 | loss 0.06334236\n",
      "| Epoch  73 |   150/  658 batches | lr 0.00006 | ms/batch 14.95 | loss 0.05910310\n",
      "| Epoch  73 |   200/  658 batches | lr 0.00006 | ms/batch 16.45 | loss 0.05862019\n",
      "| Epoch  73 |   250/  658 batches | lr 0.00006 | ms/batch 16.42 | loss 0.06271261\n",
      "| Epoch  73 |   300/  658 batches | lr 0.00006 | ms/batch 14.86 | loss 0.06215330\n",
      "| Epoch  73 |   350/  658 batches | lr 0.00006 | ms/batch 14.84 | loss 0.06279728\n",
      "| Epoch  73 |   400/  658 batches | lr 0.00006 | ms/batch 16.33 | loss 0.06004934\n",
      "| Epoch  73 |   450/  658 batches | lr 0.00006 | ms/batch 14.89 | loss 0.05704873\n",
      "| Epoch  73 |   500/  658 batches | lr 0.00006 | ms/batch 16.57 | loss 0.06061276\n",
      "| Epoch  73 |   550/  658 batches | lr 0.00006 | ms/batch 16.57 | loss 0.05976394\n",
      "| Epoch  73 |   600/  658 batches | lr 0.00006 | ms/batch 14.94 | loss 0.06221528\n",
      "| Epoch  73 |   650/  658 batches | lr 0.00006 | ms/batch 14.99 | loss 0.06061533\n",
      "\n",
      "Val set: Average loss: 0.06121949\n",
      "\n",
      "| Epoch  74 |    50/  658 batches | lr 0.00006 | ms/batch 15.15 | loss 0.06683093\n",
      "| Epoch  74 |   100/  658 batches | lr 0.00006 | ms/batch 16.59 | loss 0.06318540\n",
      "| Epoch  74 |   150/  658 batches | lr 0.00006 | ms/batch 14.76 | loss 0.05884656\n",
      "| Epoch  74 |   200/  658 batches | lr 0.00006 | ms/batch 16.51 | loss 0.05852880\n",
      "| Epoch  74 |   250/  658 batches | lr 0.00006 | ms/batch 16.31 | loss 0.06261527\n",
      "| Epoch  74 |   300/  658 batches | lr 0.00006 | ms/batch 14.78 | loss 0.06203465\n",
      "| Epoch  74 |   350/  658 batches | lr 0.00006 | ms/batch 14.85 | loss 0.06275268\n",
      "| Epoch  74 |   400/  658 batches | lr 0.00006 | ms/batch 16.45 | loss 0.06007265\n",
      "| Epoch  74 |   450/  658 batches | lr 0.00006 | ms/batch 14.90 | loss 0.05700534\n",
      "| Epoch  74 |   500/  658 batches | lr 0.00006 | ms/batch 16.50 | loss 0.06063411\n",
      "| Epoch  74 |   550/  658 batches | lr 0.00006 | ms/batch 16.44 | loss 0.05977669\n",
      "| Epoch  74 |   600/  658 batches | lr 0.00006 | ms/batch 14.79 | loss 0.06213888\n",
      "| Epoch  74 |   650/  658 batches | lr 0.00006 | ms/batch 14.71 | loss 0.06053831\n",
      "\n",
      "Val set: Average loss: 0.06133590\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  75 |    50/  658 batches | lr 0.00006 | ms/batch 15.08 | loss 0.06708102\n",
      "| Epoch  75 |   100/  658 batches | lr 0.00006 | ms/batch 16.36 | loss 0.06330695\n",
      "| Epoch  75 |   150/  658 batches | lr 0.00006 | ms/batch 14.86 | loss 0.05887648\n",
      "| Epoch  75 |   200/  658 batches | lr 0.00006 | ms/batch 16.46 | loss 0.05843747\n",
      "| Epoch  75 |   250/  658 batches | lr 0.00006 | ms/batch 16.79 | loss 0.06251148\n",
      "| Epoch  75 |   300/  658 batches | lr 0.00006 | ms/batch 15.09 | loss 0.06198660\n",
      "| Epoch  75 |   350/  658 batches | lr 0.00006 | ms/batch 14.84 | loss 0.06263856\n",
      "| Epoch  75 |   400/  658 batches | lr 0.00006 | ms/batch 16.45 | loss 0.06021052\n",
      "| Epoch  75 |   450/  658 batches | lr 0.00006 | ms/batch 14.82 | loss 0.05686068\n",
      "| Epoch  75 |   500/  658 batches | lr 0.00006 | ms/batch 16.47 | loss 0.06064622\n",
      "| Epoch  75 |   550/  658 batches | lr 0.00006 | ms/batch 16.38 | loss 0.05973938\n",
      "| Epoch  75 |   600/  658 batches | lr 0.00006 | ms/batch 14.80 | loss 0.06202964\n",
      "| Epoch  75 |   650/  658 batches | lr 0.00006 | ms/batch 14.88 | loss 0.06050503\n",
      "\n",
      "Val set: Average loss: 0.06123001\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  76 |    50/  658 batches | lr 0.00006 | ms/batch 15.06 | loss 0.06704647\n",
      "| Epoch  76 |   100/  658 batches | lr 0.00006 | ms/batch 16.40 | loss 0.06316529\n",
      "| Epoch  76 |   150/  658 batches | lr 0.00006 | ms/batch 14.77 | loss 0.05887609\n",
      "| Epoch  76 |   200/  658 batches | lr 0.00006 | ms/batch 16.36 | loss 0.05840219\n",
      "| Epoch  76 |   250/  658 batches | lr 0.00006 | ms/batch 16.41 | loss 0.06249419\n",
      "| Epoch  76 |   300/  658 batches | lr 0.00006 | ms/batch 14.87 | loss 0.06183144\n",
      "| Epoch  76 |   350/  658 batches | lr 0.00006 | ms/batch 14.77 | loss 0.06265352\n",
      "| Epoch  76 |   400/  658 batches | lr 0.00006 | ms/batch 16.46 | loss 0.05969337\n",
      "| Epoch  76 |   450/  658 batches | lr 0.00006 | ms/batch 14.78 | loss 0.05676604\n",
      "| Epoch  76 |   500/  658 batches | lr 0.00006 | ms/batch 16.73 | loss 0.06046795\n",
      "| Epoch  76 |   550/  658 batches | lr 0.00006 | ms/batch 16.48 | loss 0.05972511\n",
      "| Epoch  76 |   600/  658 batches | lr 0.00006 | ms/batch 14.84 | loss 0.06205130\n",
      "| Epoch  76 |   650/  658 batches | lr 0.00006 | ms/batch 14.82 | loss 0.06038395\n",
      "\n",
      "Val set: Average loss: 0.06113106\n",
      "\n",
      "| Epoch  77 |    50/  658 batches | lr 0.00006 | ms/batch 15.13 | loss 0.06670446\n",
      "| Epoch  77 |   100/  658 batches | lr 0.00006 | ms/batch 16.50 | loss 0.06301713\n",
      "| Epoch  77 |   150/  658 batches | lr 0.00006 | ms/batch 14.84 | loss 0.05873258\n",
      "| Epoch  77 |   200/  658 batches | lr 0.00006 | ms/batch 16.44 | loss 0.05824297\n",
      "| Epoch  77 |   250/  658 batches | lr 0.00006 | ms/batch 16.59 | loss 0.06233347\n",
      "| Epoch  77 |   300/  658 batches | lr 0.00006 | ms/batch 14.98 | loss 0.06169191\n",
      "| Epoch  77 |   350/  658 batches | lr 0.00006 | ms/batch 14.74 | loss 0.06247322\n",
      "| Epoch  77 |   400/  658 batches | lr 0.00006 | ms/batch 16.49 | loss 0.05980293\n",
      "| Epoch  77 |   450/  658 batches | lr 0.00006 | ms/batch 14.85 | loss 0.05664890\n",
      "| Epoch  77 |   500/  658 batches | lr 0.00006 | ms/batch 16.45 | loss 0.06038030\n",
      "| Epoch  77 |   550/  658 batches | lr 0.00006 | ms/batch 16.38 | loss 0.05960144\n",
      "| Epoch  77 |   600/  658 batches | lr 0.00006 | ms/batch 14.76 | loss 0.06187762\n",
      "| Epoch  77 |   650/  658 batches | lr 0.00006 | ms/batch 14.83 | loss 0.06023379\n",
      "\n",
      "Val set: Average loss: 0.06102308\n",
      "\n",
      "| Epoch  78 |    50/  658 batches | lr 0.00006 | ms/batch 15.10 | loss 0.06667504\n",
      "| Epoch  78 |   100/  658 batches | lr 0.00006 | ms/batch 16.37 | loss 0.06296064\n",
      "| Epoch  78 |   150/  658 batches | lr 0.00006 | ms/batch 14.98 | loss 0.05858716\n",
      "| Epoch  78 |   200/  658 batches | lr 0.00006 | ms/batch 16.51 | loss 0.05811393\n",
      "| Epoch  78 |   250/  658 batches | lr 0.00006 | ms/batch 16.51 | loss 0.06230003\n",
      "| Epoch  78 |   300/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.06165217\n",
      "| Epoch  78 |   350/  658 batches | lr 0.00006 | ms/batch 14.90 | loss 0.06240949\n",
      "| Epoch  78 |   400/  658 batches | lr 0.00006 | ms/batch 16.50 | loss 0.05959274\n",
      "| Epoch  78 |   450/  658 batches | lr 0.00006 | ms/batch 14.82 | loss 0.05652099\n",
      "| Epoch  78 |   500/  658 batches | lr 0.00006 | ms/batch 16.30 | loss 0.06012124\n",
      "| Epoch  78 |   550/  658 batches | lr 0.00006 | ms/batch 16.43 | loss 0.05935799\n",
      "| Epoch  78 |   600/  658 batches | lr 0.00006 | ms/batch 14.79 | loss 0.06178296\n",
      "| Epoch  78 |   650/  658 batches | lr 0.00006 | ms/batch 14.77 | loss 0.06006886\n",
      "\n",
      "Val set: Average loss: 0.06104826\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  79 |    50/  658 batches | lr 0.00006 | ms/batch 14.97 | loss 0.06663352\n",
      "| Epoch  79 |   100/  658 batches | lr 0.00006 | ms/batch 16.32 | loss 0.06294987\n",
      "| Epoch  79 |   150/  658 batches | lr 0.00006 | ms/batch 15.00 | loss 0.05844828\n",
      "| Epoch  79 |   200/  658 batches | lr 0.00006 | ms/batch 16.44 | loss 0.05815414\n",
      "| Epoch  79 |   250/  658 batches | lr 0.00006 | ms/batch 16.44 | loss 0.06221040\n",
      "| Epoch  79 |   300/  658 batches | lr 0.00006 | ms/batch 14.86 | loss 0.06157930\n",
      "| Epoch  79 |   350/  658 batches | lr 0.00006 | ms/batch 15.01 | loss 0.06223707\n",
      "| Epoch  79 |   400/  658 batches | lr 0.00006 | ms/batch 16.39 | loss 0.05964248\n",
      "| Epoch  79 |   450/  658 batches | lr 0.00006 | ms/batch 14.98 | loss 0.05640383\n",
      "| Epoch  79 |   500/  658 batches | lr 0.00006 | ms/batch 16.64 | loss 0.06012855\n",
      "| Epoch  79 |   550/  658 batches | lr 0.00006 | ms/batch 16.52 | loss 0.05935403\n",
      "| Epoch  79 |   600/  658 batches | lr 0.00006 | ms/batch 14.84 | loss 0.06181640\n",
      "| Epoch  79 |   650/  658 batches | lr 0.00006 | ms/batch 14.83 | loss 0.06005116\n",
      "\n",
      "Val set: Average loss: 0.06098475\n",
      "\n",
      "| Epoch  80 |    50/  658 batches | lr 0.00006 | ms/batch 15.08 | loss 0.06651909\n",
      "| Epoch  80 |   100/  658 batches | lr 0.00006 | ms/batch 16.47 | loss 0.06285073\n",
      "| Epoch  80 |   150/  658 batches | lr 0.00006 | ms/batch 14.85 | loss 0.05839726\n",
      "| Epoch  80 |   200/  658 batches | lr 0.00006 | ms/batch 16.59 | loss 0.05793177\n",
      "| Epoch  80 |   250/  658 batches | lr 0.00006 | ms/batch 16.46 | loss 0.06210871\n",
      "| Epoch  80 |   300/  658 batches | lr 0.00006 | ms/batch 14.81 | loss 0.06136338\n",
      "| Epoch  80 |   350/  658 batches | lr 0.00006 | ms/batch 14.80 | loss 0.06223930\n",
      "| Epoch  80 |   400/  658 batches | lr 0.00006 | ms/batch 16.81 | loss 0.05948032\n",
      "| Epoch  80 |   450/  658 batches | lr 0.00006 | ms/batch 15.17 | loss 0.05634308\n",
      "| Epoch  80 |   500/  658 batches | lr 0.00006 | ms/batch 16.40 | loss 0.06011594\n",
      "| Epoch  80 |   550/  658 batches | lr 0.00006 | ms/batch 16.62 | loss 0.05929375\n",
      "| Epoch  80 |   600/  658 batches | lr 0.00006 | ms/batch 14.61 | loss 0.06162682\n",
      "| Epoch  80 |   650/  658 batches | lr 0.00006 | ms/batch 14.74 | loss 0.05996739\n",
      "\n",
      "Val set: Average loss: 0.06094196\n",
      "\n",
      "| Epoch  81 |    50/  658 batches | lr 0.00006 | ms/batch 14.98 | loss 0.06623465\n",
      "| Epoch  81 |   100/  658 batches | lr 0.00006 | ms/batch 16.31 | loss 0.06268548\n",
      "| Epoch  81 |   150/  658 batches | lr 0.00006 | ms/batch 14.77 | loss 0.05832345\n",
      "| Epoch  81 |   200/  658 batches | lr 0.00006 | ms/batch 16.42 | loss 0.05787661\n",
      "| Epoch  81 |   250/  658 batches | lr 0.00006 | ms/batch 16.33 | loss 0.06203211\n",
      "| Epoch  81 |   300/  658 batches | lr 0.00006 | ms/batch 14.93 | loss 0.06128809\n",
      "| Epoch  81 |   350/  658 batches | lr 0.00006 | ms/batch 14.71 | loss 0.06208493\n",
      "| Epoch  81 |   400/  658 batches | lr 0.00006 | ms/batch 16.41 | loss 0.05961145\n",
      "| Epoch  81 |   450/  658 batches | lr 0.00006 | ms/batch 14.71 | loss 0.05629642\n",
      "| Epoch  81 |   500/  658 batches | lr 0.00006 | ms/batch 16.37 | loss 0.05993043\n",
      "| Epoch  81 |   550/  658 batches | lr 0.00006 | ms/batch 16.34 | loss 0.05914764\n",
      "| Epoch  81 |   600/  658 batches | lr 0.00006 | ms/batch 14.70 | loss 0.06170791\n",
      "| Epoch  81 |   650/  658 batches | lr 0.00006 | ms/batch 14.69 | loss 0.05981215\n",
      "\n",
      "Val set: Average loss: 0.06082007\n",
      "\n",
      "| Epoch  82 |    50/  658 batches | lr 0.00006 | ms/batch 14.96 | loss 0.06617857\n",
      "| Epoch  82 |   100/  658 batches | lr 0.00006 | ms/batch 16.39 | loss 0.06258645\n",
      "| Epoch  82 |   150/  658 batches | lr 0.00006 | ms/batch 14.78 | loss 0.05816344\n",
      "| Epoch  82 |   200/  658 batches | lr 0.00006 | ms/batch 16.42 | loss 0.05773568\n",
      "| Epoch  82 |   250/  658 batches | lr 0.00006 | ms/batch 16.52 | loss 0.06195239\n",
      "| Epoch  82 |   300/  658 batches | lr 0.00006 | ms/batch 14.71 | loss 0.06131999\n",
      "| Epoch  82 |   350/  658 batches | lr 0.00006 | ms/batch 14.61 | loss 0.06210162\n",
      "| Epoch  82 |   400/  658 batches | lr 0.00006 | ms/batch 16.41 | loss 0.05943675\n",
      "| Epoch  82 |   450/  658 batches | lr 0.00006 | ms/batch 14.79 | loss 0.05626302\n",
      "| Epoch  82 |   500/  658 batches | lr 0.00006 | ms/batch 16.42 | loss 0.05978283\n",
      "| Epoch  82 |   550/  658 batches | lr 0.00006 | ms/batch 16.52 | loss 0.05910423\n",
      "| Epoch  82 |   600/  658 batches | lr 0.00006 | ms/batch 14.72 | loss 0.06167382\n",
      "| Epoch  82 |   650/  658 batches | lr 0.00006 | ms/batch 14.71 | loss 0.05983886\n",
      "\n",
      "Val set: Average loss: 0.06077757\n",
      "\n",
      "| Epoch  83 |    50/  658 batches | lr 0.00006 | ms/batch 14.91 | loss 0.06623228\n",
      "| Epoch  83 |   100/  658 batches | lr 0.00006 | ms/batch 16.32 | loss 0.06264192\n",
      "| Epoch  83 |   150/  658 batches | lr 0.00006 | ms/batch 14.87 | loss 0.05817148\n",
      "| Epoch  83 |   200/  658 batches | lr 0.00006 | ms/batch 16.36 | loss 0.05772891\n",
      "| Epoch  83 |   250/  658 batches | lr 0.00006 | ms/batch 16.38 | loss 0.06175801\n",
      "| Epoch  83 |   300/  658 batches | lr 0.00006 | ms/batch 14.78 | loss 0.06124500\n",
      "| Epoch  83 |   350/  658 batches | lr 0.00006 | ms/batch 14.82 | loss 0.06201019\n",
      "| Epoch  83 |   400/  658 batches | lr 0.00006 | ms/batch 16.26 | loss 0.05940687\n",
      "| Epoch  83 |   450/  658 batches | lr 0.00006 | ms/batch 14.76 | loss 0.05612515\n",
      "| Epoch  83 |   500/  658 batches | lr 0.00006 | ms/batch 16.41 | loss 0.06004112\n",
      "| Epoch  83 |   550/  658 batches | lr 0.00006 | ms/batch 16.42 | loss 0.05915905\n",
      "| Epoch  83 |   600/  658 batches | lr 0.00006 | ms/batch 14.81 | loss 0.06140322\n",
      "| Epoch  83 |   650/  658 batches | lr 0.00006 | ms/batch 14.80 | loss 0.05961819\n",
      "\n",
      "Val set: Average loss: 0.06073178\n",
      "\n",
      "| Epoch  84 |    50/  658 batches | lr 0.00006 | ms/batch 15.07 | loss 0.06605324\n",
      "| Epoch  84 |   100/  658 batches | lr 0.00006 | ms/batch 16.50 | loss 0.06247741\n",
      "| Epoch  84 |   150/  658 batches | lr 0.00006 | ms/batch 14.98 | loss 0.05798111\n",
      "| Epoch  84 |   200/  658 batches | lr 0.00006 | ms/batch 16.34 | loss 0.05765176\n",
      "| Epoch  84 |   250/  658 batches | lr 0.00006 | ms/batch 16.44 | loss 0.06170347\n",
      "| Epoch  84 |   300/  658 batches | lr 0.00006 | ms/batch 14.77 | loss 0.06127841\n",
      "| Epoch  84 |   350/  658 batches | lr 0.00006 | ms/batch 14.74 | loss 0.06184857\n",
      "| Epoch  84 |   400/  658 batches | lr 0.00006 | ms/batch 16.32 | loss 0.05932876\n",
      "| Epoch  84 |   450/  658 batches | lr 0.00006 | ms/batch 14.77 | loss 0.05597340\n",
      "| Epoch  84 |   500/  658 batches | lr 0.00006 | ms/batch 16.39 | loss 0.05999735\n",
      "| Epoch  84 |   550/  658 batches | lr 0.00006 | ms/batch 16.26 | loss 0.05900278\n",
      "| Epoch  84 |   600/  658 batches | lr 0.00006 | ms/batch 14.82 | loss 0.06132434\n",
      "| Epoch  84 |   650/  658 batches | lr 0.00006 | ms/batch 14.72 | loss 0.05949560\n",
      "\n",
      "Val set: Average loss: 0.06073086\n",
      "\n",
      "| Epoch  85 |    50/  658 batches | lr 0.00006 | ms/batch 15.15 | loss 0.06607560\n",
      "| Epoch  85 |   100/  658 batches | lr 0.00006 | ms/batch 16.36 | loss 0.06249323\n",
      "| Epoch  85 |   150/  658 batches | lr 0.00006 | ms/batch 14.76 | loss 0.05790843\n",
      "| Epoch  85 |   200/  658 batches | lr 0.00006 | ms/batch 16.43 | loss 0.05751798\n",
      "| Epoch  85 |   250/  658 batches | lr 0.00006 | ms/batch 16.33 | loss 0.06160927\n",
      "| Epoch  85 |   300/  658 batches | lr 0.00006 | ms/batch 14.77 | loss 0.06100757\n",
      "| Epoch  85 |   350/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.06188377\n",
      "| Epoch  85 |   400/  658 batches | lr 0.00006 | ms/batch 16.32 | loss 0.05937483\n",
      "| Epoch  85 |   450/  658 batches | lr 0.00006 | ms/batch 14.91 | loss 0.05604034\n",
      "| Epoch  85 |   500/  658 batches | lr 0.00006 | ms/batch 16.38 | loss 0.05965486\n",
      "| Epoch  85 |   550/  658 batches | lr 0.00006 | ms/batch 16.85 | loss 0.05885509\n",
      "| Epoch  85 |   600/  658 batches | lr 0.00006 | ms/batch 14.95 | loss 0.06137120\n",
      "| Epoch  85 |   650/  658 batches | lr 0.00006 | ms/batch 14.65 | loss 0.05936887\n",
      "\n",
      "Val set: Average loss: 0.06065778\n",
      "\n",
      "| Epoch  86 |    50/  658 batches | lr 0.00006 | ms/batch 15.94 | loss 0.06599119\n",
      "| Epoch  86 |   100/  658 batches | lr 0.00006 | ms/batch 16.60 | loss 0.06238983\n",
      "| Epoch  86 |   150/  658 batches | lr 0.00006 | ms/batch 15.79 | loss 0.05792550\n",
      "| Epoch  86 |   200/  658 batches | lr 0.00006 | ms/batch 16.61 | loss 0.05741762\n",
      "| Epoch  86 |   250/  658 batches | lr 0.00006 | ms/batch 16.52 | loss 0.06150542\n",
      "| Epoch  86 |   300/  658 batches | lr 0.00006 | ms/batch 15.42 | loss 0.06107120\n",
      "| Epoch  86 |   350/  658 batches | lr 0.00006 | ms/batch 14.98 | loss 0.06189716\n",
      "| Epoch  86 |   400/  658 batches | lr 0.00006 | ms/batch 16.37 | loss 0.05921388\n",
      "| Epoch  86 |   450/  658 batches | lr 0.00006 | ms/batch 15.00 | loss 0.05592480\n",
      "| Epoch  86 |   500/  658 batches | lr 0.00006 | ms/batch 16.43 | loss 0.05956826\n",
      "| Epoch  86 |   550/  658 batches | lr 0.00006 | ms/batch 16.61 | loss 0.05883164\n",
      "| Epoch  86 |   600/  658 batches | lr 0.00006 | ms/batch 14.61 | loss 0.06125156\n",
      "| Epoch  86 |   650/  658 batches | lr 0.00006 | ms/batch 14.67 | loss 0.05933006\n",
      "\n",
      "Val set: Average loss: 0.06061133\n",
      "\n",
      "| Epoch  87 |    50/  658 batches | lr 0.00006 | ms/batch 14.82 | loss 0.06556819\n",
      "| Epoch  87 |   100/  658 batches | lr 0.00006 | ms/batch 16.38 | loss 0.06229573\n",
      "| Epoch  87 |   150/  658 batches | lr 0.00006 | ms/batch 14.68 | loss 0.05782925\n",
      "| Epoch  87 |   200/  658 batches | lr 0.00006 | ms/batch 16.35 | loss 0.05738022\n",
      "| Epoch  87 |   250/  658 batches | lr 0.00006 | ms/batch 16.45 | loss 0.06141974\n",
      "| Epoch  87 |   300/  658 batches | lr 0.00006 | ms/batch 14.59 | loss 0.06091194\n",
      "| Epoch  87 |   350/  658 batches | lr 0.00006 | ms/batch 14.70 | loss 0.06167915\n",
      "| Epoch  87 |   400/  658 batches | lr 0.00006 | ms/batch 16.28 | loss 0.05944914\n",
      "| Epoch  87 |   450/  658 batches | lr 0.00006 | ms/batch 14.73 | loss 0.05570627\n",
      "| Epoch  87 |   500/  658 batches | lr 0.00006 | ms/batch 16.39 | loss 0.05965685\n",
      "| Epoch  87 |   550/  658 batches | lr 0.00006 | ms/batch 16.42 | loss 0.05878728\n",
      "| Epoch  87 |   600/  658 batches | lr 0.00006 | ms/batch 14.71 | loss 0.06125994\n",
      "| Epoch  87 |   650/  658 batches | lr 0.00006 | ms/batch 14.69 | loss 0.05934128\n",
      "\n",
      "Val set: Average loss: 0.06051454\n",
      "\n",
      "| Epoch  88 |    50/  658 batches | lr 0.00006 | ms/batch 15.00 | loss 0.06559870\n",
      "| Epoch  88 |   100/  658 batches | lr 0.00006 | ms/batch 16.28 | loss 0.06228435\n",
      "| Epoch  88 |   150/  658 batches | lr 0.00006 | ms/batch 14.83 | loss 0.05772620\n",
      "| Epoch  88 |   200/  658 batches | lr 0.00006 | ms/batch 16.47 | loss 0.05720183\n",
      "| Epoch  88 |   250/  658 batches | lr 0.00006 | ms/batch 16.33 | loss 0.06137603\n",
      "| Epoch  88 |   300/  658 batches | lr 0.00006 | ms/batch 14.93 | loss 0.06089003\n",
      "| Epoch  88 |   350/  658 batches | lr 0.00006 | ms/batch 14.64 | loss 0.06171164\n",
      "| Epoch  88 |   400/  658 batches | lr 0.00006 | ms/batch 16.33 | loss 0.05916271\n",
      "| Epoch  88 |   450/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.05570592\n",
      "| Epoch  88 |   500/  658 batches | lr 0.00006 | ms/batch 16.40 | loss 0.05953253\n",
      "| Epoch  88 |   550/  658 batches | lr 0.00006 | ms/batch 16.41 | loss 0.05874706\n",
      "| Epoch  88 |   600/  658 batches | lr 0.00006 | ms/batch 14.69 | loss 0.06117621\n",
      "| Epoch  88 |   650/  658 batches | lr 0.00006 | ms/batch 14.66 | loss 0.05925921\n",
      "\n",
      "Val set: Average loss: 0.06057480\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  89 |    50/  658 batches | lr 0.00006 | ms/batch 15.02 | loss 0.06544427\n",
      "| Epoch  89 |   100/  658 batches | lr 0.00006 | ms/batch 16.35 | loss 0.06205930\n",
      "| Epoch  89 |   150/  658 batches | lr 0.00006 | ms/batch 14.77 | loss 0.05763098\n",
      "| Epoch  89 |   200/  658 batches | lr 0.00006 | ms/batch 16.32 | loss 0.05726442\n",
      "| Epoch  89 |   250/  658 batches | lr 0.00006 | ms/batch 16.46 | loss 0.06121395\n",
      "| Epoch  89 |   300/  658 batches | lr 0.00006 | ms/batch 14.66 | loss 0.06068858\n",
      "| Epoch  89 |   350/  658 batches | lr 0.00006 | ms/batch 14.77 | loss 0.06170230\n",
      "| Epoch  89 |   400/  658 batches | lr 0.00006 | ms/batch 16.27 | loss 0.05899727\n",
      "| Epoch  89 |   450/  658 batches | lr 0.00006 | ms/batch 14.90 | loss 0.05561617\n",
      "| Epoch  89 |   500/  658 batches | lr 0.00006 | ms/batch 16.46 | loss 0.05956009\n",
      "| Epoch  89 |   550/  658 batches | lr 0.00006 | ms/batch 16.42 | loss 0.05865240\n",
      "| Epoch  89 |   600/  658 batches | lr 0.00006 | ms/batch 14.70 | loss 0.06100335\n",
      "| Epoch  89 |   650/  658 batches | lr 0.00006 | ms/batch 14.69 | loss 0.05916968\n",
      "\n",
      "Val set: Average loss: 0.06058285\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch  90 |    50/  658 batches | lr 0.00006 | ms/batch 15.00 | loss 0.06538019\n",
      "| Epoch  90 |   100/  658 batches | lr 0.00006 | ms/batch 16.33 | loss 0.06209472\n",
      "| Epoch  90 |   150/  658 batches | lr 0.00006 | ms/batch 14.80 | loss 0.05759282\n",
      "| Epoch  90 |   200/  658 batches | lr 0.00006 | ms/batch 16.34 | loss 0.05725870\n",
      "| Epoch  90 |   250/  658 batches | lr 0.00006 | ms/batch 16.54 | loss 0.06110442\n",
      "| Epoch  90 |   300/  658 batches | lr 0.00006 | ms/batch 15.21 | loss 0.06076953\n",
      "| Epoch  90 |   350/  658 batches | lr 0.00006 | ms/batch 14.74 | loss 0.06180099\n",
      "| Epoch  90 |   400/  658 batches | lr 0.00006 | ms/batch 16.43 | loss 0.05925176\n",
      "| Epoch  90 |   450/  658 batches | lr 0.00006 | ms/batch 14.78 | loss 0.05562495\n",
      "| Epoch  90 |   500/  658 batches | lr 0.00006 | ms/batch 16.46 | loss 0.06013723\n",
      "| Epoch  90 |   550/  658 batches | lr 0.00006 | ms/batch 16.48 | loss 0.05876121\n",
      "| Epoch  90 |   600/  658 batches | lr 0.00006 | ms/batch 14.87 | loss 0.06092478\n",
      "| Epoch  90 |   650/  658 batches | lr 0.00006 | ms/batch 14.74 | loss 0.05918115\n",
      "\n",
      "Val set: Average loss: 0.06047316\n",
      "\n",
      "| Epoch  91 |    50/  658 batches | lr 0.00006 | ms/batch 15.03 | loss 0.06527066\n",
      "| Epoch  91 |   100/  658 batches | lr 0.00006 | ms/batch 16.45 | loss 0.06208401\n",
      "| Epoch  91 |   150/  658 batches | lr 0.00006 | ms/batch 14.86 | loss 0.05752987\n",
      "| Epoch  91 |   200/  658 batches | lr 0.00006 | ms/batch 16.33 | loss 0.05701367\n",
      "| Epoch  91 |   250/  658 batches | lr 0.00006 | ms/batch 16.42 | loss 0.06103226\n",
      "| Epoch  91 |   300/  658 batches | lr 0.00006 | ms/batch 14.78 | loss 0.06062664\n",
      "| Epoch  91 |   350/  658 batches | lr 0.00006 | ms/batch 14.78 | loss 0.06165234\n",
      "| Epoch  91 |   400/  658 batches | lr 0.00006 | ms/batch 16.38 | loss 0.05918243\n",
      "| Epoch  91 |   450/  658 batches | lr 0.00006 | ms/batch 14.84 | loss 0.05539441\n",
      "| Epoch  91 |   500/  658 batches | lr 0.00006 | ms/batch 16.39 | loss 0.05948908\n",
      "| Epoch  91 |   550/  658 batches | lr 0.00006 | ms/batch 16.37 | loss 0.05841458\n",
      "| Epoch  91 |   600/  658 batches | lr 0.00006 | ms/batch 14.79 | loss 0.06088194\n",
      "| Epoch  91 |   650/  658 batches | lr 0.00006 | ms/batch 14.82 | loss 0.05905794\n",
      "\n",
      "Val set: Average loss: 0.06047113\n",
      "\n",
      "| Epoch  92 |    50/  658 batches | lr 0.00006 | ms/batch 15.04 | loss 0.06517902\n",
      "| Epoch  92 |   100/  658 batches | lr 0.00006 | ms/batch 16.42 | loss 0.06190341\n",
      "| Epoch  92 |   150/  658 batches | lr 0.00006 | ms/batch 14.89 | loss 0.05751948\n",
      "| Epoch  92 |   200/  658 batches | lr 0.00006 | ms/batch 16.60 | loss 0.05694602\n",
      "| Epoch  92 |   250/  658 batches | lr 0.00006 | ms/batch 16.58 | loss 0.06100784\n",
      "| Epoch  92 |   300/  658 batches | lr 0.00006 | ms/batch 14.71 | loss 0.06049400\n",
      "| Epoch  92 |   350/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.06155033\n",
      "| Epoch  92 |   400/  658 batches | lr 0.00006 | ms/batch 16.43 | loss 0.05892078\n",
      "| Epoch  92 |   450/  658 batches | lr 0.00006 | ms/batch 14.70 | loss 0.05529659\n",
      "| Epoch  92 |   500/  658 batches | lr 0.00006 | ms/batch 16.49 | loss 0.05955274\n",
      "| Epoch  92 |   550/  658 batches | lr 0.00006 | ms/batch 16.50 | loss 0.05845709\n",
      "| Epoch  92 |   600/  658 batches | lr 0.00006 | ms/batch 14.71 | loss 0.06073196\n",
      "| Epoch  92 |   650/  658 batches | lr 0.00006 | ms/batch 14.86 | loss 0.05881541\n",
      "\n",
      "Val set: Average loss: 0.06031424\n",
      "\n",
      "| Epoch  93 |    50/  658 batches | lr 0.00006 | ms/batch 14.96 | loss 0.06512528\n",
      "| Epoch  93 |   100/  658 batches | lr 0.00006 | ms/batch 16.54 | loss 0.06184913\n",
      "| Epoch  93 |   150/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.05739288\n",
      "| Epoch  93 |   200/  658 batches | lr 0.00006 | ms/batch 16.56 | loss 0.05684839\n",
      "| Epoch  93 |   250/  658 batches | lr 0.00006 | ms/batch 16.55 | loss 0.06092896\n",
      "| Epoch  93 |   300/  658 batches | lr 0.00006 | ms/batch 14.87 | loss 0.06054585\n",
      "| Epoch  93 |   350/  658 batches | lr 0.00006 | ms/batch 14.85 | loss 0.06158897\n",
      "| Epoch  93 |   400/  658 batches | lr 0.00006 | ms/batch 16.35 | loss 0.05887570\n",
      "| Epoch  93 |   450/  658 batches | lr 0.00006 | ms/batch 15.11 | loss 0.05514489\n",
      "| Epoch  93 |   500/  658 batches | lr 0.00006 | ms/batch 16.41 | loss 0.05911536\n",
      "| Epoch  93 |   550/  658 batches | lr 0.00006 | ms/batch 16.49 | loss 0.05826652\n",
      "| Epoch  93 |   600/  658 batches | lr 0.00006 | ms/batch 14.93 | loss 0.06075960\n",
      "| Epoch  93 |   650/  658 batches | lr 0.00006 | ms/batch 14.90 | loss 0.05872903\n",
      "\n",
      "Val set: Average loss: 0.06028048\n",
      "\n",
      "| Epoch  94 |    50/  658 batches | lr 0.00006 | ms/batch 15.12 | loss 0.06491428\n",
      "| Epoch  94 |   100/  658 batches | lr 0.00006 | ms/batch 16.50 | loss 0.06171910\n",
      "| Epoch  94 |   150/  658 batches | lr 0.00006 | ms/batch 14.85 | loss 0.05734958\n",
      "| Epoch  94 |   200/  658 batches | lr 0.00006 | ms/batch 16.44 | loss 0.05681865\n",
      "| Epoch  94 |   250/  658 batches | lr 0.00006 | ms/batch 16.64 | loss 0.06084054\n",
      "| Epoch  94 |   300/  658 batches | lr 0.00006 | ms/batch 14.95 | loss 0.06046226\n",
      "| Epoch  94 |   350/  658 batches | lr 0.00006 | ms/batch 14.93 | loss 0.06130811\n",
      "| Epoch  94 |   400/  658 batches | lr 0.00006 | ms/batch 16.56 | loss 0.05897575\n",
      "| Epoch  94 |   450/  658 batches | lr 0.00006 | ms/batch 15.04 | loss 0.05506356\n",
      "| Epoch  94 |   500/  658 batches | lr 0.00006 | ms/batch 16.66 | loss 0.05939465\n",
      "| Epoch  94 |   550/  658 batches | lr 0.00006 | ms/batch 16.53 | loss 0.05819524\n",
      "| Epoch  94 |   600/  658 batches | lr 0.00006 | ms/batch 14.90 | loss 0.06048182\n",
      "| Epoch  94 |   650/  658 batches | lr 0.00006 | ms/batch 14.98 | loss 0.05878516\n",
      "\n",
      "Val set: Average loss: 0.06027070\n",
      "\n",
      "| Epoch  95 |    50/  658 batches | lr 0.00006 | ms/batch 15.25 | loss 0.06493807\n",
      "| Epoch  95 |   100/  658 batches | lr 0.00006 | ms/batch 16.46 | loss 0.06173796\n",
      "| Epoch  95 |   150/  658 batches | lr 0.00006 | ms/batch 14.91 | loss 0.05720846\n",
      "| Epoch  95 |   200/  658 batches | lr 0.00006 | ms/batch 16.55 | loss 0.05674391\n",
      "| Epoch  95 |   250/  658 batches | lr 0.00006 | ms/batch 16.57 | loss 0.06089085\n",
      "| Epoch  95 |   300/  658 batches | lr 0.00006 | ms/batch 14.87 | loss 0.06052470\n",
      "| Epoch  95 |   350/  658 batches | lr 0.00006 | ms/batch 15.00 | loss 0.06130390\n",
      "| Epoch  95 |   400/  658 batches | lr 0.00006 | ms/batch 16.54 | loss 0.05909014\n",
      "| Epoch  95 |   450/  658 batches | lr 0.00006 | ms/batch 14.94 | loss 0.05497910\n",
      "| Epoch  95 |   500/  658 batches | lr 0.00006 | ms/batch 16.55 | loss 0.05942678\n",
      "| Epoch  95 |   550/  658 batches | lr 0.00006 | ms/batch 16.75 | loss 0.05818910\n",
      "| Epoch  95 |   600/  658 batches | lr 0.00006 | ms/batch 14.88 | loss 0.06065059\n",
      "| Epoch  95 |   650/  658 batches | lr 0.00006 | ms/batch 14.86 | loss 0.05867773\n",
      "\n",
      "Val set: Average loss: 0.06021595\n",
      "\n",
      "| Epoch  96 |    50/  658 batches | lr 0.00006 | ms/batch 16.42 | loss 0.06486024\n",
      "| Epoch  96 |   100/  658 batches | lr 0.00006 | ms/batch 17.98 | loss 0.06160008\n",
      "| Epoch  96 |   150/  658 batches | lr 0.00006 | ms/batch 15.46 | loss 0.05717290\n",
      "| Epoch  96 |   200/  658 batches | lr 0.00006 | ms/batch 17.01 | loss 0.05667879\n",
      "| Epoch  96 |   250/  658 batches | lr 0.00006 | ms/batch 17.23 | loss 0.06073060\n",
      "| Epoch  96 |   300/  658 batches | lr 0.00006 | ms/batch 19.29 | loss 0.06039467\n",
      "| Epoch  96 |   350/  658 batches | lr 0.00006 | ms/batch 14.91 | loss 0.06111679\n",
      "| Epoch  96 |   400/  658 batches | lr 0.00006 | ms/batch 16.45 | loss 0.05891970\n",
      "| Epoch  96 |   450/  658 batches | lr 0.00006 | ms/batch 14.93 | loss 0.05487943\n",
      "| Epoch  96 |   500/  658 batches | lr 0.00006 | ms/batch 16.49 | loss 0.05917492\n",
      "| Epoch  96 |   550/  658 batches | lr 0.00006 | ms/batch 16.59 | loss 0.05808994\n",
      "| Epoch  96 |   600/  658 batches | lr 0.00006 | ms/batch 15.02 | loss 0.06063676\n",
      "| Epoch  96 |   650/  658 batches | lr 0.00006 | ms/batch 14.98 | loss 0.05850153\n",
      "\n",
      "Val set: Average loss: 0.06029399\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  97 |    50/  658 batches | lr 0.00006 | ms/batch 15.21 | loss 0.06469453\n",
      "| Epoch  97 |   100/  658 batches | lr 0.00006 | ms/batch 16.58 | loss 0.06149657\n",
      "| Epoch  97 |   150/  658 batches | lr 0.00006 | ms/batch 14.99 | loss 0.05713821\n",
      "| Epoch  97 |   200/  658 batches | lr 0.00006 | ms/batch 16.66 | loss 0.05665876\n",
      "| Epoch  97 |   250/  658 batches | lr 0.00006 | ms/batch 16.65 | loss 0.06063318\n",
      "| Epoch  97 |   300/  658 batches | lr 0.00006 | ms/batch 14.89 | loss 0.06062550\n",
      "| Epoch  97 |   350/  658 batches | lr 0.00006 | ms/batch 14.94 | loss 0.06109212\n",
      "| Epoch  97 |   400/  658 batches | lr 0.00006 | ms/batch 16.60 | loss 0.05881446\n",
      "| Epoch  97 |   450/  658 batches | lr 0.00006 | ms/batch 15.01 | loss 0.05483142\n",
      "| Epoch  97 |   500/  658 batches | lr 0.00006 | ms/batch 16.62 | loss 0.05927577\n",
      "| Epoch  97 |   550/  658 batches | lr 0.00006 | ms/batch 16.75 | loss 0.05800911\n",
      "| Epoch  97 |   600/  658 batches | lr 0.00006 | ms/batch 14.85 | loss 0.06048039\n",
      "| Epoch  97 |   650/  658 batches | lr 0.00006 | ms/batch 14.91 | loss 0.05845323\n",
      "\n",
      "Val set: Average loss: 0.06016265\n",
      "\n",
      "| Epoch  98 |    50/  658 batches | lr 0.00006 | ms/batch 15.13 | loss 0.06465358\n",
      "| Epoch  98 |   100/  658 batches | lr 0.00006 | ms/batch 16.59 | loss 0.06144483\n",
      "| Epoch  98 |   150/  658 batches | lr 0.00006 | ms/batch 14.99 | loss 0.05701317\n",
      "| Epoch  98 |   200/  658 batches | lr 0.00006 | ms/batch 16.59 | loss 0.05648610\n",
      "| Epoch  98 |   250/  658 batches | lr 0.00006 | ms/batch 16.50 | loss 0.06058266\n",
      "| Epoch  98 |   300/  658 batches | lr 0.00006 | ms/batch 14.79 | loss 0.06069959\n",
      "| Epoch  98 |   350/  658 batches | lr 0.00006 | ms/batch 14.84 | loss 0.06112018\n",
      "| Epoch  98 |   400/  658 batches | lr 0.00006 | ms/batch 16.33 | loss 0.05875717\n",
      "| Epoch  98 |   450/  658 batches | lr 0.00006 | ms/batch 14.89 | loss 0.05472511\n",
      "| Epoch  98 |   500/  658 batches | lr 0.00006 | ms/batch 16.47 | loss 0.05908770\n",
      "| Epoch  98 |   550/  658 batches | lr 0.00006 | ms/batch 16.43 | loss 0.05790088\n",
      "| Epoch  98 |   600/  658 batches | lr 0.00006 | ms/batch 14.85 | loss 0.06044067\n",
      "| Epoch  98 |   650/  658 batches | lr 0.00006 | ms/batch 14.91 | loss 0.05849820\n",
      "\n",
      "Val set: Average loss: 0.06025642\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch  99 |    50/  658 batches | lr 0.00006 | ms/batch 15.23 | loss 0.06454340\n",
      "| Epoch  99 |   100/  658 batches | lr 0.00006 | ms/batch 16.51 | loss 0.06148018\n",
      "| Epoch  99 |   150/  658 batches | lr 0.00006 | ms/batch 14.90 | loss 0.05702722\n",
      "| Epoch  99 |   200/  658 batches | lr 0.00006 | ms/batch 16.60 | loss 0.05646908\n",
      "| Epoch  99 |   250/  658 batches | lr 0.00006 | ms/batch 16.64 | loss 0.06048632\n",
      "| Epoch  99 |   300/  658 batches | lr 0.00006 | ms/batch 14.94 | loss 0.06070621\n",
      "| Epoch  99 |   350/  658 batches | lr 0.00006 | ms/batch 14.82 | loss 0.06104519\n",
      "| Epoch  99 |   400/  658 batches | lr 0.00006 | ms/batch 16.58 | loss 0.05874353\n",
      "| Epoch  99 |   450/  658 batches | lr 0.00006 | ms/batch 14.94 | loss 0.05464102\n",
      "| Epoch  99 |   500/  658 batches | lr 0.00006 | ms/batch 16.66 | loss 0.05916527\n",
      "| Epoch  99 |   550/  658 batches | lr 0.00006 | ms/batch 16.72 | loss 0.05793323\n",
      "| Epoch  99 |   600/  658 batches | lr 0.00006 | ms/batch 15.22 | loss 0.06043561\n",
      "| Epoch  99 |   650/  658 batches | lr 0.00006 | ms/batch 14.86 | loss 0.05830082\n",
      "\n",
      "Val set: Average loss: 0.06031194\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch 100 |    50/  658 batches | lr 0.00006 | ms/batch 15.11 | loss 0.06451452\n",
      "| Epoch 100 |   100/  658 batches | lr 0.00006 | ms/batch 16.58 | loss 0.06138263\n",
      "| Epoch 100 |   150/  658 batches | lr 0.00006 | ms/batch 14.86 | loss 0.05694373\n",
      "| Epoch 100 |   200/  658 batches | lr 0.00006 | ms/batch 16.57 | loss 0.05641227\n",
      "| Epoch 100 |   250/  658 batches | lr 0.00006 | ms/batch 16.49 | loss 0.06041846\n",
      "| Epoch 100 |   300/  658 batches | lr 0.00006 | ms/batch 14.90 | loss 0.06061710\n",
      "| Epoch 100 |   350/  658 batches | lr 0.00006 | ms/batch 15.11 | loss 0.06106790\n",
      "| Epoch 100 |   400/  658 batches | lr 0.00006 | ms/batch 16.88 | loss 0.05877201\n",
      "| Epoch 100 |   450/  658 batches | lr 0.00006 | ms/batch 14.89 | loss 0.05462306\n",
      "| Epoch 100 |   500/  658 batches | lr 0.00006 | ms/batch 16.45 | loss 0.05911970\n",
      "| Epoch 100 |   550/  658 batches | lr 0.00006 | ms/batch 16.48 | loss 0.05788213\n",
      "| Epoch 100 |   600/  658 batches | lr 0.00006 | ms/batch 14.68 | loss 0.06038645\n",
      "| Epoch 100 |   650/  658 batches | lr 0.00006 | ms/batch 14.79 | loss 0.05826117\n",
      "\n",
      "Val set: Average loss: 0.06019111\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch 101 |    50/  658 batches | lr 0.00006 | ms/batch 15.18 | loss 0.06440754\n",
      "| Epoch 101 |   100/  658 batches | lr 0.00006 | ms/batch 16.46 | loss 0.06136790\n",
      "| Epoch 101 |   150/  658 batches | lr 0.00006 | ms/batch 14.84 | loss 0.05678666\n",
      "| Epoch 101 |   200/  658 batches | lr 0.00006 | ms/batch 16.51 | loss 0.05634455\n",
      "| Epoch 101 |   250/  658 batches | lr 0.00006 | ms/batch 16.50 | loss 0.06035490\n",
      "| Epoch 101 |   300/  658 batches | lr 0.00006 | ms/batch 14.84 | loss 0.06036518\n",
      "| Epoch 101 |   350/  658 batches | lr 0.00006 | ms/batch 14.90 | loss 0.06086399\n",
      "| Epoch 101 |   400/  658 batches | lr 0.00006 | ms/batch 18.37 | loss 0.05894358\n",
      "| Epoch 101 |   450/  658 batches | lr 0.00006 | ms/batch 15.31 | loss 0.05463787\n",
      "| Epoch 101 |   500/  658 batches | lr 0.00006 | ms/batch 16.96 | loss 0.05884868\n",
      "| Epoch 101 |   550/  658 batches | lr 0.00006 | ms/batch 20.24 | loss 0.05765773\n",
      "| Epoch 101 |   600/  658 batches | lr 0.00006 | ms/batch 15.28 | loss 0.06036383\n",
      "| Epoch 101 |   650/  658 batches | lr 0.00006 | ms/batch 14.85 | loss 0.05824438\n",
      "\n",
      "Val set: Average loss: 0.06014932\n",
      "\n",
      "| Epoch 102 |    50/  658 batches | lr 0.00006 | ms/batch 15.08 | loss 0.06429107\n",
      "| Epoch 102 |   100/  658 batches | lr 0.00006 | ms/batch 16.60 | loss 0.06124252\n",
      "| Epoch 102 |   150/  658 batches | lr 0.00006 | ms/batch 14.79 | loss 0.05678109\n",
      "| Epoch 102 |   200/  658 batches | lr 0.00006 | ms/batch 17.29 | loss 0.05634456\n",
      "| Epoch 102 |   250/  658 batches | lr 0.00006 | ms/batch 16.85 | loss 0.06023337\n",
      "| Epoch 102 |   300/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.06049875\n",
      "| Epoch 102 |   350/  658 batches | lr 0.00006 | ms/batch 14.73 | loss 0.06086178\n",
      "| Epoch 102 |   400/  658 batches | lr 0.00006 | ms/batch 16.49 | loss 0.05867338\n",
      "| Epoch 102 |   450/  658 batches | lr 0.00006 | ms/batch 14.85 | loss 0.05448123\n",
      "| Epoch 102 |   500/  658 batches | lr 0.00006 | ms/batch 16.65 | loss 0.05855987\n",
      "| Epoch 102 |   550/  658 batches | lr 0.00006 | ms/batch 16.58 | loss 0.05750216\n",
      "| Epoch 102 |   600/  658 batches | lr 0.00006 | ms/batch 15.02 | loss 0.06024374\n",
      "| Epoch 102 |   650/  658 batches | lr 0.00006 | ms/batch 16.62 | loss 0.05811270\n",
      "\n",
      "Val set: Average loss: 0.06008808\n",
      "\n",
      "| Epoch 103 |    50/  658 batches | lr 0.00006 | ms/batch 15.85 | loss 0.06419706\n",
      "| Epoch 103 |   100/  658 batches | lr 0.00006 | ms/batch 17.29 | loss 0.06111843\n",
      "| Epoch 103 |   150/  658 batches | lr 0.00006 | ms/batch 15.05 | loss 0.05673791\n",
      "| Epoch 103 |   200/  658 batches | lr 0.00006 | ms/batch 16.35 | loss 0.05634696\n",
      "| Epoch 103 |   250/  658 batches | lr 0.00006 | ms/batch 16.38 | loss 0.06014077\n",
      "| Epoch 103 |   300/  658 batches | lr 0.00006 | ms/batch 14.76 | loss 0.06040143\n",
      "| Epoch 103 |   350/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.06081355\n",
      "| Epoch 103 |   400/  658 batches | lr 0.00006 | ms/batch 16.62 | loss 0.05845245\n",
      "| Epoch 103 |   450/  658 batches | lr 0.00006 | ms/batch 15.22 | loss 0.05438642\n",
      "| Epoch 103 |   500/  658 batches | lr 0.00006 | ms/batch 16.56 | loss 0.05878084\n",
      "| Epoch 103 |   550/  658 batches | lr 0.00006 | ms/batch 16.37 | loss 0.05755232\n",
      "| Epoch 103 |   600/  658 batches | lr 0.00006 | ms/batch 14.65 | loss 0.06020211\n",
      "| Epoch 103 |   650/  658 batches | lr 0.00006 | ms/batch 14.76 | loss 0.05802511\n",
      "\n",
      "Val set: Average loss: 0.05997038\n",
      "\n",
      "| Epoch 104 |    50/  658 batches | lr 0.00006 | ms/batch 15.79 | loss 0.06407707\n",
      "| Epoch 104 |   100/  658 batches | lr 0.00006 | ms/batch 16.96 | loss 0.06101431\n",
      "| Epoch 104 |   150/  658 batches | lr 0.00006 | ms/batch 15.71 | loss 0.05671519\n",
      "| Epoch 104 |   200/  658 batches | lr 0.00006 | ms/batch 17.20 | loss 0.05634746\n",
      "| Epoch 104 |   250/  658 batches | lr 0.00006 | ms/batch 17.59 | loss 0.06010718\n",
      "| Epoch 104 |   300/  658 batches | lr 0.00006 | ms/batch 15.12 | loss 0.06036523\n",
      "| Epoch 104 |   350/  658 batches | lr 0.00006 | ms/batch 14.71 | loss 0.06064337\n",
      "| Epoch 104 |   400/  658 batches | lr 0.00006 | ms/batch 18.80 | loss 0.05854647\n",
      "| Epoch 104 |   450/  658 batches | lr 0.00006 | ms/batch 14.81 | loss 0.05439790\n",
      "| Epoch 104 |   500/  658 batches | lr 0.00006 | ms/batch 16.37 | loss 0.05927263\n",
      "| Epoch 104 |   550/  658 batches | lr 0.00006 | ms/batch 16.34 | loss 0.05754804\n",
      "| Epoch 104 |   600/  658 batches | lr 0.00006 | ms/batch 14.80 | loss 0.06015240\n",
      "| Epoch 104 |   650/  658 batches | lr 0.00006 | ms/batch 15.33 | loss 0.05800386\n",
      "\n",
      "Val set: Average loss: 0.05988615\n",
      "\n",
      "| Epoch 105 |    50/  658 batches | lr 0.00006 | ms/batch 14.97 | loss 0.06401653\n",
      "| Epoch 105 |   100/  658 batches | lr 0.00006 | ms/batch 16.32 | loss 0.06103975\n",
      "| Epoch 105 |   150/  658 batches | lr 0.00006 | ms/batch 14.67 | loss 0.05671229\n",
      "| Epoch 105 |   200/  658 batches | lr 0.00006 | ms/batch 16.54 | loss 0.05624982\n",
      "| Epoch 105 |   250/  658 batches | lr 0.00006 | ms/batch 17.45 | loss 0.05997838\n",
      "| Epoch 105 |   300/  658 batches | lr 0.00006 | ms/batch 14.83 | loss 0.06042127\n",
      "| Epoch 105 |   350/  658 batches | lr 0.00006 | ms/batch 15.22 | loss 0.06072697\n",
      "| Epoch 105 |   400/  658 batches | lr 0.00006 | ms/batch 16.33 | loss 0.05849726\n",
      "| Epoch 105 |   450/  658 batches | lr 0.00006 | ms/batch 14.87 | loss 0.05431447\n",
      "| Epoch 105 |   500/  658 batches | lr 0.00006 | ms/batch 16.39 | loss 0.05932035\n",
      "| Epoch 105 |   550/  658 batches | lr 0.00006 | ms/batch 16.39 | loss 0.05747725\n",
      "| Epoch 105 |   600/  658 batches | lr 0.00006 | ms/batch 14.69 | loss 0.06001018\n",
      "| Epoch 105 |   650/  658 batches | lr 0.00006 | ms/batch 14.85 | loss 0.05800379\n",
      "\n",
      "Val set: Average loss: 0.05978846\n",
      "\n",
      "| Epoch 106 |    50/  658 batches | lr 0.00006 | ms/batch 14.95 | loss 0.06409626\n",
      "| Epoch 106 |   100/  658 batches | lr 0.00006 | ms/batch 16.31 | loss 0.06096801\n",
      "| Epoch 106 |   150/  658 batches | lr 0.00006 | ms/batch 14.84 | loss 0.05676539\n",
      "| Epoch 106 |   200/  658 batches | lr 0.00006 | ms/batch 16.38 | loss 0.05631607\n",
      "| Epoch 106 |   250/  658 batches | lr 0.00006 | ms/batch 16.46 | loss 0.05980815\n",
      "| Epoch 106 |   300/  658 batches | lr 0.00006 | ms/batch 14.70 | loss 0.06041020\n",
      "| Epoch 106 |   350/  658 batches | lr 0.00006 | ms/batch 14.67 | loss 0.06065513\n",
      "| Epoch 106 |   400/  658 batches | lr 0.00006 | ms/batch 16.44 | loss 0.05832316\n",
      "| Epoch 106 |   450/  658 batches | lr 0.00006 | ms/batch 14.72 | loss 0.05427999\n",
      "| Epoch 106 |   500/  658 batches | lr 0.00006 | ms/batch 16.47 | loss 0.05919422\n",
      "| Epoch 106 |   550/  658 batches | lr 0.00006 | ms/batch 16.39 | loss 0.05744167\n",
      "| Epoch 106 |   600/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.05995849\n",
      "| Epoch 106 |   650/  658 batches | lr 0.00006 | ms/batch 15.02 | loss 0.05790789\n",
      "\n",
      "Val set: Average loss: 0.05962491\n",
      "\n",
      "| Epoch 107 |    50/  658 batches | lr 0.00006 | ms/batch 16.78 | loss 0.06396407\n",
      "| Epoch 107 |   100/  658 batches | lr 0.00006 | ms/batch 18.15 | loss 0.06111823\n",
      "| Epoch 107 |   150/  658 batches | lr 0.00006 | ms/batch 15.76 | loss 0.05663470\n",
      "| Epoch 107 |   200/  658 batches | lr 0.00006 | ms/batch 17.93 | loss 0.05611269\n",
      "| Epoch 107 |   250/  658 batches | lr 0.00006 | ms/batch 19.56 | loss 0.05983895\n",
      "| Epoch 107 |   300/  658 batches | lr 0.00006 | ms/batch 16.25 | loss 0.06031045\n",
      "| Epoch 107 |   350/  658 batches | lr 0.00006 | ms/batch 15.80 | loss 0.06064973\n",
      "| Epoch 107 |   400/  658 batches | lr 0.00006 | ms/batch 16.80 | loss 0.05819052\n",
      "| Epoch 107 |   450/  658 batches | lr 0.00006 | ms/batch 15.61 | loss 0.05421729\n",
      "| Epoch 107 |   500/  658 batches | lr 0.00006 | ms/batch 18.63 | loss 0.05883781\n",
      "| Epoch 107 |   550/  658 batches | lr 0.00006 | ms/batch 21.06 | loss 0.05733955\n",
      "| Epoch 107 |   600/  658 batches | lr 0.00006 | ms/batch 19.48 | loss 0.06001498\n",
      "| Epoch 107 |   650/  658 batches | lr 0.00006 | ms/batch 15.96 | loss 0.05771557\n",
      "\n",
      "Val set: Average loss: 0.05974681\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 108 |    50/  658 batches | lr 0.00006 | ms/batch 15.70 | loss 0.06373499\n",
      "| Epoch 108 |   100/  658 batches | lr 0.00006 | ms/batch 16.41 | loss 0.06086274\n",
      "| Epoch 108 |   150/  658 batches | lr 0.00006 | ms/batch 14.56 | loss 0.05657100\n",
      "| Epoch 108 |   200/  658 batches | lr 0.00006 | ms/batch 16.07 | loss 0.05612116\n",
      "| Epoch 108 |   250/  658 batches | lr 0.00006 | ms/batch 16.12 | loss 0.05971833\n",
      "| Epoch 108 |   300/  658 batches | lr 0.00006 | ms/batch 14.56 | loss 0.06012559\n",
      "| Epoch 108 |   350/  658 batches | lr 0.00006 | ms/batch 14.52 | loss 0.06059220\n",
      "| Epoch 108 |   400/  658 batches | lr 0.00006 | ms/batch 16.27 | loss 0.05838459\n",
      "| Epoch 108 |   450/  658 batches | lr 0.00006 | ms/batch 14.53 | loss 0.05410978\n",
      "| Epoch 108 |   500/  658 batches | lr 0.00006 | ms/batch 16.76 | loss 0.05905961\n",
      "| Epoch 108 |   550/  658 batches | lr 0.00006 | ms/batch 16.05 | loss 0.05732162\n",
      "| Epoch 108 |   600/  658 batches | lr 0.00006 | ms/batch 14.92 | loss 0.05997566\n",
      "| Epoch 108 |   650/  658 batches | lr 0.00006 | ms/batch 14.54 | loss 0.05781748\n",
      "\n",
      "Val set: Average loss: 0.05955811\n",
      "\n",
      "| Epoch 109 |    50/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.06378376\n",
      "| Epoch 109 |   100/  658 batches | lr 0.00006 | ms/batch 16.24 | loss 0.06088572\n",
      "| Epoch 109 |   150/  658 batches | lr 0.00006 | ms/batch 14.71 | loss 0.05651557\n",
      "| Epoch 109 |   200/  658 batches | lr 0.00006 | ms/batch 16.71 | loss 0.05606720\n",
      "| Epoch 109 |   250/  658 batches | lr 0.00006 | ms/batch 16.30 | loss 0.05960713\n",
      "| Epoch 109 |   300/  658 batches | lr 0.00006 | ms/batch 14.77 | loss 0.06022646\n",
      "| Epoch 109 |   350/  658 batches | lr 0.00006 | ms/batch 15.15 | loss 0.06059476\n",
      "| Epoch 109 |   400/  658 batches | lr 0.00006 | ms/batch 16.34 | loss 0.05827295\n",
      "| Epoch 109 |   450/  658 batches | lr 0.00006 | ms/batch 14.55 | loss 0.05403675\n",
      "| Epoch 109 |   500/  658 batches | lr 0.00006 | ms/batch 17.26 | loss 0.05903231\n",
      "| Epoch 109 |   550/  658 batches | lr 0.00006 | ms/batch 17.20 | loss 0.05721861\n",
      "| Epoch 109 |   600/  658 batches | lr 0.00006 | ms/batch 14.59 | loss 0.05988762\n",
      "| Epoch 109 |   650/  658 batches | lr 0.00006 | ms/batch 14.70 | loss 0.05774781\n",
      "\n",
      "Val set: Average loss: 0.05955598\n",
      "\n",
      "| Epoch 110 |    50/  658 batches | lr 0.00006 | ms/batch 14.85 | loss 0.06372396\n",
      "| Epoch 110 |   100/  658 batches | lr 0.00006 | ms/batch 16.10 | loss 0.06073927\n",
      "| Epoch 110 |   150/  658 batches | lr 0.00006 | ms/batch 14.61 | loss 0.05641885\n",
      "| Epoch 110 |   200/  658 batches | lr 0.00006 | ms/batch 16.34 | loss 0.05592740\n",
      "| Epoch 110 |   250/  658 batches | lr 0.00006 | ms/batch 16.79 | loss 0.05957353\n",
      "| Epoch 110 |   300/  658 batches | lr 0.00006 | ms/batch 14.48 | loss 0.06011138\n",
      "| Epoch 110 |   350/  658 batches | lr 0.00006 | ms/batch 14.73 | loss 0.06049553\n",
      "| Epoch 110 |   400/  658 batches | lr 0.00006 | ms/batch 16.11 | loss 0.05818296\n",
      "| Epoch 110 |   450/  658 batches | lr 0.00006 | ms/batch 14.57 | loss 0.05398384\n",
      "| Epoch 110 |   500/  658 batches | lr 0.00006 | ms/batch 16.14 | loss 0.05907671\n",
      "| Epoch 110 |   550/  658 batches | lr 0.00006 | ms/batch 16.08 | loss 0.05718299\n",
      "| Epoch 110 |   600/  658 batches | lr 0.00006 | ms/batch 14.44 | loss 0.05986819\n",
      "| Epoch 110 |   650/  658 batches | lr 0.00006 | ms/batch 14.48 | loss 0.05772653\n",
      "\n",
      "Val set: Average loss: 0.05943998\n",
      "\n",
      "| Epoch 111 |    50/  658 batches | lr 0.00006 | ms/batch 14.78 | loss 0.06408512\n",
      "| Epoch 111 |   100/  658 batches | lr 0.00006 | ms/batch 16.03 | loss 0.06092335\n",
      "| Epoch 111 |   150/  658 batches | lr 0.00006 | ms/batch 14.53 | loss 0.05646818\n",
      "| Epoch 111 |   200/  658 batches | lr 0.00006 | ms/batch 16.25 | loss 0.05599032\n",
      "| Epoch 111 |   250/  658 batches | lr 0.00006 | ms/batch 16.44 | loss 0.05948601\n",
      "| Epoch 111 |   300/  658 batches | lr 0.00006 | ms/batch 14.42 | loss 0.05995943\n",
      "| Epoch 111 |   350/  658 batches | lr 0.00006 | ms/batch 14.49 | loss 0.06049349\n",
      "| Epoch 111 |   400/  658 batches | lr 0.00006 | ms/batch 16.23 | loss 0.05790579\n",
      "| Epoch 111 |   450/  658 batches | lr 0.00006 | ms/batch 14.55 | loss 0.05399406\n",
      "| Epoch 111 |   500/  658 batches | lr 0.00006 | ms/batch 16.09 | loss 0.05894278\n",
      "| Epoch 111 |   550/  658 batches | lr 0.00006 | ms/batch 16.12 | loss 0.05705138\n",
      "| Epoch 111 |   600/  658 batches | lr 0.00006 | ms/batch 14.50 | loss 0.05983207\n",
      "| Epoch 111 |   650/  658 batches | lr 0.00006 | ms/batch 14.44 | loss 0.05774424\n",
      "\n",
      "Val set: Average loss: 0.05951578\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 112 |    50/  658 batches | lr 0.00006 | ms/batch 14.72 | loss 0.06397892\n",
      "| Epoch 112 |   100/  658 batches | lr 0.00006 | ms/batch 16.03 | loss 0.06093133\n",
      "| Epoch 112 |   150/  658 batches | lr 0.00006 | ms/batch 14.55 | loss 0.05631829\n",
      "| Epoch 112 |   200/  658 batches | lr 0.00006 | ms/batch 16.11 | loss 0.05579653\n",
      "| Epoch 112 |   250/  658 batches | lr 0.00006 | ms/batch 16.17 | loss 0.05949872\n",
      "| Epoch 112 |   300/  658 batches | lr 0.00006 | ms/batch 14.44 | loss 0.05994051\n",
      "| Epoch 112 |   350/  658 batches | lr 0.00006 | ms/batch 14.50 | loss 0.06053544\n",
      "| Epoch 112 |   400/  658 batches | lr 0.00006 | ms/batch 16.08 | loss 0.05782277\n",
      "| Epoch 112 |   450/  658 batches | lr 0.00006 | ms/batch 14.56 | loss 0.05393660\n",
      "| Epoch 112 |   500/  658 batches | lr 0.00006 | ms/batch 16.22 | loss 0.05890594\n",
      "| Epoch 112 |   550/  658 batches | lr 0.00006 | ms/batch 16.11 | loss 0.05708752\n",
      "| Epoch 112 |   600/  658 batches | lr 0.00006 | ms/batch 14.44 | loss 0.05974027\n",
      "| Epoch 112 |   650/  658 batches | lr 0.00006 | ms/batch 14.48 | loss 0.05774971\n",
      "\n",
      "Val set: Average loss: 0.05936826\n",
      "\n",
      "| Epoch 113 |    50/  658 batches | lr 0.00006 | ms/batch 14.81 | loss 0.06421764\n",
      "| Epoch 113 |   100/  658 batches | lr 0.00006 | ms/batch 16.09 | loss 0.06085713\n",
      "| Epoch 113 |   150/  658 batches | lr 0.00006 | ms/batch 14.57 | loss 0.05609018\n",
      "| Epoch 113 |   200/  658 batches | lr 0.00006 | ms/batch 16.18 | loss 0.05571992\n",
      "| Epoch 113 |   250/  658 batches | lr 0.00006 | ms/batch 16.14 | loss 0.05947301\n",
      "| Epoch 113 |   300/  658 batches | lr 0.00006 | ms/batch 14.41 | loss 0.05996812\n",
      "| Epoch 113 |   350/  658 batches | lr 0.00006 | ms/batch 14.44 | loss 0.06047526\n",
      "| Epoch 113 |   400/  658 batches | lr 0.00006 | ms/batch 16.11 | loss 0.05777260\n",
      "| Epoch 113 |   450/  658 batches | lr 0.00006 | ms/batch 14.61 | loss 0.05391673\n",
      "| Epoch 113 |   500/  658 batches | lr 0.00006 | ms/batch 16.15 | loss 0.05887577\n",
      "| Epoch 113 |   550/  658 batches | lr 0.00006 | ms/batch 16.11 | loss 0.05717566\n",
      "| Epoch 113 |   600/  658 batches | lr 0.00006 | ms/batch 14.54 | loss 0.05974597\n",
      "| Epoch 113 |   650/  658 batches | lr 0.00006 | ms/batch 14.42 | loss 0.05759466\n",
      "\n",
      "Val set: Average loss: 0.05930206\n",
      "\n",
      "| Epoch 114 |    50/  658 batches | lr 0.00006 | ms/batch 14.83 | loss 0.06384723\n",
      "| Epoch 114 |   100/  658 batches | lr 0.00006 | ms/batch 16.17 | loss 0.06068493\n",
      "| Epoch 114 |   150/  658 batches | lr 0.00006 | ms/batch 14.50 | loss 0.05617285\n",
      "| Epoch 114 |   200/  658 batches | lr 0.00006 | ms/batch 16.07 | loss 0.05563370\n",
      "| Epoch 114 |   250/  658 batches | lr 0.00006 | ms/batch 16.18 | loss 0.05935806\n",
      "| Epoch 114 |   300/  658 batches | lr 0.00006 | ms/batch 14.52 | loss 0.05994109\n",
      "| Epoch 114 |   350/  658 batches | lr 0.00006 | ms/batch 14.48 | loss 0.06063354\n",
      "| Epoch 114 |   400/  658 batches | lr 0.00006 | ms/batch 16.08 | loss 0.05786883\n",
      "| Epoch 114 |   450/  658 batches | lr 0.00006 | ms/batch 14.55 | loss 0.05388030\n",
      "| Epoch 114 |   500/  658 batches | lr 0.00006 | ms/batch 16.12 | loss 0.05881454\n",
      "| Epoch 114 |   550/  658 batches | lr 0.00006 | ms/batch 16.08 | loss 0.05685688\n",
      "| Epoch 114 |   600/  658 batches | lr 0.00006 | ms/batch 14.47 | loss 0.05973160\n",
      "| Epoch 114 |   650/  658 batches | lr 0.00006 | ms/batch 14.47 | loss 0.05758527\n",
      "\n",
      "Val set: Average loss: 0.05930450\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 115 |    50/  658 batches | lr 0.00006 | ms/batch 14.76 | loss 0.06378519\n",
      "| Epoch 115 |   100/  658 batches | lr 0.00006 | ms/batch 16.16 | loss 0.06056410\n",
      "| Epoch 115 |   150/  658 batches | lr 0.00006 | ms/batch 14.53 | loss 0.05616673\n",
      "| Epoch 115 |   200/  658 batches | lr 0.00006 | ms/batch 16.17 | loss 0.05559787\n",
      "| Epoch 115 |   250/  658 batches | lr 0.00006 | ms/batch 16.02 | loss 0.05943917\n",
      "| Epoch 115 |   300/  658 batches | lr 0.00006 | ms/batch 14.47 | loss 0.05969124\n",
      "| Epoch 115 |   350/  658 batches | lr 0.00006 | ms/batch 14.50 | loss 0.06065402\n",
      "| Epoch 115 |   400/  658 batches | lr 0.00006 | ms/batch 16.05 | loss 0.05795278\n",
      "| Epoch 115 |   450/  658 batches | lr 0.00006 | ms/batch 14.86 | loss 0.05377420\n",
      "| Epoch 115 |   500/  658 batches | lr 0.00006 | ms/batch 16.62 | loss 0.05864780\n",
      "| Epoch 115 |   550/  658 batches | lr 0.00006 | ms/batch 16.49 | loss 0.05689052\n",
      "| Epoch 115 |   600/  658 batches | lr 0.00006 | ms/batch 15.41 | loss 0.05950399\n",
      "| Epoch 115 |   650/  658 batches | lr 0.00006 | ms/batch 15.19 | loss 0.05765822\n",
      "\n",
      "Val set: Average loss: 0.05925712\n",
      "\n",
      "| Epoch 116 |    50/  658 batches | lr 0.00006 | ms/batch 17.43 | loss 0.06362702\n",
      "| Epoch 116 |   100/  658 batches | lr 0.00006 | ms/batch 17.31 | loss 0.06060508\n",
      "| Epoch 116 |   150/  658 batches | lr 0.00006 | ms/batch 16.16 | loss 0.05603020\n",
      "| Epoch 116 |   200/  658 batches | lr 0.00006 | ms/batch 16.93 | loss 0.05561212\n",
      "| Epoch 116 |   250/  658 batches | lr 0.00006 | ms/batch 16.80 | loss 0.05920873\n",
      "| Epoch 116 |   300/  658 batches | lr 0.00006 | ms/batch 14.87 | loss 0.05963130\n",
      "| Epoch 116 |   350/  658 batches | lr 0.00006 | ms/batch 14.65 | loss 0.06057539\n",
      "| Epoch 116 |   400/  658 batches | lr 0.00006 | ms/batch 17.87 | loss 0.05795361\n",
      "| Epoch 116 |   450/  658 batches | lr 0.00006 | ms/batch 15.88 | loss 0.05371183\n",
      "| Epoch 116 |   500/  658 batches | lr 0.00006 | ms/batch 18.96 | loss 0.05862615\n",
      "| Epoch 116 |   550/  658 batches | lr 0.00006 | ms/batch 17.35 | loss 0.05689139\n",
      "| Epoch 116 |   600/  658 batches | lr 0.00006 | ms/batch 15.72 | loss 0.05949006\n",
      "| Epoch 116 |   650/  658 batches | lr 0.00006 | ms/batch 17.77 | loss 0.05750922\n",
      "\n",
      "Val set: Average loss: 0.05922793\n",
      "\n",
      "| Epoch 117 |    50/  658 batches | lr 0.00006 | ms/batch 17.98 | loss 0.06342780\n",
      "| Epoch 117 |   100/  658 batches | lr 0.00006 | ms/batch 21.97 | loss 0.06054352\n",
      "| Epoch 117 |   150/  658 batches | lr 0.00006 | ms/batch 19.38 | loss 0.05597680\n",
      "| Epoch 117 |   200/  658 batches | lr 0.00006 | ms/batch 19.18 | loss 0.05553944\n",
      "| Epoch 117 |   250/  658 batches | lr 0.00006 | ms/batch 20.75 | loss 0.05914988\n",
      "| Epoch 117 |   300/  658 batches | lr 0.00006 | ms/batch 18.09 | loss 0.05969222\n",
      "| Epoch 117 |   350/  658 batches | lr 0.00006 | ms/batch 19.09 | loss 0.06042995\n",
      "| Epoch 117 |   400/  658 batches | lr 0.00006 | ms/batch 21.89 | loss 0.05785145\n",
      "| Epoch 117 |   450/  658 batches | lr 0.00006 | ms/batch 18.31 | loss 0.05404668\n",
      "| Epoch 117 |   500/  658 batches | lr 0.00006 | ms/batch 19.78 | loss 0.05829699\n",
      "| Epoch 117 |   550/  658 batches | lr 0.00006 | ms/batch 19.72 | loss 0.05685382\n",
      "| Epoch 117 |   600/  658 batches | lr 0.00006 | ms/batch 17.00 | loss 0.05954677\n",
      "| Epoch 117 |   650/  658 batches | lr 0.00006 | ms/batch 19.45 | loss 0.05746925\n",
      "\n",
      "Val set: Average loss: 0.05915092\n",
      "\n",
      "| Epoch 118 |    50/  658 batches | lr 0.00006 | ms/batch 15.42 | loss 0.06334994\n",
      "| Epoch 118 |   100/  658 batches | lr 0.00006 | ms/batch 18.17 | loss 0.06037076\n",
      "| Epoch 118 |   150/  658 batches | lr 0.00006 | ms/batch 16.54 | loss 0.05592755\n",
      "| Epoch 118 |   200/  658 batches | lr 0.00006 | ms/batch 20.05 | loss 0.05543309\n",
      "| Epoch 118 |   250/  658 batches | lr 0.00006 | ms/batch 22.10 | loss 0.05908865\n",
      "| Epoch 118 |   300/  658 batches | lr 0.00006 | ms/batch 18.24 | loss 0.05958614\n",
      "| Epoch 118 |   350/  658 batches | lr 0.00006 | ms/batch 17.66 | loss 0.06031038\n",
      "| Epoch 118 |   400/  658 batches | lr 0.00006 | ms/batch 19.54 | loss 0.05772041\n",
      "| Epoch 118 |   450/  658 batches | lr 0.00006 | ms/batch 17.96 | loss 0.05392401\n",
      "| Epoch 118 |   500/  658 batches | lr 0.00006 | ms/batch 18.57 | loss 0.05819423\n",
      "| Epoch 118 |   550/  658 batches | lr 0.00006 | ms/batch 20.41 | loss 0.05677012\n",
      "| Epoch 118 |   600/  658 batches | lr 0.00006 | ms/batch 17.13 | loss 0.05957262\n",
      "| Epoch 118 |   650/  658 batches | lr 0.00006 | ms/batch 18.98 | loss 0.05733503\n",
      "\n",
      "Val set: Average loss: 0.05902866\n",
      "\n",
      "| Epoch 119 |    50/  658 batches | lr 0.00006 | ms/batch 23.38 | loss 0.06351721\n",
      "| Epoch 119 |   100/  658 batches | lr 0.00006 | ms/batch 22.52 | loss 0.06025428\n",
      "| Epoch 119 |   150/  658 batches | lr 0.00006 | ms/batch 18.92 | loss 0.05590598\n",
      "| Epoch 119 |   200/  658 batches | lr 0.00006 | ms/batch 19.94 | loss 0.05541012\n",
      "| Epoch 119 |   250/  658 batches | lr 0.00006 | ms/batch 20.10 | loss 0.05903514\n",
      "| Epoch 119 |   300/  658 batches | lr 0.00006 | ms/batch 20.72 | loss 0.05970122\n",
      "| Epoch 119 |   350/  658 batches | lr 0.00006 | ms/batch 18.19 | loss 0.06036543\n",
      "| Epoch 119 |   400/  658 batches | lr 0.00006 | ms/batch 20.24 | loss 0.05768176\n",
      "| Epoch 119 |   450/  658 batches | lr 0.00006 | ms/batch 19.68 | loss 0.05375295\n",
      "| Epoch 119 |   500/  658 batches | lr 0.00006 | ms/batch 20.30 | loss 0.05790457\n",
      "| Epoch 119 |   550/  658 batches | lr 0.00006 | ms/batch 19.40 | loss 0.05661376\n",
      "| Epoch 119 |   600/  658 batches | lr 0.00006 | ms/batch 18.39 | loss 0.05939213\n",
      "| Epoch 119 |   650/  658 batches | lr 0.00006 | ms/batch 18.36 | loss 0.05749286\n",
      "\n",
      "Val set: Average loss: 0.05909457\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 120 |    50/  658 batches | lr 0.00006 | ms/batch 19.08 | loss 0.06317251\n",
      "| Epoch 120 |   100/  658 batches | lr 0.00006 | ms/batch 20.33 | loss 0.06018920\n",
      "| Epoch 120 |   150/  658 batches | lr 0.00006 | ms/batch 18.78 | loss 0.05582911\n",
      "| Epoch 120 |   200/  658 batches | lr 0.00006 | ms/batch 19.74 | loss 0.05539172\n",
      "| Epoch 120 |   250/  658 batches | lr 0.00006 | ms/batch 21.68 | loss 0.05898215\n",
      "| Epoch 120 |   300/  658 batches | lr 0.00006 | ms/batch 17.38 | loss 0.05965630\n",
      "| Epoch 120 |   350/  658 batches | lr 0.00006 | ms/batch 14.94 | loss 0.06014731\n",
      "| Epoch 120 |   400/  658 batches | lr 0.00006 | ms/batch 17.80 | loss 0.05766248\n",
      "| Epoch 120 |   450/  658 batches | lr 0.00006 | ms/batch 16.67 | loss 0.05377071\n",
      "| Epoch 120 |   500/  658 batches | lr 0.00006 | ms/batch 16.81 | loss 0.05787736\n",
      "| Epoch 120 |   550/  658 batches | lr 0.00006 | ms/batch 16.77 | loss 0.05668971\n",
      "| Epoch 120 |   600/  658 batches | lr 0.00006 | ms/batch 14.62 | loss 0.05935987\n",
      "| Epoch 120 |   650/  658 batches | lr 0.00006 | ms/batch 14.84 | loss 0.05732061\n",
      "\n",
      "Val set: Average loss: 0.05901124\n",
      "\n",
      "| Epoch 121 |    50/  658 batches | lr 0.00006 | ms/batch 17.12 | loss 0.06336680\n",
      "| Epoch 121 |   100/  658 batches | lr 0.00006 | ms/batch 18.61 | loss 0.06026950\n",
      "| Epoch 121 |   150/  658 batches | lr 0.00006 | ms/batch 14.91 | loss 0.05576786\n",
      "| Epoch 121 |   200/  658 batches | lr 0.00006 | ms/batch 16.39 | loss 0.05527917\n",
      "| Epoch 121 |   250/  658 batches | lr 0.00006 | ms/batch 16.28 | loss 0.05892897\n",
      "| Epoch 121 |   300/  658 batches | lr 0.00006 | ms/batch 14.89 | loss 0.05962903\n",
      "| Epoch 121 |   350/  658 batches | lr 0.00006 | ms/batch 14.59 | loss 0.06001893\n",
      "| Epoch 121 |   400/  658 batches | lr 0.00006 | ms/batch 16.47 | loss 0.05750727\n",
      "| Epoch 121 |   450/  658 batches | lr 0.00006 | ms/batch 15.36 | loss 0.05358515\n",
      "| Epoch 121 |   500/  658 batches | lr 0.00006 | ms/batch 18.00 | loss 0.05854481\n",
      "| Epoch 121 |   550/  658 batches | lr 0.00006 | ms/batch 16.62 | loss 0.05657745\n",
      "| Epoch 121 |   600/  658 batches | lr 0.00006 | ms/batch 15.08 | loss 0.05908948\n",
      "| Epoch 121 |   650/  658 batches | lr 0.00006 | ms/batch 14.95 | loss 0.05711572\n",
      "\n",
      "Val set: Average loss: 0.05899900\n",
      "\n",
      "| Epoch 122 |    50/  658 batches | lr 0.00006 | ms/batch 17.28 | loss 0.06296339\n",
      "| Epoch 122 |   100/  658 batches | lr 0.00006 | ms/batch 16.46 | loss 0.06017057\n",
      "| Epoch 122 |   150/  658 batches | lr 0.00006 | ms/batch 15.37 | loss 0.05579751\n",
      "| Epoch 122 |   200/  658 batches | lr 0.00006 | ms/batch 16.55 | loss 0.05523680\n",
      "| Epoch 122 |   250/  658 batches | lr 0.00006 | ms/batch 16.72 | loss 0.05882625\n",
      "| Epoch 122 |   300/  658 batches | lr 0.00006 | ms/batch 14.70 | loss 0.05955651\n",
      "| Epoch 122 |   350/  658 batches | lr 0.00006 | ms/batch 14.70 | loss 0.05984759\n",
      "| Epoch 122 |   400/  658 batches | lr 0.00006 | ms/batch 20.16 | loss 0.05751668\n",
      "| Epoch 122 |   450/  658 batches | lr 0.00006 | ms/batch 14.70 | loss 0.05347155\n",
      "| Epoch 122 |   500/  658 batches | lr 0.00006 | ms/batch 16.38 | loss 0.05838353\n",
      "| Epoch 122 |   550/  658 batches | lr 0.00006 | ms/batch 17.02 | loss 0.05648167\n",
      "| Epoch 122 |   600/  658 batches | lr 0.00006 | ms/batch 18.83 | loss 0.05913904\n",
      "| Epoch 122 |   650/  658 batches | lr 0.00006 | ms/batch 16.98 | loss 0.05705714\n",
      "\n",
      "Val set: Average loss: 0.05888084\n",
      "\n",
      "| Epoch 123 |    50/  658 batches | lr 0.00006 | ms/batch 15.24 | loss 0.06308194\n",
      "| Epoch 123 |   100/  658 batches | lr 0.00006 | ms/batch 16.52 | loss 0.06024815\n",
      "| Epoch 123 |   150/  658 batches | lr 0.00006 | ms/batch 17.68 | loss 0.05571726\n",
      "| Epoch 123 |   200/  658 batches | lr 0.00006 | ms/batch 19.17 | loss 0.05518657\n",
      "| Epoch 123 |   250/  658 batches | lr 0.00006 | ms/batch 19.28 | loss 0.05883752\n",
      "| Epoch 123 |   300/  658 batches | lr 0.00006 | ms/batch 15.86 | loss 0.05949871\n",
      "| Epoch 123 |   350/  658 batches | lr 0.00006 | ms/batch 14.66 | loss 0.05994743\n",
      "| Epoch 123 |   400/  658 batches | lr 0.00006 | ms/batch 16.27 | loss 0.05764882\n",
      "| Epoch 123 |   450/  658 batches | lr 0.00006 | ms/batch 14.81 | loss 0.05374821\n",
      "| Epoch 123 |   500/  658 batches | lr 0.00006 | ms/batch 16.38 | loss 0.05782101\n",
      "| Epoch 123 |   550/  658 batches | lr 0.00006 | ms/batch 16.35 | loss 0.05641936\n",
      "| Epoch 123 |   600/  658 batches | lr 0.00006 | ms/batch 14.85 | loss 0.05906581\n",
      "| Epoch 123 |   650/  658 batches | lr 0.00006 | ms/batch 14.67 | loss 0.05713416\n",
      "\n",
      "Val set: Average loss: 0.05890724\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 124 |    50/  658 batches | lr 0.00006 | ms/batch 14.96 | loss 0.06298395\n",
      "| Epoch 124 |   100/  658 batches | lr 0.00006 | ms/batch 16.38 | loss 0.05991048\n",
      "| Epoch 124 |   150/  658 batches | lr 0.00006 | ms/batch 14.83 | loss 0.05567555\n",
      "| Epoch 124 |   200/  658 batches | lr 0.00006 | ms/batch 16.39 | loss 0.05514862\n",
      "| Epoch 124 |   250/  658 batches | lr 0.00006 | ms/batch 16.33 | loss 0.05877346\n",
      "| Epoch 124 |   300/  658 batches | lr 0.00006 | ms/batch 14.71 | loss 0.05958794\n",
      "| Epoch 124 |   350/  658 batches | lr 0.00006 | ms/batch 14.66 | loss 0.05992841\n",
      "| Epoch 124 |   400/  658 batches | lr 0.00006 | ms/batch 16.39 | loss 0.05774752\n",
      "| Epoch 124 |   450/  658 batches | lr 0.00006 | ms/batch 14.63 | loss 0.05366856\n",
      "| Epoch 124 |   500/  658 batches | lr 0.00006 | ms/batch 16.38 | loss 0.05754369\n",
      "| Epoch 124 |   550/  658 batches | lr 0.00006 | ms/batch 16.43 | loss 0.05632589\n",
      "| Epoch 124 |   600/  658 batches | lr 0.00006 | ms/batch 14.76 | loss 0.05910710\n",
      "| Epoch 124 |   650/  658 batches | lr 0.00006 | ms/batch 14.59 | loss 0.05709165\n",
      "\n",
      "Val set: Average loss: 0.05899395\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch 125 |    50/  658 batches | lr 0.00006 | ms/batch 14.97 | loss 0.06291180\n",
      "| Epoch 125 |   100/  658 batches | lr 0.00006 | ms/batch 16.30 | loss 0.05994526\n",
      "| Epoch 125 |   150/  658 batches | lr 0.00006 | ms/batch 14.64 | loss 0.05568588\n",
      "| Epoch 125 |   200/  658 batches | lr 0.00006 | ms/batch 16.48 | loss 0.05512297\n",
      "| Epoch 125 |   250/  658 batches | lr 0.00006 | ms/batch 16.32 | loss 0.05865784\n",
      "| Epoch 125 |   300/  658 batches | lr 0.00006 | ms/batch 14.67 | loss 0.05932487\n",
      "| Epoch 125 |   350/  658 batches | lr 0.00006 | ms/batch 14.66 | loss 0.05976637\n",
      "| Epoch 125 |   400/  658 batches | lr 0.00006 | ms/batch 16.35 | loss 0.05765917\n",
      "| Epoch 125 |   450/  658 batches | lr 0.00006 | ms/batch 14.63 | loss 0.05358989\n",
      "| Epoch 125 |   500/  658 batches | lr 0.00006 | ms/batch 16.37 | loss 0.05771651\n",
      "| Epoch 125 |   550/  658 batches | lr 0.00006 | ms/batch 16.34 | loss 0.05638808\n",
      "| Epoch 125 |   600/  658 batches | lr 0.00006 | ms/batch 14.67 | loss 0.05892627\n",
      "| Epoch 125 |   650/  658 batches | lr 0.00006 | ms/batch 14.91 | loss 0.05697042\n",
      "\n",
      "Val set: Average loss: 0.05894472\n",
      "\n",
      "EarlyStopping counter: 3 out of 20\n",
      "| Epoch 126 |    50/  658 batches | lr 0.00006 | ms/batch 14.90 | loss 0.06271998\n",
      "| Epoch 126 |   100/  658 batches | lr 0.00006 | ms/batch 16.38 | loss 0.05987098\n",
      "| Epoch 126 |   150/  658 batches | lr 0.00006 | ms/batch 14.66 | loss 0.05549513\n",
      "| Epoch 126 |   200/  658 batches | lr 0.00006 | ms/batch 16.45 | loss 0.05502777\n",
      "| Epoch 126 |   250/  658 batches | lr 0.00006 | ms/batch 16.47 | loss 0.05856755\n",
      "| Epoch 126 |   300/  658 batches | lr 0.00006 | ms/batch 14.63 | loss 0.05925656\n",
      "| Epoch 126 |   350/  658 batches | lr 0.00006 | ms/batch 14.69 | loss 0.05969789\n",
      "| Epoch 126 |   400/  658 batches | lr 0.00006 | ms/batch 16.40 | loss 0.05742189\n",
      "| Epoch 126 |   450/  658 batches | lr 0.00006 | ms/batch 14.78 | loss 0.05365378\n",
      "| Epoch 126 |   500/  658 batches | lr 0.00006 | ms/batch 16.34 | loss 0.05783938\n",
      "| Epoch 126 |   550/  658 batches | lr 0.00006 | ms/batch 16.51 | loss 0.05652735\n",
      "| Epoch 126 |   600/  658 batches | lr 0.00006 | ms/batch 14.76 | loss 0.05887709\n",
      "| Epoch 126 |   650/  658 batches | lr 0.00006 | ms/batch 14.63 | loss 0.05680709\n",
      "\n",
      "Val set: Average loss: 0.05897896\n",
      "\n",
      "EarlyStopping counter: 4 out of 20\n",
      "| Epoch 127 |    50/  658 batches | lr 0.00006 | ms/batch 15.02 | loss 0.06274793\n",
      "| Epoch 127 |   100/  658 batches | lr 0.00006 | ms/batch 16.42 | loss 0.05974940\n",
      "| Epoch 127 |   150/  658 batches | lr 0.00006 | ms/batch 14.70 | loss 0.05553472\n",
      "| Epoch 127 |   200/  658 batches | lr 0.00006 | ms/batch 16.48 | loss 0.05503279\n",
      "| Epoch 127 |   250/  658 batches | lr 0.00006 | ms/batch 16.42 | loss 0.05862368\n",
      "| Epoch 127 |   300/  658 batches | lr 0.00006 | ms/batch 14.74 | loss 0.05924777\n",
      "| Epoch 127 |   350/  658 batches | lr 0.00006 | ms/batch 14.87 | loss 0.05969045\n",
      "| Epoch 127 |   400/  658 batches | lr 0.00006 | ms/batch 16.40 | loss 0.05742751\n",
      "| Epoch 127 |   450/  658 batches | lr 0.00006 | ms/batch 14.88 | loss 0.05340580\n",
      "| Epoch 127 |   500/  658 batches | lr 0.00006 | ms/batch 16.68 | loss 0.05728006\n",
      "| Epoch 127 |   550/  658 batches | lr 0.00006 | ms/batch 16.54 | loss 0.05619856\n",
      "| Epoch 127 |   600/  658 batches | lr 0.00006 | ms/batch 14.82 | loss 0.05883829\n",
      "| Epoch 127 |   650/  658 batches | lr 0.00006 | ms/batch 14.68 | loss 0.05684611\n",
      "\n",
      "Val set: Average loss: 0.05888265\n",
      "\n",
      "EarlyStopping counter: 5 out of 20\n",
      "| Epoch 128 |    50/  658 batches | lr 0.00006 | ms/batch 15.00 | loss 0.06281804\n",
      "| Epoch 128 |   100/  658 batches | lr 0.00006 | ms/batch 16.28 | loss 0.05962903\n",
      "| Epoch 128 |   150/  658 batches | lr 0.00006 | ms/batch 14.70 | loss 0.05550585\n",
      "| Epoch 128 |   200/  658 batches | lr 0.00006 | ms/batch 16.44 | loss 0.05500658\n",
      "| Epoch 128 |   250/  658 batches | lr 0.00006 | ms/batch 16.35 | loss 0.05858543\n",
      "| Epoch 128 |   300/  658 batches | lr 0.00006 | ms/batch 14.79 | loss 0.05925181\n",
      "| Epoch 128 |   350/  658 batches | lr 0.00006 | ms/batch 14.67 | loss 0.05961411\n",
      "| Epoch 128 |   400/  658 batches | lr 0.00006 | ms/batch 16.34 | loss 0.05761734\n",
      "| Epoch 128 |   450/  658 batches | lr 0.00006 | ms/batch 14.86 | loss 0.05356950\n",
      "| Epoch 128 |   500/  658 batches | lr 0.00006 | ms/batch 16.40 | loss 0.05725291\n",
      "| Epoch 128 |   550/  658 batches | lr 0.00006 | ms/batch 16.36 | loss 0.05618364\n",
      "| Epoch 128 |   600/  658 batches | lr 0.00006 | ms/batch 14.65 | loss 0.05885722\n",
      "| Epoch 128 |   650/  658 batches | lr 0.00006 | ms/batch 14.70 | loss 0.05681636\n",
      "\n",
      "Val set: Average loss: 0.05872775\n",
      "\n",
      "| Epoch 129 |    50/  658 batches | lr 0.00006 | ms/batch 15.01 | loss 0.06265986\n",
      "| Epoch 129 |   100/  658 batches | lr 0.00006 | ms/batch 16.41 | loss 0.05959078\n",
      "| Epoch 129 |   150/  658 batches | lr 0.00006 | ms/batch 14.76 | loss 0.05537005\n",
      "| Epoch 129 |   200/  658 batches | lr 0.00006 | ms/batch 16.37 | loss 0.05487102\n",
      "| Epoch 129 |   250/  658 batches | lr 0.00006 | ms/batch 16.32 | loss 0.05857274\n",
      "| Epoch 129 |   300/  658 batches | lr 0.00006 | ms/batch 14.67 | loss 0.05918763\n",
      "| Epoch 129 |   350/  658 batches | lr 0.00006 | ms/batch 14.83 | loss 0.05956682\n",
      "| Epoch 129 |   400/  658 batches | lr 0.00006 | ms/batch 17.10 | loss 0.05737828\n",
      "| Epoch 129 |   450/  658 batches | lr 0.00006 | ms/batch 14.78 | loss 0.05345303\n",
      "| Epoch 129 |   500/  658 batches | lr 0.00006 | ms/batch 16.41 | loss 0.05776598\n",
      "| Epoch 129 |   550/  658 batches | lr 0.00006 | ms/batch 16.42 | loss 0.05628769\n",
      "| Epoch 129 |   600/  658 batches | lr 0.00006 | ms/batch 14.74 | loss 0.05886599\n",
      "| Epoch 129 |   650/  658 batches | lr 0.00006 | ms/batch 14.66 | loss 0.05659008\n",
      "\n",
      "Val set: Average loss: 0.05882477\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 130 |    50/  658 batches | lr 0.00006 | ms/batch 14.98 | loss 0.06239884\n",
      "| Epoch 130 |   100/  658 batches | lr 0.00006 | ms/batch 16.32 | loss 0.05961586\n",
      "| Epoch 130 |   150/  658 batches | lr 0.00006 | ms/batch 14.84 | loss 0.05546132\n",
      "| Epoch 130 |   200/  658 batches | lr 0.00006 | ms/batch 16.38 | loss 0.05485201\n",
      "| Epoch 130 |   250/  658 batches | lr 0.00006 | ms/batch 16.33 | loss 0.05853770\n",
      "| Epoch 130 |   300/  658 batches | lr 0.00006 | ms/batch 14.78 | loss 0.05924824\n",
      "| Epoch 130 |   350/  658 batches | lr 0.00006 | ms/batch 14.71 | loss 0.05960247\n",
      "| Epoch 130 |   400/  658 batches | lr 0.00006 | ms/batch 16.27 | loss 0.05727582\n",
      "| Epoch 130 |   450/  658 batches | lr 0.00006 | ms/batch 14.74 | loss 0.05342033\n",
      "| Epoch 130 |   500/  658 batches | lr 0.00006 | ms/batch 16.32 | loss 0.05736977\n",
      "| Epoch 130 |   550/  658 batches | lr 0.00006 | ms/batch 16.39 | loss 0.05603900\n",
      "| Epoch 130 |   600/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.05870450\n",
      "| Epoch 130 |   650/  658 batches | lr 0.00006 | ms/batch 14.68 | loss 0.05662953\n",
      "\n",
      "Val set: Average loss: 0.05882822\n",
      "\n",
      "EarlyStopping counter: 2 out of 20\n",
      "| Epoch 131 |    50/  658 batches | lr 0.00006 | ms/batch 15.13 | loss 0.06240172\n",
      "| Epoch 131 |   100/  658 batches | lr 0.00006 | ms/batch 16.42 | loss 0.05938069\n",
      "| Epoch 131 |   150/  658 batches | lr 0.00006 | ms/batch 14.74 | loss 0.05527995\n",
      "| Epoch 131 |   200/  658 batches | lr 0.00006 | ms/batch 16.37 | loss 0.05490290\n",
      "| Epoch 131 |   250/  658 batches | lr 0.00006 | ms/batch 16.46 | loss 0.05838471\n",
      "| Epoch 131 |   300/  658 batches | lr 0.00006 | ms/batch 14.69 | loss 0.05899022\n",
      "| Epoch 131 |   350/  658 batches | lr 0.00006 | ms/batch 14.71 | loss 0.05957559\n",
      "| Epoch 131 |   400/  658 batches | lr 0.00006 | ms/batch 16.33 | loss 0.05738584\n",
      "| Epoch 131 |   450/  658 batches | lr 0.00006 | ms/batch 14.83 | loss 0.05334481\n",
      "| Epoch 131 |   500/  658 batches | lr 0.00006 | ms/batch 16.38 | loss 0.05722339\n",
      "| Epoch 131 |   550/  658 batches | lr 0.00006 | ms/batch 16.38 | loss 0.05607601\n",
      "| Epoch 131 |   600/  658 batches | lr 0.00006 | ms/batch 14.76 | loss 0.05864771\n",
      "| Epoch 131 |   650/  658 batches | lr 0.00006 | ms/batch 14.71 | loss 0.05660641\n",
      "\n",
      "Val set: Average loss: 0.05868407\n",
      "\n",
      "| Epoch 132 |    50/  658 batches | lr 0.00006 | ms/batch 14.92 | loss 0.06223861\n",
      "| Epoch 132 |   100/  658 batches | lr 0.00006 | ms/batch 16.60 | loss 0.05930504\n",
      "| Epoch 132 |   150/  658 batches | lr 0.00006 | ms/batch 16.35 | loss 0.05517510\n",
      "| Epoch 132 |   200/  658 batches | lr 0.00006 | ms/batch 17.38 | loss 0.05481005\n",
      "| Epoch 132 |   250/  658 batches | lr 0.00006 | ms/batch 17.91 | loss 0.05825817\n",
      "| Epoch 132 |   300/  658 batches | lr 0.00006 | ms/batch 15.48 | loss 0.05902889\n",
      "| Epoch 132 |   350/  658 batches | lr 0.00006 | ms/batch 17.30 | loss 0.05956343\n",
      "| Epoch 132 |   400/  658 batches | lr 0.00006 | ms/batch 17.62 | loss 0.05727365\n",
      "| Epoch 132 |   450/  658 batches | lr 0.00006 | ms/batch 16.49 | loss 0.05328676\n",
      "| Epoch 132 |   500/  658 batches | lr 0.00006 | ms/batch 17.70 | loss 0.05723625\n",
      "| Epoch 132 |   550/  658 batches | lr 0.00006 | ms/batch 17.31 | loss 0.05606821\n",
      "| Epoch 132 |   600/  658 batches | lr 0.00006 | ms/batch 16.20 | loss 0.05854204\n",
      "| Epoch 132 |   650/  658 batches | lr 0.00006 | ms/batch 16.77 | loss 0.05648400\n",
      "\n",
      "Val set: Average loss: 0.05863142\n",
      "\n",
      "| Epoch 133 |    50/  658 batches | lr 0.00006 | ms/batch 15.82 | loss 0.06216013\n",
      "| Epoch 133 |   100/  658 batches | lr 0.00006 | ms/batch 17.01 | loss 0.05928827\n",
      "| Epoch 133 |   150/  658 batches | lr 0.00006 | ms/batch 15.00 | loss 0.05512561\n",
      "| Epoch 133 |   200/  658 batches | lr 0.00006 | ms/batch 16.50 | loss 0.05475078\n",
      "| Epoch 133 |   250/  658 batches | lr 0.00006 | ms/batch 16.84 | loss 0.05816217\n",
      "| Epoch 133 |   300/  658 batches | lr 0.00006 | ms/batch 15.05 | loss 0.05898105\n",
      "| Epoch 133 |   350/  658 batches | lr 0.00006 | ms/batch 15.10 | loss 0.05950927\n",
      "| Epoch 133 |   400/  658 batches | lr 0.00006 | ms/batch 16.47 | loss 0.05713379\n",
      "| Epoch 133 |   450/  658 batches | lr 0.00006 | ms/batch 14.80 | loss 0.05318304\n",
      "| Epoch 133 |   500/  658 batches | lr 0.00006 | ms/batch 16.37 | loss 0.05712268\n",
      "| Epoch 133 |   550/  658 batches | lr 0.00006 | ms/batch 16.45 | loss 0.05592730\n",
      "| Epoch 133 |   600/  658 batches | lr 0.00006 | ms/batch 14.72 | loss 0.05860047\n",
      "| Epoch 133 |   650/  658 batches | lr 0.00006 | ms/batch 14.79 | loss 0.05646922\n",
      "\n",
      "Val set: Average loss: 0.05864665\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 134 |    50/  658 batches | lr 0.00006 | ms/batch 15.14 | loss 0.06189124\n",
      "| Epoch 134 |   100/  658 batches | lr 0.00006 | ms/batch 16.25 | loss 0.05914061\n",
      "| Epoch 134 |   150/  658 batches | lr 0.00006 | ms/batch 14.76 | loss 0.05508655\n",
      "| Epoch 134 |   200/  658 batches | lr 0.00006 | ms/batch 16.33 | loss 0.05473278\n",
      "| Epoch 134 |   250/  658 batches | lr 0.00006 | ms/batch 16.78 | loss 0.05818746\n",
      "| Epoch 134 |   300/  658 batches | lr 0.00006 | ms/batch 14.64 | loss 0.05915666\n",
      "| Epoch 134 |   350/  658 batches | lr 0.00006 | ms/batch 14.82 | loss 0.05949915\n",
      "| Epoch 134 |   400/  658 batches | lr 0.00006 | ms/batch 16.42 | loss 0.05716358\n",
      "| Epoch 134 |   450/  658 batches | lr 0.00006 | ms/batch 14.71 | loss 0.05329625\n",
      "| Epoch 134 |   500/  658 batches | lr 0.00006 | ms/batch 16.39 | loss 0.05699052\n",
      "| Epoch 134 |   550/  658 batches | lr 0.00006 | ms/batch 16.45 | loss 0.05586534\n",
      "| Epoch 134 |   600/  658 batches | lr 0.00006 | ms/batch 14.71 | loss 0.05834202\n",
      "| Epoch 134 |   650/  658 batches | lr 0.00006 | ms/batch 14.73 | loss 0.05637708\n",
      "\n",
      "Val set: Average loss: 0.05858153\n",
      "\n",
      "| Epoch 135 |    50/  658 batches | lr 0.00006 | ms/batch 14.94 | loss 0.06204891\n",
      "| Epoch 135 |   100/  658 batches | lr 0.00006 | ms/batch 16.27 | loss 0.05918701\n",
      "| Epoch 135 |   150/  658 batches | lr 0.00006 | ms/batch 14.72 | loss 0.05499418\n",
      "| Epoch 135 |   200/  658 batches | lr 0.00006 | ms/batch 16.34 | loss 0.05467344\n",
      "| Epoch 135 |   250/  658 batches | lr 0.00006 | ms/batch 16.42 | loss 0.05824773\n",
      "| Epoch 135 |   300/  658 batches | lr 0.00006 | ms/batch 14.87 | loss 0.05920870\n",
      "| Epoch 135 |   350/  658 batches | lr 0.00006 | ms/batch 14.67 | loss 0.05941741\n",
      "| Epoch 135 |   400/  658 batches | lr 0.00006 | ms/batch 16.36 | loss 0.05702140\n",
      "| Epoch 135 |   450/  658 batches | lr 0.00006 | ms/batch 14.71 | loss 0.05324163\n",
      "| Epoch 135 |   500/  658 batches | lr 0.00006 | ms/batch 16.65 | loss 0.05693418\n",
      "| Epoch 135 |   550/  658 batches | lr 0.00006 | ms/batch 16.57 | loss 0.05584675\n",
      "| Epoch 135 |   600/  658 batches | lr 0.00006 | ms/batch 14.72 | loss 0.05841879\n",
      "| Epoch 135 |   650/  658 batches | lr 0.00006 | ms/batch 14.70 | loss 0.05628050\n",
      "\n",
      "Val set: Average loss: 0.05860567\n",
      "\n",
      "EarlyStopping counter: 1 out of 20\n",
      "| Epoch 136 |    50/  658 batches | lr 0.00006 | ms/batch 14.98 | loss 0.06192528\n",
      "| Epoch 136 |   100/  658 batches | lr 0.00006 | ms/batch 16.35 | loss 0.05905303\n",
      "| Epoch 136 |   150/  658 batches | lr 0.00006 | ms/batch 14.69 | loss 0.05493626\n",
      "| Epoch 136 |   200/  658 batches | lr 0.00006 | ms/batch 16.50 | loss 0.05456816\n",
      "| Epoch 136 |   250/  658 batches | lr 0.00006 | ms/batch 16.35 | loss 0.05819692\n",
      "| Epoch 136 |   300/  658 batches | lr 0.00006 | ms/batch 14.75 | loss 0.05892725\n",
      "| Epoch 136 |   350/  658 batches | lr 0.00006 | ms/batch 14.70 | loss 0.05937326\n",
      "| Epoch 136 |   400/  658 batches | lr 0.00006 | ms/batch 16.41 | loss 0.05698725\n",
      "| Epoch 136 |   450/  658 batches | lr 0.00006 | ms/batch 14.79 | loss 0.05319467\n",
      "| Epoch 136 |   500/  658 batches | lr 0.00006 | ms/batch 16.47 | loss 0.05693736\n",
      "| Epoch 136 |   550/  658 batches | lr 0.00006 | ms/batch 16.79 | loss 0.05582746\n",
      "| Epoch 136 |   600/  658 batches | lr 0.00006 | ms/batch 15.43 | loss 0.05840031\n",
      "| Epoch 136 |   650/  658 batches | lr 0.00006 | ms/batch 14.55 | loss 0.05617126\n",
      "\n",
      "Val set: Average loss: 0.05854789\n",
      "\n",
      "| Epoch 137 |    50/  658 batches | lr 0.00006 | ms/batch 15.75 | loss 0.06183120\n",
      "| Epoch 137 |   100/  658 batches | lr 0.00006 | ms/batch 19.60 | loss 0.05894136\n",
      "| Epoch 137 |   150/  658 batches | lr 0.00006 | ms/batch 15.16 | loss 0.05497083\n",
      "| Epoch 137 |   200/  658 batches | lr 0.00006 | ms/batch 16.35 | loss 0.05452470\n",
      "| Epoch 137 |   250/  658 batches | lr 0.00006 | ms/batch 16.58 | loss 0.05825046\n",
      "| Epoch 137 |   300/  658 batches | lr 0.00006 | ms/batch 14.61 | loss 0.05904522\n",
      "| Epoch 137 |   350/  658 batches | lr 0.00006 | ms/batch 14.62 | loss 0.05922376\n",
      "| Epoch 137 |   400/  658 batches | lr 0.00006 | ms/batch 16.14 | loss 0.05681295\n",
      "| Epoch 137 |   450/  658 batches | lr 0.00006 | ms/batch 14.65 | loss 0.05312385\n",
      "| Epoch 137 |   500/  658 batches | lr 0.00006 | ms/batch 16.23 | loss 0.05693033\n",
      "| Epoch 137 |   550/  658 batches | lr 0.00006 | ms/batch 16.49 | loss 0.05581127\n",
      "| Epoch 137 |   600/  658 batches | lr 0.00006 | ms/batch 14.68 | loss 0.05823234\n",
      "| Epoch 137 |   650/  658 batches | lr 0.00006 | ms/batch 14.64 | loss 0.05615954\n",
      "\n",
      "Val set: Average loss: 0.05852812\n",
      "\n",
      "| Epoch 138 |    50/  658 batches | lr 0.00006 | ms/batch 14.85 | loss 0.06181590\n",
      "| Epoch 138 |   100/  658 batches | lr 0.00006 | ms/batch 16.48 | loss 0.05898553\n",
      "| Epoch 138 |   150/  658 batches | lr 0.00006 | ms/batch 14.82 | loss 0.05489832\n",
      "| Epoch 138 |   200/  658 batches | lr 0.00006 | ms/batch 17.82 | loss 0.05444436\n",
      "| Epoch 138 |   250/  658 batches | lr 0.00006 | ms/batch 17.62 | loss 0.05807325\n",
      "| Epoch 138 |   300/  658 batches | lr 0.00006 | ms/batch 16.79 | loss 0.05899335\n",
      "| Epoch 138 |   350/  658 batches | lr 0.00006 | ms/batch 16.22 | loss 0.05928495\n",
      "| Epoch 138 |   400/  658 batches | lr 0.00006 | ms/batch 19.56 | loss 0.05669687\n",
      "| Epoch 138 |   450/  658 batches | lr 0.00006 | ms/batch 15.08 | loss 0.05287734\n",
      "| Epoch 138 |   500/  658 batches | lr 0.00006 | ms/batch 16.36 | loss 0.05671649\n",
      "| Epoch 138 |   550/  658 batches | lr 0.00006 | ms/batch 16.51 | loss 0.05575354\n",
      "| Epoch 138 |   600/  658 batches | lr 0.00006 | ms/batch 17.27 | loss 0.05855230\n",
      "| Epoch 138 |   650/  658 batches | lr 0.00006 | ms/batch 18.97 | loss 0.05609838\n",
      "\n",
      "Val set: Average loss: 0.05847621\n",
      "\n",
      "| Epoch 139 |    50/  658 batches | lr 0.00006 | ms/batch 14.88 | loss 0.06187879\n",
      "| Epoch 139 |   100/  658 batches | lr 0.00006 | ms/batch 16.53 | loss 0.05897254\n",
      "| Epoch 139 |   150/  658 batches | lr 0.00006 | ms/batch 14.81 | loss 0.05479921\n",
      "| Epoch 139 |   200/  658 batches | lr 0.00006 | ms/batch 16.82 | loss 0.05432055\n",
      "| Epoch 139 |   250/  658 batches | lr 0.00006 | ms/batch 16.60 | loss 0.05832561\n",
      "| Epoch 139 |   300/  658 batches | lr 0.00006 | ms/batch 14.84 | loss 0.05891497\n",
      "| Epoch 139 |   350/  658 batches | lr 0.00006 | ms/batch 15.65 | loss 0.05914650\n",
      "| Epoch 139 |   400/  658 batches | lr 0.00006 | ms/batch 16.26 | loss 0.05680276\n",
      "| Epoch 139 |   450/  658 batches | lr 0.00006 | ms/batch 14.99 | loss 0.05279593\n",
      "| Epoch 139 |   500/  658 batches | lr 0.00006 | ms/batch 16.51 | loss 0.05676386\n",
      "| Epoch 139 |   550/  658 batches | lr 0.00006 | ms/batch 16.41 | loss 0.05573079\n",
      "| Epoch 139 |   600/  658 batches | lr 0.00006 | ms/batch 14.87 | loss 0.05842661\n",
      "| Epoch 139 |   650/  658 batches | lr 0.00006 | ms/batch 15.19 | loss 0.05592088\n"
     ]
    }
   ],
   "source": [
    "load = False\n",
    "save_model_path = '../models/final_real_data_model.chkpt'\n",
    "val_err_df_path = '../results/val_final_real_data_model.csv'\n",
    "\n",
    "if not load:\n",
    "  train_losses, val_losses = train(\n",
    "      epochs,\n",
    "      batch_size,\n",
    "      model,\n",
    "      optimizer,\n",
    "      loss_fn,\n",
    "      X_train,\n",
    "      y_train,\n",
    "      X_val,\n",
    "      y_val)\n",
    "  val_err_df = pd.DataFrame({\n",
    "      'Training': train_losses,\n",
    "      'Validation': val_losses})\n",
    "  val_err_df.to_csv(val_err_df_path)\n",
    "  torch.save(model.state_dict(), save_model_path)\n",
    "else:\n",
    "  model = Net(input_size, output_size, hidden_size, num_layers, act_fn)\n",
    "  model.load_state_dict(torch.load(save_model_path, map_location=device))\n",
    "  model = model.to(device)\n",
    "  val_err_df = pd.read_csv(val_err_df_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1650894219921,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "KkenWSRYvDpl",
    "outputId": "37746aa5-0b46-4a80-d14d-397868e89361",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "val_err_df[1:].plot(xlabel='epoch', ylabel='MSE')\n",
    "plt.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FlG5Ky25vDpm",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1650894219922,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "TBZ4eHAdvDpn",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test_size = 30\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_out = model(X_test[0:test_size].to(device))\n",
    "\n",
    "test_out = output_sc.inverse_transform(test_out.cpu().detach().numpy())\n",
    "real_out = output_sc.inverse_transform(y_test[0:test_size].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1650894219926,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "wK1WeGIZvDpo",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cols = ['strike', 'close', 'hv_21', 'moneyness', 'tau', 'r',\n",
    "       'call', 'put']\n",
    "test_options = pd.DataFrame(input_sc.inverse_transform(X_test[0:test_size].detach().cpu().numpy()), columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 68,
     "status": "ok",
     "timestamp": 1650894220542,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "_dvE5LGXvDpq",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test_options['Prediction'] = test_out\n",
    "test_options['Real'] = real_out\n",
    "test_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 67,
     "status": "ok",
     "timestamp": 1650894220545,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "TNw5-1jgvDpr",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test_options['Abs Error'] = np.abs(test_options.Prediction - test_options.Real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 990
    },
    "executionInfo": {
     "elapsed": 65,
     "status": "ok",
     "timestamp": 1650894220546,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "lAC6AdeVvDpr",
    "outputId": "78bd13cc-c5a0-4746-f402-9e84d8b78696",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test_options.sort_values('Abs Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fDJ-hkrSAqVh",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### MSE on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_mse(model, X, y, batch_size):\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for batch, batch_labels in DataLoader(OptDataset(X, y), batch_size=batch_size):\n",
    "            out = model(batch.to(device))\n",
    "            loss = loss_fn(out, batch_labels.to(device))\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    losses = np.array(losses)\n",
    "    return losses"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 276,
     "status": "ok",
     "timestamp": 1650895213041,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "GG64Xp3vAib-",
    "outputId": "f846ee65-029d-4a76-b006-d65e4ac07a48",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "print('The MSE on the train set is: ', get_mse(model, X_train, y_train, batch_size).mean())\n",
    "print('The MSE on the val set is: ', get_mse(model, X_val, y_val, batch_size).mean())\n",
    "print('The MSE on the test set is: ', get_mse(model, X_test, y_test, batch_size).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCLf2KQJAvoE",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### MAE on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_mae(model, X, y, batch_size):\n",
    "    mae_loss = nn.L1Loss()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for batch, batch_labels in DataLoader(OptDataset(X, y), batch_size=batch_size):\n",
    "            out = model(batch.to(device))\n",
    "            loss = mae_loss(out, batch_labels.to(device))\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    losses = np.array(losses)\n",
    "    return losses"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1650895213494,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "mZohsEyLAu7S",
    "outputId": "4d6bfba3-5751-478d-d53e-73751702414e",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "print('The MAE on the train set is: ', get_mae(model, X_train, y_train, batch_size).mean())\n",
    "print('The MAE on the val set is: ', get_mae(model, X_val, y_val, batch_size).mean())\n",
    "print('The MAE on the test set is: ', get_mae(model, X_test, y_test, batch_size).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmsZ4aPaA1SJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### RSME on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "print('The RMSE on the train set is: ', np.sqrt(get_mse(model, X_train, y_train, batch_size)).mean())\n",
    "print('The RMSE on the val set is: ', np.sqrt(get_mse(model, X_val, y_val, batch_size)).mean())\n",
    "print('The RMSE on the test set is: ', np.sqrt(get_mse(model, X_test, y_test, batch_size)).mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8Jxp0L4A5zb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### MAPE on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_mape(model, X, y, batch_size):\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for batch, batch_labels in DataLoader(OptDataset(X, y), batch_size=batch_size):\n",
    "            out = model(batch.to(device))\n",
    "            loss = MAPELoss(out, batch_labels.to(device)).detach().cpu().item()\n",
    "            losses.append(loss)\n",
    "\n",
    "    return np.array(losses)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 335,
     "status": "ok",
     "timestamp": 1650895213818,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "fHghkyflA79o",
    "outputId": "37838323-11f0-4eb9-d7d7-50303bf4e9ce",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "print('The MAPE on the train set is: ', get_mape(model, X_train, y_train, batch_size).mean())\n",
    "print('The MAPE on the val set is: ', get_mape(model, X_val, y_val, batch_size).mean())\n",
    "print('The MAPE on the test set is: ', get_mape(model, X_test, y_test, batch_size).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLLLqkX6BEle",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1650895213820,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "sf8FmLxxBGcu",
    "outputId": "764313a9-78fc-46ca-dd08-9fb8834e4374",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(X_test[0:batch_size].to(device)).squeeze().cpu().detach().numpy()\n",
    "\n",
    "y_true = y_test[0:batch_size].cpu().squeeze().detach().numpy()\n",
    "\n",
    "r2 = r2_score(y_pred=out, y_true=y_true)\n",
    "\n",
    "print('the R^2 score is: ', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "executionInfo": {
     "elapsed": 744,
     "status": "ok",
     "timestamp": 1650895214553,
     "user": {
      "displayName": "Paolo D'Elia",
      "userId": "06873635760880783531"
     },
     "user_tz": -120
    },
    "id": "awvWu7WxBIHB",
    "outputId": "1b3dccd3-90ef-47d5-9895-267fdf93020c",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9, 6))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "ax.scatter(\n",
    "    y=output_sc.inverse_transform(out.reshape(-1, 1)),\n",
    "    x=output_sc.inverse_transform(y_true.squeeze().reshape(-1, 1))\n",
    ")\n",
    "ax.set_xlabel('Actual Value')\n",
    "ax.set_ylabel('Predicted Value')\n",
    "\n",
    "ax.text(20, 80, f'$R^2$ = {np.round(r2, 6)}', fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Model-Testing-Heston.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}