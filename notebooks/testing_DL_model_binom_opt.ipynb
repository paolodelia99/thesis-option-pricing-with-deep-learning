{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "testing-DL-model-binom-opt.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_bpYSe6m_Y4",
        "outputId": "13eb1ead-4876-4404-c0ac-ab9a6beffe27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.modules.activation import LeakyReLU"
      ],
      "metadata": {
        "id": "AKrX1m8ppyDF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "synthetic_calls_path = '/content/drive/MyDrive/Progetto Stage/data/binom_synthetic_calls.csv'\n",
        "synthetic_puts_path = '/content/drive/MyDrive/Progetto Stage/data/binom_synthetic_puts.csv'"
      ],
      "metadata": {
        "id": "zJ-MkVamqE0g"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "    \n",
        "    return df"
      ],
      "metadata": {
        "id": "xF4SDmRO01pn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "synthetic_calls = pd.read_csv(synthetic_calls_path, index_col=0)\n",
        "synthetic_puts = pd.read_csv(synthetic_puts_path, index_col=0)\n",
        "\n",
        "synthetic_calls = reduce_mem_usage(synthetic_calls)\n",
        "synthetic_puts = reduce_mem_usage(synthetic_puts)"
      ],
      "metadata": {
        "id": "t2egQn4JtegQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "synthetic_options = pd.concat([synthetic_calls, synthetic_puts], axis=0)\n",
        "synthetic_options = shuffle(synthetic_options)\n",
        "synthetic_options = synthetic_options.reset_index()\n",
        "synthetic_options = synthetic_options.drop('index', axis=1)"
      ],
      "metadata": {
        "id": "tHAKbC6IxnOg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "synthetic_options.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Lm6Al15cL42T",
        "outputId": "fa5eb90a-d140-4745-ee69-eaa9d127de14"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Price  Strike Type       Vol  Interest Rate  Time to Expiration  \\\n",
              "0    100   126.0    C  0.850098       0.099976            0.300049   \n",
              "1    100   132.0    P  0.600098       0.049988            0.600098   \n",
              "2    100   160.0    P  0.399902       0.090027            1.000000   \n",
              "3    100    67.0    P  0.549805       0.010002            0.600098   \n",
              "4    100   160.0    C  0.649902       0.049988            0.600098   \n",
              "\n",
              "   Option Price  \n",
              "0     11.140625  \n",
              "1     37.843750  \n",
              "2     50.593750  \n",
              "3      3.121094  \n",
              "4      6.492188  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e8658a83-14b6-4465-a5d5-8f8385b32b30\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Price</th>\n",
              "      <th>Strike</th>\n",
              "      <th>Type</th>\n",
              "      <th>Vol</th>\n",
              "      <th>Interest Rate</th>\n",
              "      <th>Time to Expiration</th>\n",
              "      <th>Option Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100</td>\n",
              "      <td>126.0</td>\n",
              "      <td>C</td>\n",
              "      <td>0.850098</td>\n",
              "      <td>0.099976</td>\n",
              "      <td>0.300049</td>\n",
              "      <td>11.140625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100</td>\n",
              "      <td>132.0</td>\n",
              "      <td>P</td>\n",
              "      <td>0.600098</td>\n",
              "      <td>0.049988</td>\n",
              "      <td>0.600098</td>\n",
              "      <td>37.843750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100</td>\n",
              "      <td>160.0</td>\n",
              "      <td>P</td>\n",
              "      <td>0.399902</td>\n",
              "      <td>0.090027</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>50.593750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100</td>\n",
              "      <td>67.0</td>\n",
              "      <td>P</td>\n",
              "      <td>0.549805</td>\n",
              "      <td>0.010002</td>\n",
              "      <td>0.600098</td>\n",
              "      <td>3.121094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100</td>\n",
              "      <td>160.0</td>\n",
              "      <td>C</td>\n",
              "      <td>0.649902</td>\n",
              "      <td>0.049988</td>\n",
              "      <td>0.600098</td>\n",
              "      <td>6.492188</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e8658a83-14b6-4465-a5d5-8f8385b32b30')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e8658a83-14b6-4465-a5d5-8f8385b32b30 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e8658a83-14b6-4465-a5d5-8f8385b32b30');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "pFskCrb2wKil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "synthetic_options = pd.get_dummies(synthetic_options, prefix='', prefix_sep='')"
      ],
      "metadata": {
        "id": "lQYEZiPdArQT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sc = StandardScaler()\n",
        "output_sc = StandardScaler()\n",
        "input_data = input_sc.fit_transform(synthetic_options.drop('Option Price', axis=1))\n",
        "output_data = output_sc.fit_transform(synthetic_options['Option Price'].values.reshape(-1, 1))\n",
        "\n",
        "train_size = 0.8\n",
        "val_size = 0.1\n",
        "\n",
        "last_train_idx = int(np.round(len(input_data) * train_size))\n",
        "last_val_idx = last_train_idx + int(np.round(len(input_data) * val_size))\n",
        "\n",
        "X_train = input_data[0:last_train_idx]\n",
        "X_val = input_data[last_train_idx:last_val_idx]\n",
        "X_test = input_data[last_val_idx:]\n",
        "\n",
        "y_train = output_data[0:last_train_idx]\n",
        "y_val = output_data[last_train_idx:last_val_idx]\n",
        "y_test = output_data[last_val_idx:]"
      ],
      "metadata": {
        "id": "37ZypfWYwIZS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = Variable(torch.Tensor(X_train))\n",
        "X_val = Variable(torch.Tensor(X_val))\n",
        "X_test = Variable(torch.Tensor(X_test))\n",
        "\n",
        "y_train = Variable(torch.Tensor(y_train))\n",
        "y_val = Variable(torch.Tensor(y_val))\n",
        "y_test = Variable(torch.Tensor(y_test))"
      ],
      "metadata": {
        "id": "zqw3nQdG5ca7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Model"
      ],
      "metadata": {
        "id": "J2OS-HGd5gv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CUDA = torch.cuda.is_available()\n",
        "device = 'cuda:0' if CUDA else 'cpu'"
      ],
      "metadata": {
        "id": "cZcW1lwB6pPa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HiddenLayer(nn.Module):\n",
        "\n",
        "  def __init__(self, layer_size, dropout=0.1):\n",
        "      super(HiddenLayer, self).__init__()\n",
        "      self.layer = nn.Sequential(\n",
        "          nn.Linear(layer_size, layer_size),\n",
        "          nn.LeakyReLU(),\n",
        "          nn.Dropout(dropout)\n",
        "      )\n",
        "    \n",
        "  def forward(self, x):\n",
        "    return self.layer(x)"
      ],
      "metadata": {
        "id": "JbJDYtL86BIN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 1\n",
        "\n",
        "- 4 hidden layers\n",
        "- Leaky ReLU as activation function"
      ],
      "metadata": {
        "id": "S_4EPSyEUo9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "  def __init__(self, input_size, output_size, hidden_size):\n",
        "    super(Net, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.output_size = output_size\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(self.input_size, self.hidden_size),\n",
        "        nn.LeakyReLU(),\n",
        "        HiddenLayer(self.hidden_size),\n",
        "        HiddenLayer(self.hidden_size),\n",
        "        HiddenLayer(self.hidden_size),\n",
        "        HiddenLayer(self.hidden_size),  \n",
        "        nn.Linear(self.hidden_size, self.output_size)\n",
        "    )\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.net(x)"
      ],
      "metadata": {
        "id": "XO41ruSn5dZD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 2\n",
        "\n",
        "- Number of Layer as input\n",
        "- same as model 1\n",
        "\n",
        "code: https://stackoverflow.com/questions/62937388/pytorch-dynamic-amount-of-layers"
      ],
      "metadata": {
        "id": "Hd-6ppPxUsB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: to implement"
      ],
      "metadata": {
        "id": "Zz6gGjaPU796"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 3\n",
        "\n",
        "- as model 2 but with residual connections\n",
        "\n",
        "code:  https://stackoverflow.com/questions/57229054/how-to-implement-my-own-resnet-with-torch-nn-sequential-in-pytorc"
      ],
      "metadata": {
        "id": "HkEhRhYDU8pH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: to implement"
      ],
      "metadata": {
        "id": "n2-nsobJVI6L"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "vkv-KmfNVLoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 7\n",
        "hidden_size = 64\n",
        "output_size = 1\n",
        "batch_size = 1208\n",
        "epochs = 1000\n",
        "lr = 1e-4\n",
        "\n",
        "model = Net(input_size, output_size, hidden_size)\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "2SKLn8jU9DAu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n",
        "\n",
        "X_train = X_train.to(device)\n",
        "y_train = y_train.to(device)\n",
        "\n",
        "X_val = X_val.to(device)\n",
        "y_val = y_val.to(device)\n",
        "\n",
        "X_test = X_test.to(device)\n",
        "y_test = y_test.to(device)"
      ],
      "metadata": {
        "id": "1H5fGvG7JuCm"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OptDataset(Dataset):\n",
        "\n",
        "  def __init__(self, X, y):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.X[idx], self.y[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.X)"
      ],
      "metadata": {
        "id": "eS2k1XKyDcB5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loss_fn, X_val, y_val):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    out = model(X_test)\n",
        "    loss = loss_fn(out, y_test)\n",
        "    print('\\nVal set: Average loss: {:.8f}\\n'.format(\n",
        "            loss.item()))\n",
        "    return loss.item()"
      ],
      "metadata": {
        "id": "v0vrGBjGH7xA"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(\n",
        "    epochs, \n",
        "    batch_size, \n",
        "    model,\n",
        "    optimizer,\n",
        "    loss_fn, \n",
        "    X_train,\n",
        "    y_train,\n",
        "    X_val,\n",
        "    y_val\n",
        "):\n",
        "  for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    start_time = time.time()\n",
        "    i = 0\n",
        "\n",
        "    for batch, batch_labels in DataLoader(OptDataset(X_train, y_train), batch_size=batch_size):\n",
        "      out = model(batch.to(device))\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      loss = loss_fn(out, batch_labels.to(device))\n",
        "      total_loss += loss.item()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      if i > 0 and i % 50 == 0:\n",
        "        avg_loss = total_loss / 50\n",
        "        elapsed = time.time() - start_time\n",
        "        print('| Epoch {:3d} | {:5d}/{:5d} batches | lr {:2.5f} | ms/batch {:5.2f} | '\n",
        "                  'loss {:5.8f}'.format(\n",
        "              epoch, i, len(X_train) // batch_size+1, lr, elapsed * 1000 / 50,\n",
        "              avg_loss))\n",
        "        start_time = time.time()\n",
        "        total_loss = 0\n",
        "\n",
        "      i += 1\n",
        "    \n",
        "    evaluate(model, loss_fn, X_val, y_val)"
      ],
      "metadata": {
        "id": "U_qp8B6KAnv7"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load = False\n",
        "save_model_path = f'/content/drive/MyDrive/Progetto Stage/models/opt_net1_h{hidden_size}.chkpt'\n",
        "\n",
        "if not load:\n",
        "  train(\n",
        "      epochs, \n",
        "      batch_size, \n",
        "      model, \n",
        "      optimizer, \n",
        "      loss_fn, \n",
        "      X_train, \n",
        "      y_train,\n",
        "      X_val,\n",
        "      y_val)\n",
        "  torch.save(model.state_dict(), save_model_path)\n",
        "else:\n",
        "  model = Net(input_size, output_size, hidden_size)\n",
        "  model.load_state_dict(torch.load(save_model_path, map_location=device))"
      ],
      "metadata": {
        "id": "EEr6snmyIgX-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21c852c5-0621-4acd-bf5a-8f1665ccab6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Epoch   0 |    50/  401 batches | lr 0.00010 | ms/batch 15.46 | loss 1.01290744\n",
            "| Epoch   0 |   100/  401 batches | lr 0.00010 | ms/batch 10.89 | loss 0.92099674\n",
            "| Epoch   0 |   150/  401 batches | lr 0.00010 | ms/batch 11.20 | loss 0.68641208\n",
            "| Epoch   0 |   200/  401 batches | lr 0.00010 | ms/batch 12.39 | loss 0.31637840\n",
            "| Epoch   0 |   250/  401 batches | lr 0.00010 | ms/batch 11.35 | loss 0.16292509\n",
            "| Epoch   0 |   300/  401 batches | lr 0.00010 | ms/batch 10.84 | loss 0.10498055\n",
            "| Epoch   0 |   350/  401 batches | lr 0.00010 | ms/batch 11.05 | loss 0.07734603\n",
            "\n",
            "Val set: Average loss: 0.01922312\n",
            "\n",
            "| Epoch   1 |    50/  401 batches | lr 0.00010 | ms/batch 11.27 | loss 0.05400861\n",
            "| Epoch   1 |   100/  401 batches | lr 0.00010 | ms/batch 11.74 | loss 0.04641830\n",
            "| Epoch   1 |   150/  401 batches | lr 0.00010 | ms/batch 12.56 | loss 0.04169635\n",
            "| Epoch   1 |   200/  401 batches | lr 0.00010 | ms/batch 11.52 | loss 0.03928902\n",
            "| Epoch   1 |   250/  401 batches | lr 0.00010 | ms/batch 10.95 | loss 0.03668114\n",
            "| Epoch   1 |   300/  401 batches | lr 0.00010 | ms/batch 12.62 | loss 0.03452163\n",
            "| Epoch   1 |   350/  401 batches | lr 0.00010 | ms/batch 11.29 | loss 0.03272766\n",
            "\n",
            "Val set: Average loss: 0.00541141\n",
            "\n",
            "| Epoch   2 |    50/  401 batches | lr 0.00010 | ms/batch 11.51 | loss 0.03103050\n",
            "| Epoch   2 |   100/  401 batches | lr 0.00010 | ms/batch 12.30 | loss 0.02889751\n",
            "| Epoch   2 |   150/  401 batches | lr 0.00010 | ms/batch 11.41 | loss 0.02791725\n",
            "| Epoch   2 |   200/  401 batches | lr 0.00010 | ms/batch 11.32 | loss 0.02728841\n",
            "| Epoch   2 |   250/  401 batches | lr 0.00010 | ms/batch 12.61 | loss 0.02613034\n",
            "| Epoch   2 |   300/  401 batches | lr 0.00010 | ms/batch 11.05 | loss 0.02528505\n",
            "| Epoch   2 |   350/  401 batches | lr 0.00010 | ms/batch 11.04 | loss 0.02487106\n",
            "\n",
            "Val set: Average loss: 0.00302598\n",
            "\n",
            "| Epoch   3 |    50/  401 batches | lr 0.00010 | ms/batch 12.32 | loss 0.02398533\n",
            "| Epoch   3 |   100/  401 batches | lr 0.00010 | ms/batch 11.86 | loss 0.02268898\n",
            "| Epoch   3 |   150/  401 batches | lr 0.00010 | ms/batch 11.02 | loss 0.02225369\n",
            "| Epoch   3 |   200/  401 batches | lr 0.00010 | ms/batch 12.88 | loss 0.02184364\n",
            "| Epoch   3 |   250/  401 batches | lr 0.00010 | ms/batch 11.33 | loss 0.02121002\n",
            "| Epoch   3 |   300/  401 batches | lr 0.00010 | ms/batch 10.87 | loss 0.02120971\n",
            "| Epoch   3 |   350/  401 batches | lr 0.00010 | ms/batch 12.35 | loss 0.02058516\n",
            "\n",
            "Val set: Average loss: 0.00217057\n",
            "\n",
            "| Epoch   4 |    50/  401 batches | lr 0.00010 | ms/batch 11.34 | loss 0.01987570\n",
            "| Epoch   4 |   100/  401 batches | lr 0.00010 | ms/batch 12.40 | loss 0.01915937\n",
            "| Epoch   4 |   150/  401 batches | lr 0.00010 | ms/batch 11.29 | loss 0.01906194\n",
            "| Epoch   4 |   200/  401 batches | lr 0.00010 | ms/batch 10.89 | loss 0.01871140\n",
            "| Epoch   4 |   250/  401 batches | lr 0.00010 | ms/batch 12.11 | loss 0.01825789\n",
            "| Epoch   4 |   300/  401 batches | lr 0.00010 | ms/batch 11.21 | loss 0.01792139\n",
            "| Epoch   4 |   350/  401 batches | lr 0.00010 | ms/batch 11.05 | loss 0.01767923\n",
            "\n",
            "Val set: Average loss: 0.00189807\n",
            "\n",
            "| Epoch   5 |    50/  401 batches | lr 0.00010 | ms/batch 11.56 | loss 0.01767750\n",
            "| Epoch   5 |   100/  401 batches | lr 0.00010 | ms/batch 11.14 | loss 0.01695832\n",
            "| Epoch   5 |   150/  401 batches | lr 0.00010 | ms/batch 11.45 | loss 0.01662385\n",
            "| Epoch   5 |   200/  401 batches | lr 0.00010 | ms/batch 12.18 | loss 0.01635409\n",
            "| Epoch   5 |   250/  401 batches | lr 0.00010 | ms/batch 11.59 | loss 0.01617528\n",
            "| Epoch   5 |   300/  401 batches | lr 0.00010 | ms/batch 11.49 | loss 0.01610145\n",
            "| Epoch   5 |   350/  401 batches | lr 0.00010 | ms/batch 12.55 | loss 0.01557110\n",
            "\n",
            "Val set: Average loss: 0.00165411\n",
            "\n",
            "| Epoch   6 |    50/  401 batches | lr 0.00010 | ms/batch 11.07 | loss 0.01577154\n",
            "| Epoch   6 |   100/  401 batches | lr 0.00010 | ms/batch 12.23 | loss 0.01528635\n",
            "| Epoch   6 |   150/  401 batches | lr 0.00010 | ms/batch 11.11 | loss 0.01493220\n",
            "| Epoch   6 |   200/  401 batches | lr 0.00010 | ms/batch 11.28 | loss 0.01491619\n",
            "| Epoch   6 |   250/  401 batches | lr 0.00010 | ms/batch 12.03 | loss 0.01461940\n",
            "| Epoch   6 |   300/  401 batches | lr 0.00010 | ms/batch 11.12 | loss 0.01459403\n",
            "| Epoch   6 |   350/  401 batches | lr 0.00010 | ms/batch 11.11 | loss 0.01441530\n",
            "\n",
            "Val set: Average loss: 0.00162741\n",
            "\n",
            "| Epoch   7 |    50/  401 batches | lr 0.00010 | ms/batch 12.26 | loss 0.01431776\n",
            "| Epoch   7 |   100/  401 batches | lr 0.00010 | ms/batch 11.17 | loss 0.01389927\n",
            "| Epoch   7 |   150/  401 batches | lr 0.00010 | ms/batch 11.33 | loss 0.01375316\n",
            "| Epoch   7 |   200/  401 batches | lr 0.00010 | ms/batch 12.28 | loss 0.01373477\n",
            "| Epoch   7 |   250/  401 batches | lr 0.00010 | ms/batch 11.12 | loss 0.01330820\n",
            "| Epoch   7 |   300/  401 batches | lr 0.00010 | ms/batch 11.00 | loss 0.01301875\n",
            "| Epoch   7 |   350/  401 batches | lr 0.00010 | ms/batch 12.39 | loss 0.01314441\n",
            "\n",
            "Val set: Average loss: 0.00168906\n",
            "\n",
            "| Epoch   8 |    50/  401 batches | lr 0.00010 | ms/batch 11.48 | loss 0.01325212\n",
            "| Epoch   8 |   100/  401 batches | lr 0.00010 | ms/batch 12.14 | loss 0.01267412\n",
            "| Epoch   8 |   150/  401 batches | lr 0.00010 | ms/batch 11.07 | loss 0.01260938\n",
            "| Epoch   8 |   200/  401 batches | lr 0.00010 | ms/batch 11.55 | loss 0.01255057\n",
            "| Epoch   8 |   250/  401 batches | lr 0.00010 | ms/batch 12.65 | loss 0.01234007\n",
            "| Epoch   8 |   300/  401 batches | lr 0.00010 | ms/batch 11.14 | loss 0.01262252\n",
            "| Epoch   8 |   350/  401 batches | lr 0.00010 | ms/batch 11.27 | loss 0.01217138\n",
            "\n",
            "Val set: Average loss: 0.00117533\n",
            "\n",
            "| Epoch   9 |    50/  401 batches | lr 0.00010 | ms/batch 12.62 | loss 0.01230988\n",
            "| Epoch   9 |   100/  401 batches | lr 0.00010 | ms/batch 11.47 | loss 0.01188890\n",
            "| Epoch   9 |   150/  401 batches | lr 0.00010 | ms/batch 11.37 | loss 0.01196852\n",
            "| Epoch   9 |   200/  401 batches | lr 0.00010 | ms/batch 12.52 | loss 0.01195078\n",
            "| Epoch   9 |   250/  401 batches | lr 0.00010 | ms/batch 11.09 | loss 0.01173435\n",
            "| Epoch   9 |   300/  401 batches | lr 0.00010 | ms/batch 11.13 | loss 0.01160419\n",
            "| Epoch   9 |   350/  401 batches | lr 0.00010 | ms/batch 12.63 | loss 0.01140283\n",
            "\n",
            "Val set: Average loss: 0.00155185\n",
            "\n",
            "| Epoch  10 |    50/  401 batches | lr 0.00010 | ms/batch 11.34 | loss 0.01178362\n",
            "| Epoch  10 |   100/  401 batches | lr 0.00010 | ms/batch 11.74 | loss 0.01096100\n",
            "| Epoch  10 |   150/  401 batches | lr 0.00010 | ms/batch 12.50 | loss 0.01085783\n",
            "| Epoch  10 |   200/  401 batches | lr 0.00010 | ms/batch 11.35 | loss 0.01097754\n",
            "| Epoch  10 |   250/  401 batches | lr 0.00010 | ms/batch 11.25 | loss 0.01097661\n",
            "| Epoch  10 |   300/  401 batches | lr 0.00010 | ms/batch 12.67 | loss 0.01097881\n",
            "| Epoch  10 |   350/  401 batches | lr 0.00010 | ms/batch 11.34 | loss 0.01099943\n",
            "\n",
            "Val set: Average loss: 0.00119088\n",
            "\n",
            "| Epoch  11 |    50/  401 batches | lr 0.00010 | ms/batch 12.94 | loss 0.01117779\n",
            "| Epoch  11 |   100/  401 batches | lr 0.00010 | ms/batch 11.33 | loss 0.01086688\n",
            "| Epoch  11 |   150/  401 batches | lr 0.00010 | ms/batch 11.50 | loss 0.01047819\n",
            "| Epoch  11 |   200/  401 batches | lr 0.00010 | ms/batch 12.47 | loss 0.01060890\n",
            "| Epoch  11 |   250/  401 batches | lr 0.00010 | ms/batch 11.13 | loss 0.01037117\n",
            "| Epoch  11 |   300/  401 batches | lr 0.00010 | ms/batch 11.26 | loss 0.01044600\n",
            "| Epoch  11 |   350/  401 batches | lr 0.00010 | ms/batch 11.13 | loss 0.01040667\n",
            "\n",
            "Val set: Average loss: 0.00143735\n",
            "\n",
            "| Epoch  12 |    50/  401 batches | lr 0.00010 | ms/batch 11.52 | loss 0.01040941\n",
            "| Epoch  12 |   100/  401 batches | lr 0.00010 | ms/batch 11.20 | loss 0.00992947\n",
            "| Epoch  12 |   150/  401 batches | lr 0.00010 | ms/batch 12.46 | loss 0.00985160\n",
            "| Epoch  12 |   200/  401 batches | lr 0.00010 | ms/batch 11.95 | loss 0.01008252\n",
            "| Epoch  12 |   250/  401 batches | lr 0.00010 | ms/batch 11.14 | loss 0.01007292\n",
            "| Epoch  12 |   300/  401 batches | lr 0.00010 | ms/batch 12.16 | loss 0.00994339\n",
            "| Epoch  12 |   350/  401 batches | lr 0.00010 | ms/batch 11.28 | loss 0.00973518\n",
            "\n",
            "Val set: Average loss: 0.00104800\n",
            "\n",
            "| Epoch  13 |    50/  401 batches | lr 0.00010 | ms/batch 12.85 | loss 0.01003882\n",
            "| Epoch  13 |   100/  401 batches | lr 0.00010 | ms/batch 11.31 | loss 0.00954706\n",
            "| Epoch  13 |   150/  401 batches | lr 0.00010 | ms/batch 11.23 | loss 0.00950557\n",
            "| Epoch  13 |   200/  401 batches | lr 0.00010 | ms/batch 11.33 | loss 0.00966663\n",
            "| Epoch  13 |   250/  401 batches | lr 0.00010 | ms/batch 12.67 | loss 0.00942411\n",
            "| Epoch  13 |   300/  401 batches | lr 0.00010 | ms/batch 11.41 | loss 0.00936220\n",
            "| Epoch  13 |   350/  401 batches | lr 0.00010 | ms/batch 11.19 | loss 0.00943575\n",
            "\n",
            "Val set: Average loss: 0.00110328\n",
            "\n",
            "| Epoch  14 |    50/  401 batches | lr 0.00010 | ms/batch 11.41 | loss 0.00968621\n",
            "| Epoch  14 |   100/  401 batches | lr 0.00010 | ms/batch 11.39 | loss 0.00907296\n",
            "| Epoch  14 |   150/  401 batches | lr 0.00010 | ms/batch 12.57 | loss 0.00922868\n",
            "| Epoch  14 |   200/  401 batches | lr 0.00010 | ms/batch 11.14 | loss 0.00909794\n",
            "| Epoch  14 |   250/  401 batches | lr 0.00010 | ms/batch 11.48 | loss 0.00908599\n",
            "| Epoch  14 |   300/  401 batches | lr 0.00010 | ms/batch 11.16 | loss 0.00908578\n",
            "| Epoch  14 |   350/  401 batches | lr 0.00010 | ms/batch 12.82 | loss 0.00884947\n",
            "\n",
            "Val set: Average loss: 0.00156165\n",
            "\n",
            "| Epoch  15 |    50/  401 batches | lr 0.00010 | ms/batch 11.67 | loss 0.00911740\n",
            "| Epoch  15 |   100/  401 batches | lr 0.00010 | ms/batch 12.88 | loss 0.00869053\n",
            "| Epoch  15 |   150/  401 batches | lr 0.00010 | ms/batch 11.29 | loss 0.00862920\n",
            "| Epoch  15 |   200/  401 batches | lr 0.00010 | ms/batch 18.26 | loss 0.00864405\n",
            "| Epoch  15 |   250/  401 batches | lr 0.00010 | ms/batch 14.46 | loss 0.00860384\n",
            "| Epoch  15 |   300/  401 batches | lr 0.00010 | ms/batch 11.58 | loss 0.00866534\n",
            "| Epoch  15 |   350/  401 batches | lr 0.00010 | ms/batch 11.69 | loss 0.00853111\n",
            "\n",
            "Val set: Average loss: 0.00182168\n",
            "\n",
            "| Epoch  16 |    50/  401 batches | lr 0.00010 | ms/batch 11.21 | loss 0.00875080\n",
            "| Epoch  16 |   100/  401 batches | lr 0.00010 | ms/batch 11.31 | loss 0.00841143\n",
            "| Epoch  16 |   150/  401 batches | lr 0.00010 | ms/batch 11.25 | loss 0.00832158\n",
            "| Epoch  16 |   200/  401 batches | lr 0.00010 | ms/batch 12.60 | loss 0.00829316\n",
            "| Epoch  16 |   250/  401 batches | lr 0.00010 | ms/batch 11.25 | loss 0.00814207\n",
            "| Epoch  16 |   300/  401 batches | lr 0.00010 | ms/batch 11.20 | loss 0.00838093\n",
            "| Epoch  16 |   350/  401 batches | lr 0.00010 | ms/batch 12.47 | loss 0.00824403\n",
            "\n",
            "Val set: Average loss: 0.00185151\n",
            "\n",
            "| Epoch  17 |    50/  401 batches | lr 0.00010 | ms/batch 11.57 | loss 0.00834089\n",
            "| Epoch  17 |   100/  401 batches | lr 0.00010 | ms/batch 12.55 | loss 0.00803950\n",
            "| Epoch  17 |   150/  401 batches | lr 0.00010 | ms/batch 11.42 | loss 0.00795566\n",
            "| Epoch  17 |   200/  401 batches | lr 0.00010 | ms/batch 11.06 | loss 0.00798251\n",
            "| Epoch  17 |   250/  401 batches | lr 0.00010 | ms/batch 12.53 | loss 0.00794296\n",
            "| Epoch  17 |   300/  401 batches | lr 0.00010 | ms/batch 11.40 | loss 0.00789765\n",
            "| Epoch  17 |   350/  401 batches | lr 0.00010 | ms/batch 11.55 | loss 0.00797027\n",
            "\n",
            "Val set: Average loss: 0.00170747\n",
            "\n",
            "| Epoch  18 |    50/  401 batches | lr 0.00010 | ms/batch 12.21 | loss 0.00793320\n",
            "| Epoch  18 |   100/  401 batches | lr 0.00010 | ms/batch 11.22 | loss 0.00777596\n",
            "| Epoch  18 |   150/  401 batches | lr 0.00010 | ms/batch 11.22 | loss 0.00764401\n",
            "| Epoch  18 |   200/  401 batches | lr 0.00010 | ms/batch 12.53 | loss 0.00772239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the model"
      ],
      "metadata": {
        "id": "3EHvwZY_P-b2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_out = model(X_test[0:10])\n",
        "test_out = output_sc.inverse_transform(test_out.cpu().detach().numpy())\n",
        "test_out"
      ],
      "metadata": {
        "id": "OCuRVZFCP7kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_sc.inverse_transform(y_test[0:10].cpu().detach().numpy())"
      ],
      "metadata": {
        "id": "scYrsWq2QfQD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}