{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "S4QcxABpFBjv"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from itertools import product\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9m-yA4y0FCQ0"
   },
   "outputs": [],
   "source": [
    "# Set seeds\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uYe9Ip7oFEFb"
   },
   "outputs": [],
   "source": [
    "synthetic_calls_path = '../data/binom_synthetic_calls.csv'\n",
    "synthetic_puts_path = '../data/binom_synthetic_puts.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xF4SDmRO01pn"
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "42GblRwWFH1Y"
   },
   "outputs": [],
   "source": [
    "synthetic_calls = pd.read_csv(synthetic_calls_path, index_col=0)\n",
    "synthetic_puts = pd.read_csv(synthetic_puts_path, index_col=0)\n",
    "\n",
    "synthetic_calls = reduce_mem_usage(synthetic_calls)\n",
    "synthetic_puts = reduce_mem_usage(synthetic_puts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ekVnxlkpFJ1I"
   },
   "outputs": [],
   "source": [
    "synthetic_options = pd.concat([synthetic_calls, synthetic_puts], axis=0)\n",
    "synthetic_options = shuffle(synthetic_options, random_state=0)\n",
    "synthetic_options = synthetic_options.reset_index()\n",
    "synthetic_options = synthetic_options.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "WRaZp-1nFLa8",
    "outputId": "0ebfe2f0-ac80-456a-a230-780e80621839"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Strike</th>\n",
       "      <th>Type</th>\n",
       "      <th>Vol</th>\n",
       "      <th>Interest Rate</th>\n",
       "      <th>Time to Expiration</th>\n",
       "      <th>Option Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>97.0</td>\n",
       "      <td>C</td>\n",
       "      <td>0.799805</td>\n",
       "      <td>0.070007</td>\n",
       "      <td>0.600098</td>\n",
       "      <td>27.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>101.0</td>\n",
       "      <td>P</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.099976</td>\n",
       "      <td>0.600098</td>\n",
       "      <td>12.671875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>90.0</td>\n",
       "      <td>P</td>\n",
       "      <td>0.300049</td>\n",
       "      <td>0.059998</td>\n",
       "      <td>0.899902</td>\n",
       "      <td>4.707031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>104.0</td>\n",
       "      <td>P</td>\n",
       "      <td>0.899902</td>\n",
       "      <td>0.090027</td>\n",
       "      <td>0.899902</td>\n",
       "      <td>30.390625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>144.0</td>\n",
       "      <td>C</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.099976</td>\n",
       "      <td>0.899902</td>\n",
       "      <td>28.078125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Price  Strike Type       Vol  Interest Rate  Time to Expiration  \\\n",
       "0    100    97.0    C  0.799805       0.070007            0.600098   \n",
       "1    100   101.0    P  0.500000       0.099976            0.600098   \n",
       "2    100    90.0    P  0.300049       0.059998            0.899902   \n",
       "3    100   104.0    P  0.899902       0.090027            0.899902   \n",
       "4    100   144.0    C  1.000000       0.099976            0.899902   \n",
       "\n",
       "   Option Price  \n",
       "0     27.125000  \n",
       "1     12.671875  \n",
       "2      4.707031  \n",
       "3     30.390625  \n",
       "4     28.078125  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_options.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pFskCrb2wKil"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "C1GhYyqkFmc8"
   },
   "outputs": [],
   "source": [
    "synthetic_options = pd.get_dummies(synthetic_options, prefix='', prefix_sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "37ZypfWYwIZS"
   },
   "outputs": [],
   "source": [
    "input_sc = StandardScaler()\n",
    "output_sc = StandardScaler()\n",
    "input_data = input_sc.fit_transform(synthetic_options.drop('Option Price', axis=1))\n",
    "output_data = output_sc.fit_transform(synthetic_options['Option Price'].values.reshape(-1, 1))\n",
    "\n",
    "train_size = 0.9\n",
    "last_train_idx = int(np.round(len(input_data) * train_size))\n",
    "\n",
    "X_train = input_data[0:last_train_idx]\n",
    "X_test = input_data[last_train_idx:]\n",
    "\n",
    "y_train = output_data[0:last_train_idx]\n",
    "y_test = output_data[last_train_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zqw3nQdG5ca7"
   },
   "outputs": [],
   "source": [
    "X_train = Variable(torch.Tensor(X_train))\n",
    "X_test = Variable(torch.Tensor(X_test))\n",
    "\n",
    "y_train = Variable(torch.Tensor(y_train))\n",
    "y_test = Variable(torch.Tensor(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J2OS-HGd5gv_"
   },
   "source": [
    " # Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cZcW1lwB6pPa"
   },
   "outputs": [],
   "source": [
    "CUDA = torch.cuda.is_available()\n",
    "device = 'cuda:0' if CUDA else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "G4oQHZhCZvKK"
   },
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "\n",
    "  def __init__(self, module):\n",
    "    super(ResBlock, self).__init__()\n",
    "    self.module = module\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.module(x) + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "JbJDYtL86BIN"
   },
   "outputs": [],
   "source": [
    "class HiddenLayer(nn.Module):\n",
    "\n",
    "  def __init__(self, layer_size, act_fn):\n",
    "      super(HiddenLayer, self).__init__()\n",
    "      \n",
    "      if act_fn == 'ReLU':\n",
    "        self.layer = nn.Sequential(\n",
    "          nn.Linear(layer_size, layer_size),\n",
    "          nn.ReLU())\n",
    "      elif act_fn == 'LeakyReLU':\n",
    "        self.layer = nn.Sequential(\n",
    "          nn.Linear(layer_size, layer_size),\n",
    "          nn.LeakyReLU())\n",
    "      elif act_fn == 'ELU':\n",
    "        self.layer = nn.Sequential(\n",
    "          nn.Linear(layer_size, layer_size),\n",
    "          nn.ELU())\n",
    "    \n",
    "  def forward(self, x):\n",
    "    return self.layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "XO41ruSn5dZD"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "  def __init__(self, input_size, output_size, hidden_size, num_layers, act_fn):\n",
    "    super(Net, self).__init__()\n",
    "    self.input_size = input_size\n",
    "    self.output_size = output_size\n",
    "    self.hidden_size = hidden_size\n",
    "\n",
    "    if act_fn == 'ReLU':\n",
    "      self.initial_layer = nn.Sequential(\n",
    "          nn.Linear(self.input_size, self.hidden_size),\n",
    "          nn.ReLU())\n",
    "    elif act_fn == 'LeakyReLU':\n",
    "      self.initial_layer = nn.Sequential(\n",
    "          nn.Linear(self.input_size, self.hidden_size),\n",
    "          nn.LeakyReLU())\n",
    "    elif act_fn == 'ELU':\n",
    "      self.initial_layer = nn.Sequential(\n",
    "          nn.Linear(self.input_size, self.hidden_size),\n",
    "          nn.ELU())\n",
    "\n",
    "    self.hidden_layers_list = []\n",
    "\n",
    "    for i in range(num_layers // 2):\n",
    "      self.hidden_layers_list.append(\n",
    "          ResBlock(\n",
    "            nn.Sequential(\n",
    "                HiddenLayer(self.hidden_size, act_fn),\n",
    "                HiddenLayer(self.hidden_size, act_fn)\n",
    "            )\n",
    "        )\n",
    "      )\n",
    "\n",
    "    self.hidden_layers = nn.Sequential(*self.hidden_layers_list)\n",
    "\n",
    "    self.net = nn.Sequential(\n",
    "        self.initial_layer,\n",
    "        self.hidden_layers,\n",
    "        nn.Linear(self.hidden_size, self.output_size)\n",
    "    )\n",
    "  \n",
    "  def forward(self, x):\n",
    "    return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "E2VJ3Bi1rgeP"
   },
   "outputs": [],
   "source": [
    "def init_weights(m, init_m: str):\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def init_uniform(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "      torch.nn.init.uniform_(m.weight)\n",
    "      m.bias.data.fill_(0.01)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def init_normal(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "      torch.nn.init.normal_(m.weight)\n",
    "      m.bias.data.fill_(0.01)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def init_xuniform(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "      torch.nn.init.xavier_uniform_(m.weight)\n",
    "      m.bias.data.fill_(0.01)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def init_xnormal(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "      torch.nn.init.xavier_normal_(m.weight)\n",
    "      m.bias.data.fill_(0.01)\n",
    "\n",
    "  if init_m == 'uniform':\n",
    "    m.apply(init_uniform)\n",
    "  elif init_m == 'normal':\n",
    "    m.apply(init_normal)\n",
    "  elif init_m == 'xaiver uniform':\n",
    "    m.apply(init_xuniform)\n",
    "  elif init_m == 'xavier normal':\n",
    "    m.apply(init_xnormal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztiu-so7amMz"
   },
   "source": [
    "## Hyperparameter options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "OnIDl9Q1alxC"
   },
   "outputs": [],
   "source": [
    "hidden_size = [200, 400, 600]\n",
    "n_layers = [4, 6, 8]\n",
    "act_fun = ['ReLU', 'LeakyReLU', 'ELU']\n",
    "init_methods = ['xavier uniform', 'xavier normal']\n",
    "epochs = 25\n",
    "n_folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d0VRRxShvv5I",
    "outputId": "296940ec-6078-4160-8f29-88c89de6a38f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_params = list(product(hidden_size,\n",
    "                         n_layers,\n",
    "                         act_fun,\n",
    "                         init_methods))\n",
    "n_cv_params = len(cv_params)\n",
    "n_cv_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IubLoZx-wBmb",
    "outputId": "74475100-a401-402c-fafd-7b4443204e43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# CV parameters: 32\n"
     ]
    }
   ],
   "source": [
    "sample_proportion = 0.6\n",
    "sample_size = int(sample_proportion * n_cv_params)\n",
    "\n",
    "cv_param_sample = np.random.choice(list(range(n_cv_params)),\n",
    "                                     size=int(sample_size),\n",
    "                                     replace=False)\n",
    "cv_params_ = [cv_params[i] for i in cv_param_sample]\n",
    "print('# CV parameters:', len(cv_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vkv-KmfNVLoX"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "2SKLn8jU9DAu"
   },
   "outputs": [],
   "source": [
    "input_size = 7\n",
    "output_size = 1\n",
    "batch_size = 1208\n",
    "lr = 1e-4\n",
    "\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "eS2k1XKyDcB5"
   },
   "outputs": [],
   "source": [
    "class OptDataset(Dataset):\n",
    "\n",
    "  def __init__(self, X, y):\n",
    "    self.X = X\n",
    "    self.y = y\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.X[idx], self.y[idx]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "v0vrGBjGH7xA"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, loss_fn, X_val, y_val):\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    out = model(X_val)\n",
    "    loss = loss_fn(out, y_val)\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "1M6PuwBgzLYp"
   },
   "outputs": [],
   "source": [
    "crossval_result = pd.DataFrame(columns=\n",
    "                               ['hidden_size',\n",
    "                                'n_layers',\n",
    "                                'act_fun',\n",
    "                                'init_methods',\n",
    "                                'mean_val_result',\n",
    "                                'std_val_result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "jxUdG0Smz3nn"
   },
   "outputs": [],
   "source": [
    "def cross_validation(\n",
    "  cv_params_,\n",
    "  epochs,\n",
    "  n_folds,\n",
    "  batch_size,\n",
    "  X,\n",
    "  y,\n",
    "  loss_fn\n",
    "):\n",
    "  crossval_result = pd.DataFrame(columns=\n",
    "                               ['hidden_size',\n",
    "                                'n_layers',\n",
    "                                'act_fun',\n",
    "                                'init_methods',\n",
    "                                'mean_val_result',\n",
    "                                'std_val_result'])\n",
    "\n",
    "  for h_size, n_layers, act, init_m in cv_params_:\n",
    "    model = Net(input_size, output_size, h_size, n_layers, act).to(device)\n",
    "    init_weights(model, init_m)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    c_val_size = len(X) // n_folds\n",
    "\n",
    "    validation_losses = []\n",
    "    cv_res = {\n",
    "        'hidden_size': h_size,\n",
    "        'n_layers': n_layers,\n",
    "        'act_fun': act,\n",
    "        'init_methods': init_m\n",
    "    }\n",
    "\n",
    "    print('Model: ', cv_res)\n",
    "\n",
    "    for i in range(n_folds):\n",
    "      model.train()\n",
    "\n",
    "      X_train = torch.cat((X[0:c_val_size*i], X[c_val_size*(i+1):]))\n",
    "      y_train = torch.cat((y[0:c_val_size*i], y[c_val_size*(i+1):]))\n",
    "      X_val = X[c_val_size*i:c_val_size*(i+1)]\n",
    "      y_val = y[c_val_size*i:c_val_size*(i+1)]\n",
    "\n",
    "      for epoch in range(epochs):\n",
    "\n",
    "        for batch, batch_labels in DataLoader(OptDataset(\n",
    "            X_train, \n",
    "            y_train), \n",
    "            batch_size=batch_size):\n",
    "          out = model(batch.to(device))\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          loss = loss_fn(out, batch_labels.to(device))\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "\n",
    "        validation_losses.append(evaluate(model, \n",
    "                                          loss_fn, \n",
    "                                          X_val.to(device), \n",
    "                                          y_val.to(device)))\n",
    "        print('fold: ', i + 1 ,', epoch: ', epoch + 1, ', val loss: ', validation_losses[-1])\n",
    "\n",
    "    validation_losses = np.array(validation_losses)\n",
    "    cv_res['mean_val_result'] = validation_losses.mean()\n",
    "    cv_res['std_val_result'] = validation_losses.std()\n",
    "    print('Model results: ', cv_res, '\\n')\n",
    "    crossval_result = crossval_result.append(cv_res, ignore_index=True)\n",
    "\n",
    "\n",
    "  return crossval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U_qp8B6KAnv7",
    "outputId": "12765d6e-1454-4e2d-dcba-c9405f9eb1c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  {'hidden_size': 600, 'n_layers': 8, 'act_fun': 'ELU', 'init_methods': 'xavier normal'}\n",
      "fold:  1 , epoch:  1 , val loss:  0.004184442572295666\n",
      "fold:  1 , epoch:  2 , val loss:  0.001227384665980935\n",
      "fold:  1 , epoch:  3 , val loss:  0.0015790387988090515\n",
      "fold:  1 , epoch:  4 , val loss:  0.00038043083623051643\n",
      "fold:  1 , epoch:  5 , val loss:  0.0003624866367317736\n",
      "fold:  1 , epoch:  6 , val loss:  0.00028280678088776767\n",
      "fold:  1 , epoch:  7 , val loss:  0.0010647728340700269\n",
      "fold:  1 , epoch:  8 , val loss:  0.00032244017347693443\n",
      "fold:  1 , epoch:  9 , val loss:  0.00016348068311344832\n",
      "fold:  1 , epoch:  10 , val loss:  0.0005539879784919322\n",
      "fold:  1 , epoch:  11 , val loss:  0.00019334722310304642\n",
      "fold:  1 , epoch:  12 , val loss:  0.0009476420818828046\n",
      "fold:  1 , epoch:  13 , val loss:  0.0010139707010239363\n",
      "fold:  1 , epoch:  14 , val loss:  0.0016273148357868195\n",
      "fold:  1 , epoch:  15 , val loss:  0.00017711175314616412\n",
      "fold:  1 , epoch:  16 , val loss:  0.00010271321662003174\n",
      "fold:  1 , epoch:  17 , val loss:  0.0006399194244295359\n",
      "fold:  1 , epoch:  18 , val loss:  0.00014152814401313663\n",
      "fold:  1 , epoch:  19 , val loss:  0.0004890031414106488\n",
      "fold:  1 , epoch:  20 , val loss:  8.739537588553503e-05\n",
      "fold:  1 , epoch:  21 , val loss:  0.00011192316742381081\n",
      "fold:  1 , epoch:  22 , val loss:  0.0003483545151539147\n",
      "fold:  1 , epoch:  23 , val loss:  0.00021383841522037983\n",
      "fold:  1 , epoch:  24 , val loss:  0.0001249409542651847\n",
      "fold:  1 , epoch:  25 , val loss:  7.608738815179095e-05\n",
      "fold:  2 , epoch:  1 , val loss:  0.0003152632270939648\n",
      "fold:  2 , epoch:  2 , val loss:  0.00043493954581208527\n",
      "fold:  2 , epoch:  3 , val loss:  0.00016583000251557678\n",
      "fold:  2 , epoch:  4 , val loss:  0.00036037256359122694\n",
      "fold:  2 , epoch:  5 , val loss:  0.00024781603133305907\n",
      "fold:  2 , epoch:  6 , val loss:  9.019533899845555e-05\n",
      "fold:  2 , epoch:  7 , val loss:  0.0006900831358507276\n",
      "fold:  2 , epoch:  8 , val loss:  8.407842688029632e-05\n",
      "fold:  2 , epoch:  9 , val loss:  0.00018123140034731477\n",
      "fold:  2 , epoch:  10 , val loss:  0.0002125709579559043\n",
      "fold:  2 , epoch:  11 , val loss:  0.0002790855651255697\n",
      "fold:  2 , epoch:  12 , val loss:  0.00019651130423881114\n",
      "fold:  2 , epoch:  13 , val loss:  0.00029267132049426436\n",
      "fold:  2 , epoch:  14 , val loss:  0.00015274234465323389\n",
      "fold:  2 , epoch:  15 , val loss:  4.606822403729893e-05\n",
      "fold:  2 , epoch:  16 , val loss:  6.594685692107305e-05\n",
      "fold:  2 , epoch:  17 , val loss:  0.00013649732863996178\n",
      "fold:  2 , epoch:  18 , val loss:  0.00010173865302931517\n",
      "fold:  2 , epoch:  19 , val loss:  0.00014881642709951848\n",
      "fold:  2 , epoch:  20 , val loss:  0.00026446609990671277\n",
      "fold:  2 , epoch:  21 , val loss:  0.0003348766767885536\n",
      "fold:  2 , epoch:  22 , val loss:  0.0004214841465000063\n",
      "fold:  2 , epoch:  23 , val loss:  0.00021887788898311555\n",
      "fold:  2 , epoch:  24 , val loss:  0.00020859780488535762\n",
      "fold:  2 , epoch:  25 , val loss:  0.0004421230114530772\n",
      "fold:  3 , epoch:  1 , val loss:  2.8469286917243153e-05\n",
      "fold:  3 , epoch:  2 , val loss:  9.235483594238758e-05\n",
      "fold:  3 , epoch:  3 , val loss:  0.000124447513371706\n",
      "fold:  3 , epoch:  4 , val loss:  0.00028609903529286385\n",
      "fold:  3 , epoch:  5 , val loss:  6.743923586327583e-05\n",
      "fold:  3 , epoch:  6 , val loss:  3.095662759733386e-05\n",
      "fold:  3 , epoch:  7 , val loss:  0.00023262601462192833\n",
      "fold:  3 , epoch:  8 , val loss:  0.00041242994484491646\n",
      "fold:  3 , epoch:  9 , val loss:  1.9308437913423404e-05\n",
      "fold:  3 , epoch:  10 , val loss:  2.748376391537022e-05\n",
      "fold:  3 , epoch:  11 , val loss:  9.454791870666668e-05\n",
      "fold:  3 , epoch:  12 , val loss:  0.0002928601170424372\n",
      "fold:  3 , epoch:  13 , val loss:  0.0003039884031750262\n",
      "fold:  3 , epoch:  14 , val loss:  0.0001945413532666862\n",
      "fold:  3 , epoch:  15 , val loss:  0.00010262027353746817\n",
      "fold:  3 , epoch:  16 , val loss:  1.9022098058485426e-05\n",
      "fold:  3 , epoch:  17 , val loss:  6.019124703016132e-05\n",
      "fold:  3 , epoch:  18 , val loss:  0.0001762898318702355\n",
      "fold:  3 , epoch:  19 , val loss:  0.0002654064737726003\n",
      "fold:  3 , epoch:  20 , val loss:  5.156108090886846e-05\n",
      "fold:  3 , epoch:  21 , val loss:  4.7932400775607675e-05\n",
      "fold:  3 , epoch:  22 , val loss:  1.8219243429484777e-05\n",
      "fold:  3 , epoch:  23 , val loss:  0.0001541044475743547\n",
      "fold:  3 , epoch:  24 , val loss:  0.000105615945358295\n",
      "fold:  3 , epoch:  25 , val loss:  3.1846928322920576e-05\n",
      "fold:  4 , epoch:  1 , val loss:  1.52684842760209e-05\n",
      "fold:  4 , epoch:  2 , val loss:  7.277720578713343e-05\n",
      "fold:  4 , epoch:  3 , val loss:  0.00011179417924722657\n",
      "fold:  4 , epoch:  4 , val loss:  1.1117762369394768e-05\n",
      "fold:  4 , epoch:  5 , val loss:  0.00015472766244783998\n",
      "fold:  4 , epoch:  6 , val loss:  8.831363629724365e-06\n",
      "fold:  4 , epoch:  7 , val loss:  0.0002995004178956151\n",
      "fold:  4 , epoch:  8 , val loss:  2.772902007563971e-05\n",
      "fold:  4 , epoch:  9 , val loss:  1.1493845704535488e-05\n",
      "fold:  4 , epoch:  10 , val loss:  1.0547983038122766e-05\n",
      "fold:  4 , epoch:  11 , val loss:  6.0079750255681574e-05\n",
      "fold:  4 , epoch:  12 , val loss:  1.0873095561692026e-05\n",
      "fold:  4 , epoch:  13 , val loss:  2.629663322295528e-05\n",
      "fold:  4 , epoch:  14 , val loss:  0.00016982834495138377\n",
      "fold:  4 , epoch:  15 , val loss:  1.228505152539583e-05\n",
      "fold:  4 , epoch:  16 , val loss:  0.00025372346863150597\n",
      "fold:  4 , epoch:  17 , val loss:  8.869911835063249e-05\n",
      "fold:  4 , epoch:  18 , val loss:  2.5902860215865076e-05\n",
      "fold:  4 , epoch:  19 , val loss:  1.6116271581267938e-05\n",
      "fold:  4 , epoch:  20 , val loss:  8.483949386572931e-06\n",
      "fold:  4 , epoch:  21 , val loss:  1.8153554265154526e-05\n",
      "fold:  4 , epoch:  22 , val loss:  9.308160770160612e-06\n",
      "fold:  4 , epoch:  23 , val loss:  0.00012642843648791313\n",
      "fold:  4 , epoch:  24 , val loss:  7.67016717873048e-06\n",
      "fold:  4 , epoch:  25 , val loss:  7.75214266468538e-06\n",
      "fold:  5 , epoch:  1 , val loss:  2.1124609702383168e-05\n",
      "fold:  5 , epoch:  2 , val loss:  0.00016208700253628194\n",
      "fold:  5 , epoch:  3 , val loss:  2.0629015125450678e-05\n",
      "fold:  5 , epoch:  4 , val loss:  1.666725984250661e-05\n",
      "fold:  5 , epoch:  5 , val loss:  6.9749075919389725e-06\n",
      "fold:  5 , epoch:  6 , val loss:  6.956367724342272e-05\n",
      "fold:  5 , epoch:  7 , val loss:  5.876494014955824e-06\n",
      "fold:  5 , epoch:  8 , val loss:  1.9720800992217846e-05\n",
      "fold:  5 , epoch:  9 , val loss:  5.376457920647226e-05\n",
      "fold:  5 , epoch:  10 , val loss:  8.02273461886216e-06\n",
      "fold:  5 , epoch:  11 , val loss:  0.00023552072525490075\n",
      "fold:  5 , epoch:  12 , val loss:  2.7358824809198268e-05\n",
      "fold:  5 , epoch:  13 , val loss:  3.338958049425855e-05\n",
      "fold:  5 , epoch:  14 , val loss:  2.939640216936823e-05\n",
      "fold:  5 , epoch:  15 , val loss:  3.4159682400058955e-05\n",
      "fold:  5 , epoch:  16 , val loss:  7.395737156912219e-06\n",
      "fold:  5 , epoch:  17 , val loss:  3.279308293713257e-05\n",
      "fold:  5 , epoch:  18 , val loss:  0.00015678026829846203\n",
      "fold:  5 , epoch:  19 , val loss:  5.006355422665365e-06\n",
      "fold:  5 , epoch:  20 , val loss:  1.2604523362824693e-05\n",
      "fold:  5 , epoch:  21 , val loss:  5.952388164587319e-06\n",
      "fold:  5 , epoch:  22 , val loss:  3.6121018638368696e-06\n",
      "fold:  5 , epoch:  23 , val loss:  1.4371827091963496e-05\n",
      "fold:  5 , epoch:  24 , val loss:  0.0001742447930155322\n",
      "fold:  5 , epoch:  25 , val loss:  7.736516272416338e-05\n",
      "Model results:  {'hidden_size': 600, 'n_layers': 8, 'act_fun': 'ELU', 'init_methods': 'xavier normal', 'mean_val_result': 0.00022839504404328182, 'std_val_result': 0.00045243396068718196} \n",
      "\n",
      "Model:  {'hidden_size': 400, 'n_layers': 8, 'act_fun': 'LeakyReLU', 'init_methods': 'xavier normal'}\n",
      "fold:  1 , epoch:  1 , val loss:  0.0002770586870610714\n",
      "fold:  1 , epoch:  2 , val loss:  0.00032006503897719085\n",
      "fold:  1 , epoch:  3 , val loss:  0.0002972064830828458\n",
      "fold:  1 , epoch:  4 , val loss:  0.0001295701222261414\n",
      "fold:  1 , epoch:  5 , val loss:  0.0001364108029520139\n",
      "fold:  1 , epoch:  6 , val loss:  4.411139525473118e-05\n",
      "fold:  1 , epoch:  7 , val loss:  4.104174513486214e-05\n",
      "fold:  1 , epoch:  8 , val loss:  5.1244023779872805e-05\n",
      "fold:  1 , epoch:  9 , val loss:  7.017731695668772e-05\n",
      "fold:  1 , epoch:  10 , val loss:  2.4439181288471445e-05\n",
      "fold:  1 , epoch:  11 , val loss:  0.00031955563463270664\n",
      "fold:  1 , epoch:  12 , val loss:  5.896134825889021e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  1 , epoch:  13 , val loss:  6.318851956166327e-05\n",
      "fold:  1 , epoch:  14 , val loss:  2.0704970665974542e-05\n",
      "fold:  1 , epoch:  15 , val loss:  3.3405063732061535e-05\n",
      "fold:  1 , epoch:  16 , val loss:  7.820063183316961e-05\n",
      "fold:  1 , epoch:  17 , val loss:  0.00025096317403949797\n",
      "fold:  1 , epoch:  18 , val loss:  2.0367167962831445e-05\n",
      "fold:  1 , epoch:  19 , val loss:  2.4869646949809976e-05\n",
      "fold:  1 , epoch:  20 , val loss:  8.727824024390429e-05\n",
      "fold:  1 , epoch:  21 , val loss:  2.6011586669483222e-05\n",
      "fold:  1 , epoch:  22 , val loss:  0.00011127620382467285\n",
      "fold:  1 , epoch:  23 , val loss:  2.6818608603207394e-05\n",
      "fold:  1 , epoch:  24 , val loss:  1.7316519006271847e-05\n",
      "fold:  1 , epoch:  25 , val loss:  5.472290649777278e-05\n",
      "fold:  2 , epoch:  1 , val loss:  0.00010275805834680796\n",
      "fold:  2 , epoch:  2 , val loss:  1.7212822058354504e-05\n",
      "fold:  2 , epoch:  3 , val loss:  1.416673057974549e-05\n",
      "fold:  2 , epoch:  4 , val loss:  1.8451924916007556e-05\n",
      "fold:  2 , epoch:  5 , val loss:  1.1731359336408786e-05\n",
      "fold:  2 , epoch:  6 , val loss:  1.590011379448697e-05\n",
      "fold:  2 , epoch:  7 , val loss:  6.825228774687275e-05\n",
      "fold:  2 , epoch:  8 , val loss:  5.1463244744809344e-05\n",
      "fold:  2 , epoch:  9 , val loss:  4.644721411750652e-05\n",
      "fold:  2 , epoch:  10 , val loss:  3.12358170049265e-05\n",
      "fold:  2 , epoch:  11 , val loss:  8.203602192224935e-05\n",
      "fold:  2 , epoch:  12 , val loss:  4.043037915835157e-05\n",
      "fold:  2 , epoch:  13 , val loss:  3.3437285310355946e-05\n",
      "fold:  2 , epoch:  14 , val loss:  1.2954517842445057e-05\n",
      "fold:  2 , epoch:  15 , val loss:  1.3340714758669492e-05\n",
      "fold:  2 , epoch:  16 , val loss:  1.4668787116534077e-05\n",
      "fold:  2 , epoch:  17 , val loss:  9.869517270999495e-06\n",
      "fold:  2 , epoch:  18 , val loss:  5.2699069783557206e-05\n",
      "fold:  2 , epoch:  19 , val loss:  2.9760603865724988e-05\n",
      "fold:  2 , epoch:  20 , val loss:  2.206500903412234e-05\n",
      "fold:  2 , epoch:  21 , val loss:  9.140670954366215e-06\n",
      "fold:  2 , epoch:  22 , val loss:  1.3480987945513334e-05\n",
      "fold:  2 , epoch:  23 , val loss:  7.0211808633757755e-06\n",
      "fold:  2 , epoch:  24 , val loss:  7.553274826932466e-06\n",
      "fold:  2 , epoch:  25 , val loss:  1.2795351722161286e-05\n",
      "fold:  3 , epoch:  1 , val loss:  1.0737783668446355e-05\n",
      "fold:  3 , epoch:  2 , val loss:  1.7729596947901882e-05\n",
      "fold:  3 , epoch:  3 , val loss:  8.281422196887434e-06\n",
      "fold:  3 , epoch:  4 , val loss:  2.5968118279706687e-05\n",
      "fold:  3 , epoch:  5 , val loss:  3.3512515074107796e-05\n",
      "fold:  3 , epoch:  6 , val loss:  2.5685983928269707e-05\n",
      "fold:  3 , epoch:  7 , val loss:  1.1894061572093051e-05\n",
      "fold:  3 , epoch:  8 , val loss:  4.18525560235139e-05\n",
      "fold:  3 , epoch:  9 , val loss:  2.1517242203117348e-05\n",
      "fold:  3 , epoch:  10 , val loss:  7.1720573942002375e-06\n",
      "fold:  3 , epoch:  11 , val loss:  3.931661922251806e-05\n",
      "fold:  3 , epoch:  12 , val loss:  5.387120381783461e-06\n",
      "fold:  3 , epoch:  13 , val loss:  8.596677616878878e-06\n",
      "fold:  3 , epoch:  14 , val loss:  2.3741939003230073e-05\n",
      "fold:  3 , epoch:  15 , val loss:  1.25915994431125e-05\n",
      "fold:  3 , epoch:  16 , val loss:  8.020459972613025e-06\n",
      "fold:  3 , epoch:  17 , val loss:  3.825207386398688e-05\n",
      "fold:  3 , epoch:  18 , val loss:  6.689652218483388e-05\n",
      "fold:  3 , epoch:  19 , val loss:  5.8442142290004995e-06\n",
      "fold:  3 , epoch:  20 , val loss:  2.033579039562028e-05\n",
      "fold:  3 , epoch:  21 , val loss:  6.057825157768093e-05\n",
      "fold:  3 , epoch:  22 , val loss:  1.0888910765061155e-05\n",
      "fold:  3 , epoch:  23 , val loss:  1.0499730706214905e-05\n",
      "fold:  3 , epoch:  24 , val loss:  0.00010164184641325846\n",
      "fold:  3 , epoch:  25 , val loss:  1.844333382905461e-05\n",
      "fold:  4 , epoch:  1 , val loss:  3.3131542295450345e-05\n",
      "fold:  4 , epoch:  2 , val loss:  1.617933412489947e-05\n",
      "fold:  4 , epoch:  3 , val loss:  9.706503988127224e-06\n",
      "fold:  4 , epoch:  4 , val loss:  5.440515451482497e-06\n",
      "fold:  4 , epoch:  5 , val loss:  8.07262313173851e-06\n",
      "fold:  4 , epoch:  6 , val loss:  6.721141107846051e-05\n",
      "fold:  4 , epoch:  7 , val loss:  5.756950122304261e-05\n",
      "fold:  4 , epoch:  8 , val loss:  7.499790172005305e-06\n",
      "fold:  4 , epoch:  9 , val loss:  4.169940893916646e-06\n",
      "fold:  4 , epoch:  10 , val loss:  1.6196876458707266e-05\n",
      "fold:  4 , epoch:  11 , val loss:  1.8306667698197998e-05\n",
      "fold:  4 , epoch:  12 , val loss:  2.265335751872044e-05\n",
      "fold:  4 , epoch:  13 , val loss:  1.6865174984559417e-05\n",
      "fold:  4 , epoch:  14 , val loss:  5.337191396392882e-06\n",
      "fold:  4 , epoch:  15 , val loss:  5.564083949138876e-06\n",
      "fold:  4 , epoch:  16 , val loss:  0.00013503426453098655\n",
      "fold:  4 , epoch:  17 , val loss:  1.2809709915018175e-05\n",
      "fold:  4 , epoch:  18 , val loss:  1.0610516255837865e-05\n",
      "fold:  4 , epoch:  19 , val loss:  3.142981222481467e-05\n",
      "fold:  4 , epoch:  20 , val loss:  6.781202955608023e-06\n",
      "fold:  4 , epoch:  21 , val loss:  4.084903594048228e-06\n",
      "fold:  4 , epoch:  22 , val loss:  3.6584165172826033e-06\n",
      "fold:  4 , epoch:  23 , val loss:  8.115676791931037e-06\n",
      "fold:  4 , epoch:  24 , val loss:  1.8848906620405614e-05\n",
      "fold:  4 , epoch:  25 , val loss:  9.300831152359024e-06\n",
      "fold:  5 , epoch:  1 , val loss:  4.018812433059793e-06\n",
      "fold:  5 , epoch:  2 , val loss:  3.5527473301044665e-06\n",
      "fold:  5 , epoch:  3 , val loss:  1.4912039659975562e-05\n",
      "fold:  5 , epoch:  4 , val loss:  3.034884457520093e-06\n",
      "fold:  5 , epoch:  5 , val loss:  1.4505418221233413e-05\n",
      "fold:  5 , epoch:  6 , val loss:  1.3080112694296986e-05\n",
      "fold:  5 , epoch:  7 , val loss:  1.2031044207105879e-05\n",
      "fold:  5 , epoch:  8 , val loss:  4.5296724238141906e-06\n",
      "fold:  5 , epoch:  9 , val loss:  7.026510502328165e-06\n",
      "fold:  5 , epoch:  10 , val loss:  1.6956215404206887e-05\n",
      "fold:  5 , epoch:  11 , val loss:  4.4517881178762764e-05\n",
      "fold:  5 , epoch:  12 , val loss:  2.7378675895306515e-06\n",
      "fold:  5 , epoch:  13 , val loss:  8.142696970026009e-06\n",
      "fold:  5 , epoch:  14 , val loss:  3.642774800027837e-06\n",
      "fold:  5 , epoch:  15 , val loss:  2.0216944903950207e-05\n",
      "fold:  5 , epoch:  16 , val loss:  8.817130037641618e-06\n",
      "fold:  5 , epoch:  17 , val loss:  2.1473899323609658e-05\n",
      "fold:  5 , epoch:  18 , val loss:  6.638114427914843e-06\n",
      "fold:  5 , epoch:  19 , val loss:  6.481086074927589e-06\n",
      "fold:  5 , epoch:  20 , val loss:  2.0587172912200913e-05\n",
      "fold:  5 , epoch:  21 , val loss:  5.363261152524501e-05\n",
      "fold:  5 , epoch:  22 , val loss:  1.5199169865809381e-05\n",
      "fold:  5 , epoch:  23 , val loss:  1.2560012692119926e-05\n",
      "fold:  5 , epoch:  24 , val loss:  7.741588888166007e-06\n",
      "fold:  5 , epoch:  25 , val loss:  4.710831944976235e-06\n",
      "Model results:  {'hidden_size': 400, 'n_layers': 8, 'act_fun': 'LeakyReLU', 'init_methods': 'xavier normal', 'mean_val_result': 3.8596403092014954e-05, 'std_val_result': 5.928006176370393e-05} \n",
      "\n",
      "Model:  {'hidden_size': 600, 'n_layers': 8, 'act_fun': 'ReLU', 'init_methods': 'xavier uniform'}\n",
      "fold:  1 , epoch:  1 , val loss:  0.000469947379315272\n",
      "fold:  1 , epoch:  2 , val loss:  0.00010938616469502449\n",
      "fold:  1 , epoch:  3 , val loss:  4.894234371022321e-05\n",
      "fold:  1 , epoch:  4 , val loss:  0.0001835964503698051\n",
      "fold:  1 , epoch:  5 , val loss:  7.565411215182394e-05\n",
      "fold:  1 , epoch:  6 , val loss:  5.797352423542179e-05\n",
      "fold:  1 , epoch:  7 , val loss:  2.2958578483667225e-05\n",
      "fold:  1 , epoch:  8 , val loss:  0.00014953977370169014\n",
      "fold:  1 , epoch:  9 , val loss:  2.9926040951977484e-05\n",
      "fold:  1 , epoch:  10 , val loss:  0.0001068958081305027\n",
      "fold:  1 , epoch:  11 , val loss:  3.679240035125986e-05\n",
      "fold:  1 , epoch:  12 , val loss:  2.7702610168489628e-05\n",
      "fold:  1 , epoch:  13 , val loss:  1.7164695236715488e-05\n",
      "fold:  1 , epoch:  14 , val loss:  1.8881857613450848e-05\n",
      "fold:  1 , epoch:  15 , val loss:  1.400311248289654e-05\n",
      "fold:  1 , epoch:  16 , val loss:  8.7646723841317e-05\n",
      "fold:  1 , epoch:  17 , val loss:  2.6124585929210298e-05\n",
      "fold:  1 , epoch:  18 , val loss:  0.0004012338467873633\n",
      "fold:  1 , epoch:  19 , val loss:  9.774992577149533e-06\n",
      "fold:  1 , epoch:  20 , val loss:  1.2046076335536782e-05\n",
      "fold:  1 , epoch:  21 , val loss:  1.6858290109666996e-05\n",
      "fold:  1 , epoch:  22 , val loss:  3.5734392440645024e-05\n",
      "fold:  1 , epoch:  23 , val loss:  3.667317287181504e-05\n",
      "fold:  1 , epoch:  24 , val loss:  3.2505078706890345e-05\n",
      "fold:  1 , epoch:  25 , val loss:  7.4255581239413004e-06\n",
      "fold:  2 , epoch:  1 , val loss:  2.253154707432259e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  2 , epoch:  2 , val loss:  1.159082239610143e-05\n",
      "fold:  2 , epoch:  3 , val loss:  9.692519597592764e-06\n",
      "fold:  2 , epoch:  4 , val loss:  1.0515496796870138e-05\n",
      "fold:  2 , epoch:  5 , val loss:  9.716713975649327e-06\n",
      "fold:  2 , epoch:  6 , val loss:  6.135208877822151e-06\n",
      "fold:  2 , epoch:  7 , val loss:  1.2552953194244765e-05\n",
      "fold:  2 , epoch:  8 , val loss:  5.644363409373909e-05\n",
      "fold:  2 , epoch:  9 , val loss:  2.062359453702811e-05\n",
      "fold:  2 , epoch:  10 , val loss:  2.7827649319078773e-05\n",
      "fold:  2 , epoch:  11 , val loss:  1.8319253285881132e-05\n",
      "fold:  2 , epoch:  12 , val loss:  1.9400720702833496e-05\n",
      "fold:  2 , epoch:  13 , val loss:  5.754057383455802e-06\n",
      "fold:  2 , epoch:  14 , val loss:  7.725527211732697e-06\n",
      "fold:  2 , epoch:  15 , val loss:  4.020398046122864e-05\n",
      "fold:  2 , epoch:  16 , val loss:  9.869249879557174e-06\n",
      "fold:  2 , epoch:  17 , val loss:  1.835109833336901e-05\n",
      "fold:  2 , epoch:  18 , val loss:  6.290745204751147e-06\n",
      "fold:  2 , epoch:  19 , val loss:  2.511904494895134e-05\n",
      "fold:  2 , epoch:  20 , val loss:  4.637070378521457e-05\n",
      "fold:  2 , epoch:  21 , val loss:  2.851715726137627e-05\n",
      "fold:  2 , epoch:  22 , val loss:  2.1951900635031052e-05\n",
      "fold:  2 , epoch:  23 , val loss:  1.2638932275876869e-05\n",
      "fold:  2 , epoch:  24 , val loss:  8.554387022741139e-06\n",
      "fold:  2 , epoch:  25 , val loss:  9.490628144703805e-06\n",
      "fold:  3 , epoch:  1 , val loss:  8.178535790648311e-05\n",
      "fold:  3 , epoch:  2 , val loss:  5.699016583093908e-06\n",
      "fold:  3 , epoch:  3 , val loss:  1.2984341992705595e-05\n",
      "fold:  3 , epoch:  4 , val loss:  4.419096057972638e-06\n",
      "fold:  3 , epoch:  5 , val loss:  2.131586370524019e-05\n",
      "fold:  3 , epoch:  6 , val loss:  2.5428829758311622e-05\n",
      "fold:  3 , epoch:  7 , val loss:  3.9077574911061674e-05\n",
      "fold:  3 , epoch:  8 , val loss:  2.2105799871496856e-05\n",
      "fold:  3 , epoch:  9 , val loss:  1.5103320038178936e-05\n",
      "fold:  3 , epoch:  10 , val loss:  1.6262163626379333e-05\n",
      "fold:  3 , epoch:  11 , val loss:  1.034371780406218e-05\n",
      "fold:  3 , epoch:  12 , val loss:  2.6086783691425808e-05\n",
      "fold:  3 , epoch:  13 , val loss:  4.731451099360129e-06\n",
      "fold:  3 , epoch:  14 , val loss:  8.06884781923145e-06\n",
      "fold:  3 , epoch:  15 , val loss:  8.35088940220885e-06\n",
      "fold:  3 , epoch:  16 , val loss:  6.74708717269823e-05\n",
      "fold:  3 , epoch:  17 , val loss:  2.49802087637363e-05\n",
      "fold:  3 , epoch:  18 , val loss:  5.931211944698589e-06\n",
      "fold:  3 , epoch:  19 , val loss:  2.9712330160691636e-06\n",
      "fold:  3 , epoch:  20 , val loss:  1.0300583198841196e-05\n",
      "fold:  3 , epoch:  21 , val loss:  1.3580631275544874e-05\n",
      "fold:  3 , epoch:  22 , val loss:  1.5473025996470824e-05\n",
      "fold:  3 , epoch:  23 , val loss:  1.3195965948398225e-05\n",
      "fold:  3 , epoch:  24 , val loss:  3.985795956396032e-06\n",
      "fold:  3 , epoch:  25 , val loss:  3.102278014921467e-06\n",
      "fold:  4 , epoch:  1 , val loss:  3.504872211124166e-06\n",
      "fold:  4 , epoch:  2 , val loss:  8.33698231872404e-06\n",
      "fold:  4 , epoch:  3 , val loss:  7.804672350175679e-06\n",
      "fold:  4 , epoch:  4 , val loss:  5.072038675280055e-06\n",
      "fold:  4 , epoch:  5 , val loss:  3.041131776626571e-06\n",
      "fold:  4 , epoch:  6 , val loss:  3.4235829389217542e-06\n",
      "fold:  4 , epoch:  7 , val loss:  6.488395683845738e-06\n",
      "fold:  4 , epoch:  8 , val loss:  2.2092952349339612e-05\n",
      "fold:  4 , epoch:  9 , val loss:  2.0152379875071347e-05\n",
      "fold:  4 , epoch:  10 , val loss:  3.6269323118176544e-06\n",
      "fold:  4 , epoch:  11 , val loss:  3.88680837204447e-06\n",
      "fold:  4 , epoch:  12 , val loss:  3.973071216023527e-06\n",
      "fold:  4 , epoch:  13 , val loss:  3.5308135011291597e-06\n",
      "fold:  4 , epoch:  14 , val loss:  4.3301279220031574e-05\n",
      "fold:  4 , epoch:  15 , val loss:  4.608652943716152e-06\n",
      "fold:  4 , epoch:  16 , val loss:  3.5521316021913663e-06\n",
      "fold:  4 , epoch:  17 , val loss:  2.9738789635302965e-06\n",
      "fold:  4 , epoch:  18 , val loss:  3.2554187328059925e-06\n",
      "fold:  4 , epoch:  19 , val loss:  6.92753155817627e-06\n",
      "fold:  4 , epoch:  20 , val loss:  3.5179202768631512e-06\n",
      "fold:  4 , epoch:  21 , val loss:  2.044359098363202e-05\n",
      "fold:  4 , epoch:  22 , val loss:  1.2555070497910492e-05\n",
      "fold:  4 , epoch:  23 , val loss:  9.381190466228873e-06\n",
      "fold:  4 , epoch:  24 , val loss:  3.577778898034012e-06\n",
      "fold:  4 , epoch:  25 , val loss:  4.336267011240125e-06\n",
      "fold:  5 , epoch:  1 , val loss:  3.9772307900420856e-06\n",
      "fold:  5 , epoch:  2 , val loss:  1.4726183508173563e-05\n",
      "fold:  5 , epoch:  3 , val loss:  0.0001016299138427712\n",
      "fold:  5 , epoch:  4 , val loss:  1.055196116794832e-05\n",
      "fold:  5 , epoch:  5 , val loss:  6.857791504444322e-06\n",
      "fold:  5 , epoch:  6 , val loss:  9.6699150162749e-06\n",
      "fold:  5 , epoch:  7 , val loss:  5.839297500642715e-06\n",
      "fold:  5 , epoch:  8 , val loss:  2.960667188744992e-05\n",
      "fold:  5 , epoch:  9 , val loss:  1.3304957064974587e-05\n",
      "fold:  5 , epoch:  10 , val loss:  3.6573378565663006e-06\n",
      "fold:  5 , epoch:  11 , val loss:  3.908218786818907e-06\n",
      "fold:  5 , epoch:  12 , val loss:  3.1776903597346973e-06\n",
      "fold:  5 , epoch:  13 , val loss:  4.352804353402462e-06\n",
      "fold:  5 , epoch:  14 , val loss:  1.5292804164346308e-05\n",
      "fold:  5 , epoch:  15 , val loss:  5.71550026506884e-06\n",
      "fold:  5 , epoch:  16 , val loss:  6.399319772754097e-06\n",
      "fold:  5 , epoch:  17 , val loss:  2.7016801595891593e-06\n",
      "fold:  5 , epoch:  18 , val loss:  3.055418574149371e-06\n",
      "fold:  5 , epoch:  19 , val loss:  6.2709245867154095e-06\n",
      "fold:  5 , epoch:  20 , val loss:  4.743728368339362e-06\n",
      "fold:  5 , epoch:  21 , val loss:  2.802538574542268e-06\n",
      "fold:  5 , epoch:  22 , val loss:  4.554807674139738e-06\n",
      "fold:  5 , epoch:  23 , val loss:  3.658760078906198e-06\n",
      "fold:  5 , epoch:  24 , val loss:  2.4361397663597018e-06\n",
      "fold:  5 , epoch:  25 , val loss:  5.772425993200159e-06\n",
      "Model results:  {'hidden_size': 600, 'n_layers': 8, 'act_fun': 'ReLU', 'init_methods': 'xavier uniform', 'mean_val_result': 2.7618874577456153e-05, 'std_val_result': 5.9394655263826497e-05} \n",
      "\n",
      "Model:  {'hidden_size': 400, 'n_layers': 6, 'act_fun': 'LeakyReLU', 'init_methods': 'xavier uniform'}\n",
      "fold:  1 , epoch:  1 , val loss:  0.00023231349769048393\n",
      "fold:  1 , epoch:  2 , val loss:  9.432752267457545e-05\n",
      "fold:  1 , epoch:  3 , val loss:  6.694236799376085e-05\n",
      "fold:  1 , epoch:  4 , val loss:  7.487182301701978e-05\n",
      "fold:  1 , epoch:  5 , val loss:  6.389198097167537e-05\n",
      "fold:  1 , epoch:  6 , val loss:  3.414716775296256e-05\n",
      "fold:  1 , epoch:  7 , val loss:  3.840577119262889e-05\n",
      "fold:  1 , epoch:  8 , val loss:  4.88298901473172e-05\n",
      "fold:  1 , epoch:  9 , val loss:  9.49976674746722e-05\n",
      "fold:  1 , epoch:  10 , val loss:  2.5592797101126052e-05\n",
      "fold:  1 , epoch:  11 , val loss:  2.38696356973378e-05\n",
      "fold:  1 , epoch:  12 , val loss:  6.0275615396676585e-05\n",
      "fold:  1 , epoch:  13 , val loss:  6.834688974777237e-05\n",
      "fold:  1 , epoch:  14 , val loss:  3.2588588510407135e-05\n",
      "fold:  1 , epoch:  15 , val loss:  3.233152165194042e-05\n",
      "fold:  1 , epoch:  16 , val loss:  3.1271312764147297e-05\n",
      "fold:  1 , epoch:  17 , val loss:  2.6480411179363728e-05\n",
      "fold:  1 , epoch:  18 , val loss:  3.6902209103573114e-05\n",
      "fold:  1 , epoch:  19 , val loss:  1.3094544556224719e-05\n",
      "fold:  1 , epoch:  20 , val loss:  1.2155552212789189e-05\n",
      "fold:  1 , epoch:  21 , val loss:  1.784223786671646e-05\n",
      "fold:  1 , epoch:  22 , val loss:  3.318976087030023e-05\n",
      "fold:  1 , epoch:  23 , val loss:  2.001906068471726e-05\n",
      "fold:  1 , epoch:  24 , val loss:  1.5839896150282584e-05\n",
      "fold:  1 , epoch:  25 , val loss:  2.658491393958684e-05\n",
      "fold:  2 , epoch:  1 , val loss:  3.676881897263229e-05\n",
      "fold:  2 , epoch:  2 , val loss:  4.0571412682766095e-05\n",
      "fold:  2 , epoch:  3 , val loss:  5.183422763366252e-05\n",
      "fold:  2 , epoch:  4 , val loss:  0.00012199468619655818\n",
      "fold:  2 , epoch:  5 , val loss:  3.119780740235001e-05\n",
      "fold:  2 , epoch:  6 , val loss:  5.227958536124788e-05\n",
      "fold:  2 , epoch:  7 , val loss:  6.232972373254597e-05\n",
      "fold:  2 , epoch:  8 , val loss:  9.597938515071291e-06\n",
      "fold:  2 , epoch:  9 , val loss:  1.4330462363432162e-05\n",
      "fold:  2 , epoch:  10 , val loss:  1.8872769942390732e-05\n",
      "fold:  2 , epoch:  11 , val loss:  1.1022216312994715e-05\n",
      "fold:  2 , epoch:  12 , val loss:  2.441121068841312e-05\n",
      "fold:  2 , epoch:  13 , val loss:  1.7333575669908896e-05\n",
      "fold:  2 , epoch:  14 , val loss:  7.5521857070270926e-06\n",
      "fold:  2 , epoch:  15 , val loss:  1.5035689102660399e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  2 , epoch:  16 , val loss:  1.6725447494536638e-05\n",
      "fold:  2 , epoch:  17 , val loss:  1.1329660082992632e-05\n",
      "fold:  2 , epoch:  18 , val loss:  3.343671414768323e-05\n",
      "fold:  2 , epoch:  19 , val loss:  3.340365583426319e-05\n",
      "fold:  2 , epoch:  20 , val loss:  8.479610187350772e-06\n",
      "fold:  2 , epoch:  21 , val loss:  1.0786008715513162e-05\n",
      "fold:  2 , epoch:  22 , val loss:  7.143617040128447e-06\n",
      "fold:  2 , epoch:  23 , val loss:  2.3277048967429437e-05\n",
      "fold:  2 , epoch:  24 , val loss:  1.9494404114084318e-05\n",
      "fold:  2 , epoch:  25 , val loss:  1.0860469046747312e-05\n",
      "fold:  3 , epoch:  1 , val loss:  6.672677045571618e-06\n",
      "fold:  3 , epoch:  2 , val loss:  6.508530987048289e-06\n",
      "fold:  3 , epoch:  3 , val loss:  9.940004019881599e-06\n",
      "fold:  3 , epoch:  4 , val loss:  7.879998520365916e-06\n",
      "fold:  3 , epoch:  5 , val loss:  8.648913535580505e-06\n",
      "fold:  3 , epoch:  6 , val loss:  1.5004959095676895e-05\n",
      "fold:  3 , epoch:  7 , val loss:  2.4938532078522258e-05\n",
      "fold:  3 , epoch:  8 , val loss:  1.1322150385240093e-05\n",
      "fold:  3 , epoch:  9 , val loss:  1.201534723804798e-05\n",
      "fold:  3 , epoch:  10 , val loss:  2.5819181246333756e-05\n",
      "fold:  3 , epoch:  11 , val loss:  2.456135734973941e-05\n",
      "fold:  3 , epoch:  12 , val loss:  5.825320386065869e-06\n",
      "fold:  3 , epoch:  13 , val loss:  1.85660883289529e-05\n",
      "fold:  3 , epoch:  14 , val loss:  2.486270386725664e-05\n",
      "fold:  3 , epoch:  15 , val loss:  2.8637383366003633e-05\n",
      "fold:  3 , epoch:  16 , val loss:  8.328330295626074e-06\n",
      "fold:  3 , epoch:  17 , val loss:  1.1883991646755021e-05\n",
      "fold:  3 , epoch:  18 , val loss:  7.890627784945536e-06\n",
      "fold:  3 , epoch:  19 , val loss:  6.714544724673033e-06\n",
      "fold:  3 , epoch:  20 , val loss:  2.258260064991191e-05\n",
      "fold:  3 , epoch:  21 , val loss:  5.278708613332128e-06\n",
      "fold:  3 , epoch:  22 , val loss:  6.121160367911216e-06\n",
      "fold:  3 , epoch:  23 , val loss:  3.651081215139129e-06\n",
      "fold:  3 , epoch:  24 , val loss:  1.2707502719422337e-05\n",
      "fold:  3 , epoch:  25 , val loss:  6.859276254544966e-06\n",
      "fold:  4 , epoch:  1 , val loss:  0.0001118726358981803\n",
      "fold:  4 , epoch:  2 , val loss:  6.922743068571435e-06\n",
      "fold:  4 , epoch:  3 , val loss:  8.248435915447772e-05\n",
      "fold:  4 , epoch:  4 , val loss:  6.479580861196155e-06\n",
      "fold:  4 , epoch:  5 , val loss:  7.177740371844266e-06\n",
      "fold:  4 , epoch:  6 , val loss:  4.8636197789164726e-06\n",
      "fold:  4 , epoch:  7 , val loss:  8.883110240276437e-06\n",
      "fold:  4 , epoch:  8 , val loss:  6.156173185445368e-06\n",
      "fold:  4 , epoch:  9 , val loss:  1.597166010469664e-05\n",
      "fold:  4 , epoch:  10 , val loss:  3.457287311903201e-05\n",
      "fold:  4 , epoch:  11 , val loss:  8.798357157502323e-06\n",
      "fold:  4 , epoch:  12 , val loss:  6.5108670241897926e-06\n",
      "fold:  4 , epoch:  13 , val loss:  1.6286147001665086e-05\n",
      "fold:  4 , epoch:  14 , val loss:  7.148491022235248e-06\n",
      "fold:  4 , epoch:  15 , val loss:  1.7481143004260957e-05\n",
      "fold:  4 , epoch:  16 , val loss:  1.0388595910626464e-05\n",
      "fold:  4 , epoch:  17 , val loss:  1.3181247595639434e-05\n",
      "fold:  4 , epoch:  18 , val loss:  2.2709364202455617e-05\n",
      "fold:  4 , epoch:  19 , val loss:  4.157211606070632e-06\n",
      "fold:  4 , epoch:  20 , val loss:  1.5933195754769258e-05\n",
      "fold:  4 , epoch:  21 , val loss:  1.990845521504525e-05\n",
      "fold:  4 , epoch:  22 , val loss:  1.6704967492842115e-05\n",
      "fold:  4 , epoch:  23 , val loss:  3.8015039081074065e-06\n",
      "fold:  4 , epoch:  24 , val loss:  6.193406443344429e-05\n",
      "fold:  4 , epoch:  25 , val loss:  5.247185981716029e-06\n",
      "fold:  5 , epoch:  1 , val loss:  2.1151638065930456e-05\n",
      "fold:  5 , epoch:  2 , val loss:  2.703687869143323e-06\n",
      "fold:  5 , epoch:  3 , val loss:  7.648073733435012e-06\n",
      "fold:  5 , epoch:  4 , val loss:  6.475345344369998e-06\n",
      "fold:  5 , epoch:  5 , val loss:  4.422625352162868e-06\n",
      "fold:  5 , epoch:  6 , val loss:  5.989115379634313e-06\n",
      "fold:  5 , epoch:  7 , val loss:  3.2476930300617823e-06\n",
      "fold:  5 , epoch:  8 , val loss:  3.223237217753194e-05\n",
      "fold:  5 , epoch:  9 , val loss:  1.787930159480311e-05\n",
      "fold:  5 , epoch:  10 , val loss:  6.704710540361702e-05\n",
      "fold:  5 , epoch:  11 , val loss:  1.0496072718524374e-05\n",
      "fold:  5 , epoch:  12 , val loss:  6.0938536989851855e-06\n",
      "fold:  5 , epoch:  13 , val loss:  3.0343046546477126e-06\n",
      "fold:  5 , epoch:  14 , val loss:  2.7076232527178945e-06\n",
      "fold:  5 , epoch:  15 , val loss:  1.2427914043655619e-05\n",
      "fold:  5 , epoch:  16 , val loss:  4.360393631941406e-06\n",
      "fold:  5 , epoch:  17 , val loss:  2.370687980146613e-06\n",
      "fold:  5 , epoch:  18 , val loss:  4.073894160683267e-06\n",
      "fold:  5 , epoch:  19 , val loss:  3.7769862046843627e-06\n",
      "fold:  5 , epoch:  20 , val loss:  4.204724518785952e-06\n",
      "fold:  5 , epoch:  21 , val loss:  2.2419578726839973e-06\n",
      "fold:  5 , epoch:  22 , val loss:  5.9519452406675555e-06\n",
      "fold:  5 , epoch:  23 , val loss:  1.5041006918181665e-05\n",
      "fold:  5 , epoch:  24 , val loss:  7.231893505377229e-06\n",
      "fold:  5 , epoch:  25 , val loss:  3.9397973523591645e-06\n",
      "Model results:  {'hidden_size': 400, 'n_layers': 6, 'act_fun': 'LeakyReLU', 'init_methods': 'xavier uniform', 'mean_val_result': 2.4085822886263487e-05, 'std_val_result': 2.9750981093359556e-05} \n",
      "\n",
      "Model:  {'hidden_size': 200, 'n_layers': 6, 'act_fun': 'ELU', 'init_methods': 'xavier normal'}\n",
      "fold:  1 , epoch:  1 , val loss:  0.004232209641486406\n",
      "fold:  1 , epoch:  2 , val loss:  0.0016968657728284597\n",
      "fold:  1 , epoch:  3 , val loss:  0.0008653886616230011\n",
      "fold:  1 , epoch:  4 , val loss:  0.0005159525317139924\n",
      "fold:  1 , epoch:  5 , val loss:  0.0003395334060769528\n",
      "fold:  1 , epoch:  6 , val loss:  0.0002558004925958812\n",
      "fold:  1 , epoch:  7 , val loss:  0.00021681873477064073\n",
      "fold:  1 , epoch:  8 , val loss:  0.00022697652457281947\n",
      "fold:  1 , epoch:  9 , val loss:  0.00019265063747297972\n",
      "fold:  1 , epoch:  10 , val loss:  0.00015113383415155113\n",
      "fold:  1 , epoch:  11 , val loss:  0.00014558076509274542\n",
      "fold:  1 , epoch:  12 , val loss:  0.00011754678416764364\n",
      "fold:  1 , epoch:  13 , val loss:  0.00010291131911799312\n",
      "fold:  1 , epoch:  14 , val loss:  9.514927660347894e-05\n",
      "fold:  1 , epoch:  15 , val loss:  8.636111306259409e-05\n",
      "fold:  1 , epoch:  16 , val loss:  8.051309850998223e-05\n",
      "fold:  1 , epoch:  17 , val loss:  7.936218025861308e-05\n",
      "fold:  1 , epoch:  18 , val loss:  7.70086408010684e-05\n",
      "fold:  1 , epoch:  19 , val loss:  7.480250496882945e-05\n",
      "fold:  1 , epoch:  20 , val loss:  6.731396570103243e-05\n",
      "fold:  1 , epoch:  21 , val loss:  9.945216152118519e-05\n",
      "fold:  1 , epoch:  22 , val loss:  7.848983659641817e-05\n",
      "fold:  1 , epoch:  23 , val loss:  7.82558781793341e-05\n",
      "fold:  1 , epoch:  24 , val loss:  7.513375021517277e-05\n",
      "fold:  1 , epoch:  25 , val loss:  5.050187246524729e-05\n",
      "fold:  2 , epoch:  1 , val loss:  4.8946967581287026e-05\n",
      "fold:  2 , epoch:  2 , val loss:  3.961854235967621e-05\n",
      "fold:  2 , epoch:  3 , val loss:  3.620431016315706e-05\n",
      "fold:  2 , epoch:  4 , val loss:  4.750808875542134e-05\n",
      "fold:  2 , epoch:  5 , val loss:  4.251455175108276e-05\n",
      "fold:  2 , epoch:  6 , val loss:  7.304878818104044e-05\n",
      "fold:  2 , epoch:  7 , val loss:  3.774205833906308e-05\n",
      "fold:  2 , epoch:  8 , val loss:  3.2591964554740116e-05\n",
      "fold:  2 , epoch:  9 , val loss:  3.161814311170019e-05\n",
      "fold:  2 , epoch:  10 , val loss:  7.03547993907705e-05\n",
      "fold:  2 , epoch:  11 , val loss:  3.0823943234281614e-05\n",
      "fold:  2 , epoch:  12 , val loss:  3.508497684379108e-05\n",
      "fold:  2 , epoch:  13 , val loss:  3.0509118005284108e-05\n",
      "fold:  2 , epoch:  14 , val loss:  4.419990364112891e-05\n",
      "fold:  2 , epoch:  15 , val loss:  2.6280329620931298e-05\n",
      "fold:  2 , epoch:  16 , val loss:  2.8248008675291203e-05\n",
      "fold:  2 , epoch:  17 , val loss:  2.5259359972551465e-05\n",
      "fold:  2 , epoch:  18 , val loss:  5.478458842844702e-05\n",
      "fold:  2 , epoch:  19 , val loss:  2.7145768399350345e-05\n",
      "fold:  2 , epoch:  20 , val loss:  3.23272543027997e-05\n",
      "fold:  2 , epoch:  21 , val loss:  2.1673275114153512e-05\n",
      "fold:  2 , epoch:  22 , val loss:  4.505007018451579e-05\n",
      "fold:  2 , epoch:  23 , val loss:  3.9566722989548e-05\n",
      "fold:  2 , epoch:  24 , val loss:  0.00012961718311998993\n",
      "fold:  2 , epoch:  25 , val loss:  4.851629273616709e-05\n",
      "fold:  3 , epoch:  1 , val loss:  6.765741272829473e-05\n",
      "fold:  3 , epoch:  2 , val loss:  8.928988972911611e-05\n",
      "fold:  3 , epoch:  3 , val loss:  3.390046549611725e-05\n",
      "fold:  3 , epoch:  4 , val loss:  5.9814137784997e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  3 , epoch:  5 , val loss:  0.00021887135517317802\n",
      "fold:  3 , epoch:  6 , val loss:  0.0001276827388210222\n",
      "fold:  3 , epoch:  7 , val loss:  6.152045534690842e-05\n",
      "fold:  3 , epoch:  8 , val loss:  7.441697380272672e-05\n",
      "fold:  3 , epoch:  9 , val loss:  0.00010634979844326153\n",
      "fold:  3 , epoch:  10 , val loss:  5.4751300922362134e-05\n",
      "fold:  3 , epoch:  11 , val loss:  1.6675321603543125e-05\n",
      "fold:  3 , epoch:  12 , val loss:  2.3750064428895712e-05\n",
      "fold:  3 , epoch:  13 , val loss:  4.908817572868429e-05\n",
      "fold:  3 , epoch:  14 , val loss:  2.0656982087530196e-05\n",
      "fold:  3 , epoch:  15 , val loss:  4.756159978569485e-05\n",
      "fold:  3 , epoch:  16 , val loss:  2.458396556903608e-05\n",
      "fold:  3 , epoch:  17 , val loss:  3.485723209450953e-05\n",
      "fold:  3 , epoch:  18 , val loss:  4.467489634407684e-05\n",
      "fold:  3 , epoch:  19 , val loss:  3.063111216761172e-05\n",
      "fold:  3 , epoch:  20 , val loss:  2.5302209905930795e-05\n",
      "fold:  3 , epoch:  21 , val loss:  2.7519768991624005e-05\n",
      "fold:  3 , epoch:  22 , val loss:  2.594621582829859e-05\n",
      "fold:  3 , epoch:  23 , val loss:  2.320227758900728e-05\n",
      "fold:  3 , epoch:  24 , val loss:  2.4474900783388875e-05\n",
      "fold:  3 , epoch:  25 , val loss:  1.5726909623481333e-05\n",
      "fold:  4 , epoch:  1 , val loss:  6.559953908436e-05\n",
      "fold:  4 , epoch:  2 , val loss:  2.1735297195846215e-05\n",
      "fold:  4 , epoch:  3 , val loss:  4.1749859519768506e-05\n",
      "fold:  4 , epoch:  4 , val loss:  1.833151327446103e-05\n",
      "fold:  4 , epoch:  5 , val loss:  1.521809372206917e-05\n",
      "fold:  4 , epoch:  6 , val loss:  3.181829379172996e-05\n",
      "fold:  4 , epoch:  7 , val loss:  4.866049130214378e-05\n",
      "fold:  4 , epoch:  8 , val loss:  3.8354752177838236e-05\n",
      "fold:  4 , epoch:  9 , val loss:  5.918040915275924e-05\n",
      "fold:  4 , epoch:  10 , val loss:  7.749814540147781e-05\n",
      "fold:  4 , epoch:  11 , val loss:  2.4363787815673277e-05\n",
      "fold:  4 , epoch:  12 , val loss:  4.644457294489257e-05\n",
      "fold:  4 , epoch:  13 , val loss:  1.829996836022474e-05\n",
      "fold:  4 , epoch:  14 , val loss:  4.9414531531510875e-05\n",
      "fold:  4 , epoch:  15 , val loss:  3.392201688257046e-05\n",
      "fold:  4 , epoch:  16 , val loss:  1.9106193576590158e-05\n",
      "fold:  4 , epoch:  17 , val loss:  1.2450686881493311e-05\n",
      "fold:  4 , epoch:  18 , val loss:  8.70979274623096e-05\n",
      "fold:  4 , epoch:  19 , val loss:  1.7829215721576475e-05\n",
      "fold:  4 , epoch:  20 , val loss:  1.166745278169401e-05\n",
      "fold:  4 , epoch:  21 , val loss:  2.031690200965386e-05\n",
      "fold:  4 , epoch:  22 , val loss:  1.6714651792426594e-05\n",
      "fold:  4 , epoch:  23 , val loss:  8.322046778630465e-05\n",
      "fold:  4 , epoch:  24 , val loss:  4.657922909245826e-05\n",
      "fold:  4 , epoch:  25 , val loss:  4.278040796634741e-05\n",
      "fold:  5 , epoch:  1 , val loss:  1.0819730050570797e-05\n",
      "fold:  5 , epoch:  2 , val loss:  3.6486995668383315e-05\n",
      "fold:  5 , epoch:  3 , val loss:  8.116371463984251e-05\n",
      "fold:  5 , epoch:  4 , val loss:  9.365846381115261e-06\n",
      "fold:  5 , epoch:  5 , val loss:  1.5908772184047848e-05\n",
      "fold:  5 , epoch:  6 , val loss:  1.6308629710692912e-05\n",
      "fold:  5 , epoch:  7 , val loss:  1.5124382116482593e-05\n",
      "fold:  5 , epoch:  8 , val loss:  5.292925197863951e-05\n",
      "fold:  5 , epoch:  9 , val loss:  3.5439443308860064e-05\n",
      "fold:  5 , epoch:  10 , val loss:  0.00011755330342566594\n",
      "fold:  5 , epoch:  11 , val loss:  1.125160724768648e-05\n",
      "fold:  5 , epoch:  12 , val loss:  3.472505704849027e-05\n",
      "fold:  5 , epoch:  13 , val loss:  9.816409146878868e-06\n",
      "fold:  5 , epoch:  14 , val loss:  8.810158760752529e-06\n",
      "fold:  5 , epoch:  15 , val loss:  0.00023700782912783325\n",
      "fold:  5 , epoch:  16 , val loss:  8.17289219412487e-06\n",
      "fold:  5 , epoch:  17 , val loss:  1.600493851583451e-05\n",
      "fold:  5 , epoch:  18 , val loss:  2.1003419533371925e-05\n",
      "fold:  5 , epoch:  19 , val loss:  2.900279469031375e-05\n",
      "fold:  5 , epoch:  20 , val loss:  1.697386323940009e-05\n",
      "fold:  5 , epoch:  21 , val loss:  1.3294127711560577e-05\n",
      "fold:  5 , epoch:  22 , val loss:  4.4505683035822585e-05\n",
      "fold:  5 , epoch:  23 , val loss:  6.923630280653015e-05\n",
      "fold:  5 , epoch:  24 , val loss:  1.0104343346029054e-05\n",
      "fold:  5 , epoch:  25 , val loss:  5.863827027496882e-05\n",
      "Model results:  {'hidden_size': 200, 'n_layers': 6, 'act_fun': 'ELU', 'init_methods': 'xavier normal', 'mean_val_result': 0.00011470285382529255, 'std_val_result': 0.0004093377362743747} \n",
      "\n",
      "Model:  {'hidden_size': 200, 'n_layers': 4, 'act_fun': 'LeakyReLU', 'init_methods': 'xavier uniform'}\n",
      "fold:  1 , epoch:  1 , val loss:  0.0013363530160859227\n",
      "fold:  1 , epoch:  2 , val loss:  0.00042987088090740144\n",
      "fold:  1 , epoch:  3 , val loss:  0.000243453832808882\n",
      "fold:  1 , epoch:  4 , val loss:  0.00016407413932029158\n",
      "fold:  1 , epoch:  5 , val loss:  0.00012256958871148527\n",
      "fold:  1 , epoch:  6 , val loss:  9.979705646401271e-05\n",
      "fold:  1 , epoch:  7 , val loss:  9.914806287270039e-05\n",
      "fold:  1 , epoch:  8 , val loss:  7.101415394572541e-05\n",
      "fold:  1 , epoch:  9 , val loss:  7.131908205337822e-05\n",
      "fold:  1 , epoch:  10 , val loss:  7.14423440513201e-05\n",
      "fold:  1 , epoch:  11 , val loss:  7.666349119972438e-05\n",
      "fold:  1 , epoch:  12 , val loss:  7.221521809697151e-05\n",
      "fold:  1 , epoch:  13 , val loss:  6.529279198730364e-05\n",
      "fold:  1 , epoch:  14 , val loss:  5.759943087468855e-05\n",
      "fold:  1 , epoch:  15 , val loss:  5.1098617404932156e-05\n",
      "fold:  1 , epoch:  16 , val loss:  4.592815093928948e-05\n",
      "fold:  1 , epoch:  17 , val loss:  4.226077362545766e-05\n",
      "fold:  1 , epoch:  18 , val loss:  3.879834184772335e-05\n",
      "fold:  1 , epoch:  19 , val loss:  3.6206245567882434e-05\n",
      "fold:  1 , epoch:  20 , val loss:  3.458050196059048e-05\n",
      "fold:  1 , epoch:  21 , val loss:  3.279027441749349e-05\n",
      "fold:  1 , epoch:  22 , val loss:  3.07755108224228e-05\n",
      "fold:  1 , epoch:  23 , val loss:  3.1482366466661915e-05\n",
      "fold:  1 , epoch:  24 , val loss:  3.08846210828051e-05\n",
      "fold:  1 , epoch:  25 , val loss:  2.545803909015376e-05\n",
      "fold:  2 , epoch:  1 , val loss:  3.8414709706557915e-05\n",
      "fold:  2 , epoch:  2 , val loss:  3.597203249228187e-05\n",
      "fold:  2 , epoch:  3 , val loss:  2.1426585590234026e-05\n",
      "fold:  2 , epoch:  4 , val loss:  3.5568886232795194e-05\n",
      "fold:  2 , epoch:  5 , val loss:  1.8677317711990327e-05\n",
      "fold:  2 , epoch:  6 , val loss:  3.732384357135743e-05\n",
      "fold:  2 , epoch:  7 , val loss:  1.6687941752024926e-05\n",
      "fold:  2 , epoch:  8 , val loss:  3.036670204892289e-05\n",
      "fold:  2 , epoch:  9 , val loss:  1.5782619811943732e-05\n",
      "fold:  2 , epoch:  10 , val loss:  1.8544002159615047e-05\n",
      "fold:  2 , epoch:  11 , val loss:  1.4723659660376143e-05\n",
      "fold:  2 , epoch:  12 , val loss:  3.119105167570524e-05\n",
      "fold:  2 , epoch:  13 , val loss:  1.5114858797460329e-05\n",
      "fold:  2 , epoch:  14 , val loss:  1.3806420611217618e-05\n",
      "fold:  2 , epoch:  15 , val loss:  2.8077954993932508e-05\n",
      "fold:  2 , epoch:  16 , val loss:  3.294613634352572e-05\n",
      "fold:  2 , epoch:  17 , val loss:  3.003441815963015e-05\n",
      "fold:  2 , epoch:  18 , val loss:  1.2717055142275058e-05\n",
      "fold:  2 , epoch:  19 , val loss:  2.218873123638332e-05\n",
      "fold:  2 , epoch:  20 , val loss:  1.4106061826169025e-05\n",
      "fold:  2 , epoch:  21 , val loss:  3.033801112906076e-05\n",
      "fold:  2 , epoch:  22 , val loss:  2.3765183868817985e-05\n",
      "fold:  2 , epoch:  23 , val loss:  3.323084092698991e-05\n",
      "fold:  2 , epoch:  24 , val loss:  1.2353138117759954e-05\n",
      "fold:  2 , epoch:  25 , val loss:  1.6808386135380715e-05\n",
      "fold:  3 , epoch:  1 , val loss:  1.9712771972990595e-05\n",
      "fold:  3 , epoch:  2 , val loss:  1.590891224623192e-05\n",
      "fold:  3 , epoch:  3 , val loss:  1.0217622730124276e-05\n",
      "fold:  3 , epoch:  4 , val loss:  3.911546809831634e-05\n",
      "fold:  3 , epoch:  5 , val loss:  1.3302794286573771e-05\n",
      "fold:  3 , epoch:  6 , val loss:  1.227864959219005e-05\n",
      "fold:  3 , epoch:  7 , val loss:  1.008621165965451e-05\n",
      "fold:  3 , epoch:  8 , val loss:  1.2746874745062087e-05\n",
      "fold:  3 , epoch:  9 , val loss:  3.724360794876702e-05\n",
      "fold:  3 , epoch:  10 , val loss:  1.1472197002149187e-05\n",
      "fold:  3 , epoch:  11 , val loss:  1.3965515790914651e-05\n",
      "fold:  3 , epoch:  12 , val loss:  1.3609852430818137e-05\n",
      "fold:  3 , epoch:  13 , val loss:  8.924984285840765e-06\n",
      "fold:  3 , epoch:  14 , val loss:  1.1077859198849183e-05\n",
      "fold:  3 , epoch:  15 , val loss:  1.1746795280487277e-05\n",
      "fold:  3 , epoch:  16 , val loss:  1.0053498044726439e-05\n",
      "fold:  3 , epoch:  17 , val loss:  8.33714693726506e-06\n",
      "fold:  3 , epoch:  18 , val loss:  1.046184388542315e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  3 , epoch:  19 , val loss:  1.054645690601319e-05\n",
      "fold:  3 , epoch:  20 , val loss:  9.741471330926288e-06\n",
      "fold:  3 , epoch:  21 , val loss:  8.728995453566313e-06\n",
      "fold:  3 , epoch:  22 , val loss:  8.512499334756285e-06\n",
      "fold:  3 , epoch:  23 , val loss:  9.638598385208752e-06\n",
      "fold:  3 , epoch:  24 , val loss:  3.2957603252725676e-05\n",
      "fold:  3 , epoch:  25 , val loss:  9.17117631615838e-06\n",
      "fold:  4 , epoch:  1 , val loss:  6.948313966859132e-06\n",
      "fold:  4 , epoch:  2 , val loss:  8.255613465735223e-06\n",
      "fold:  4 , epoch:  3 , val loss:  7.786987225699704e-06\n",
      "fold:  4 , epoch:  4 , val loss:  8.5743222371093e-06\n",
      "fold:  4 , epoch:  5 , val loss:  8.824002179608215e-06\n",
      "fold:  4 , epoch:  6 , val loss:  9.222632797900587e-06\n",
      "fold:  4 , epoch:  7 , val loss:  8.323160727741197e-06\n",
      "fold:  4 , epoch:  8 , val loss:  7.308913609449519e-06\n",
      "fold:  4 , epoch:  9 , val loss:  8.946257366915233e-06\n",
      "fold:  4 , epoch:  10 , val loss:  3.214102616766468e-05\n",
      "fold:  4 , epoch:  11 , val loss:  6.7913679231423885e-06\n",
      "fold:  4 , epoch:  12 , val loss:  1.0551118975854479e-05\n",
      "fold:  4 , epoch:  13 , val loss:  7.840494617994409e-06\n",
      "fold:  4 , epoch:  14 , val loss:  8.7422240540036e-06\n",
      "fold:  4 , epoch:  15 , val loss:  2.314509401912801e-05\n",
      "fold:  4 , epoch:  16 , val loss:  8.294600775116123e-06\n",
      "fold:  4 , epoch:  17 , val loss:  7.210227067844244e-06\n",
      "fold:  4 , epoch:  18 , val loss:  5.9928397604380734e-06\n",
      "fold:  4 , epoch:  19 , val loss:  1.0935143109236378e-05\n",
      "fold:  4 , epoch:  20 , val loss:  6.090512670198223e-06\n",
      "fold:  4 , epoch:  21 , val loss:  7.568085038656136e-06\n",
      "fold:  4 , epoch:  22 , val loss:  5.5581022024853155e-06\n",
      "fold:  4 , epoch:  23 , val loss:  5.637035428662784e-06\n",
      "fold:  4 , epoch:  24 , val loss:  9.530052011541557e-06\n",
      "fold:  4 , epoch:  25 , val loss:  1.6535143004148267e-05\n",
      "fold:  5 , epoch:  1 , val loss:  6.574040980922291e-06\n",
      "fold:  5 , epoch:  2 , val loss:  6.099274742155103e-06\n",
      "fold:  5 , epoch:  3 , val loss:  8.013333172129933e-06\n",
      "fold:  5 , epoch:  4 , val loss:  6.798262347729178e-06\n",
      "fold:  5 , epoch:  5 , val loss:  1.1612997695920058e-05\n",
      "fold:  5 , epoch:  6 , val loss:  5.367774519982049e-06\n",
      "fold:  5 , epoch:  7 , val loss:  6.93235369908507e-06\n",
      "fold:  5 , epoch:  8 , val loss:  5.975438398309052e-06\n",
      "fold:  5 , epoch:  9 , val loss:  6.972446499275975e-06\n",
      "fold:  5 , epoch:  10 , val loss:  1.207834247907158e-05\n",
      "fold:  5 , epoch:  11 , val loss:  8.894769052858464e-06\n",
      "fold:  5 , epoch:  12 , val loss:  6.01506053499179e-06\n",
      "fold:  5 , epoch:  13 , val loss:  5.29564340467914e-06\n",
      "fold:  5 , epoch:  14 , val loss:  1.181791776616592e-05\n",
      "fold:  5 , epoch:  15 , val loss:  9.77126182988286e-06\n",
      "fold:  5 , epoch:  16 , val loss:  4.907140009891009e-06\n",
      "fold:  5 , epoch:  17 , val loss:  5.354225322662387e-06\n",
      "fold:  5 , epoch:  18 , val loss:  5.211829829931958e-06\n",
      "fold:  5 , epoch:  19 , val loss:  4.971498128725216e-06\n",
      "fold:  5 , epoch:  20 , val loss:  7.156077572290087e-06\n",
      "fold:  5 , epoch:  21 , val loss:  1.4897435903549194e-05\n",
      "fold:  5 , epoch:  22 , val loss:  5.8186760725220665e-06\n",
      "fold:  5 , epoch:  23 , val loss:  5.759854502684902e-06\n",
      "fold:  5 , epoch:  24 , val loss:  5.118716671859147e-06\n",
      "fold:  5 , epoch:  25 , val loss:  5.1374267059145495e-05\n",
      "Model results:  {'hidden_size': 200, 'n_layers': 4, 'act_fun': 'LeakyReLU', 'init_methods': 'xavier uniform', 'mean_val_result': 3.853075518418336e-05, 'std_val_result': 0.00012604098453006468} \n",
      "\n",
      "Model:  {'hidden_size': 400, 'n_layers': 8, 'act_fun': 'LeakyReLU', 'init_methods': 'xavier uniform'}\n",
      "fold:  1 , epoch:  1 , val loss:  0.00024161617329809815\n",
      "fold:  1 , epoch:  2 , val loss:  0.00011297888704575598\n",
      "fold:  1 , epoch:  3 , val loss:  7.686933531658724e-05\n",
      "fold:  1 , epoch:  4 , val loss:  6.756568473065272e-05\n",
      "fold:  1 , epoch:  5 , val loss:  8.728745160624385e-05\n",
      "fold:  1 , epoch:  6 , val loss:  7.880301564000547e-05\n",
      "fold:  1 , epoch:  7 , val loss:  2.8523432774818502e-05\n",
      "fold:  1 , epoch:  8 , val loss:  6.58598801237531e-05\n",
      "fold:  1 , epoch:  9 , val loss:  4.213401916786097e-05\n",
      "fold:  1 , epoch:  10 , val loss:  2.4272927475976758e-05\n",
      "fold:  1 , epoch:  11 , val loss:  2.794999090838246e-05\n",
      "fold:  1 , epoch:  12 , val loss:  7.704557356191799e-05\n",
      "fold:  1 , epoch:  13 , val loss:  1.7882381143863313e-05\n",
      "fold:  1 , epoch:  14 , val loss:  1.4093549907556735e-05\n",
      "fold:  1 , epoch:  15 , val loss:  1.344293741567526e-05\n",
      "fold:  1 , epoch:  16 , val loss:  2.6797679311130196e-05\n",
      "fold:  1 , epoch:  17 , val loss:  6.902948371134698e-05\n",
      "fold:  1 , epoch:  18 , val loss:  1.3579527148976922e-05\n",
      "fold:  1 , epoch:  19 , val loss:  2.1555504645220935e-05\n",
      "fold:  1 , epoch:  20 , val loss:  1.67970920301741e-05\n",
      "fold:  1 , epoch:  21 , val loss:  1.4559812370862346e-05\n",
      "fold:  1 , epoch:  22 , val loss:  4.831683691008948e-05\n",
      "fold:  1 , epoch:  23 , val loss:  1.771299503161572e-05\n",
      "fold:  1 , epoch:  24 , val loss:  4.083094245288521e-05\n",
      "fold:  1 , epoch:  25 , val loss:  1.2043212336720899e-05\n",
      "fold:  2 , epoch:  1 , val loss:  1.0888134056585841e-05\n",
      "fold:  2 , epoch:  2 , val loss:  9.274161129724234e-06\n",
      "fold:  2 , epoch:  3 , val loss:  2.5628949515521526e-05\n",
      "fold:  2 , epoch:  4 , val loss:  1.5456549590453506e-05\n",
      "fold:  2 , epoch:  5 , val loss:  5.750386117142625e-05\n",
      "fold:  2 , epoch:  6 , val loss:  8.133578376146033e-06\n",
      "fold:  2 , epoch:  7 , val loss:  8.903257366910111e-06\n",
      "fold:  2 , epoch:  8 , val loss:  3.52905917679891e-05\n",
      "fold:  2 , epoch:  9 , val loss:  2.4131575628416613e-05\n",
      "fold:  2 , epoch:  10 , val loss:  1.7790498532122e-05\n",
      "fold:  2 , epoch:  11 , val loss:  9.75634884525789e-06\n",
      "fold:  2 , epoch:  12 , val loss:  1.347370107396273e-05\n",
      "fold:  2 , epoch:  13 , val loss:  7.207533144537592e-06\n",
      "fold:  2 , epoch:  14 , val loss:  1.3983993994770572e-05\n",
      "fold:  2 , epoch:  15 , val loss:  1.3991127161716577e-05\n",
      "fold:  2 , epoch:  16 , val loss:  1.6482523278682493e-05\n",
      "fold:  2 , epoch:  17 , val loss:  1.4723672393301968e-05\n",
      "fold:  2 , epoch:  18 , val loss:  6.434130682464456e-06\n",
      "fold:  2 , epoch:  19 , val loss:  1.3343369573703967e-05\n",
      "fold:  2 , epoch:  20 , val loss:  1.493588752055075e-05\n",
      "fold:  2 , epoch:  21 , val loss:  2.2518981495522894e-05\n",
      "fold:  2 , epoch:  22 , val loss:  8.190080734493677e-06\n",
      "fold:  2 , epoch:  23 , val loss:  1.0945392205030657e-05\n",
      "fold:  2 , epoch:  24 , val loss:  7.542290404671803e-06\n",
      "fold:  2 , epoch:  25 , val loss:  1.0383396329416428e-05\n",
      "fold:  3 , epoch:  1 , val loss:  1.0516740076127462e-05\n",
      "fold:  3 , epoch:  2 , val loss:  1.5203803741314914e-05\n",
      "fold:  3 , epoch:  3 , val loss:  3.560498953447677e-05\n",
      "fold:  3 , epoch:  4 , val loss:  6.361712621583138e-06\n",
      "fold:  3 , epoch:  5 , val loss:  1.4893666048010346e-05\n",
      "fold:  3 , epoch:  6 , val loss:  9.001813850773033e-06\n",
      "fold:  3 , epoch:  7 , val loss:  3.31675837514922e-05\n",
      "fold:  3 , epoch:  8 , val loss:  1.3626604413730092e-05\n",
      "fold:  3 , epoch:  9 , val loss:  1.3486952411767561e-05\n",
      "fold:  3 , epoch:  10 , val loss:  1.933665589604061e-05\n",
      "fold:  3 , epoch:  11 , val loss:  7.6128903856442776e-06\n",
      "fold:  3 , epoch:  12 , val loss:  1.8395434381091036e-05\n",
      "fold:  3 , epoch:  13 , val loss:  2.0533134375000373e-05\n",
      "fold:  3 , epoch:  14 , val loss:  0.0001186224035336636\n",
      "fold:  3 , epoch:  15 , val loss:  2.2626785721513443e-05\n",
      "fold:  3 , epoch:  16 , val loss:  6.237034085643245e-06\n",
      "fold:  3 , epoch:  17 , val loss:  5.007972504245117e-06\n",
      "fold:  3 , epoch:  18 , val loss:  6.220094746822724e-06\n",
      "fold:  3 , epoch:  19 , val loss:  5.1863203225366306e-06\n",
      "fold:  3 , epoch:  20 , val loss:  8.093626092886552e-06\n",
      "fold:  3 , epoch:  21 , val loss:  1.1157616427226458e-05\n",
      "fold:  3 , epoch:  22 , val loss:  9.611673704057466e-06\n",
      "fold:  3 , epoch:  23 , val loss:  2.027227310463786e-05\n",
      "fold:  3 , epoch:  24 , val loss:  6.397547167580342e-06\n",
      "fold:  3 , epoch:  25 , val loss:  1.1983678632532246e-05\n",
      "fold:  4 , epoch:  1 , val loss:  1.0734423085523304e-05\n",
      "fold:  4 , epoch:  2 , val loss:  1.2239682291692588e-05\n",
      "fold:  4 , epoch:  3 , val loss:  4.184307726973202e-06\n",
      "fold:  4 , epoch:  4 , val loss:  3.362525239936076e-05\n",
      "fold:  4 , epoch:  5 , val loss:  3.5731632124225143e-06\n",
      "fold:  4 , epoch:  6 , val loss:  2.875950031011598e-06\n",
      "fold:  4 , epoch:  7 , val loss:  6.4025916799437255e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  4 , epoch:  8 , val loss:  4.962236744177062e-06\n",
      "fold:  4 , epoch:  9 , val loss:  4.263534265191993e-06\n",
      "fold:  4 , epoch:  10 , val loss:  3.1434187803824898e-06\n",
      "fold:  4 , epoch:  11 , val loss:  2.0694886188721284e-05\n",
      "fold:  4 , epoch:  12 , val loss:  1.12796269604587e-05\n",
      "fold:  4 , epoch:  13 , val loss:  5.274873274174752e-06\n",
      "fold:  4 , epoch:  14 , val loss:  3.880604708683677e-05\n",
      "fold:  4 , epoch:  15 , val loss:  6.736616342095658e-06\n",
      "fold:  4 , epoch:  16 , val loss:  6.484168352471897e-06\n",
      "fold:  4 , epoch:  17 , val loss:  4.3173098674742505e-05\n",
      "fold:  4 , epoch:  18 , val loss:  3.2605199521640316e-05\n",
      "fold:  4 , epoch:  19 , val loss:  4.706342679128284e-06\n",
      "fold:  4 , epoch:  20 , val loss:  6.751640739821596e-06\n",
      "fold:  4 , epoch:  21 , val loss:  5.84919580433052e-05\n",
      "fold:  4 , epoch:  22 , val loss:  3.232081144233234e-05\n",
      "fold:  4 , epoch:  23 , val loss:  6.577080966962967e-06\n",
      "fold:  4 , epoch:  24 , val loss:  5.165461516298819e-06\n",
      "fold:  4 , epoch:  25 , val loss:  1.0912643119809218e-05\n",
      "fold:  5 , epoch:  1 , val loss:  5.889043677598238e-05\n",
      "fold:  5 , epoch:  2 , val loss:  2.4108281650114805e-05\n",
      "fold:  5 , epoch:  3 , val loss:  3.829378329101019e-06\n",
      "fold:  5 , epoch:  4 , val loss:  2.577413215476554e-05\n",
      "fold:  5 , epoch:  5 , val loss:  9.916784620145336e-06\n",
      "fold:  5 , epoch:  6 , val loss:  6.954937816772144e-06\n",
      "fold:  5 , epoch:  7 , val loss:  6.719496923324186e-06\n",
      "fold:  5 , epoch:  8 , val loss:  1.2480236364353914e-05\n",
      "fold:  5 , epoch:  9 , val loss:  4.380493464850588e-06\n",
      "fold:  5 , epoch:  10 , val loss:  8.264015377790201e-06\n",
      "fold:  5 , epoch:  11 , val loss:  3.5470345665089553e-06\n",
      "fold:  5 , epoch:  12 , val loss:  9.922991011990234e-06\n",
      "fold:  5 , epoch:  13 , val loss:  1.1545435881998856e-05\n",
      "fold:  5 , epoch:  14 , val loss:  1.4949668184272014e-05\n",
      "fold:  5 , epoch:  15 , val loss:  3.5156001558789285e-06\n",
      "fold:  5 , epoch:  16 , val loss:  1.1285261280136183e-05\n",
      "fold:  5 , epoch:  17 , val loss:  8.797589543974027e-06\n",
      "fold:  5 , epoch:  18 , val loss:  4.574986178340623e-06\n",
      "fold:  5 , epoch:  19 , val loss:  3.7616650843119714e-06\n",
      "fold:  5 , epoch:  20 , val loss:  2.735710268098046e-06\n",
      "fold:  5 , epoch:  21 , val loss:  5.345877980289515e-06\n",
      "fold:  5 , epoch:  22 , val loss:  9.001158105093054e-06\n",
      "fold:  5 , epoch:  23 , val loss:  2.500878281352925e-06\n",
      "fold:  5 , epoch:  24 , val loss:  2.1733665107603883e-06\n",
      "fold:  5 , epoch:  25 , val loss:  1.065806736733066e-05\n",
      "Model results:  {'hidden_size': 400, 'n_layers': 8, 'act_fun': 'LeakyReLU', 'init_methods': 'xavier uniform', 'mean_val_result': 2.1961915348583716e-05, 'std_val_result': 2.940236478818364e-05} \n",
      "\n",
      "Model:  {'hidden_size': 600, 'n_layers': 6, 'act_fun': 'ReLU', 'init_methods': 'xavier uniform'}\n",
      "fold:  1 , epoch:  1 , val loss:  0.00022455093858297914\n",
      "fold:  1 , epoch:  2 , val loss:  9.733026672620326e-05\n",
      "fold:  1 , epoch:  3 , val loss:  4.8878544475883245e-05\n",
      "fold:  1 , epoch:  4 , val loss:  5.1112594519509e-05\n",
      "fold:  1 , epoch:  5 , val loss:  4.413356145960279e-05\n",
      "fold:  1 , epoch:  6 , val loss:  5.257955126580782e-05\n",
      "fold:  1 , epoch:  7 , val loss:  2.9400933271972463e-05\n",
      "fold:  1 , epoch:  8 , val loss:  2.1824338546139188e-05\n",
      "fold:  1 , epoch:  9 , val loss:  2.0307594240875915e-05\n",
      "fold:  1 , epoch:  10 , val loss:  0.00010018255125032738\n",
      "fold:  1 , epoch:  11 , val loss:  2.8375940019031987e-05\n",
      "fold:  1 , epoch:  12 , val loss:  6.4137413573917e-05\n",
      "fold:  1 , epoch:  13 , val loss:  3.505314089125022e-05\n",
      "fold:  1 , epoch:  14 , val loss:  2.67523337242892e-05\n",
      "fold:  1 , epoch:  15 , val loss:  3.5794033465208486e-05\n",
      "fold:  1 , epoch:  16 , val loss:  2.5588005883037113e-05\n",
      "fold:  1 , epoch:  17 , val loss:  2.3253842300619e-05\n",
      "fold:  1 , epoch:  18 , val loss:  3.3175198041135445e-05\n",
      "fold:  1 , epoch:  19 , val loss:  9.030060755321756e-05\n",
      "fold:  1 , epoch:  20 , val loss:  1.5948744476190768e-05\n",
      "fold:  1 , epoch:  21 , val loss:  2.509387195459567e-05\n",
      "fold:  1 , epoch:  22 , val loss:  1.0755841685750056e-05\n",
      "fold:  1 , epoch:  23 , val loss:  2.3184498786577024e-05\n",
      "fold:  1 , epoch:  24 , val loss:  1.3858294551027939e-05\n",
      "fold:  1 , epoch:  25 , val loss:  2.140219476132188e-05\n",
      "fold:  2 , epoch:  1 , val loss:  2.0625411707442254e-05\n",
      "fold:  2 , epoch:  2 , val loss:  1.718482053547632e-05\n",
      "fold:  2 , epoch:  3 , val loss:  1.2596855412994046e-05\n",
      "fold:  2 , epoch:  4 , val loss:  1.0646429473126773e-05\n",
      "fold:  2 , epoch:  5 , val loss:  8.839267138682771e-06\n",
      "fold:  2 , epoch:  6 , val loss:  1.3564287655754015e-05\n",
      "fold:  2 , epoch:  7 , val loss:  1.8938209905172698e-05\n",
      "fold:  2 , epoch:  8 , val loss:  3.505908534862101e-05\n",
      "fold:  2 , epoch:  9 , val loss:  2.9515869755414315e-05\n",
      "fold:  2 , epoch:  10 , val loss:  2.8375272449920885e-05\n",
      "fold:  2 , epoch:  11 , val loss:  2.191385647165589e-05\n",
      "fold:  2 , epoch:  12 , val loss:  7.172837649704888e-05\n",
      "fold:  2 , epoch:  13 , val loss:  2.0237084754626267e-05\n",
      "fold:  2 , epoch:  14 , val loss:  1.345399232377531e-05\n",
      "fold:  2 , epoch:  15 , val loss:  2.259590291942004e-05\n",
      "fold:  2 , epoch:  16 , val loss:  1.4088243915466592e-05\n",
      "fold:  2 , epoch:  17 , val loss:  2.1454296074807644e-05\n",
      "fold:  2 , epoch:  18 , val loss:  3.0334193070302717e-05\n",
      "fold:  2 , epoch:  19 , val loss:  0.00014266790822148323\n",
      "fold:  2 , epoch:  20 , val loss:  2.8698594178422354e-05\n",
      "fold:  2 , epoch:  21 , val loss:  1.3201225556258578e-05\n",
      "fold:  2 , epoch:  22 , val loss:  6.062492502678651e-06\n",
      "fold:  2 , epoch:  23 , val loss:  1.1042649020964745e-05\n",
      "fold:  2 , epoch:  24 , val loss:  5.021310698793968e-06\n",
      "fold:  2 , epoch:  25 , val loss:  4.624417215381982e-06\n",
      "fold:  3 , epoch:  1 , val loss:  3.5879758797818795e-05\n",
      "fold:  3 , epoch:  2 , val loss:  2.80895437754225e-05\n",
      "fold:  3 , epoch:  3 , val loss:  3.0036671887501143e-05\n",
      "fold:  3 , epoch:  4 , val loss:  1.0025863048213068e-05\n",
      "fold:  3 , epoch:  5 , val loss:  4.3370517232688144e-05\n",
      "fold:  3 , epoch:  6 , val loss:  5.43149872100912e-06\n",
      "fold:  3 , epoch:  7 , val loss:  1.7120426491601393e-05\n",
      "fold:  3 , epoch:  8 , val loss:  9.823703294387087e-06\n",
      "fold:  3 , epoch:  9 , val loss:  4.10549582738895e-05\n",
      "fold:  3 , epoch:  10 , val loss:  2.2220467144506983e-05\n",
      "fold:  3 , epoch:  11 , val loss:  1.8306485799257644e-05\n",
      "fold:  3 , epoch:  12 , val loss:  2.993472844536882e-05\n",
      "fold:  3 , epoch:  13 , val loss:  5.8672221712186e-06\n",
      "fold:  3 , epoch:  14 , val loss:  6.6878542384074535e-06\n",
      "fold:  3 , epoch:  15 , val loss:  5.350613719201647e-05\n",
      "fold:  3 , epoch:  16 , val loss:  2.316115569556132e-05\n",
      "fold:  3 , epoch:  17 , val loss:  4.038478436996229e-06\n",
      "fold:  3 , epoch:  18 , val loss:  7.4531785685394425e-06\n",
      "fold:  3 , epoch:  19 , val loss:  5.427110409073066e-06\n",
      "fold:  3 , epoch:  20 , val loss:  3.752406882995274e-06\n",
      "fold:  3 , epoch:  21 , val loss:  5.091785169497598e-06\n",
      "fold:  3 , epoch:  22 , val loss:  6.1160631048551295e-06\n",
      "fold:  3 , epoch:  23 , val loss:  1.0681022104108706e-05\n",
      "fold:  3 , epoch:  24 , val loss:  4.306322352931602e-06\n",
      "fold:  3 , epoch:  25 , val loss:  6.0527745517902076e-05\n",
      "fold:  4 , epoch:  1 , val loss:  4.37153767052223e-06\n",
      "fold:  4 , epoch:  2 , val loss:  6.475202098954469e-06\n",
      "fold:  4 , epoch:  3 , val loss:  1.2410056115186308e-05\n",
      "fold:  4 , epoch:  4 , val loss:  6.249152647797018e-06\n",
      "fold:  4 , epoch:  5 , val loss:  4.946509307046654e-06\n",
      "fold:  4 , epoch:  6 , val loss:  4.174679361312883e-06\n",
      "fold:  4 , epoch:  7 , val loss:  2.37153290072456e-05\n",
      "fold:  4 , epoch:  8 , val loss:  1.0114786164194811e-05\n",
      "fold:  4 , epoch:  9 , val loss:  4.663251274905633e-06\n",
      "fold:  4 , epoch:  10 , val loss:  4.768905910168542e-06\n",
      "fold:  4 , epoch:  11 , val loss:  7.985318916325923e-06\n",
      "fold:  4 , epoch:  12 , val loss:  3.202355856046779e-06\n",
      "fold:  4 , epoch:  13 , val loss:  2.9065447961329482e-05\n",
      "fold:  4 , epoch:  14 , val loss:  4.325068584876135e-05\n",
      "fold:  4 , epoch:  15 , val loss:  1.0357935025240295e-05\n",
      "fold:  4 , epoch:  16 , val loss:  8.479289681417868e-05\n",
      "fold:  4 , epoch:  17 , val loss:  3.558378239176818e-06\n",
      "fold:  4 , epoch:  18 , val loss:  4.220188930048607e-05\n",
      "fold:  4 , epoch:  19 , val loss:  8.530884770152625e-06\n",
      "fold:  4 , epoch:  20 , val loss:  6.532070528919576e-06\n",
      "fold:  4 , epoch:  21 , val loss:  3.2754612675489625e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  4 , epoch:  22 , val loss:  3.1508282063441584e-06\n",
      "fold:  4 , epoch:  23 , val loss:  4.208840891806176e-06\n",
      "fold:  4 , epoch:  24 , val loss:  4.543131581158377e-06\n",
      "fold:  4 , epoch:  25 , val loss:  3.4350057831034064e-05\n",
      "fold:  5 , epoch:  1 , val loss:  1.4781789104745258e-05\n",
      "fold:  5 , epoch:  2 , val loss:  3.1155821034190012e-06\n",
      "fold:  5 , epoch:  3 , val loss:  2.667716898940853e-06\n",
      "fold:  5 , epoch:  4 , val loss:  1.7985674276133068e-05\n",
      "fold:  5 , epoch:  5 , val loss:  4.739789437735453e-05\n",
      "fold:  5 , epoch:  6 , val loss:  9.635716196498834e-06\n",
      "fold:  5 , epoch:  7 , val loss:  3.1576203127769986e-06\n",
      "fold:  5 , epoch:  8 , val loss:  4.037908183818217e-06\n",
      "fold:  5 , epoch:  9 , val loss:  5.042232260166202e-06\n",
      "fold:  5 , epoch:  10 , val loss:  2.558826508902712e-06\n",
      "fold:  5 , epoch:  11 , val loss:  4.374978743726388e-06\n",
      "fold:  5 , epoch:  12 , val loss:  2.5801960873650387e-05\n",
      "fold:  5 , epoch:  13 , val loss:  1.4856833331577946e-05\n",
      "fold:  5 , epoch:  14 , val loss:  3.763012045965297e-06\n",
      "fold:  5 , epoch:  15 , val loss:  8.76994636200834e-06\n",
      "fold:  5 , epoch:  16 , val loss:  3.348116251800093e-06\n",
      "fold:  5 , epoch:  17 , val loss:  3.506167558953166e-05\n",
      "fold:  5 , epoch:  18 , val loss:  3.2015095712267794e-06\n",
      "fold:  5 , epoch:  19 , val loss:  5.504200998984743e-06\n",
      "fold:  5 , epoch:  20 , val loss:  7.986777745827567e-06\n",
      "fold:  5 , epoch:  21 , val loss:  7.401366474368842e-06\n",
      "fold:  5 , epoch:  22 , val loss:  3.637837653513998e-05\n",
      "fold:  5 , epoch:  23 , val loss:  1.2660713764489628e-05\n",
      "fold:  5 , epoch:  24 , val loss:  8.173163223545998e-06\n",
      "fold:  5 , epoch:  25 , val loss:  1.1196038030902855e-05\n",
      "Model results:  {'hidden_size': 600, 'n_layers': 6, 'act_fun': 'ReLU', 'init_methods': 'xavier uniform', 'mean_val_result': 2.3544889727418196e-05, 'std_val_result': 2.895236751043195e-05} \n",
      "\n",
      "Model:  {'hidden_size': 600, 'n_layers': 6, 'act_fun': 'LeakyReLU', 'init_methods': 'xavier normal'}\n",
      "fold:  1 , epoch:  1 , val loss:  0.00021046586334705353\n",
      "fold:  1 , epoch:  2 , val loss:  0.0001996627397602424\n",
      "fold:  1 , epoch:  3 , val loss:  0.0003944002964999527\n",
      "fold:  1 , epoch:  4 , val loss:  0.0001495191390858963\n",
      "fold:  1 , epoch:  5 , val loss:  3.4183976822532713e-05\n",
      "fold:  1 , epoch:  6 , val loss:  0.0001468332629883662\n",
      "fold:  1 , epoch:  7 , val loss:  7.953080057632178e-05\n",
      "fold:  1 , epoch:  8 , val loss:  6.510502134915441e-05\n",
      "fold:  1 , epoch:  9 , val loss:  2.5229497623513453e-05\n",
      "fold:  1 , epoch:  10 , val loss:  2.0992194549762644e-05\n",
      "fold:  1 , epoch:  11 , val loss:  2.4449152988381684e-05\n",
      "fold:  1 , epoch:  12 , val loss:  8.109499322017655e-05\n",
      "fold:  1 , epoch:  13 , val loss:  1.786106440704316e-05\n",
      "fold:  1 , epoch:  14 , val loss:  2.587407288956456e-05\n",
      "fold:  1 , epoch:  15 , val loss:  1.3318851415533572e-05\n",
      "fold:  1 , epoch:  16 , val loss:  1.9026720110559836e-05\n",
      "fold:  1 , epoch:  17 , val loss:  1.8337290384806693e-05\n",
      "fold:  1 , epoch:  18 , val loss:  5.4986554459901527e-05\n",
      "fold:  1 , epoch:  19 , val loss:  3.6469307815423235e-05\n",
      "fold:  1 , epoch:  20 , val loss:  6.28595516900532e-05\n",
      "fold:  1 , epoch:  21 , val loss:  3.973837738158181e-05\n",
      "fold:  1 , epoch:  22 , val loss:  3.112745616817847e-05\n",
      "fold:  1 , epoch:  23 , val loss:  5.848522050655447e-05\n",
      "fold:  1 , epoch:  24 , val loss:  4.6302728151204064e-05\n",
      "fold:  1 , epoch:  25 , val loss:  2.586753726063762e-05\n",
      "fold:  2 , epoch:  1 , val loss:  3.806865424849093e-05\n",
      "fold:  2 , epoch:  2 , val loss:  5.189724106458016e-05\n",
      "fold:  2 , epoch:  3 , val loss:  7.537679266533814e-06\n",
      "fold:  2 , epoch:  4 , val loss:  6.0905520513188094e-05\n",
      "fold:  2 , epoch:  5 , val loss:  0.00017867008864413947\n",
      "fold:  2 , epoch:  6 , val loss:  0.0004771783424075693\n",
      "fold:  2 , epoch:  7 , val loss:  0.00013393651170190424\n",
      "fold:  2 , epoch:  8 , val loss:  3.957461012760177e-05\n",
      "fold:  2 , epoch:  9 , val loss:  0.0001003520519589074\n",
      "fold:  2 , epoch:  10 , val loss:  1.355152198811993e-05\n",
      "fold:  2 , epoch:  11 , val loss:  1.5247051123878919e-05\n",
      "fold:  2 , epoch:  12 , val loss:  2.4762048269622028e-05\n",
      "fold:  2 , epoch:  13 , val loss:  4.9832433433039114e-05\n",
      "fold:  2 , epoch:  14 , val loss:  9.682289237389341e-05\n",
      "fold:  2 , epoch:  15 , val loss:  1.3670793123310432e-05\n",
      "fold:  2 , epoch:  16 , val loss:  2.4234719603555277e-05\n",
      "fold:  2 , epoch:  17 , val loss:  7.229598395497305e-06\n",
      "fold:  2 , epoch:  18 , val loss:  5.3992003813618794e-05\n",
      "fold:  2 , epoch:  19 , val loss:  0.00010034265869762748\n",
      "fold:  2 , epoch:  20 , val loss:  0.00010995888442266732\n",
      "fold:  2 , epoch:  21 , val loss:  0.00021960330195724964\n",
      "fold:  2 , epoch:  22 , val loss:  1.7417309209122322e-05\n",
      "fold:  2 , epoch:  23 , val loss:  7.257048764586216e-06\n",
      "fold:  2 , epoch:  24 , val loss:  2.5358760467497632e-05\n",
      "fold:  2 , epoch:  25 , val loss:  8.088794129434973e-05\n",
      "fold:  3 , epoch:  1 , val loss:  2.641397077240981e-05\n",
      "fold:  3 , epoch:  2 , val loss:  2.9162023565731943e-05\n",
      "fold:  3 , epoch:  3 , val loss:  1.2718895959551446e-05\n",
      "fold:  3 , epoch:  4 , val loss:  8.483838610118255e-05\n",
      "fold:  3 , epoch:  5 , val loss:  1.1106455531262327e-05\n",
      "fold:  3 , epoch:  6 , val loss:  3.1462113838642836e-05\n",
      "fold:  3 , epoch:  7 , val loss:  1.233880266227061e-05\n",
      "fold:  3 , epoch:  8 , val loss:  0.000109624867036473\n",
      "fold:  3 , epoch:  9 , val loss:  0.00016544795653317124\n",
      "fold:  3 , epoch:  10 , val loss:  0.00010338196443626657\n",
      "fold:  3 , epoch:  11 , val loss:  7.019587428658269e-06\n",
      "fold:  3 , epoch:  12 , val loss:  5.840414360136492e-06\n",
      "fold:  3 , epoch:  13 , val loss:  1.1241441825404763e-05\n",
      "fold:  3 , epoch:  14 , val loss:  1.5482140952371992e-05\n",
      "fold:  3 , epoch:  15 , val loss:  3.6780045775230974e-05\n",
      "fold:  3 , epoch:  16 , val loss:  2.667621993168723e-05\n",
      "fold:  3 , epoch:  17 , val loss:  1.957238964678254e-05\n",
      "fold:  3 , epoch:  18 , val loss:  2.815068182826508e-05\n",
      "fold:  3 , epoch:  19 , val loss:  4.222553798172157e-06\n",
      "fold:  3 , epoch:  20 , val loss:  5.630306986859068e-06\n",
      "fold:  3 , epoch:  21 , val loss:  1.1688050108205061e-05\n",
      "fold:  3 , epoch:  22 , val loss:  3.138534157187678e-05\n",
      "fold:  3 , epoch:  23 , val loss:  3.3406904549337924e-05\n",
      "fold:  3 , epoch:  24 , val loss:  9.694921027403325e-05\n",
      "fold:  3 , epoch:  25 , val loss:  7.170579920057207e-06\n",
      "fold:  4 , epoch:  1 , val loss:  8.924891517381184e-06\n",
      "fold:  4 , epoch:  2 , val loss:  8.948629329097457e-06\n",
      "fold:  4 , epoch:  3 , val loss:  1.8873945009545423e-05\n",
      "fold:  4 , epoch:  4 , val loss:  3.020228359673638e-05\n",
      "fold:  4 , epoch:  5 , val loss:  7.693033694522455e-06\n",
      "fold:  4 , epoch:  6 , val loss:  5.358665930543793e-06\n",
      "fold:  4 , epoch:  7 , val loss:  7.944316166685894e-06\n",
      "fold:  4 , epoch:  8 , val loss:  7.430601272062631e-06\n",
      "fold:  4 , epoch:  9 , val loss:  9.831143870542292e-06\n",
      "fold:  4 , epoch:  10 , val loss:  1.3139938346284907e-05\n",
      "fold:  4 , epoch:  11 , val loss:  3.619139306465513e-06\n",
      "fold:  4 , epoch:  12 , val loss:  3.994707185484003e-06\n",
      "fold:  4 , epoch:  13 , val loss:  3.240925025238539e-06\n",
      "fold:  4 , epoch:  14 , val loss:  3.5248314816271886e-05\n",
      "fold:  4 , epoch:  15 , val loss:  1.5280023944796994e-05\n",
      "fold:  4 , epoch:  16 , val loss:  3.2491263937117765e-06\n",
      "fold:  4 , epoch:  17 , val loss:  2.4592898171249544e-06\n",
      "fold:  4 , epoch:  18 , val loss:  5.808097739645746e-06\n",
      "fold:  4 , epoch:  19 , val loss:  8.96482106327312e-06\n",
      "fold:  4 , epoch:  20 , val loss:  1.0739539902715478e-05\n",
      "fold:  4 , epoch:  21 , val loss:  1.282891389564611e-05\n",
      "fold:  4 , epoch:  22 , val loss:  6.784352535760263e-06\n",
      "fold:  4 , epoch:  23 , val loss:  4.777522917720489e-06\n",
      "fold:  4 , epoch:  24 , val loss:  1.616995723452419e-05\n",
      "fold:  4 , epoch:  25 , val loss:  6.083250809751917e-06\n",
      "fold:  5 , epoch:  1 , val loss:  3.856130661006318e-06\n",
      "fold:  5 , epoch:  2 , val loss:  1.1917523806914687e-05\n",
      "fold:  5 , epoch:  3 , val loss:  7.548202574980678e-06\n",
      "fold:  5 , epoch:  4 , val loss:  7.568553428427549e-06\n",
      "fold:  5 , epoch:  5 , val loss:  1.7468250007368624e-05\n",
      "fold:  5 , epoch:  6 , val loss:  9.056136150320526e-06\n",
      "fold:  5 , epoch:  7 , val loss:  1.7233003745786846e-05\n",
      "fold:  5 , epoch:  8 , val loss:  5.835245701746317e-06\n",
      "fold:  5 , epoch:  9 , val loss:  9.630675776861608e-06\n",
      "fold:  5 , epoch:  10 , val loss:  4.096880729775876e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  5 , epoch:  11 , val loss:  5.747675459133461e-06\n",
      "fold:  5 , epoch:  12 , val loss:  1.1212934623472393e-05\n",
      "fold:  5 , epoch:  13 , val loss:  2.371923255850561e-05\n",
      "fold:  5 , epoch:  14 , val loss:  7.329771324293688e-05\n",
      "fold:  5 , epoch:  15 , val loss:  6.556339940289035e-05\n",
      "fold:  5 , epoch:  16 , val loss:  4.383475607028231e-05\n",
      "fold:  5 , epoch:  17 , val loss:  1.5804809663677588e-05\n",
      "fold:  5 , epoch:  18 , val loss:  2.445751306368038e-05\n",
      "fold:  5 , epoch:  19 , val loss:  1.4445254237216432e-05\n",
      "fold:  5 , epoch:  20 , val loss:  2.782216370178503e-06\n",
      "fold:  5 , epoch:  21 , val loss:  9.455184226681013e-06\n",
      "fold:  5 , epoch:  22 , val loss:  1.2977646292711142e-05\n",
      "fold:  5 , epoch:  23 , val loss:  3.397380396563676e-06\n",
      "fold:  5 , epoch:  24 , val loss:  4.1011358007381205e-06\n",
      "fold:  5 , epoch:  25 , val loss:  7.584265858895378e-06\n",
      "Model results:  {'hidden_size': 600, 'n_layers': 6, 'act_fun': 'LeakyReLU', 'init_methods': 'xavier normal', 'mean_val_result': 4.3718253771658056e-05, 'std_val_result': 6.762681177116975e-05} \n",
      "\n",
      "Model:  {'hidden_size': 400, 'n_layers': 8, 'act_fun': 'ReLU', 'init_methods': 'xavier uniform'}\n",
      "fold:  1 , epoch:  1 , val loss:  0.00026326559600420296\n",
      "fold:  1 , epoch:  2 , val loss:  0.00019085381063632667\n",
      "fold:  1 , epoch:  3 , val loss:  0.00016054774459917098\n",
      "fold:  1 , epoch:  4 , val loss:  4.5250544644659385e-05\n",
      "fold:  1 , epoch:  5 , val loss:  6.1006579926470295e-05\n",
      "fold:  1 , epoch:  6 , val loss:  0.0001719981519272551\n",
      "fold:  1 , epoch:  7 , val loss:  9.336874791188166e-05\n",
      "fold:  1 , epoch:  8 , val loss:  6.117603334132582e-05\n",
      "fold:  1 , epoch:  9 , val loss:  4.054136297781952e-05\n",
      "fold:  1 , epoch:  10 , val loss:  8.313776925206184e-05\n",
      "fold:  1 , epoch:  11 , val loss:  1.785728454706259e-05\n",
      "fold:  1 , epoch:  12 , val loss:  2.0095963918720372e-05\n",
      "fold:  1 , epoch:  13 , val loss:  9.04184635146521e-05\n",
      "fold:  1 , epoch:  14 , val loss:  2.6854091629502364e-05\n",
      "fold:  1 , epoch:  15 , val loss:  1.3211151781433728e-05\n",
      "fold:  1 , epoch:  16 , val loss:  5.929120379732922e-05\n",
      "fold:  1 , epoch:  17 , val loss:  1.581438846187666e-05\n",
      "fold:  1 , epoch:  18 , val loss:  1.1598783203226048e-05\n",
      "fold:  1 , epoch:  19 , val loss:  2.5802812160691246e-05\n",
      "fold:  1 , epoch:  20 , val loss:  5.996827167109586e-05\n",
      "fold:  1 , epoch:  21 , val loss:  2.542221591284033e-05\n",
      "fold:  1 , epoch:  22 , val loss:  2.766809302556794e-05\n",
      "fold:  1 , epoch:  23 , val loss:  1.181433708552504e-05\n",
      "fold:  1 , epoch:  24 , val loss:  1.2391540622047614e-05\n",
      "fold:  1 , epoch:  25 , val loss:  1.5530727978330106e-05\n",
      "fold:  2 , epoch:  1 , val loss:  2.0314852008596063e-05\n",
      "fold:  2 , epoch:  2 , val loss:  9.875122486846521e-06\n",
      "fold:  2 , epoch:  3 , val loss:  1.418589545210125e-05\n",
      "fold:  2 , epoch:  4 , val loss:  2.8164004106656648e-05\n",
      "fold:  2 , epoch:  5 , val loss:  2.1006886527175084e-05\n",
      "fold:  2 , epoch:  6 , val loss:  1.6443542335764505e-05\n",
      "fold:  2 , epoch:  7 , val loss:  9.65394065133296e-06\n",
      "fold:  2 , epoch:  8 , val loss:  1.344082374998834e-05\n",
      "fold:  2 , epoch:  9 , val loss:  2.166906779166311e-05\n",
      "fold:  2 , epoch:  10 , val loss:  8.556942702853121e-06\n",
      "fold:  2 , epoch:  11 , val loss:  6.8667441155412234e-06\n",
      "fold:  2 , epoch:  12 , val loss:  0.00017484142153989524\n",
      "fold:  2 , epoch:  13 , val loss:  9.492706885794178e-05\n",
      "fold:  2 , epoch:  14 , val loss:  1.0473402653587982e-05\n",
      "fold:  2 , epoch:  15 , val loss:  7.329952950385632e-06\n",
      "fold:  2 , epoch:  16 , val loss:  1.2626468560483772e-05\n",
      "fold:  2 , epoch:  17 , val loss:  6.83414691593498e-05\n",
      "fold:  2 , epoch:  18 , val loss:  1.0164633749809582e-05\n",
      "fold:  2 , epoch:  19 , val loss:  2.0186671463306993e-05\n",
      "fold:  2 , epoch:  20 , val loss:  1.6071844584075734e-05\n",
      "fold:  2 , epoch:  21 , val loss:  1.2595222870004363e-05\n",
      "fold:  2 , epoch:  22 , val loss:  5.1208822696935385e-05\n",
      "fold:  2 , epoch:  23 , val loss:  7.441641173500102e-06\n",
      "fold:  2 , epoch:  24 , val loss:  1.4956582162994891e-05\n",
      "fold:  2 , epoch:  25 , val loss:  3.130470577161759e-05\n",
      "fold:  3 , epoch:  1 , val loss:  1.5080821867741179e-05\n",
      "fold:  3 , epoch:  2 , val loss:  2.4525388653273694e-05\n",
      "fold:  3 , epoch:  3 , val loss:  1.907197838590946e-05\n",
      "fold:  3 , epoch:  4 , val loss:  6.350039711833233e-06\n",
      "fold:  3 , epoch:  5 , val loss:  5.1032107876380906e-05\n",
      "fold:  3 , epoch:  6 , val loss:  7.658615686523262e-06\n",
      "fold:  3 , epoch:  7 , val loss:  1.8765711502055638e-05\n",
      "fold:  3 , epoch:  8 , val loss:  1.653066647122614e-05\n",
      "fold:  3 , epoch:  9 , val loss:  1.197926849272335e-05\n",
      "fold:  3 , epoch:  10 , val loss:  7.550217105745105e-06\n",
      "fold:  3 , epoch:  11 , val loss:  6.344640496536158e-06\n",
      "fold:  3 , epoch:  12 , val loss:  6.075482815504074e-06\n",
      "fold:  3 , epoch:  13 , val loss:  3.385549644008279e-05\n",
      "fold:  3 , epoch:  14 , val loss:  3.336004738230258e-05\n",
      "fold:  3 , epoch:  15 , val loss:  2.1849657059647143e-05\n",
      "fold:  3 , epoch:  16 , val loss:  5.167489234736422e-06\n",
      "fold:  3 , epoch:  17 , val loss:  4.3265467866149265e-06\n",
      "fold:  3 , epoch:  18 , val loss:  5.22214213560801e-06\n",
      "fold:  3 , epoch:  19 , val loss:  8.505259756930172e-06\n",
      "fold:  3 , epoch:  20 , val loss:  3.602972356020473e-05\n",
      "fold:  3 , epoch:  21 , val loss:  2.8840835511800833e-05\n",
      "fold:  3 , epoch:  22 , val loss:  4.098858880752232e-06\n",
      "fold:  3 , epoch:  23 , val loss:  7.600480785185937e-06\n",
      "fold:  3 , epoch:  24 , val loss:  2.445057180011645e-05\n",
      "fold:  3 , epoch:  25 , val loss:  3.0811846954748034e-05\n",
      "fold:  4 , epoch:  1 , val loss:  3.601850039558485e-05\n",
      "fold:  4 , epoch:  2 , val loss:  3.876843948091846e-06\n",
      "fold:  4 , epoch:  3 , val loss:  4.39318091594032e-06\n",
      "fold:  4 , epoch:  4 , val loss:  1.4684078450954985e-05\n",
      "fold:  4 , epoch:  5 , val loss:  8.507323400408495e-06\n",
      "fold:  4 , epoch:  6 , val loss:  8.671227078593802e-06\n",
      "fold:  4 , epoch:  7 , val loss:  4.212629210087471e-05\n",
      "fold:  4 , epoch:  8 , val loss:  2.2654257918475196e-05\n",
      "fold:  4 , epoch:  9 , val loss:  2.4782801119727083e-05\n",
      "fold:  4 , epoch:  10 , val loss:  3.9890987864055205e-06\n",
      "fold:  4 , epoch:  11 , val loss:  2.042094274656847e-05\n",
      "fold:  4 , epoch:  12 , val loss:  3.10086375066021e-06\n",
      "fold:  4 , epoch:  13 , val loss:  1.7847651179181412e-05\n",
      "fold:  4 , epoch:  14 , val loss:  8.223209079005755e-06\n",
      "fold:  4 , epoch:  15 , val loss:  3.60905755769636e-06\n",
      "fold:  4 , epoch:  16 , val loss:  3.8928387766645756e-06\n",
      "fold:  4 , epoch:  17 , val loss:  2.6699763111537322e-06\n",
      "fold:  4 , epoch:  18 , val loss:  2.607670467114076e-06\n",
      "fold:  4 , epoch:  19 , val loss:  4.984178667655215e-05\n",
      "fold:  4 , epoch:  20 , val loss:  9.791147931537125e-06\n",
      "fold:  4 , epoch:  21 , val loss:  5.330843123374507e-06\n",
      "fold:  4 , epoch:  22 , val loss:  5.88402781431796e-06\n",
      "fold:  4 , epoch:  23 , val loss:  7.0217256507021375e-06\n",
      "fold:  4 , epoch:  24 , val loss:  1.600936593604274e-05\n",
      "fold:  4 , epoch:  25 , val loss:  5.2991021220805123e-05\n",
      "fold:  5 , epoch:  1 , val loss:  2.292762246725033e-06\n",
      "fold:  5 , epoch:  2 , val loss:  3.789732545556035e-06\n",
      "fold:  5 , epoch:  3 , val loss:  6.098981884861132e-06\n",
      "fold:  5 , epoch:  4 , val loss:  3.897623173543252e-06\n",
      "fold:  5 , epoch:  5 , val loss:  2.4665198452566983e-06\n",
      "fold:  5 , epoch:  6 , val loss:  4.123024154978339e-06\n",
      "fold:  5 , epoch:  7 , val loss:  4.114436706004199e-06\n",
      "fold:  5 , epoch:  8 , val loss:  3.700427669173223e-06\n",
      "fold:  5 , epoch:  9 , val loss:  6.081791980250273e-06\n",
      "fold:  5 , epoch:  10 , val loss:  3.628507556641125e-06\n",
      "fold:  5 , epoch:  11 , val loss:  5.937384685239522e-06\n",
      "fold:  5 , epoch:  12 , val loss:  1.1796803846664261e-05\n",
      "fold:  5 , epoch:  13 , val loss:  1.0744072824309114e-05\n",
      "fold:  5 , epoch:  14 , val loss:  8.107155736070126e-06\n",
      "fold:  5 , epoch:  15 , val loss:  9.031585250340868e-06\n",
      "fold:  5 , epoch:  16 , val loss:  5.9812759900523815e-06\n",
      "fold:  5 , epoch:  17 , val loss:  3.4535062241047854e-06\n",
      "fold:  5 , epoch:  18 , val loss:  2.575513235569815e-06\n",
      "fold:  5 , epoch:  19 , val loss:  2.9585050924652023e-06\n",
      "fold:  5 , epoch:  20 , val loss:  3.0657035949843703e-06\n",
      "fold:  5 , epoch:  21 , val loss:  3.171503976773238e-06\n",
      "fold:  5 , epoch:  22 , val loss:  4.505391189013608e-06\n",
      "fold:  5 , epoch:  23 , val loss:  9.80892036750447e-06\n",
      "fold:  5 , epoch:  24 , val loss:  2.5441215257160366e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  5 , epoch:  25 , val loss:  3.580029442673549e-06\n",
      "Model results:  {'hidden_size': 400, 'n_layers': 8, 'act_fun': 'ReLU', 'init_methods': 'xavier uniform', 'mean_val_result': 2.617532322256011e-05, 'std_val_result': 3.987268616473944e-05} \n",
      "\n",
      "Model:  {'hidden_size': 200, 'n_layers': 4, 'act_fun': 'ELU', 'init_methods': 'xavier uniform'}\n",
      "fold:  1 , epoch:  1 , val loss:  0.00830057729035616\n",
      "fold:  1 , epoch:  2 , val loss:  0.0032745273783802986\n",
      "fold:  1 , epoch:  3 , val loss:  0.0017530195182189345\n",
      "fold:  1 , epoch:  4 , val loss:  0.0010464494116604328\n",
      "fold:  1 , epoch:  5 , val loss:  0.0007053331355564296\n",
      "fold:  1 , epoch:  6 , val loss:  0.00047634379006922245\n",
      "fold:  1 , epoch:  7 , val loss:  0.00041956763016059995\n",
      "fold:  1 , epoch:  8 , val loss:  0.00028877155273221433\n",
      "fold:  1 , epoch:  9 , val loss:  0.00024333709734492004\n",
      "fold:  1 , epoch:  10 , val loss:  0.00025341869331896305\n",
      "fold:  1 , epoch:  11 , val loss:  0.00022344828175846487\n",
      "fold:  1 , epoch:  12 , val loss:  0.00019766528566833586\n",
      "fold:  1 , epoch:  13 , val loss:  0.00018268993881065398\n",
      "fold:  1 , epoch:  14 , val loss:  0.00016361552115995437\n",
      "fold:  1 , epoch:  15 , val loss:  0.00014513944915961474\n",
      "fold:  1 , epoch:  16 , val loss:  0.00014073705824557692\n",
      "fold:  1 , epoch:  17 , val loss:  0.000148041668580845\n",
      "fold:  1 , epoch:  18 , val loss:  0.00013779543223790824\n",
      "fold:  1 , epoch:  19 , val loss:  0.00012043723108945414\n",
      "fold:  1 , epoch:  20 , val loss:  0.0001100229928852059\n",
      "fold:  1 , epoch:  21 , val loss:  0.0001041632131091319\n",
      "fold:  1 , epoch:  22 , val loss:  9.838168625719845e-05\n",
      "fold:  1 , epoch:  23 , val loss:  9.51773690758273e-05\n",
      "fold:  1 , epoch:  24 , val loss:  9.662486263550818e-05\n",
      "fold:  1 , epoch:  25 , val loss:  0.00010040168126579374\n",
      "fold:  2 , epoch:  1 , val loss:  7.792895485181361e-05\n",
      "fold:  2 , epoch:  2 , val loss:  6.326674338197336e-05\n",
      "fold:  2 , epoch:  3 , val loss:  5.938362664892338e-05\n",
      "fold:  2 , epoch:  4 , val loss:  6.037330240360461e-05\n",
      "fold:  2 , epoch:  5 , val loss:  5.6470336858183146e-05\n",
      "fold:  2 , epoch:  6 , val loss:  9.330292959930375e-05\n",
      "fold:  2 , epoch:  7 , val loss:  0.00013843778287991881\n",
      "fold:  2 , epoch:  8 , val loss:  6.447351915994659e-05\n",
      "fold:  2 , epoch:  9 , val loss:  6.611454591620713e-05\n",
      "fold:  2 , epoch:  10 , val loss:  6.723328988300636e-05\n",
      "fold:  2 , epoch:  11 , val loss:  6.539483001688495e-05\n",
      "fold:  2 , epoch:  12 , val loss:  6.136871525086462e-05\n",
      "fold:  2 , epoch:  13 , val loss:  5.81260392209515e-05\n",
      "fold:  2 , epoch:  14 , val loss:  5.668338417308405e-05\n",
      "fold:  2 , epoch:  15 , val loss:  5.566956315306015e-05\n",
      "fold:  2 , epoch:  16 , val loss:  5.513309224625118e-05\n",
      "fold:  2 , epoch:  17 , val loss:  5.490726471180096e-05\n",
      "fold:  2 , epoch:  18 , val loss:  5.518049147212878e-05\n",
      "fold:  2 , epoch:  19 , val loss:  5.6200617109425366e-05\n",
      "fold:  2 , epoch:  20 , val loss:  5.6820103054633364e-05\n",
      "fold:  2 , epoch:  21 , val loss:  5.839809091412462e-05\n",
      "fold:  2 , epoch:  22 , val loss:  5.830320151289925e-05\n",
      "fold:  2 , epoch:  23 , val loss:  5.9020912885898724e-05\n",
      "fold:  2 , epoch:  24 , val loss:  6.143071368569508e-05\n",
      "fold:  2 , epoch:  25 , val loss:  6.551604747073725e-05\n",
      "fold:  3 , epoch:  1 , val loss:  9.889448847388849e-05\n",
      "fold:  3 , epoch:  2 , val loss:  9.093640983337536e-05\n",
      "fold:  3 , epoch:  3 , val loss:  9.942139149643481e-05\n",
      "fold:  3 , epoch:  4 , val loss:  0.00011246294161537662\n",
      "fold:  3 , epoch:  5 , val loss:  0.00013035206939093769\n",
      "fold:  3 , epoch:  6 , val loss:  0.000136083661345765\n",
      "fold:  3 , epoch:  7 , val loss:  0.0001297988637816161\n",
      "fold:  3 , epoch:  8 , val loss:  5.291424167808145e-05\n",
      "fold:  3 , epoch:  9 , val loss:  3.408006523386575e-05\n",
      "fold:  3 , epoch:  10 , val loss:  3.281730096205138e-05\n",
      "fold:  3 , epoch:  11 , val loss:  5.152612357051112e-05\n",
      "fold:  3 , epoch:  12 , val loss:  2.844994560291525e-05\n",
      "fold:  3 , epoch:  13 , val loss:  3.591724453144707e-05\n",
      "fold:  3 , epoch:  14 , val loss:  2.483122625562828e-05\n",
      "fold:  3 , epoch:  15 , val loss:  2.8373211534926668e-05\n",
      "fold:  3 , epoch:  16 , val loss:  2.9194285161793232e-05\n",
      "fold:  3 , epoch:  17 , val loss:  2.8025611754856072e-05\n",
      "fold:  3 , epoch:  18 , val loss:  2.922815110650845e-05\n",
      "fold:  3 , epoch:  19 , val loss:  2.7645581212709658e-05\n",
      "fold:  3 , epoch:  20 , val loss:  3.524745989125222e-05\n",
      "fold:  3 , epoch:  21 , val loss:  3.2068975997390226e-05\n",
      "fold:  3 , epoch:  22 , val loss:  6.02666987106204e-05\n",
      "fold:  3 , epoch:  23 , val loss:  3.0832023185212165e-05\n",
      "fold:  3 , epoch:  24 , val loss:  2.7959276849287562e-05\n",
      "fold:  3 , epoch:  25 , val loss:  2.282171590195503e-05\n",
      "fold:  4 , epoch:  1 , val loss:  1.8927701603388414e-05\n",
      "fold:  4 , epoch:  2 , val loss:  0.00010816854774020612\n",
      "fold:  4 , epoch:  3 , val loss:  8.479940152028576e-05\n",
      "fold:  4 , epoch:  4 , val loss:  1.555701601319015e-05\n",
      "fold:  4 , epoch:  5 , val loss:  9.548204980092123e-05\n",
      "fold:  4 , epoch:  6 , val loss:  1.4788633052376099e-05\n",
      "fold:  4 , epoch:  7 , val loss:  0.00012242536467965692\n",
      "fold:  4 , epoch:  8 , val loss:  1.5647457985323854e-05\n",
      "fold:  4 , epoch:  9 , val loss:  0.0001489290880272165\n",
      "fold:  4 , epoch:  10 , val loss:  0.00013602126273326576\n",
      "fold:  4 , epoch:  11 , val loss:  1.4255694622988813e-05\n",
      "fold:  4 , epoch:  12 , val loss:  1.9427796360105276e-05\n",
      "fold:  4 , epoch:  13 , val loss:  1.473470274504507e-05\n",
      "fold:  4 , epoch:  14 , val loss:  0.00017686339560896158\n",
      "fold:  4 , epoch:  15 , val loss:  0.00013931251305621117\n",
      "fold:  4 , epoch:  16 , val loss:  4.572247416945174e-05\n",
      "fold:  4 , epoch:  17 , val loss:  8.165993494912982e-05\n",
      "fold:  4 , epoch:  18 , val loss:  8.69089417392388e-05\n",
      "fold:  4 , epoch:  19 , val loss:  1.2974532182852272e-05\n",
      "fold:  4 , epoch:  20 , val loss:  1.9899838662240654e-05\n",
      "fold:  4 , epoch:  21 , val loss:  0.00010913162986980751\n",
      "fold:  4 , epoch:  22 , val loss:  3.039615876332391e-05\n",
      "fold:  4 , epoch:  23 , val loss:  0.0001726387708913535\n",
      "fold:  4 , epoch:  24 , val loss:  0.00013368621875997633\n",
      "fold:  4 , epoch:  25 , val loss:  6.521739851450548e-05\n",
      "fold:  5 , epoch:  1 , val loss:  1.0217694580205716e-05\n",
      "fold:  5 , epoch:  2 , val loss:  1.773734220478218e-05\n",
      "fold:  5 , epoch:  3 , val loss:  8.748382242629305e-06\n",
      "fold:  5 , epoch:  4 , val loss:  1.0656889571691863e-05\n",
      "fold:  5 , epoch:  5 , val loss:  8.611478733655531e-06\n",
      "fold:  5 , epoch:  6 , val loss:  1.0805744750541635e-05\n",
      "fold:  5 , epoch:  7 , val loss:  9.024986866279505e-06\n",
      "fold:  5 , epoch:  8 , val loss:  1.0545218174229376e-05\n",
      "fold:  5 , epoch:  9 , val loss:  9.420081369171385e-06\n",
      "fold:  5 , epoch:  10 , val loss:  1.896592766570393e-05\n",
      "fold:  5 , epoch:  11 , val loss:  1.1741243724827655e-05\n",
      "fold:  5 , epoch:  12 , val loss:  9.914544534694869e-06\n",
      "fold:  5 , epoch:  13 , val loss:  1.2712042916973587e-05\n",
      "fold:  5 , epoch:  14 , val loss:  1.4613197890867013e-05\n",
      "fold:  5 , epoch:  15 , val loss:  1.147156763181556e-05\n",
      "fold:  5 , epoch:  16 , val loss:  1.2604099538293667e-05\n",
      "fold:  5 , epoch:  17 , val loss:  2.0632569430745207e-05\n",
      "fold:  5 , epoch:  18 , val loss:  7.903634468675591e-06\n",
      "fold:  5 , epoch:  19 , val loss:  1.218462875840487e-05\n",
      "fold:  5 , epoch:  20 , val loss:  8.456410796497948e-06\n",
      "fold:  5 , epoch:  21 , val loss:  1.1269457900198177e-05\n",
      "fold:  5 , epoch:  22 , val loss:  2.136756847903598e-05\n",
      "fold:  5 , epoch:  23 , val loss:  9.012464033730794e-06\n",
      "fold:  5 , epoch:  24 , val loss:  1.1784161870309617e-05\n",
      "fold:  5 , epoch:  25 , val loss:  1.333899490418844e-05\n",
      "Model results:  {'hidden_size': 200, 'n_layers': 4, 'act_fun': 'ELU', 'init_methods': 'xavier uniform', 'mean_val_result': 0.00019238632872293238, 'std_val_result': 0.0008051229991578082} \n",
      "\n",
      "Model:  {'hidden_size': 200, 'n_layers': 6, 'act_fun': 'ELU', 'init_methods': 'xavier uniform'}\n",
      "fold:  1 , epoch:  1 , val loss:  0.004244210664182901\n",
      "fold:  1 , epoch:  2 , val loss:  0.0018441049614921212\n",
      "fold:  1 , epoch:  3 , val loss:  0.0009997222805395722\n",
      "fold:  1 , epoch:  4 , val loss:  0.0006485352059826255\n",
      "fold:  1 , epoch:  5 , val loss:  0.0004832275735680014\n",
      "fold:  1 , epoch:  6 , val loss:  0.0004106864216737449\n",
      "fold:  1 , epoch:  7 , val loss:  0.00031686079455539584\n",
      "fold:  1 , epoch:  8 , val loss:  0.00024927753838710487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  1 , epoch:  9 , val loss:  0.00023952421906869859\n",
      "fold:  1 , epoch:  10 , val loss:  0.0002454384812153876\n",
      "fold:  1 , epoch:  11 , val loss:  0.00025011395337060094\n",
      "fold:  1 , epoch:  12 , val loss:  0.00026483225519768894\n",
      "fold:  1 , epoch:  13 , val loss:  0.00023413004237227142\n",
      "fold:  1 , epoch:  14 , val loss:  0.00013625918654724956\n",
      "fold:  1 , epoch:  15 , val loss:  0.0002724182268138975\n",
      "fold:  1 , epoch:  16 , val loss:  0.0002368777641095221\n",
      "fold:  1 , epoch:  17 , val loss:  0.0001664396550040692\n",
      "fold:  1 , epoch:  18 , val loss:  0.00017473161278758198\n",
      "fold:  1 , epoch:  19 , val loss:  0.0001421313063474372\n",
      "fold:  1 , epoch:  20 , val loss:  0.00012182283535366878\n",
      "fold:  1 , epoch:  21 , val loss:  0.00021040748106315732\n",
      "fold:  1 , epoch:  22 , val loss:  0.00018481227743905038\n",
      "fold:  1 , epoch:  23 , val loss:  0.00012539404269773513\n",
      "fold:  1 , epoch:  24 , val loss:  0.00013991040759719908\n",
      "fold:  1 , epoch:  25 , val loss:  0.0001597641676198691\n",
      "fold:  2 , epoch:  1 , val loss:  0.00018211855785921216\n",
      "fold:  2 , epoch:  2 , val loss:  0.00017105329607147723\n",
      "fold:  2 , epoch:  3 , val loss:  0.00015717270434834063\n",
      "fold:  2 , epoch:  4 , val loss:  0.0002256912412121892\n",
      "fold:  2 , epoch:  5 , val loss:  0.00019227489246986806\n",
      "fold:  2 , epoch:  6 , val loss:  0.00013345698243938386\n",
      "fold:  2 , epoch:  7 , val loss:  9.935101115843281e-05\n",
      "fold:  2 , epoch:  8 , val loss:  0.00010912672587437555\n",
      "fold:  2 , epoch:  9 , val loss:  9.474397666053846e-05\n",
      "fold:  2 , epoch:  10 , val loss:  8.60163927427493e-05\n",
      "fold:  2 , epoch:  11 , val loss:  8.641830208944157e-05\n",
      "fold:  2 , epoch:  12 , val loss:  0.00014207413187250495\n",
      "fold:  2 , epoch:  13 , val loss:  9.335334470961243e-05\n",
      "fold:  2 , epoch:  14 , val loss:  0.0001568838197272271\n",
      "fold:  2 , epoch:  15 , val loss:  0.00014293448475655168\n",
      "fold:  2 , epoch:  16 , val loss:  0.00023062239051796496\n",
      "fold:  2 , epoch:  17 , val loss:  4.713289308710955e-05\n",
      "fold:  2 , epoch:  18 , val loss:  0.000156116540892981\n",
      "fold:  2 , epoch:  19 , val loss:  0.00013820973981637508\n",
      "fold:  2 , epoch:  20 , val loss:  7.465708767995238e-05\n",
      "fold:  2 , epoch:  21 , val loss:  0.00013545158435590565\n",
      "fold:  2 , epoch:  22 , val loss:  0.00010368321090936661\n",
      "fold:  2 , epoch:  23 , val loss:  0.00010051801655208692\n",
      "fold:  2 , epoch:  24 , val loss:  9.928258805302903e-05\n",
      "fold:  2 , epoch:  25 , val loss:  9.525220229988918e-05\n",
      "fold:  3 , epoch:  1 , val loss:  0.0001238500262843445\n",
      "fold:  3 , epoch:  2 , val loss:  0.0001191643241327256\n",
      "fold:  3 , epoch:  3 , val loss:  0.00015560469182673842\n",
      "fold:  3 , epoch:  4 , val loss:  8.584553143009543e-05\n",
      "fold:  3 , epoch:  5 , val loss:  0.00015020488353911787\n",
      "fold:  3 , epoch:  6 , val loss:  0.00015166054072324187\n",
      "fold:  3 , epoch:  7 , val loss:  4.581699249683879e-05\n",
      "fold:  3 , epoch:  8 , val loss:  0.00011750002158805728\n",
      "fold:  3 , epoch:  9 , val loss:  5.131568104843609e-05\n",
      "fold:  3 , epoch:  10 , val loss:  5.0665330491028726e-05\n",
      "fold:  3 , epoch:  11 , val loss:  0.00012157567834947258\n",
      "fold:  3 , epoch:  12 , val loss:  4.490464925765991e-05\n",
      "fold:  3 , epoch:  13 , val loss:  2.6608186090015806e-05\n",
      "fold:  3 , epoch:  14 , val loss:  0.00010908461263170466\n",
      "fold:  3 , epoch:  15 , val loss:  5.182627137401141e-05\n",
      "fold:  3 , epoch:  16 , val loss:  0.00010070337884826586\n",
      "fold:  3 , epoch:  17 , val loss:  0.00011157133849337697\n",
      "fold:  3 , epoch:  18 , val loss:  7.128533616196364e-05\n",
      "fold:  3 , epoch:  19 , val loss:  0.00011549104965524748\n",
      "fold:  3 , epoch:  20 , val loss:  6.059134830138646e-05\n",
      "fold:  3 , epoch:  21 , val loss:  6.7036526161246e-05\n",
      "fold:  3 , epoch:  22 , val loss:  2.7436006348580122e-05\n",
      "fold:  3 , epoch:  23 , val loss:  3.5300854506203905e-05\n",
      "fold:  3 , epoch:  24 , val loss:  1.713272104097996e-05\n",
      "fold:  3 , epoch:  25 , val loss:  9.078314178623259e-05\n",
      "fold:  4 , epoch:  1 , val loss:  8.043181878747419e-05\n",
      "fold:  4 , epoch:  2 , val loss:  6.152216519694775e-05\n",
      "fold:  4 , epoch:  3 , val loss:  1.0616647159622516e-05\n",
      "fold:  4 , epoch:  4 , val loss:  3.4440949093550444e-05\n",
      "fold:  4 , epoch:  5 , val loss:  5.144243186805397e-05\n",
      "fold:  4 , epoch:  6 , val loss:  2.9979473765706643e-05\n",
      "fold:  4 , epoch:  7 , val loss:  6.565045623574406e-05\n",
      "fold:  4 , epoch:  8 , val loss:  0.00010574309999356046\n",
      "fold:  4 , epoch:  9 , val loss:  4.051521318615414e-05\n",
      "fold:  4 , epoch:  10 , val loss:  9.675999899627641e-05\n",
      "fold:  4 , epoch:  11 , val loss:  9.911027154885232e-05\n",
      "fold:  4 , epoch:  12 , val loss:  2.107168984366581e-05\n",
      "fold:  4 , epoch:  13 , val loss:  9.901517842081375e-06\n",
      "fold:  4 , epoch:  14 , val loss:  2.4383125492022373e-05\n",
      "fold:  4 , epoch:  15 , val loss:  0.00011568243644433096\n",
      "fold:  4 , epoch:  16 , val loss:  9.292190952692181e-06\n",
      "fold:  4 , epoch:  17 , val loss:  9.289770969189703e-05\n",
      "fold:  4 , epoch:  18 , val loss:  5.11584548803512e-05\n",
      "fold:  4 , epoch:  19 , val loss:  1.7036523786373436e-05\n",
      "fold:  4 , epoch:  20 , val loss:  1.945887561305426e-05\n",
      "fold:  4 , epoch:  21 , val loss:  2.9106267902534455e-05\n",
      "fold:  4 , epoch:  22 , val loss:  8.084273576969281e-05\n",
      "fold:  4 , epoch:  23 , val loss:  8.878624066710472e-05\n",
      "fold:  4 , epoch:  24 , val loss:  0.00010109960567206144\n",
      "fold:  4 , epoch:  25 , val loss:  4.818008164875209e-05\n",
      "fold:  5 , epoch:  1 , val loss:  9.404379670741037e-05\n",
      "fold:  5 , epoch:  2 , val loss:  8.75308433023747e-06\n",
      "fold:  5 , epoch:  3 , val loss:  2.2836737116449513e-05\n",
      "fold:  5 , epoch:  4 , val loss:  2.1896339603699744e-05\n",
      "fold:  5 , epoch:  5 , val loss:  6.319906333374092e-06\n",
      "fold:  5 , epoch:  6 , val loss:  1.972354220924899e-05\n",
      "fold:  5 , epoch:  7 , val loss:  1.0995263437507674e-05\n",
      "fold:  5 , epoch:  8 , val loss:  3.147557072225027e-05\n",
      "fold:  5 , epoch:  9 , val loss:  8.571692887926474e-06\n",
      "fold:  5 , epoch:  10 , val loss:  2.523766852391418e-05\n",
      "fold:  5 , epoch:  11 , val loss:  1.3256900274427608e-05\n",
      "fold:  5 , epoch:  12 , val loss:  5.995595984131796e-06\n",
      "fold:  5 , epoch:  13 , val loss:  2.2219472157303244e-05\n",
      "fold:  5 , epoch:  14 , val loss:  9.092461550608277e-05\n",
      "fold:  5 , epoch:  15 , val loss:  1.5624998923158273e-05\n",
      "fold:  5 , epoch:  16 , val loss:  2.2923653887119144e-05\n",
      "fold:  5 , epoch:  17 , val loss:  3.7003854231443256e-05\n",
      "fold:  5 , epoch:  18 , val loss:  4.987820375390584e-06\n",
      "fold:  5 , epoch:  19 , val loss:  4.7338609874714166e-05\n",
      "fold:  5 , epoch:  20 , val loss:  1.4306855518952943e-05\n",
      "fold:  5 , epoch:  21 , val loss:  8.148459528456442e-06\n",
      "fold:  5 , epoch:  22 , val loss:  5.6785553169902414e-05\n",
      "fold:  5 , epoch:  23 , val loss:  9.951889296644367e-06\n",
      "fold:  5 , epoch:  24 , val loss:  8.234206688939594e-06\n",
      "fold:  5 , epoch:  25 , val loss:  6.141698577266652e-06\n",
      "Model results:  {'hidden_size': 200, 'n_layers': 6, 'act_fun': 'ELU', 'init_methods': 'xavier uniform', 'mean_val_result': 0.00015885597090891678, 'std_val_result': 0.00041723394499634044} \n",
      "\n",
      "Model:  {'hidden_size': 400, 'n_layers': 6, 'act_fun': 'ELU', 'init_methods': 'xavier uniform'}\n",
      "fold:  1 , epoch:  1 , val loss:  0.003096755128353834\n",
      "fold:  1 , epoch:  2 , val loss:  0.0011624237522482872\n",
      "fold:  1 , epoch:  3 , val loss:  0.0006314921192824841\n",
      "fold:  1 , epoch:  4 , val loss:  0.00040238825022242963\n",
      "fold:  1 , epoch:  5 , val loss:  0.0005363196250982583\n",
      "fold:  1 , epoch:  6 , val loss:  0.00042605397175066173\n",
      "fold:  1 , epoch:  7 , val loss:  0.00021317369828466326\n",
      "fold:  1 , epoch:  8 , val loss:  0.00032216202816925943\n",
      "fold:  1 , epoch:  9 , val loss:  0.0003286505816504359\n",
      "fold:  1 , epoch:  10 , val loss:  0.0001770246308296919\n",
      "fold:  1 , epoch:  11 , val loss:  0.0005339703639037907\n",
      "fold:  1 , epoch:  12 , val loss:  0.0001478097401559353\n",
      "fold:  1 , epoch:  13 , val loss:  0.0003626823890954256\n",
      "fold:  1 , epoch:  14 , val loss:  9.791283082449809e-05\n",
      "fold:  1 , epoch:  15 , val loss:  0.0001519795332569629\n",
      "fold:  1 , epoch:  16 , val loss:  7.9517369158566e-05\n",
      "fold:  1 , epoch:  17 , val loss:  0.0001075349937309511\n",
      "fold:  1 , epoch:  18 , val loss:  0.00032564718276262283\n",
      "fold:  1 , epoch:  19 , val loss:  0.00034514954313635826\n",
      "fold:  1 , epoch:  20 , val loss:  7.109009311534464e-05\n",
      "fold:  1 , epoch:  21 , val loss:  0.00020968937315046787\n",
      "fold:  1 , epoch:  22 , val loss:  0.00028651562752202153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  1 , epoch:  23 , val loss:  0.00013427971862256527\n",
      "fold:  1 , epoch:  24 , val loss:  0.0001673876104177907\n",
      "fold:  1 , epoch:  25 , val loss:  0.00029119194368831813\n",
      "fold:  2 , epoch:  1 , val loss:  3.7555590097326785e-05\n",
      "fold:  2 , epoch:  2 , val loss:  0.0001124343543779105\n",
      "fold:  2 , epoch:  3 , val loss:  0.00017180520808324218\n",
      "fold:  2 , epoch:  4 , val loss:  0.0001275026152143255\n",
      "fold:  2 , epoch:  5 , val loss:  0.00013632816262543201\n",
      "fold:  2 , epoch:  6 , val loss:  0.00012437274563126266\n",
      "fold:  2 , epoch:  7 , val loss:  0.00011826420814031735\n",
      "fold:  2 , epoch:  8 , val loss:  0.00023573494399897754\n",
      "fold:  2 , epoch:  9 , val loss:  5.354562745196745e-05\n",
      "fold:  2 , epoch:  10 , val loss:  2.5078443286474794e-05\n",
      "fold:  2 , epoch:  11 , val loss:  8.980787970358506e-05\n",
      "fold:  2 , epoch:  12 , val loss:  5.262682316242717e-05\n",
      "fold:  2 , epoch:  13 , val loss:  0.0002149976062355563\n",
      "fold:  2 , epoch:  14 , val loss:  3.9073147490853444e-05\n",
      "fold:  2 , epoch:  15 , val loss:  9.216988837579265e-05\n",
      "fold:  2 , epoch:  16 , val loss:  0.00012907874770462513\n",
      "fold:  2 , epoch:  17 , val loss:  0.00011591475777095184\n",
      "fold:  2 , epoch:  18 , val loss:  3.576982271624729e-05\n",
      "fold:  2 , epoch:  19 , val loss:  3.5884313547285274e-05\n",
      "fold:  2 , epoch:  20 , val loss:  3.266767816967331e-05\n",
      "fold:  2 , epoch:  21 , val loss:  0.00011653716501314193\n",
      "fold:  2 , epoch:  22 , val loss:  7.481626380467787e-05\n",
      "fold:  2 , epoch:  23 , val loss:  4.711624205810949e-05\n",
      "fold:  2 , epoch:  24 , val loss:  6.80111043038778e-05\n",
      "fold:  2 , epoch:  25 , val loss:  7.296179683180526e-05\n",
      "fold:  3 , epoch:  1 , val loss:  2.084810876112897e-05\n",
      "fold:  3 , epoch:  2 , val loss:  3.935079075745307e-05\n",
      "fold:  3 , epoch:  3 , val loss:  1.8279361029271968e-05\n",
      "fold:  3 , epoch:  4 , val loss:  7.731560617685318e-05\n",
      "fold:  3 , epoch:  5 , val loss:  2.2521706341649406e-05\n",
      "fold:  3 , epoch:  6 , val loss:  1.925670039781835e-05\n",
      "fold:  3 , epoch:  7 , val loss:  2.6060646632686257e-05\n",
      "fold:  3 , epoch:  8 , val loss:  3.6234177969163284e-05\n",
      "fold:  3 , epoch:  9 , val loss:  4.8737019824329764e-05\n",
      "fold:  3 , epoch:  10 , val loss:  3.316166112199426e-05\n",
      "fold:  3 , epoch:  11 , val loss:  4.612611883203499e-05\n",
      "fold:  3 , epoch:  12 , val loss:  8.641699423606042e-06\n",
      "fold:  3 , epoch:  13 , val loss:  1.793588489817921e-05\n",
      "fold:  3 , epoch:  14 , val loss:  8.558094850741327e-05\n",
      "fold:  3 , epoch:  15 , val loss:  0.00026255592820234597\n",
      "fold:  3 , epoch:  16 , val loss:  8.655551027914044e-06\n",
      "fold:  3 , epoch:  17 , val loss:  1.532138412585482e-05\n",
      "fold:  3 , epoch:  18 , val loss:  5.760964995715767e-05\n",
      "fold:  3 , epoch:  19 , val loss:  5.8419253036845475e-05\n",
      "fold:  3 , epoch:  20 , val loss:  4.546629497781396e-05\n",
      "fold:  3 , epoch:  21 , val loss:  1.1540955711097922e-05\n",
      "fold:  3 , epoch:  22 , val loss:  3.324797944515012e-05\n",
      "fold:  3 , epoch:  23 , val loss:  0.00012448262714315206\n",
      "fold:  3 , epoch:  24 , val loss:  2.10016114579048e-05\n",
      "fold:  3 , epoch:  25 , val loss:  8.578287088312209e-05\n",
      "fold:  4 , epoch:  1 , val loss:  6.7534651861933526e-06\n",
      "fold:  4 , epoch:  2 , val loss:  1.5625419109710492e-05\n",
      "fold:  4 , epoch:  3 , val loss:  8.272541890619323e-06\n",
      "fold:  4 , epoch:  4 , val loss:  4.223894575261511e-05\n",
      "fold:  4 , epoch:  5 , val loss:  2.1010118871345185e-05\n",
      "fold:  4 , epoch:  6 , val loss:  5.004365084460005e-05\n",
      "fold:  4 , epoch:  7 , val loss:  1.6467900422867388e-05\n",
      "fold:  4 , epoch:  8 , val loss:  3.101682887063362e-05\n",
      "fold:  4 , epoch:  9 , val loss:  1.2622371286852285e-05\n",
      "fold:  4 , epoch:  10 , val loss:  3.350474071339704e-05\n",
      "fold:  4 , epoch:  11 , val loss:  7.176836334110703e-06\n",
      "fold:  4 , epoch:  12 , val loss:  7.569732133561047e-06\n",
      "fold:  4 , epoch:  13 , val loss:  5.940917253610678e-05\n",
      "fold:  4 , epoch:  14 , val loss:  1.2488158063206356e-05\n",
      "fold:  4 , epoch:  15 , val loss:  1.3082917575957254e-05\n",
      "fold:  4 , epoch:  16 , val loss:  4.816937234863872e-06\n",
      "fold:  4 , epoch:  17 , val loss:  2.55968225246761e-05\n",
      "fold:  4 , epoch:  18 , val loss:  6.979578756727278e-06\n",
      "fold:  4 , epoch:  19 , val loss:  5.817127021146007e-05\n",
      "fold:  4 , epoch:  20 , val loss:  5.820841124659637e-06\n",
      "fold:  4 , epoch:  21 , val loss:  3.858917989418842e-05\n",
      "fold:  4 , epoch:  22 , val loss:  1.6966509065241553e-05\n",
      "fold:  4 , epoch:  23 , val loss:  0.000267121649812907\n",
      "fold:  4 , epoch:  24 , val loss:  5.183799657970667e-05\n",
      "fold:  4 , epoch:  25 , val loss:  1.4585718417947646e-05\n",
      "fold:  5 , epoch:  1 , val loss:  6.457279141613981e-06\n",
      "fold:  5 , epoch:  2 , val loss:  2.30859932344174e-05\n",
      "fold:  5 , epoch:  3 , val loss:  3.0864070140523836e-05\n",
      "fold:  5 , epoch:  4 , val loss:  2.9317649023141712e-05\n",
      "fold:  5 , epoch:  5 , val loss:  7.016964082140476e-05\n",
      "fold:  5 , epoch:  6 , val loss:  1.4789601664233487e-05\n",
      "fold:  5 , epoch:  7 , val loss:  8.984491614683066e-06\n",
      "fold:  5 , epoch:  8 , val loss:  6.222664524102584e-05\n",
      "fold:  5 , epoch:  9 , val loss:  7.852264388930053e-06\n",
      "fold:  5 , epoch:  10 , val loss:  2.3671413146075793e-05\n",
      "fold:  5 , epoch:  11 , val loss:  2.503924952179659e-05\n",
      "fold:  5 , epoch:  12 , val loss:  2.0900692106806673e-05\n",
      "fold:  5 , epoch:  13 , val loss:  9.353686436952557e-06\n",
      "fold:  5 , epoch:  14 , val loss:  2.037893864326179e-05\n",
      "fold:  5 , epoch:  15 , val loss:  1.1699366950779222e-05\n",
      "fold:  5 , epoch:  16 , val loss:  5.8237499615643173e-05\n",
      "fold:  5 , epoch:  17 , val loss:  2.2745800379198045e-05\n",
      "fold:  5 , epoch:  18 , val loss:  1.568189873069059e-05\n",
      "fold:  5 , epoch:  19 , val loss:  8.115544187603518e-05\n",
      "fold:  5 , epoch:  20 , val loss:  1.7041664250427857e-05\n",
      "fold:  5 , epoch:  21 , val loss:  3.14402932417579e-05\n",
      "fold:  5 , epoch:  22 , val loss:  6.9158209043962415e-06\n",
      "fold:  5 , epoch:  23 , val loss:  2.7659789338940755e-05\n",
      "fold:  5 , epoch:  24 , val loss:  1.5971831089700572e-05\n",
      "fold:  5 , epoch:  25 , val loss:  6.024326921760803e-06\n",
      "Model results:  {'hidden_size': 400, 'n_layers': 6, 'act_fun': 'ELU', 'init_methods': 'xavier uniform', 'mean_val_result': 0.0001253474113800621, 'std_val_result': 0.00030746205020753354} \n",
      "\n",
      "Model:  {'hidden_size': 400, 'n_layers': 4, 'act_fun': 'ELU', 'init_methods': 'xavier uniform'}\n",
      "fold:  1 , epoch:  1 , val loss:  0.0033587715588510036\n",
      "fold:  1 , epoch:  2 , val loss:  0.0012787049636244774\n",
      "fold:  1 , epoch:  3 , val loss:  0.0006434756214730442\n",
      "fold:  1 , epoch:  4 , val loss:  0.0005634892731904984\n",
      "fold:  1 , epoch:  5 , val loss:  0.0003507121582515538\n",
      "fold:  1 , epoch:  6 , val loss:  0.0004245186282787472\n",
      "fold:  1 , epoch:  7 , val loss:  0.0003368261968716979\n",
      "fold:  1 , epoch:  8 , val loss:  0.00025747474865056574\n",
      "fold:  1 , epoch:  9 , val loss:  0.0002470372128300369\n",
      "fold:  1 , epoch:  10 , val loss:  0.00017088961612898856\n",
      "fold:  1 , epoch:  11 , val loss:  0.00015381354023702443\n",
      "fold:  1 , epoch:  12 , val loss:  0.00025002844631671906\n",
      "fold:  1 , epoch:  13 , val loss:  0.00019428826635703444\n",
      "fold:  1 , epoch:  14 , val loss:  0.00011790433200076222\n",
      "fold:  1 , epoch:  15 , val loss:  0.00014531560009345412\n",
      "fold:  1 , epoch:  16 , val loss:  0.00011515381629578769\n",
      "fold:  1 , epoch:  17 , val loss:  0.00015520415036007762\n",
      "fold:  1 , epoch:  18 , val loss:  7.964340329635888e-05\n",
      "fold:  1 , epoch:  19 , val loss:  0.00012369456817395985\n",
      "fold:  1 , epoch:  20 , val loss:  0.00013536166807170957\n",
      "fold:  1 , epoch:  21 , val loss:  8.120342681650072e-05\n",
      "fold:  1 , epoch:  22 , val loss:  0.00014253017434384674\n",
      "fold:  1 , epoch:  23 , val loss:  0.00013214485079515725\n",
      "fold:  1 , epoch:  24 , val loss:  7.302566518774256e-05\n",
      "fold:  1 , epoch:  25 , val loss:  5.413355029304512e-05\n",
      "fold:  2 , epoch:  1 , val loss:  6.477724673459306e-05\n",
      "fold:  2 , epoch:  2 , val loss:  6.040023799869232e-05\n",
      "fold:  2 , epoch:  3 , val loss:  6.921029125805944e-05\n",
      "fold:  2 , epoch:  4 , val loss:  7.110347360139713e-05\n",
      "fold:  2 , epoch:  5 , val loss:  0.00017679181473795325\n",
      "fold:  2 , epoch:  6 , val loss:  5.7654466218082234e-05\n",
      "fold:  2 , epoch:  7 , val loss:  8.025914576137438e-05\n",
      "fold:  2 , epoch:  8 , val loss:  9.672636952018365e-05\n",
      "fold:  2 , epoch:  9 , val loss:  0.00013842369662597775\n",
      "fold:  2 , epoch:  10 , val loss:  0.0002388601569691673\n",
      "fold:  2 , epoch:  11 , val loss:  0.00013620423851534724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  2 , epoch:  12 , val loss:  0.00017973179637920111\n",
      "fold:  2 , epoch:  13 , val loss:  5.9207395679550245e-05\n",
      "fold:  2 , epoch:  14 , val loss:  0.00015433531370945275\n",
      "fold:  2 , epoch:  15 , val loss:  5.722710193367675e-05\n",
      "fold:  2 , epoch:  16 , val loss:  5.2902356401318684e-05\n",
      "fold:  2 , epoch:  17 , val loss:  4.740234726341441e-05\n",
      "fold:  2 , epoch:  18 , val loss:  0.00018079709843732417\n",
      "fold:  2 , epoch:  19 , val loss:  0.00010950999421766028\n",
      "fold:  2 , epoch:  20 , val loss:  0.0001370843092445284\n",
      "fold:  2 , epoch:  21 , val loss:  3.332293272251263e-05\n",
      "fold:  2 , epoch:  22 , val loss:  6.670098809991032e-05\n",
      "fold:  2 , epoch:  23 , val loss:  4.238612382323481e-05\n",
      "fold:  2 , epoch:  24 , val loss:  6.765355647075921e-05\n",
      "fold:  2 , epoch:  25 , val loss:  6.855765968794003e-05\n",
      "fold:  3 , epoch:  1 , val loss:  6.259299698285758e-05\n",
      "fold:  3 , epoch:  2 , val loss:  2.1465757527039386e-05\n",
      "fold:  3 , epoch:  3 , val loss:  7.571392779937014e-05\n",
      "fold:  3 , epoch:  4 , val loss:  7.838742021704093e-05\n",
      "fold:  3 , epoch:  5 , val loss:  5.500200131791644e-05\n",
      "fold:  3 , epoch:  6 , val loss:  8.503260323777795e-05\n",
      "fold:  3 , epoch:  7 , val loss:  3.770870534935966e-05\n",
      "fold:  3 , epoch:  8 , val loss:  4.6736728108953685e-05\n",
      "fold:  3 , epoch:  9 , val loss:  6.64663384668529e-05\n",
      "fold:  3 , epoch:  10 , val loss:  7.002757774898782e-05\n",
      "fold:  3 , epoch:  11 , val loss:  3.9220001781359315e-05\n",
      "fold:  3 , epoch:  12 , val loss:  0.00029269207152538\n",
      "fold:  3 , epoch:  13 , val loss:  3.015522270288784e-05\n",
      "fold:  3 , epoch:  14 , val loss:  2.7116009732708335e-05\n",
      "fold:  3 , epoch:  15 , val loss:  4.4675580284092575e-05\n",
      "fold:  3 , epoch:  16 , val loss:  0.00012231145228724927\n",
      "fold:  3 , epoch:  17 , val loss:  4.040688509121537e-05\n",
      "fold:  3 , epoch:  18 , val loss:  5.591626904788427e-05\n",
      "fold:  3 , epoch:  19 , val loss:  4.067943154950626e-05\n",
      "fold:  3 , epoch:  20 , val loss:  6.757412484148517e-05\n",
      "fold:  3 , epoch:  21 , val loss:  0.00024154159473255277\n",
      "fold:  3 , epoch:  22 , val loss:  0.00011317636381136253\n",
      "fold:  3 , epoch:  23 , val loss:  1.796776632545516e-05\n",
      "fold:  3 , epoch:  24 , val loss:  8.516423986293375e-05\n",
      "fold:  3 , epoch:  25 , val loss:  4.3234391341684386e-05\n",
      "fold:  4 , epoch:  1 , val loss:  4.2802304960787296e-05\n",
      "fold:  4 , epoch:  2 , val loss:  3.763825225178152e-05\n",
      "fold:  4 , epoch:  3 , val loss:  0.00016963673988357186\n",
      "fold:  4 , epoch:  4 , val loss:  1.4571235624316614e-05\n",
      "fold:  4 , epoch:  5 , val loss:  8.886424620868638e-05\n",
      "fold:  4 , epoch:  6 , val loss:  7.363028089457657e-06\n",
      "fold:  4 , epoch:  7 , val loss:  3.116308289463632e-05\n",
      "fold:  4 , epoch:  8 , val loss:  6.806629698985489e-06\n",
      "fold:  4 , epoch:  9 , val loss:  6.798607500968501e-05\n",
      "fold:  4 , epoch:  10 , val loss:  8.734104631002992e-05\n",
      "fold:  4 , epoch:  11 , val loss:  2.3235941625898704e-05\n",
      "fold:  4 , epoch:  12 , val loss:  1.3648325875692535e-05\n",
      "fold:  4 , epoch:  13 , val loss:  3.4565349778858945e-05\n",
      "fold:  4 , epoch:  14 , val loss:  1.189714384963736e-05\n",
      "fold:  4 , epoch:  15 , val loss:  1.0966778972942848e-05\n",
      "fold:  4 , epoch:  16 , val loss:  9.360013791592792e-06\n",
      "fold:  4 , epoch:  17 , val loss:  1.0129124348168261e-05\n",
      "fold:  4 , epoch:  18 , val loss:  0.0001316328125540167\n",
      "fold:  4 , epoch:  19 , val loss:  1.779518606781494e-05\n",
      "fold:  4 , epoch:  20 , val loss:  1.1754282240872271e-05\n",
      "fold:  4 , epoch:  21 , val loss:  2.274156577186659e-05\n",
      "fold:  4 , epoch:  22 , val loss:  2.5620649466873147e-05\n",
      "fold:  4 , epoch:  23 , val loss:  3.811829083133489e-05\n",
      "fold:  4 , epoch:  24 , val loss:  4.4608183088712394e-05\n",
      "fold:  4 , epoch:  25 , val loss:  1.4936543266230728e-05\n",
      "fold:  5 , epoch:  1 , val loss:  2.226279138994869e-05\n",
      "fold:  5 , epoch:  2 , val loss:  1.7636393749853596e-05\n",
      "fold:  5 , epoch:  3 , val loss:  1.3402644071902614e-05\n",
      "fold:  5 , epoch:  4 , val loss:  0.0001210415139212273\n",
      "fold:  5 , epoch:  5 , val loss:  1.0857372217287775e-05\n",
      "fold:  5 , epoch:  6 , val loss:  9.185757335217204e-06\n",
      "fold:  5 , epoch:  7 , val loss:  2.9486127459676936e-05\n",
      "fold:  5 , epoch:  8 , val loss:  0.0002081541606457904\n",
      "fold:  5 , epoch:  9 , val loss:  7.259632639033953e-06\n",
      "fold:  5 , epoch:  10 , val loss:  1.1568740774237085e-05\n",
      "fold:  5 , epoch:  11 , val loss:  1.1226851711398922e-05\n",
      "fold:  5 , epoch:  12 , val loss:  1.2023087037960067e-05\n",
      "fold:  5 , epoch:  13 , val loss:  1.0799239134939853e-05\n",
      "fold:  5 , epoch:  14 , val loss:  7.2516027103119995e-06\n",
      "fold:  5 , epoch:  15 , val loss:  8.533917934983037e-06\n",
      "fold:  5 , epoch:  16 , val loss:  2.0338662579888478e-05\n",
      "fold:  5 , epoch:  17 , val loss:  1.7479678717791103e-05\n",
      "fold:  5 , epoch:  18 , val loss:  6.593852958758362e-06\n",
      "fold:  5 , epoch:  19 , val loss:  3.0001672712387517e-05\n",
      "fold:  5 , epoch:  20 , val loss:  1.0762755664472934e-05\n",
      "fold:  5 , epoch:  21 , val loss:  8.18724583950825e-06\n",
      "fold:  5 , epoch:  22 , val loss:  4.6311557525768876e-05\n",
      "fold:  5 , epoch:  23 , val loss:  1.1889745110238437e-05\n",
      "fold:  5 , epoch:  24 , val loss:  1.388325199513929e-05\n",
      "fold:  5 , epoch:  25 , val loss:  2.538443550292868e-05\n",
      "Model results:  {'hidden_size': 400, 'n_layers': 4, 'act_fun': 'ELU', 'init_methods': 'xavier uniform', 'mean_val_result': 0.00012448197227422496, 'std_val_result': 0.00032576053674017577} \n",
      "\n",
      "Model:  {'hidden_size': 400, 'n_layers': 8, 'act_fun': 'ReLU', 'init_methods': 'xavier normal'}\n",
      "fold:  1 , epoch:  1 , val loss:  0.0002841941313818097\n",
      "fold:  1 , epoch:  2 , val loss:  0.00018771071336232126\n",
      "fold:  1 , epoch:  3 , val loss:  0.0006384940352290869\n",
      "fold:  1 , epoch:  4 , val loss:  6.020907676429488e-05\n",
      "fold:  1 , epoch:  5 , val loss:  5.839535151608288e-05\n",
      "fold:  1 , epoch:  6 , val loss:  9.929782390827313e-05\n",
      "fold:  1 , epoch:  7 , val loss:  4.225144220981747e-05\n",
      "fold:  1 , epoch:  8 , val loss:  0.0002884571731556207\n",
      "fold:  1 , epoch:  9 , val loss:  8.24394664959982e-05\n",
      "fold:  1 , epoch:  10 , val loss:  5.1623530453071e-05\n",
      "fold:  1 , epoch:  11 , val loss:  2.6911926397588104e-05\n",
      "fold:  1 , epoch:  12 , val loss:  0.00011700305185513571\n",
      "fold:  1 , epoch:  13 , val loss:  2.0381705326144584e-05\n",
      "fold:  1 , epoch:  14 , val loss:  6.023256719345227e-05\n",
      "fold:  1 , epoch:  15 , val loss:  8.320487540913746e-05\n",
      "fold:  1 , epoch:  16 , val loss:  2.1762316464446485e-05\n",
      "fold:  1 , epoch:  17 , val loss:  1.641432572796475e-05\n",
      "fold:  1 , epoch:  18 , val loss:  2.5780440410017036e-05\n",
      "fold:  1 , epoch:  19 , val loss:  5.903960845898837e-05\n",
      "fold:  1 , epoch:  20 , val loss:  2.914189826697111e-05\n",
      "fold:  1 , epoch:  21 , val loss:  1.9540648281690665e-05\n",
      "fold:  1 , epoch:  22 , val loss:  2.1508996724151075e-05\n",
      "fold:  1 , epoch:  23 , val loss:  1.8831909983418882e-05\n",
      "fold:  1 , epoch:  24 , val loss:  0.00010918934276560321\n",
      "fold:  1 , epoch:  25 , val loss:  6.954783020773903e-05\n",
      "fold:  2 , epoch:  1 , val loss:  1.3656564988195896e-05\n",
      "fold:  2 , epoch:  2 , val loss:  1.0986854249495082e-05\n",
      "fold:  2 , epoch:  3 , val loss:  1.0096850019181147e-05\n",
      "fold:  2 , epoch:  4 , val loss:  1.4431605450226925e-05\n",
      "fold:  2 , epoch:  5 , val loss:  5.362661249819212e-05\n",
      "fold:  2 , epoch:  6 , val loss:  1.4945753719075583e-05\n",
      "fold:  2 , epoch:  7 , val loss:  9.893026799545623e-06\n",
      "fold:  2 , epoch:  8 , val loss:  2.2474654542747885e-05\n",
      "fold:  2 , epoch:  9 , val loss:  2.0735285943374038e-05\n",
      "fold:  2 , epoch:  10 , val loss:  1.4682538676424883e-05\n",
      "fold:  2 , epoch:  11 , val loss:  1.3749012396147009e-05\n",
      "fold:  2 , epoch:  12 , val loss:  1.1191037629032508e-05\n",
      "fold:  2 , epoch:  13 , val loss:  2.3413240342051722e-05\n",
      "fold:  2 , epoch:  14 , val loss:  1.391192290611798e-05\n",
      "fold:  2 , epoch:  15 , val loss:  7.239769183797762e-05\n",
      "fold:  2 , epoch:  16 , val loss:  3.545614890754223e-05\n",
      "fold:  2 , epoch:  17 , val loss:  2.178077193093486e-05\n",
      "fold:  2 , epoch:  18 , val loss:  8.547692232241388e-06\n",
      "fold:  2 , epoch:  19 , val loss:  2.7130439775646664e-05\n",
      "fold:  2 , epoch:  20 , val loss:  3.953143459511921e-05\n",
      "fold:  2 , epoch:  21 , val loss:  1.1513841855048668e-05\n",
      "fold:  2 , epoch:  22 , val loss:  4.721385266748257e-05\n",
      "fold:  2 , epoch:  23 , val loss:  3.474058030406013e-05\n",
      "fold:  2 , epoch:  24 , val loss:  3.315125286462717e-05\n",
      "fold:  2 , epoch:  25 , val loss:  2.388242501183413e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  3 , epoch:  1 , val loss:  1.0150904017791618e-05\n",
      "fold:  3 , epoch:  2 , val loss:  4.059540151502006e-05\n",
      "fold:  3 , epoch:  3 , val loss:  3.3699361665640026e-05\n",
      "fold:  3 , epoch:  4 , val loss:  1.8704316971707158e-05\n",
      "fold:  3 , epoch:  5 , val loss:  4.092376912012696e-05\n",
      "fold:  3 , epoch:  6 , val loss:  5.6026415222731885e-06\n",
      "fold:  3 , epoch:  7 , val loss:  1.354144205834018e-05\n",
      "fold:  3 , epoch:  8 , val loss:  1.7387634215992875e-05\n",
      "fold:  3 , epoch:  9 , val loss:  8.323827387357596e-06\n",
      "fold:  3 , epoch:  10 , val loss:  6.188461156853009e-06\n",
      "fold:  3 , epoch:  11 , val loss:  4.691140020440798e-06\n",
      "fold:  3 , epoch:  12 , val loss:  1.3194739040045533e-05\n",
      "fold:  3 , epoch:  13 , val loss:  1.9939030607929453e-05\n",
      "fold:  3 , epoch:  14 , val loss:  2.373227289353963e-05\n",
      "fold:  3 , epoch:  15 , val loss:  1.3277843208925333e-05\n",
      "fold:  3 , epoch:  16 , val loss:  2.188275902881287e-05\n",
      "fold:  3 , epoch:  17 , val loss:  1.804665407689754e-05\n",
      "fold:  3 , epoch:  18 , val loss:  7.044388894428266e-06\n",
      "fold:  3 , epoch:  19 , val loss:  9.945241799869109e-06\n",
      "fold:  3 , epoch:  20 , val loss:  5.018432602810208e-06\n",
      "fold:  3 , epoch:  21 , val loss:  0.00010985363769577816\n",
      "fold:  3 , epoch:  22 , val loss:  2.4210652554756962e-05\n",
      "fold:  3 , epoch:  23 , val loss:  5.949120350123849e-06\n",
      "fold:  3 , epoch:  24 , val loss:  7.4637728175730444e-06\n",
      "fold:  3 , epoch:  25 , val loss:  6.495021807495505e-06\n",
      "fold:  4 , epoch:  1 , val loss:  6.946172561583808e-06\n",
      "fold:  4 , epoch:  2 , val loss:  6.356376161420485e-06\n",
      "fold:  4 , epoch:  3 , val loss:  6.292925263551297e-06\n",
      "fold:  4 , epoch:  4 , val loss:  2.4166161892935634e-05\n",
      "fold:  4 , epoch:  5 , val loss:  1.4465334061242174e-05\n",
      "fold:  4 , epoch:  6 , val loss:  1.206212164106546e-05\n",
      "fold:  4 , epoch:  7 , val loss:  3.8154448702698573e-05\n",
      "fold:  4 , epoch:  8 , val loss:  3.70328598364722e-05\n",
      "fold:  4 , epoch:  9 , val loss:  1.4568438928108662e-05\n",
      "fold:  4 , epoch:  10 , val loss:  9.089222658076324e-06\n",
      "fold:  4 , epoch:  11 , val loss:  1.028337464958895e-05\n",
      "fold:  4 , epoch:  12 , val loss:  1.0620015927997883e-05\n",
      "fold:  4 , epoch:  13 , val loss:  2.4591934561613016e-05\n",
      "fold:  4 , epoch:  14 , val loss:  2.8429551093722694e-05\n",
      "fold:  4 , epoch:  15 , val loss:  6.951507202757057e-06\n",
      "fold:  4 , epoch:  16 , val loss:  3.9979011489776894e-05\n",
      "fold:  4 , epoch:  17 , val loss:  3.234007454011589e-05\n",
      "fold:  4 , epoch:  18 , val loss:  4.0833201637724414e-06\n",
      "fold:  4 , epoch:  19 , val loss:  9.909093023452442e-06\n",
      "fold:  4 , epoch:  20 , val loss:  3.438270869082771e-05\n",
      "fold:  4 , epoch:  21 , val loss:  7.149972225306556e-05\n",
      "fold:  4 , epoch:  22 , val loss:  6.948685950192157e-06\n",
      "fold:  4 , epoch:  23 , val loss:  1.0543755706748925e-05\n",
      "fold:  4 , epoch:  24 , val loss:  5.822741968586342e-06\n",
      "fold:  4 , epoch:  25 , val loss:  8.403843821724877e-06\n",
      "fold:  5 , epoch:  1 , val loss:  3.068219712076825e-06\n",
      "fold:  5 , epoch:  2 , val loss:  1.1347123290761374e-05\n",
      "fold:  5 , epoch:  3 , val loss:  2.31726371566765e-05\n",
      "fold:  5 , epoch:  4 , val loss:  1.9747605620068498e-05\n",
      "fold:  5 , epoch:  5 , val loss:  1.661926944507286e-05\n",
      "fold:  5 , epoch:  6 , val loss:  5.210133622313151e-06\n",
      "fold:  5 , epoch:  7 , val loss:  5.180834705242887e-06\n",
      "fold:  5 , epoch:  8 , val loss:  5.2782706916332245e-06\n",
      "fold:  5 , epoch:  9 , val loss:  1.4574766282748897e-05\n",
      "fold:  5 , epoch:  10 , val loss:  7.623837973369518e-06\n",
      "fold:  5 , epoch:  11 , val loss:  8.402252205996774e-06\n",
      "fold:  5 , epoch:  12 , val loss:  5.658310328726657e-05\n",
      "fold:  5 , epoch:  13 , val loss:  4.192763753962936e-06\n",
      "fold:  5 , epoch:  14 , val loss:  6.319696694845334e-06\n",
      "fold:  5 , epoch:  15 , val loss:  3.7416625673358794e-06\n",
      "fold:  5 , epoch:  16 , val loss:  7.665410521440208e-06\n",
      "fold:  5 , epoch:  17 , val loss:  3.0329738365253434e-05\n",
      "fold:  5 , epoch:  18 , val loss:  6.0232760006329045e-06\n",
      "fold:  5 , epoch:  19 , val loss:  1.5760100723127834e-05\n",
      "fold:  5 , epoch:  20 , val loss:  4.297517807572149e-05\n",
      "fold:  5 , epoch:  21 , val loss:  2.760951429081615e-05\n",
      "fold:  5 , epoch:  22 , val loss:  5.143273665453307e-05\n",
      "fold:  5 , epoch:  23 , val loss:  2.303241126355715e-05\n",
      "fold:  5 , epoch:  24 , val loss:  4.132109552301699e-06\n",
      "fold:  5 , epoch:  25 , val loss:  4.655926204577554e-06\n",
      "Model results:  {'hidden_size': 400, 'n_layers': 8, 'act_fun': 'ReLU', 'init_methods': 'xavier normal', 'mean_val_result': 3.5673357828272853e-05, 'std_val_result': 6.891052963462228e-05} \n",
      "\n",
      "Model:  {'hidden_size': 600, 'n_layers': 4, 'act_fun': 'LeakyReLU', 'init_methods': 'xavier uniform'}\n",
      "fold:  1 , epoch:  1 , val loss:  0.0002313233562745154\n",
      "fold:  1 , epoch:  2 , val loss:  9.555763244861737e-05\n",
      "fold:  1 , epoch:  3 , val loss:  0.00011950590851483867\n",
      "fold:  1 , epoch:  4 , val loss:  5.4514279327122495e-05\n",
      "fold:  1 , epoch:  5 , val loss:  4.479337076190859e-05\n",
      "fold:  1 , epoch:  6 , val loss:  5.0004957302007824e-05\n",
      "fold:  1 , epoch:  7 , val loss:  4.4706241169478744e-05\n",
      "fold:  1 , epoch:  8 , val loss:  5.472413249663077e-05\n",
      "fold:  1 , epoch:  9 , val loss:  3.5815639421343803e-05\n",
      "fold:  1 , epoch:  10 , val loss:  3.0138759029796347e-05\n",
      "fold:  1 , epoch:  11 , val loss:  8.96575438673608e-05\n",
      "fold:  1 , epoch:  12 , val loss:  1.8608530808705837e-05\n",
      "fold:  1 , epoch:  13 , val loss:  2.1192850908846594e-05\n",
      "fold:  1 , epoch:  14 , val loss:  5.796139521407895e-05\n",
      "fold:  1 , epoch:  15 , val loss:  3.2471252779942006e-05\n",
      "fold:  1 , epoch:  16 , val loss:  3.528934030327946e-05\n",
      "fold:  1 , epoch:  17 , val loss:  1.6460937331430614e-05\n",
      "fold:  1 , epoch:  18 , val loss:  1.2732052709907293e-05\n",
      "fold:  1 , epoch:  19 , val loss:  0.00012891725054942071\n",
      "fold:  1 , epoch:  20 , val loss:  1.4167732842906844e-05\n",
      "fold:  1 , epoch:  21 , val loss:  1.3613682313007303e-05\n",
      "fold:  1 , epoch:  22 , val loss:  3.126348747173324e-05\n",
      "fold:  1 , epoch:  23 , val loss:  1.810442154237535e-05\n",
      "fold:  1 , epoch:  24 , val loss:  1.0609464879962616e-05\n",
      "fold:  1 , epoch:  25 , val loss:  4.5616907300427556e-05\n",
      "fold:  2 , epoch:  1 , val loss:  1.191648425447056e-05\n",
      "fold:  2 , epoch:  2 , val loss:  1.6421436157543212e-05\n",
      "fold:  2 , epoch:  3 , val loss:  9.64927767199697e-06\n",
      "fold:  2 , epoch:  4 , val loss:  1.4520465811074246e-05\n",
      "fold:  2 , epoch:  5 , val loss:  1.257500935025746e-05\n",
      "fold:  2 , epoch:  6 , val loss:  1.4109933545114473e-05\n",
      "fold:  2 , epoch:  7 , val loss:  1.3197725820646156e-05\n",
      "fold:  2 , epoch:  8 , val loss:  3.396373722353019e-05\n",
      "fold:  2 , epoch:  9 , val loss:  8.649937626614701e-06\n",
      "fold:  2 , epoch:  10 , val loss:  7.479776741092792e-06\n",
      "fold:  2 , epoch:  11 , val loss:  1.7916085198521614e-05\n",
      "fold:  2 , epoch:  12 , val loss:  1.1222243301745038e-05\n",
      "fold:  2 , epoch:  13 , val loss:  1.888938459160272e-05\n",
      "fold:  2 , epoch:  14 , val loss:  8.284848263429012e-06\n",
      "fold:  2 , epoch:  15 , val loss:  6.694067451462615e-06\n",
      "fold:  2 , epoch:  16 , val loss:  6.319018211797811e-06\n",
      "fold:  2 , epoch:  17 , val loss:  1.7893746189656667e-05\n",
      "fold:  2 , epoch:  18 , val loss:  1.2784906175511423e-05\n",
      "fold:  2 , epoch:  19 , val loss:  7.258512596308719e-06\n",
      "fold:  2 , epoch:  20 , val loss:  6.172914254420903e-06\n",
      "fold:  2 , epoch:  21 , val loss:  1.0889792065427173e-05\n",
      "fold:  2 , epoch:  22 , val loss:  5.905957550567109e-06\n",
      "fold:  2 , epoch:  23 , val loss:  9.126267832471058e-05\n",
      "fold:  2 , epoch:  24 , val loss:  8.108669135253876e-06\n",
      "fold:  2 , epoch:  25 , val loss:  2.014976962527726e-05\n",
      "fold:  3 , epoch:  1 , val loss:  3.0183635317371227e-05\n",
      "fold:  3 , epoch:  2 , val loss:  7.809586350049358e-06\n",
      "fold:  3 , epoch:  3 , val loss:  1.4956566701584961e-05\n",
      "fold:  3 , epoch:  4 , val loss:  1.2328442608122714e-05\n",
      "fold:  3 , epoch:  5 , val loss:  6.784043944207951e-05\n",
      "fold:  3 , epoch:  6 , val loss:  1.2789216270903125e-05\n",
      "fold:  3 , epoch:  7 , val loss:  8.609939868620131e-06\n",
      "fold:  3 , epoch:  8 , val loss:  8.299268301925622e-06\n",
      "fold:  3 , epoch:  9 , val loss:  6.241317805688595e-06\n",
      "fold:  3 , epoch:  10 , val loss:  9.845622844295576e-05\n",
      "fold:  3 , epoch:  11 , val loss:  1.3417868103715591e-05\n",
      "fold:  3 , epoch:  12 , val loss:  3.244843537686393e-05\n",
      "fold:  3 , epoch:  13 , val loss:  5.38993081136141e-05\n",
      "fold:  3 , epoch:  14 , val loss:  5.407926073530689e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  3 , epoch:  15 , val loss:  6.663750536972657e-05\n",
      "fold:  3 , epoch:  16 , val loss:  4.853371501667425e-05\n",
      "fold:  3 , epoch:  17 , val loss:  1.0949336683552247e-05\n",
      "fold:  3 , epoch:  18 , val loss:  5.626115125778597e-06\n",
      "fold:  3 , epoch:  19 , val loss:  3.455574915278703e-05\n",
      "fold:  3 , epoch:  20 , val loss:  1.3836936886946205e-05\n",
      "fold:  3 , epoch:  21 , val loss:  8.279305802716408e-06\n",
      "fold:  3 , epoch:  22 , val loss:  9.172630598186515e-06\n",
      "fold:  3 , epoch:  23 , val loss:  2.270833465445321e-05\n",
      "fold:  3 , epoch:  24 , val loss:  1.4623971765104216e-05\n",
      "fold:  3 , epoch:  25 , val loss:  2.4132654289132915e-05\n",
      "fold:  4 , epoch:  1 , val loss:  3.0328636057674885e-05\n",
      "fold:  4 , epoch:  2 , val loss:  6.533285613841144e-06\n",
      "fold:  4 , epoch:  3 , val loss:  5.041093572799582e-06\n",
      "fold:  4 , epoch:  4 , val loss:  2.3534410502179526e-05\n",
      "fold:  4 , epoch:  5 , val loss:  2.4929922801675275e-05\n",
      "fold:  4 , epoch:  6 , val loss:  4.838784207095159e-06\n",
      "fold:  4 , epoch:  7 , val loss:  3.842375463136705e-06\n",
      "fold:  4 , epoch:  8 , val loss:  3.6592757624021033e-06\n",
      "fold:  4 , epoch:  9 , val loss:  3.966177246184088e-06\n",
      "fold:  4 , epoch:  10 , val loss:  7.809261660440825e-06\n",
      "fold:  4 , epoch:  11 , val loss:  3.4638701436051633e-06\n",
      "fold:  4 , epoch:  12 , val loss:  4.254637133271899e-06\n",
      "fold:  4 , epoch:  13 , val loss:  2.4133198166964576e-05\n",
      "fold:  4 , epoch:  14 , val loss:  4.4781681936001405e-06\n",
      "fold:  4 , epoch:  15 , val loss:  4.8584133764961734e-06\n",
      "fold:  4 , epoch:  16 , val loss:  1.0894626029767096e-05\n",
      "fold:  4 , epoch:  17 , val loss:  7.707195436523762e-06\n",
      "fold:  4 , epoch:  18 , val loss:  3.7329252791096224e-06\n",
      "fold:  4 , epoch:  19 , val loss:  9.581800441083033e-06\n",
      "fold:  4 , epoch:  20 , val loss:  5.1278066166560166e-06\n",
      "fold:  4 , epoch:  21 , val loss:  3.323943701616372e-06\n",
      "fold:  4 , epoch:  22 , val loss:  1.2554416571219917e-05\n",
      "fold:  4 , epoch:  23 , val loss:  3.932991148758447e-06\n",
      "fold:  4 , epoch:  24 , val loss:  3.83321093977429e-06\n",
      "fold:  4 , epoch:  25 , val loss:  1.6444912034785375e-05\n",
      "fold:  5 , epoch:  1 , val loss:  3.517947334330529e-05\n",
      "fold:  5 , epoch:  2 , val loss:  1.907255864352919e-05\n",
      "fold:  5 , epoch:  3 , val loss:  5.819270882057026e-06\n",
      "fold:  5 , epoch:  4 , val loss:  4.852180427405983e-05\n",
      "fold:  5 , epoch:  5 , val loss:  6.824490992585197e-05\n",
      "fold:  5 , epoch:  6 , val loss:  1.20092527140514e-05\n",
      "fold:  5 , epoch:  7 , val loss:  5.809048161609098e-06\n",
      "fold:  5 , epoch:  8 , val loss:  8.737325515539851e-06\n",
      "fold:  5 , epoch:  9 , val loss:  3.470978072073194e-06\n",
      "fold:  5 , epoch:  10 , val loss:  2.447442602715455e-05\n",
      "fold:  5 , epoch:  11 , val loss:  3.536046733643161e-06\n",
      "fold:  5 , epoch:  12 , val loss:  2.152041815861594e-05\n",
      "fold:  5 , epoch:  13 , val loss:  5.422902177087963e-06\n",
      "fold:  5 , epoch:  14 , val loss:  4.6712448238395154e-05\n",
      "fold:  5 , epoch:  15 , val loss:  4.917357273370726e-06\n",
      "fold:  5 , epoch:  16 , val loss:  3.7950890146021266e-06\n",
      "fold:  5 , epoch:  17 , val loss:  9.708591278467793e-06\n",
      "fold:  5 , epoch:  18 , val loss:  6.47262731945375e-06\n",
      "fold:  5 , epoch:  19 , val loss:  9.066985512617975e-06\n",
      "fold:  5 , epoch:  20 , val loss:  1.1590713256737217e-05\n",
      "fold:  5 , epoch:  21 , val loss:  4.386751697893487e-06\n",
      "fold:  5 , epoch:  22 , val loss:  8.441696991212666e-06\n",
      "fold:  5 , epoch:  23 , val loss:  2.9523791454266757e-05\n",
      "fold:  5 , epoch:  24 , val loss:  7.241850653372239e-06\n",
      "fold:  5 , epoch:  25 , val loss:  2.6473526304471307e-06\n",
      "Model results:  {'hidden_size': 600, 'n_layers': 4, 'act_fun': 'LeakyReLU', 'init_methods': 'xavier uniform', 'mean_val_result': 2.4156258252332917e-05, 'std_val_result': 3.063104982159955e-05} \n",
      "\n",
      "Model:  {'hidden_size': 600, 'n_layers': 4, 'act_fun': 'ReLU', 'init_methods': 'xavier normal'}\n",
      "fold:  1 , epoch:  1 , val loss:  0.00022235093638300896\n",
      "fold:  1 , epoch:  2 , val loss:  8.530122431693599e-05\n",
      "fold:  1 , epoch:  3 , val loss:  5.191488526179455e-05\n",
      "fold:  1 , epoch:  4 , val loss:  4.2354571633040905e-05\n",
      "fold:  1 , epoch:  5 , val loss:  0.000178185073309578\n",
      "fold:  1 , epoch:  6 , val loss:  6.440010474761948e-05\n",
      "fold:  1 , epoch:  7 , val loss:  2.7569903977564536e-05\n",
      "fold:  1 , epoch:  8 , val loss:  4.964743129676208e-05\n",
      "fold:  1 , epoch:  9 , val loss:  2.779905298666563e-05\n",
      "fold:  1 , epoch:  10 , val loss:  1.7272897821385413e-05\n",
      "fold:  1 , epoch:  11 , val loss:  3.636041219579056e-05\n",
      "fold:  1 , epoch:  12 , val loss:  3.8404665247071534e-05\n",
      "fold:  1 , epoch:  13 , val loss:  1.5864316083025187e-05\n",
      "fold:  1 , epoch:  14 , val loss:  2.4759516236372292e-05\n",
      "fold:  1 , epoch:  15 , val loss:  2.73678706435021e-05\n",
      "fold:  1 , epoch:  16 , val loss:  1.8923781681223772e-05\n",
      "fold:  1 , epoch:  17 , val loss:  1.218267425429076e-05\n",
      "fold:  1 , epoch:  18 , val loss:  2.5915385776897892e-05\n",
      "fold:  1 , epoch:  19 , val loss:  4.6158173063304275e-05\n",
      "fold:  1 , epoch:  20 , val loss:  7.823892519809306e-05\n",
      "fold:  1 , epoch:  21 , val loss:  0.00014539826952386647\n",
      "fold:  1 , epoch:  22 , val loss:  3.055917113670148e-05\n",
      "fold:  1 , epoch:  23 , val loss:  1.3976051377539989e-05\n",
      "fold:  1 , epoch:  24 , val loss:  6.486338679678738e-05\n",
      "fold:  1 , epoch:  25 , val loss:  6.816408131271601e-05\n",
      "fold:  2 , epoch:  1 , val loss:  2.632566429383587e-05\n",
      "fold:  2 , epoch:  2 , val loss:  2.9225184334791265e-05\n",
      "fold:  2 , epoch:  3 , val loss:  3.848260530503467e-05\n",
      "fold:  2 , epoch:  4 , val loss:  1.2327417607593816e-05\n",
      "fold:  2 , epoch:  5 , val loss:  5.7648587244329974e-05\n",
      "fold:  2 , epoch:  6 , val loss:  1.4138078768155538e-05\n",
      "fold:  2 , epoch:  7 , val loss:  1.2281745512154885e-05\n",
      "fold:  2 , epoch:  8 , val loss:  8.251823601312935e-06\n",
      "fold:  2 , epoch:  9 , val loss:  7.557655408163555e-06\n",
      "fold:  2 , epoch:  10 , val loss:  2.2152142264530994e-05\n",
      "fold:  2 , epoch:  11 , val loss:  1.8855535017792135e-05\n",
      "fold:  2 , epoch:  12 , val loss:  1.2653834346565418e-05\n",
      "fold:  2 , epoch:  13 , val loss:  5.230164333624998e-06\n",
      "fold:  2 , epoch:  14 , val loss:  3.020322765223682e-05\n",
      "fold:  2 , epoch:  15 , val loss:  8.001085006981157e-06\n",
      "fold:  2 , epoch:  16 , val loss:  1.9793071260210127e-05\n",
      "fold:  2 , epoch:  17 , val loss:  1.1110819286841433e-05\n",
      "fold:  2 , epoch:  18 , val loss:  8.141272701323032e-06\n",
      "fold:  2 , epoch:  19 , val loss:  6.362165549944621e-06\n",
      "fold:  2 , epoch:  20 , val loss:  4.009761141787749e-06\n",
      "fold:  2 , epoch:  21 , val loss:  1.9433893612585962e-05\n",
      "fold:  2 , epoch:  22 , val loss:  3.9274953451240435e-05\n",
      "fold:  2 , epoch:  23 , val loss:  5.606995546258986e-05\n",
      "fold:  2 , epoch:  24 , val loss:  3.2832700526341796e-05\n",
      "fold:  2 , epoch:  25 , val loss:  3.815003583440557e-05\n",
      "fold:  3 , epoch:  1 , val loss:  0.00010090430441778153\n",
      "fold:  3 , epoch:  2 , val loss:  2.3393595256493427e-05\n",
      "fold:  3 , epoch:  3 , val loss:  3.2814499718369916e-05\n",
      "fold:  3 , epoch:  4 , val loss:  1.9086872271145694e-05\n",
      "fold:  3 , epoch:  5 , val loss:  9.3446797109209e-06\n",
      "fold:  3 , epoch:  6 , val loss:  1.6988122297334485e-05\n",
      "fold:  3 , epoch:  7 , val loss:  1.0428490895719733e-05\n",
      "fold:  3 , epoch:  8 , val loss:  0.00011875724885612726\n",
      "fold:  3 , epoch:  9 , val loss:  1.635760963836219e-05\n",
      "fold:  3 , epoch:  10 , val loss:  3.3183016057591885e-05\n",
      "fold:  3 , epoch:  11 , val loss:  2.8779375497833826e-05\n",
      "fold:  3 , epoch:  12 , val loss:  1.9843861082335934e-05\n",
      "fold:  3 , epoch:  13 , val loss:  8.90091723704245e-06\n",
      "fold:  3 , epoch:  14 , val loss:  3.708661779455724e-06\n",
      "fold:  3 , epoch:  15 , val loss:  7.663543328817468e-06\n",
      "fold:  3 , epoch:  16 , val loss:  8.299763976538088e-06\n",
      "fold:  3 , epoch:  17 , val loss:  4.3418312998255715e-06\n",
      "fold:  3 , epoch:  18 , val loss:  9.953377229976468e-06\n",
      "fold:  3 , epoch:  19 , val loss:  2.3550568585051224e-05\n",
      "fold:  3 , epoch:  20 , val loss:  1.3436225344776176e-05\n",
      "fold:  3 , epoch:  21 , val loss:  5.108211098558968e-06\n",
      "fold:  3 , epoch:  22 , val loss:  1.1575729331525508e-05\n",
      "fold:  3 , epoch:  23 , val loss:  1.1966169040533714e-05\n",
      "fold:  3 , epoch:  24 , val loss:  1.0505104910407681e-05\n",
      "fold:  3 , epoch:  25 , val loss:  8.512338354194071e-06\n",
      "fold:  4 , epoch:  1 , val loss:  5.974332452751696e-06\n",
      "fold:  4 , epoch:  2 , val loss:  3.91187313653063e-06\n",
      "fold:  4 , epoch:  3 , val loss:  6.079061859054491e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  4 , epoch:  4 , val loss:  1.3518754713004455e-05\n",
      "fold:  4 , epoch:  5 , val loss:  5.77936725676409e-06\n",
      "fold:  4 , epoch:  6 , val loss:  1.2299838999751955e-05\n",
      "fold:  4 , epoch:  7 , val loss:  1.9339360733283684e-05\n",
      "fold:  4 , epoch:  8 , val loss:  4.5496020902646706e-05\n",
      "fold:  4 , epoch:  9 , val loss:  5.64782658329932e-06\n",
      "fold:  4 , epoch:  10 , val loss:  4.127661213715328e-06\n",
      "fold:  4 , epoch:  11 , val loss:  6.146889518277021e-06\n",
      "fold:  4 , epoch:  12 , val loss:  1.4421576452150475e-05\n",
      "fold:  4 , epoch:  13 , val loss:  1.1083021490776446e-05\n",
      "fold:  4 , epoch:  14 , val loss:  4.89795820612926e-06\n",
      "fold:  4 , epoch:  15 , val loss:  3.798671968979761e-05\n",
      "fold:  4 , epoch:  16 , val loss:  3.99235614167992e-06\n",
      "fold:  4 , epoch:  17 , val loss:  4.6999077312648296e-05\n",
      "fold:  4 , epoch:  18 , val loss:  5.294113179843407e-06\n",
      "fold:  4 , epoch:  19 , val loss:  5.8929990700562485e-06\n",
      "fold:  4 , epoch:  20 , val loss:  4.442273166205268e-06\n",
      "fold:  4 , epoch:  21 , val loss:  3.6261187688069185e-06\n",
      "fold:  4 , epoch:  22 , val loss:  1.3425035831460264e-05\n",
      "fold:  4 , epoch:  23 , val loss:  1.396119114360772e-05\n",
      "fold:  4 , epoch:  24 , val loss:  3.532127493599546e-06\n",
      "fold:  4 , epoch:  25 , val loss:  2.005944224947598e-05\n",
      "fold:  5 , epoch:  1 , val loss:  1.688777410890907e-05\n",
      "fold:  5 , epoch:  2 , val loss:  2.804415544233052e-06\n",
      "fold:  5 , epoch:  3 , val loss:  4.481109499465674e-06\n",
      "fold:  5 , epoch:  4 , val loss:  5.187695933273062e-06\n",
      "fold:  5 , epoch:  5 , val loss:  2.8301042220846284e-06\n",
      "fold:  5 , epoch:  6 , val loss:  3.119799885098473e-06\n",
      "fold:  5 , epoch:  7 , val loss:  3.2844482120708562e-06\n",
      "fold:  5 , epoch:  8 , val loss:  7.435278348566499e-06\n",
      "fold:  5 , epoch:  9 , val loss:  2.894551471399609e-06\n",
      "fold:  5 , epoch:  10 , val loss:  1.126855204347521e-05\n",
      "fold:  5 , epoch:  11 , val loss:  2.7866197342518717e-05\n",
      "fold:  5 , epoch:  12 , val loss:  2.8177191779832356e-06\n",
      "fold:  5 , epoch:  13 , val loss:  7.870158697187435e-06\n",
      "fold:  5 , epoch:  14 , val loss:  3.0276819416030776e-06\n",
      "fold:  5 , epoch:  15 , val loss:  6.8081230892858e-06\n",
      "fold:  5 , epoch:  16 , val loss:  4.263694791006856e-06\n",
      "fold:  5 , epoch:  17 , val loss:  6.587529696844285e-06\n",
      "fold:  5 , epoch:  18 , val loss:  4.726677161670523e-06\n",
      "fold:  5 , epoch:  19 , val loss:  2.773768983388436e-06\n",
      "fold:  5 , epoch:  20 , val loss:  8.41054497868754e-06\n",
      "fold:  5 , epoch:  21 , val loss:  6.854042112536263e-06\n",
      "fold:  5 , epoch:  22 , val loss:  5.597617473540595e-06\n",
      "fold:  5 , epoch:  23 , val loss:  7.320601980609354e-06\n",
      "fold:  5 , epoch:  24 , val loss:  2.801076516334433e-05\n",
      "fold:  5 , epoch:  25 , val loss:  1.309900289925281e-05\n",
      "Model results:  {'hidden_size': 600, 'n_layers': 4, 'act_fun': 'ReLU', 'init_methods': 'xavier normal', 'mean_val_result': 2.4629797344459803e-05, 'std_val_result': 3.2610704893899694e-05} \n",
      "\n",
      "Model:  {'hidden_size': 200, 'n_layers': 6, 'act_fun': 'ReLU', 'init_methods': 'xavier normal'}\n",
      "fold:  1 , epoch:  1 , val loss:  0.0016482038190588355\n",
      "fold:  1 , epoch:  2 , val loss:  0.0005398960784077644\n",
      "fold:  1 , epoch:  3 , val loss:  0.000309616734739393\n",
      "fold:  1 , epoch:  4 , val loss:  0.00021800835384055972\n",
      "fold:  1 , epoch:  5 , val loss:  0.0001676362007856369\n",
      "fold:  1 , epoch:  6 , val loss:  0.0001335970446234569\n",
      "fold:  1 , epoch:  7 , val loss:  0.0001111605015466921\n",
      "fold:  1 , epoch:  8 , val loss:  0.00010824164201039821\n",
      "fold:  1 , epoch:  9 , val loss:  8.787027036305517e-05\n",
      "fold:  1 , epoch:  10 , val loss:  7.658029062440619e-05\n",
      "fold:  1 , epoch:  11 , val loss:  9.922248864313588e-05\n",
      "fold:  1 , epoch:  12 , val loss:  0.00011222469038330019\n",
      "fold:  1 , epoch:  13 , val loss:  9.113398846238852e-05\n",
      "fold:  1 , epoch:  14 , val loss:  8.198115392588079e-05\n",
      "fold:  1 , epoch:  15 , val loss:  0.00012189961853437126\n",
      "fold:  1 , epoch:  16 , val loss:  0.00016307085752487183\n",
      "fold:  1 , epoch:  17 , val loss:  0.00015777528460603207\n",
      "fold:  1 , epoch:  18 , val loss:  0.00025113209267146885\n",
      "fold:  1 , epoch:  19 , val loss:  0.00022110715508460999\n",
      "fold:  1 , epoch:  20 , val loss:  0.00019228161545470357\n",
      "fold:  1 , epoch:  21 , val loss:  0.00017626603948883712\n",
      "fold:  1 , epoch:  22 , val loss:  0.00016599925584159791\n",
      "fold:  1 , epoch:  23 , val loss:  0.00019278166291769594\n",
      "fold:  1 , epoch:  24 , val loss:  9.891822264762595e-05\n",
      "fold:  1 , epoch:  25 , val loss:  0.0001282349694520235\n",
      "fold:  2 , epoch:  1 , val loss:  0.0001417899620719254\n",
      "fold:  2 , epoch:  2 , val loss:  9.14985139388591e-05\n",
      "fold:  2 , epoch:  3 , val loss:  5.4757390898885205e-05\n",
      "fold:  2 , epoch:  4 , val loss:  3.541170372045599e-05\n",
      "fold:  2 , epoch:  5 , val loss:  2.49610748142004e-05\n",
      "fold:  2 , epoch:  6 , val loss:  3.784903310588561e-05\n",
      "fold:  2 , epoch:  7 , val loss:  6.247685087146237e-05\n",
      "fold:  2 , epoch:  8 , val loss:  0.00011987514153588563\n",
      "fold:  2 , epoch:  9 , val loss:  0.00018288243154529482\n",
      "fold:  2 , epoch:  10 , val loss:  7.446512609021738e-05\n",
      "fold:  2 , epoch:  11 , val loss:  0.0001578776864334941\n",
      "fold:  2 , epoch:  12 , val loss:  1.9714432710316032e-05\n",
      "fold:  2 , epoch:  13 , val loss:  2.4321228920598514e-05\n",
      "fold:  2 , epoch:  14 , val loss:  2.2433972844737582e-05\n",
      "fold:  2 , epoch:  15 , val loss:  1.860803422459867e-05\n",
      "fold:  2 , epoch:  16 , val loss:  6.56769989291206e-05\n",
      "fold:  2 , epoch:  17 , val loss:  8.85548724909313e-05\n",
      "fold:  2 , epoch:  18 , val loss:  1.9741592041100375e-05\n",
      "fold:  2 , epoch:  19 , val loss:  2.3033864636090584e-05\n",
      "fold:  2 , epoch:  20 , val loss:  1.7030884919222444e-05\n",
      "fold:  2 , epoch:  21 , val loss:  2.8080732590751722e-05\n",
      "fold:  2 , epoch:  22 , val loss:  1.589631210663356e-05\n",
      "fold:  2 , epoch:  23 , val loss:  1.5552432159893215e-05\n",
      "fold:  2 , epoch:  24 , val loss:  5.204760600463487e-05\n",
      "fold:  2 , epoch:  25 , val loss:  1.5334047930082306e-05\n",
      "fold:  3 , epoch:  1 , val loss:  5.06006290379446e-05\n",
      "fold:  3 , epoch:  2 , val loss:  1.7542106434120797e-05\n",
      "fold:  3 , epoch:  3 , val loss:  8.086564048426226e-05\n",
      "fold:  3 , epoch:  4 , val loss:  1.3252427379484288e-05\n",
      "fold:  3 , epoch:  5 , val loss:  1.9274206351838075e-05\n",
      "fold:  3 , epoch:  6 , val loss:  5.4096177336759865e-05\n",
      "fold:  3 , epoch:  7 , val loss:  2.0451718228287064e-05\n",
      "fold:  3 , epoch:  8 , val loss:  1.3033226423431188e-05\n",
      "fold:  3 , epoch:  9 , val loss:  5.089546539238654e-05\n",
      "fold:  3 , epoch:  10 , val loss:  5.1086411986034364e-05\n",
      "fold:  3 , epoch:  11 , val loss:  1.3382556062424555e-05\n",
      "fold:  3 , epoch:  12 , val loss:  1.4412684322451241e-05\n",
      "fold:  3 , epoch:  13 , val loss:  0.00011005749547621235\n",
      "fold:  3 , epoch:  14 , val loss:  1.5960917153279297e-05\n",
      "fold:  3 , epoch:  15 , val loss:  1.5482655726373196e-05\n",
      "fold:  3 , epoch:  16 , val loss:  5.0927483243867755e-05\n",
      "fold:  3 , epoch:  17 , val loss:  1.2635960047191475e-05\n",
      "fold:  3 , epoch:  18 , val loss:  1.3512443729268853e-05\n",
      "fold:  3 , epoch:  19 , val loss:  6.902337918290868e-05\n",
      "fold:  3 , epoch:  20 , val loss:  6.055134508642368e-05\n",
      "fold:  3 , epoch:  21 , val loss:  7.662217831239104e-05\n",
      "fold:  3 , epoch:  22 , val loss:  6.133085116744041e-05\n",
      "fold:  3 , epoch:  23 , val loss:  1.1583822924876586e-05\n",
      "fold:  3 , epoch:  24 , val loss:  1.1019440535164904e-05\n",
      "fold:  3 , epoch:  25 , val loss:  1.5900686776149087e-05\n",
      "fold:  4 , epoch:  1 , val loss:  5.150380820850842e-05\n",
      "fold:  4 , epoch:  2 , val loss:  1.4449376976699568e-05\n",
      "fold:  4 , epoch:  3 , val loss:  0.00010209756146650761\n",
      "fold:  4 , epoch:  4 , val loss:  2.5698378522065468e-05\n",
      "fold:  4 , epoch:  5 , val loss:  2.273595418955665e-05\n",
      "fold:  4 , epoch:  6 , val loss:  1.3277715879667085e-05\n",
      "fold:  4 , epoch:  7 , val loss:  1.9249335309723392e-05\n",
      "fold:  4 , epoch:  8 , val loss:  1.1550553608685732e-05\n",
      "fold:  4 , epoch:  9 , val loss:  1.1147697478008922e-05\n",
      "fold:  4 , epoch:  10 , val loss:  3.350070983287878e-05\n",
      "fold:  4 , epoch:  11 , val loss:  1.1238436854910105e-05\n",
      "fold:  4 , epoch:  12 , val loss:  2.2346350306179374e-05\n",
      "fold:  4 , epoch:  13 , val loss:  1.5615431038895622e-05\n",
      "fold:  4 , epoch:  14 , val loss:  8.790790161583573e-06\n",
      "fold:  4 , epoch:  15 , val loss:  3.7173365853959695e-05\n",
      "fold:  4 , epoch:  16 , val loss:  1.2576591871038545e-05\n",
      "fold:  4 , epoch:  17 , val loss:  3.0229419280658476e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  4 , epoch:  18 , val loss:  3.703924812725745e-05\n",
      "fold:  4 , epoch:  19 , val loss:  1.6483792933286168e-05\n",
      "fold:  4 , epoch:  20 , val loss:  7.866682608437259e-06\n",
      "fold:  4 , epoch:  21 , val loss:  1.4514896065520588e-05\n",
      "fold:  4 , epoch:  22 , val loss:  1.3749947356700432e-05\n",
      "fold:  4 , epoch:  23 , val loss:  1.0378079423389863e-05\n",
      "fold:  4 , epoch:  24 , val loss:  9.250067705579568e-06\n",
      "fold:  4 , epoch:  25 , val loss:  1.1877657925651874e-05\n",
      "fold:  5 , epoch:  1 , val loss:  1.735805744829122e-05\n",
      "fold:  5 , epoch:  2 , val loss:  1.139953383244574e-05\n",
      "fold:  5 , epoch:  3 , val loss:  9.003314517030958e-06\n",
      "fold:  5 , epoch:  4 , val loss:  6.756386483175447e-06\n",
      "fold:  5 , epoch:  5 , val loss:  7.0452329055115115e-06\n",
      "fold:  5 , epoch:  6 , val loss:  8.076985068328213e-06\n",
      "fold:  5 , epoch:  7 , val loss:  1.557153882458806e-05\n",
      "fold:  5 , epoch:  8 , val loss:  1.2008764315396547e-05\n",
      "fold:  5 , epoch:  9 , val loss:  9.800472980714403e-06\n",
      "fold:  5 , epoch:  10 , val loss:  7.047906365187373e-06\n",
      "fold:  5 , epoch:  11 , val loss:  9.94558104139287e-06\n",
      "fold:  5 , epoch:  12 , val loss:  6.870079232612625e-06\n",
      "fold:  5 , epoch:  13 , val loss:  6.7284204305906314e-06\n",
      "fold:  5 , epoch:  14 , val loss:  1.6457141100545414e-05\n",
      "fold:  5 , epoch:  15 , val loss:  1.20844570119516e-05\n",
      "fold:  5 , epoch:  16 , val loss:  7.707607437623665e-06\n",
      "fold:  5 , epoch:  17 , val loss:  9.54784445639234e-06\n",
      "fold:  5 , epoch:  18 , val loss:  6.002092959533911e-06\n",
      "fold:  5 , epoch:  19 , val loss:  7.268991339515196e-06\n",
      "fold:  5 , epoch:  20 , val loss:  7.497615570173366e-06\n",
      "fold:  5 , epoch:  21 , val loss:  6.16566421740572e-06\n",
      "fold:  5 , epoch:  22 , val loss:  9.679577487986535e-06\n",
      "fold:  5 , epoch:  23 , val loss:  1.005140074994415e-05\n",
      "fold:  5 , epoch:  24 , val loss:  1.856310154835228e-05\n",
      "fold:  5 , epoch:  25 , val loss:  9.33926276047714e-06\n",
      "Model results:  {'hidden_size': 200, 'n_layers': 6, 'act_fun': 'ReLU', 'init_methods': 'xavier normal', 'mean_val_result': 7.040426197636406e-05, 'std_val_result': 0.00016011985320046158} \n",
      "\n",
      "Model:  {'hidden_size': 200, 'n_layers': 8, 'act_fun': 'LeakyReLU', 'init_methods': 'xavier uniform'}\n",
      "fold:  1 , epoch:  1 , val loss:  0.0006180769996717572\n",
      "fold:  1 , epoch:  2 , val loss:  0.00023280843743123114\n",
      "fold:  1 , epoch:  3 , val loss:  0.00015075731789693236\n",
      "fold:  1 , epoch:  4 , val loss:  0.0001075674663297832\n",
      "fold:  1 , epoch:  5 , val loss:  9.345619764644653e-05\n",
      "fold:  1 , epoch:  6 , val loss:  7.118016947060823e-05\n",
      "fold:  1 , epoch:  7 , val loss:  6.521816976601258e-05\n",
      "fold:  1 , epoch:  8 , val loss:  5.559051351156086e-05\n",
      "fold:  1 , epoch:  9 , val loss:  4.371633622213267e-05\n",
      "fold:  1 , epoch:  10 , val loss:  4.132169488002546e-05\n",
      "fold:  1 , epoch:  11 , val loss:  4.135924973525107e-05\n",
      "fold:  1 , epoch:  12 , val loss:  4.126722342334688e-05\n",
      "fold:  1 , epoch:  13 , val loss:  5.4992062359815463e-05\n",
      "fold:  1 , epoch:  14 , val loss:  3.887686034431681e-05\n",
      "fold:  1 , epoch:  15 , val loss:  3.237857163185254e-05\n",
      "fold:  1 , epoch:  16 , val loss:  6.420880527002737e-05\n",
      "fold:  1 , epoch:  17 , val loss:  3.139373075100593e-05\n",
      "fold:  1 , epoch:  18 , val loss:  2.6120131224161014e-05\n",
      "fold:  1 , epoch:  19 , val loss:  2.207598663517274e-05\n",
      "fold:  1 , epoch:  20 , val loss:  2.1566786017501727e-05\n",
      "fold:  1 , epoch:  21 , val loss:  2.7012909413315356e-05\n",
      "fold:  1 , epoch:  22 , val loss:  5.007806248613633e-05\n",
      "fold:  1 , epoch:  23 , val loss:  4.589692616718821e-05\n",
      "fold:  1 , epoch:  24 , val loss:  1.950297155417502e-05\n",
      "fold:  1 , epoch:  25 , val loss:  2.54410279012518e-05\n",
      "fold:  2 , epoch:  1 , val loss:  2.872676486731507e-05\n",
      "fold:  2 , epoch:  2 , val loss:  2.2211581381270662e-05\n",
      "fold:  2 , epoch:  3 , val loss:  1.5113447261683177e-05\n",
      "fold:  2 , epoch:  4 , val loss:  1.4815502254350577e-05\n",
      "fold:  2 , epoch:  5 , val loss:  1.3774774743069429e-05\n",
      "fold:  2 , epoch:  6 , val loss:  1.7062166079995222e-05\n",
      "fold:  2 , epoch:  7 , val loss:  1.3621955986309331e-05\n",
      "fold:  2 , epoch:  8 , val loss:  1.365068783343304e-05\n",
      "fold:  2 , epoch:  9 , val loss:  1.6908512407098897e-05\n",
      "fold:  2 , epoch:  10 , val loss:  1.5420604540850036e-05\n",
      "fold:  2 , epoch:  11 , val loss:  1.3523028428608086e-05\n",
      "fold:  2 , epoch:  12 , val loss:  1.7128688341472298e-05\n",
      "fold:  2 , epoch:  13 , val loss:  1.5470424841623753e-05\n",
      "fold:  2 , epoch:  14 , val loss:  2.0129436961724423e-05\n",
      "fold:  2 , epoch:  15 , val loss:  2.4115694031934254e-05\n",
      "fold:  2 , epoch:  16 , val loss:  1.4457667020906229e-05\n",
      "fold:  2 , epoch:  17 , val loss:  2.55025352089433e-05\n",
      "fold:  2 , epoch:  18 , val loss:  1.0385718269390054e-05\n",
      "fold:  2 , epoch:  19 , val loss:  3.2820404157973826e-05\n",
      "fold:  2 , epoch:  20 , val loss:  1.21929033412016e-05\n",
      "fold:  2 , epoch:  21 , val loss:  1.0467258107382804e-05\n",
      "fold:  2 , epoch:  22 , val loss:  1.1478311535029206e-05\n",
      "fold:  2 , epoch:  23 , val loss:  9.426817086932715e-06\n",
      "fold:  2 , epoch:  24 , val loss:  9.884717655950226e-06\n",
      "fold:  2 , epoch:  25 , val loss:  1.5885389075265266e-05\n",
      "fold:  3 , epoch:  1 , val loss:  1.0799484698509332e-05\n",
      "fold:  3 , epoch:  2 , val loss:  9.305234925705008e-06\n",
      "fold:  3 , epoch:  3 , val loss:  1.0608690899971407e-05\n",
      "fold:  3 , epoch:  4 , val loss:  1.441724452888593e-05\n",
      "fold:  3 , epoch:  5 , val loss:  8.622849236417096e-06\n",
      "fold:  3 , epoch:  6 , val loss:  8.24058679427253e-06\n",
      "fold:  3 , epoch:  7 , val loss:  4.962059756508097e-05\n",
      "fold:  3 , epoch:  8 , val loss:  8.947566129791085e-06\n",
      "fold:  3 , epoch:  9 , val loss:  8.56049246067414e-06\n",
      "fold:  3 , epoch:  10 , val loss:  1.0027341886598151e-05\n",
      "fold:  3 , epoch:  11 , val loss:  9.764672540768515e-06\n",
      "fold:  3 , epoch:  12 , val loss:  7.658838512725197e-06\n",
      "fold:  3 , epoch:  13 , val loss:  8.924029316403903e-06\n",
      "fold:  3 , epoch:  14 , val loss:  4.67497666249983e-05\n",
      "fold:  3 , epoch:  15 , val loss:  3.903560354956426e-05\n",
      "fold:  3 , epoch:  16 , val loss:  1.7968324755202048e-05\n",
      "fold:  3 , epoch:  17 , val loss:  5.4891886975383386e-05\n",
      "fold:  3 , epoch:  18 , val loss:  8.080137376964558e-06\n",
      "fold:  3 , epoch:  19 , val loss:  1.0323574315407313e-05\n",
      "fold:  3 , epoch:  20 , val loss:  7.121277121768799e-06\n",
      "fold:  3 , epoch:  21 , val loss:  8.086729394563008e-06\n",
      "fold:  3 , epoch:  22 , val loss:  6.737785497534787e-06\n",
      "fold:  3 , epoch:  23 , val loss:  9.529204362479504e-06\n",
      "fold:  3 , epoch:  24 , val loss:  1.0030164958152454e-05\n",
      "fold:  3 , epoch:  25 , val loss:  1.3016220691497438e-05\n",
      "fold:  4 , epoch:  1 , val loss:  2.5730865672812797e-05\n",
      "fold:  4 , epoch:  2 , val loss:  6.015108283463633e-06\n",
      "fold:  4 , epoch:  3 , val loss:  6.20474929746706e-06\n",
      "fold:  4 , epoch:  4 , val loss:  1.1750518751796335e-05\n",
      "fold:  4 , epoch:  5 , val loss:  8.016092579055112e-06\n",
      "fold:  4 , epoch:  6 , val loss:  1.805190731829498e-05\n",
      "fold:  4 , epoch:  7 , val loss:  1.5956376955728047e-05\n",
      "fold:  4 , epoch:  8 , val loss:  1.2396098099998198e-05\n",
      "fold:  4 , epoch:  9 , val loss:  1.5304343833122402e-05\n",
      "fold:  4 , epoch:  10 , val loss:  2.2015092326910235e-05\n",
      "fold:  4 , epoch:  11 , val loss:  7.755506885587238e-06\n",
      "fold:  4 , epoch:  12 , val loss:  7.04408830642933e-06\n",
      "fold:  4 , epoch:  13 , val loss:  9.336438779428136e-06\n",
      "fold:  4 , epoch:  14 , val loss:  7.145359177229693e-06\n",
      "fold:  4 , epoch:  15 , val loss:  7.528161404479761e-06\n",
      "fold:  4 , epoch:  16 , val loss:  7.515381639677798e-06\n",
      "fold:  4 , epoch:  17 , val loss:  1.4066304174775723e-05\n",
      "fold:  4 , epoch:  18 , val loss:  2.913482421718072e-05\n",
      "fold:  4 , epoch:  19 , val loss:  1.6319005226250738e-05\n",
      "fold:  4 , epoch:  20 , val loss:  5.388854697230272e-05\n",
      "fold:  4 , epoch:  21 , val loss:  2.082272112602368e-05\n",
      "fold:  4 , epoch:  22 , val loss:  3.4481501643313095e-05\n",
      "fold:  4 , epoch:  23 , val loss:  4.475894456845708e-06\n",
      "fold:  4 , epoch:  24 , val loss:  5.700706878997153e-06\n",
      "fold:  4 , epoch:  25 , val loss:  6.575376119144494e-06\n",
      "fold:  5 , epoch:  1 , val loss:  1.0636760634952225e-05\n",
      "fold:  5 , epoch:  2 , val loss:  5.462992703542113e-06\n",
      "fold:  5 , epoch:  3 , val loss:  8.098864782368764e-06\n",
      "fold:  5 , epoch:  4 , val loss:  7.210462172224652e-06\n",
      "fold:  5 , epoch:  5 , val loss:  6.760503765690373e-06\n",
      "fold:  5 , epoch:  6 , val loss:  2.024611058004666e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  5 , epoch:  7 , val loss:  4.640969109459547e-06\n",
      "fold:  5 , epoch:  8 , val loss:  4.595111022354104e-06\n",
      "fold:  5 , epoch:  9 , val loss:  1.8835507944459096e-05\n",
      "fold:  5 , epoch:  10 , val loss:  6.270097401284147e-06\n",
      "fold:  5 , epoch:  11 , val loss:  6.2564618019678164e-06\n",
      "fold:  5 , epoch:  12 , val loss:  2.16861444641836e-05\n",
      "fold:  5 , epoch:  13 , val loss:  5.949753813183634e-06\n",
      "fold:  5 , epoch:  14 , val loss:  4.944524334860034e-06\n",
      "fold:  5 , epoch:  15 , val loss:  8.112140494631603e-05\n",
      "fold:  5 , epoch:  16 , val loss:  7.065831596264616e-05\n",
      "fold:  5 , epoch:  17 , val loss:  4.106108917767415e-06\n",
      "fold:  5 , epoch:  18 , val loss:  6.158736596262315e-06\n",
      "fold:  5 , epoch:  19 , val loss:  7.190014457592042e-06\n",
      "fold:  5 , epoch:  20 , val loss:  1.047793102770811e-05\n",
      "fold:  5 , epoch:  21 , val loss:  4.847199306823313e-05\n",
      "fold:  5 , epoch:  22 , val loss:  5.028551640862133e-06\n",
      "fold:  5 , epoch:  23 , val loss:  6.163247599033639e-05\n",
      "fold:  5 , epoch:  24 , val loss:  1.856872950156685e-05\n",
      "fold:  5 , epoch:  25 , val loss:  2.035096986219287e-05\n",
      "Model results:  {'hidden_size': 200, 'n_layers': 8, 'act_fun': 'LeakyReLU', 'init_methods': 'xavier uniform', 'mean_val_result': 2.937358696726733e-05, 'std_val_result': 6.051433972955322e-05} \n",
      "\n",
      "Model:  {'hidden_size': 400, 'n_layers': 6, 'act_fun': 'LeakyReLU', 'init_methods': 'xavier normal'}\n",
      "fold:  1 , epoch:  1 , val loss:  0.0003607584221754223\n",
      "fold:  1 , epoch:  2 , val loss:  0.00013148211291991174\n",
      "fold:  1 , epoch:  3 , val loss:  0.00017551981727592647\n",
      "fold:  1 , epoch:  4 , val loss:  0.0002600460429675877\n",
      "fold:  1 , epoch:  5 , val loss:  0.00017668094369582832\n",
      "fold:  1 , epoch:  6 , val loss:  4.201547199045308e-05\n",
      "fold:  1 , epoch:  7 , val loss:  0.00011814683239208534\n",
      "fold:  1 , epoch:  8 , val loss:  5.692728882422671e-05\n",
      "fold:  1 , epoch:  9 , val loss:  8.06955067673698e-05\n",
      "fold:  1 , epoch:  10 , val loss:  5.6016750022536144e-05\n",
      "fold:  1 , epoch:  11 , val loss:  2.7814634449896403e-05\n",
      "fold:  1 , epoch:  12 , val loss:  0.0001683930604485795\n",
      "fold:  1 , epoch:  13 , val loss:  2.165379555663094e-05\n",
      "fold:  1 , epoch:  14 , val loss:  2.1720832592109218e-05\n",
      "fold:  1 , epoch:  15 , val loss:  7.040322088869289e-05\n",
      "fold:  1 , epoch:  16 , val loss:  3.288327934569679e-05\n",
      "fold:  1 , epoch:  17 , val loss:  3.5564367863116786e-05\n",
      "fold:  1 , epoch:  18 , val loss:  0.00010863662464544177\n",
      "fold:  1 , epoch:  19 , val loss:  3.62709179171361e-05\n",
      "fold:  1 , epoch:  20 , val loss:  2.3843846065574326e-05\n",
      "fold:  1 , epoch:  21 , val loss:  2.1020394342485815e-05\n",
      "fold:  1 , epoch:  22 , val loss:  0.0001541298843221739\n",
      "fold:  1 , epoch:  23 , val loss:  1.5935554984025657e-05\n",
      "fold:  1 , epoch:  24 , val loss:  2.1698424461646937e-05\n",
      "fold:  1 , epoch:  25 , val loss:  1.3156188288121484e-05\n",
      "fold:  2 , epoch:  1 , val loss:  1.88242247531889e-05\n",
      "fold:  2 , epoch:  2 , val loss:  1.0352625395171344e-05\n",
      "fold:  2 , epoch:  3 , val loss:  4.0606511902296916e-05\n",
      "fold:  2 , epoch:  4 , val loss:  1.3647587365994696e-05\n",
      "fold:  2 , epoch:  5 , val loss:  2.2096775865065865e-05\n",
      "fold:  2 , epoch:  6 , val loss:  7.05799029674381e-05\n",
      "fold:  2 , epoch:  7 , val loss:  2.53697216976434e-05\n",
      "fold:  2 , epoch:  8 , val loss:  1.663930743234232e-05\n",
      "fold:  2 , epoch:  9 , val loss:  4.231967614032328e-05\n",
      "fold:  2 , epoch:  10 , val loss:  2.7560772650758736e-05\n",
      "fold:  2 , epoch:  11 , val loss:  4.6781784476479515e-05\n",
      "fold:  2 , epoch:  12 , val loss:  2.668353045010008e-05\n",
      "fold:  2 , epoch:  13 , val loss:  1.3101972399454098e-05\n",
      "fold:  2 , epoch:  14 , val loss:  1.2114778655814007e-05\n",
      "fold:  2 , epoch:  15 , val loss:  2.0990004486520775e-05\n",
      "fold:  2 , epoch:  16 , val loss:  7.3935034379246645e-06\n",
      "fold:  2 , epoch:  17 , val loss:  1.1098080904048402e-05\n",
      "fold:  2 , epoch:  18 , val loss:  2.6387881007394753e-05\n",
      "fold:  2 , epoch:  19 , val loss:  8.571266334911343e-06\n",
      "fold:  2 , epoch:  20 , val loss:  1.22451256174827e-05\n",
      "fold:  2 , epoch:  21 , val loss:  1.9113456801278517e-05\n",
      "fold:  2 , epoch:  22 , val loss:  1.5606896340614185e-05\n",
      "fold:  2 , epoch:  23 , val loss:  1.1455619642219972e-05\n",
      "fold:  2 , epoch:  24 , val loss:  3.24345201079268e-05\n",
      "fold:  2 , epoch:  25 , val loss:  1.3746785953117069e-05\n",
      "fold:  3 , epoch:  1 , val loss:  8.224858902394772e-05\n",
      "fold:  3 , epoch:  2 , val loss:  3.321095209685154e-05\n",
      "fold:  3 , epoch:  3 , val loss:  8.055767830228433e-05\n",
      "fold:  3 , epoch:  4 , val loss:  1.0200466022070032e-05\n",
      "fold:  3 , epoch:  5 , val loss:  7.542260573245585e-05\n",
      "fold:  3 , epoch:  6 , val loss:  3.0284883905551396e-05\n",
      "fold:  3 , epoch:  7 , val loss:  1.8719360014074482e-05\n",
      "fold:  3 , epoch:  8 , val loss:  3.7452704418683425e-05\n",
      "fold:  3 , epoch:  9 , val loss:  2.9443721359712072e-05\n",
      "fold:  3 , epoch:  10 , val loss:  1.0770403605420142e-05\n",
      "fold:  3 , epoch:  11 , val loss:  5.951923867542064e-06\n",
      "fold:  3 , epoch:  12 , val loss:  6.451709850807674e-06\n",
      "fold:  3 , epoch:  13 , val loss:  9.583007340552285e-06\n",
      "fold:  3 , epoch:  14 , val loss:  7.866641681175679e-05\n",
      "fold:  3 , epoch:  15 , val loss:  1.2520699783635791e-05\n",
      "fold:  3 , epoch:  16 , val loss:  1.944411087606568e-05\n",
      "fold:  3 , epoch:  17 , val loss:  4.9251980271947104e-06\n",
      "fold:  3 , epoch:  18 , val loss:  4.672046088671777e-06\n",
      "fold:  3 , epoch:  19 , val loss:  6.97356244927505e-06\n",
      "fold:  3 , epoch:  20 , val loss:  1.7552283679833636e-05\n",
      "fold:  3 , epoch:  21 , val loss:  8.834125765133649e-06\n",
      "fold:  3 , epoch:  22 , val loss:  1.885554229374975e-05\n",
      "fold:  3 , epoch:  23 , val loss:  4.4982491090195253e-05\n",
      "fold:  3 , epoch:  24 , val loss:  9.231053809344303e-06\n",
      "fold:  3 , epoch:  25 , val loss:  4.622761935024755e-06\n",
      "fold:  4 , epoch:  1 , val loss:  9.43975737754954e-06\n",
      "fold:  4 , epoch:  2 , val loss:  7.921683391032275e-06\n",
      "fold:  4 , epoch:  3 , val loss:  4.6752015805395786e-06\n",
      "fold:  4 , epoch:  4 , val loss:  3.268749060225673e-05\n",
      "fold:  4 , epoch:  5 , val loss:  8.154047463904135e-06\n",
      "fold:  4 , epoch:  6 , val loss:  1.0613144695525989e-05\n",
      "fold:  4 , epoch:  7 , val loss:  2.55597842624411e-05\n",
      "fold:  4 , epoch:  8 , val loss:  2.9457944037858397e-05\n",
      "fold:  4 , epoch:  9 , val loss:  6.434046099457191e-06\n",
      "fold:  4 , epoch:  10 , val loss:  4.2487558857828844e-06\n",
      "fold:  4 , epoch:  11 , val loss:  2.0739347746712156e-05\n",
      "fold:  4 , epoch:  12 , val loss:  4.729431566374842e-06\n",
      "fold:  4 , epoch:  13 , val loss:  6.006711828376865e-06\n",
      "fold:  4 , epoch:  14 , val loss:  1.7653617760515772e-05\n",
      "fold:  4 , epoch:  15 , val loss:  5.657505607814528e-05\n",
      "fold:  4 , epoch:  16 , val loss:  6.371033668983728e-05\n",
      "fold:  4 , epoch:  17 , val loss:  5.411082383943722e-06\n",
      "fold:  4 , epoch:  18 , val loss:  1.5623398212483153e-05\n",
      "fold:  4 , epoch:  19 , val loss:  3.0232695280574262e-06\n",
      "fold:  4 , epoch:  20 , val loss:  4.596719008986838e-06\n",
      "fold:  4 , epoch:  21 , val loss:  2.0350342310848646e-05\n",
      "fold:  4 , epoch:  22 , val loss:  2.5609095246181823e-05\n",
      "fold:  4 , epoch:  23 , val loss:  7.942629963508807e-06\n",
      "fold:  4 , epoch:  24 , val loss:  5.846130534337135e-06\n",
      "fold:  4 , epoch:  25 , val loss:  1.8912651285063475e-05\n",
      "fold:  5 , epoch:  1 , val loss:  2.7581829272094183e-05\n",
      "fold:  5 , epoch:  2 , val loss:  1.8316335626877844e-05\n",
      "fold:  5 , epoch:  3 , val loss:  7.593208920297911e-06\n",
      "fold:  5 , epoch:  4 , val loss:  5.669178335665492e-06\n",
      "fold:  5 , epoch:  5 , val loss:  4.925315352011239e-06\n",
      "fold:  5 , epoch:  6 , val loss:  7.1216745709534734e-06\n",
      "fold:  5 , epoch:  7 , val loss:  2.8794302124879323e-06\n",
      "fold:  5 , epoch:  8 , val loss:  4.299983174860245e-06\n",
      "fold:  5 , epoch:  9 , val loss:  1.8830553017323837e-05\n",
      "fold:  5 , epoch:  10 , val loss:  1.844567304942757e-05\n",
      "fold:  5 , epoch:  11 , val loss:  8.293925020552706e-06\n",
      "fold:  5 , epoch:  12 , val loss:  1.0875412044697441e-05\n",
      "fold:  5 , epoch:  13 , val loss:  1.3843539818481077e-05\n",
      "fold:  5 , epoch:  14 , val loss:  8.871231329976581e-06\n",
      "fold:  5 , epoch:  15 , val loss:  2.8637912237172714e-06\n",
      "fold:  5 , epoch:  16 , val loss:  6.106946329964558e-06\n",
      "fold:  5 , epoch:  17 , val loss:  6.782926448067883e-06\n",
      "fold:  5 , epoch:  18 , val loss:  4.450146661838517e-06\n",
      "fold:  5 , epoch:  19 , val loss:  8.593607162765693e-06\n",
      "fold:  5 , epoch:  20 , val loss:  5.099908958072774e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  5 , epoch:  21 , val loss:  1.5562098269583657e-05\n",
      "fold:  5 , epoch:  22 , val loss:  8.302020432893187e-06\n",
      "fold:  5 , epoch:  23 , val loss:  6.151723027869593e-06\n",
      "fold:  5 , epoch:  24 , val loss:  4.9623657105257735e-05\n",
      "fold:  5 , epoch:  25 , val loss:  2.834973747667391e-05\n",
      "Model results:  {'hidden_size': 400, 'n_layers': 6, 'act_fun': 'LeakyReLU', 'init_methods': 'xavier normal', 'mean_val_result': 3.3759756281142474e-05, 'std_val_result': 5.0020378084945505e-05} \n",
      "\n",
      "Model:  {'hidden_size': 400, 'n_layers': 8, 'act_fun': 'ELU', 'init_methods': 'xavier normal'}\n",
      "fold:  1 , epoch:  1 , val loss:  0.0015917542623355985\n",
      "fold:  1 , epoch:  2 , val loss:  0.0005563193699344993\n",
      "fold:  1 , epoch:  3 , val loss:  0.0003825286985374987\n",
      "fold:  1 , epoch:  4 , val loss:  0.00027356354985386133\n",
      "fold:  1 , epoch:  5 , val loss:  0.00018227938562631607\n",
      "fold:  1 , epoch:  6 , val loss:  0.000424072437454015\n",
      "fold:  1 , epoch:  7 , val loss:  0.003267091466113925\n",
      "fold:  1 , epoch:  8 , val loss:  0.00022065284429118037\n",
      "fold:  1 , epoch:  9 , val loss:  0.00027129982481710613\n",
      "fold:  1 , epoch:  10 , val loss:  0.00016413936100434512\n",
      "fold:  1 , epoch:  11 , val loss:  0.00025996079784817994\n",
      "fold:  1 , epoch:  12 , val loss:  0.0006731027388013899\n",
      "fold:  1 , epoch:  13 , val loss:  0.00010506447870284319\n",
      "fold:  1 , epoch:  14 , val loss:  0.00010314139217371121\n",
      "fold:  1 , epoch:  15 , val loss:  0.0010959103237837553\n",
      "fold:  1 , epoch:  16 , val loss:  0.0004690682690124959\n",
      "fold:  1 , epoch:  17 , val loss:  0.0011962263379245996\n",
      "fold:  1 , epoch:  18 , val loss:  0.00024096255947370082\n",
      "fold:  1 , epoch:  19 , val loss:  0.00048719588085077703\n",
      "fold:  1 , epoch:  20 , val loss:  8.862686809152365e-05\n",
      "fold:  1 , epoch:  21 , val loss:  9.074064291780815e-05\n",
      "fold:  1 , epoch:  22 , val loss:  5.1807928684866056e-05\n",
      "fold:  1 , epoch:  23 , val loss:  0.0001423612848157063\n",
      "fold:  1 , epoch:  24 , val loss:  0.00010696671961341053\n",
      "fold:  1 , epoch:  25 , val loss:  0.00013268734619487077\n",
      "fold:  2 , epoch:  1 , val loss:  0.00015729988808743656\n",
      "fold:  2 , epoch:  2 , val loss:  9.843519364949316e-05\n",
      "fold:  2 , epoch:  3 , val loss:  5.223355765338056e-05\n",
      "fold:  2 , epoch:  4 , val loss:  5.955105007160455e-05\n",
      "fold:  2 , epoch:  5 , val loss:  0.0001605074357939884\n",
      "fold:  2 , epoch:  6 , val loss:  0.0006727151339873672\n",
      "fold:  2 , epoch:  7 , val loss:  7.85599258961156e-05\n",
      "fold:  2 , epoch:  8 , val loss:  0.00015424082812387496\n",
      "fold:  2 , epoch:  9 , val loss:  0.0003137742751277983\n",
      "fold:  2 , epoch:  10 , val loss:  0.00011754674778785557\n",
      "fold:  2 , epoch:  11 , val loss:  6.337686500046402e-05\n",
      "fold:  2 , epoch:  12 , val loss:  8.800789510132745e-05\n",
      "fold:  2 , epoch:  13 , val loss:  9.62590056587942e-05\n",
      "fold:  2 , epoch:  14 , val loss:  5.573523958446458e-05\n",
      "fold:  2 , epoch:  15 , val loss:  7.811497926013544e-05\n",
      "fold:  2 , epoch:  16 , val loss:  4.347585854702629e-05\n",
      "fold:  2 , epoch:  17 , val loss:  6.249640136957169e-05\n",
      "fold:  2 , epoch:  18 , val loss:  4.0385915781371295e-05\n",
      "fold:  2 , epoch:  19 , val loss:  2.7687747206073254e-05\n",
      "fold:  2 , epoch:  20 , val loss:  5.209981827647425e-05\n",
      "fold:  2 , epoch:  21 , val loss:  4.096803240827285e-05\n",
      "fold:  2 , epoch:  22 , val loss:  0.00014689443923998624\n",
      "fold:  2 , epoch:  23 , val loss:  0.00042342019150964916\n",
      "fold:  2 , epoch:  24 , val loss:  0.0003846394538413733\n",
      "fold:  2 , epoch:  25 , val loss:  0.00023332495766226202\n",
      "fold:  3 , epoch:  1 , val loss:  2.0744180801557377e-05\n",
      "fold:  3 , epoch:  2 , val loss:  4.000147964688949e-05\n",
      "fold:  3 , epoch:  3 , val loss:  2.152537854271941e-05\n",
      "fold:  3 , epoch:  4 , val loss:  5.015035276301205e-05\n",
      "fold:  3 , epoch:  5 , val loss:  0.00012498159776441753\n",
      "fold:  3 , epoch:  6 , val loss:  0.00029943641857244074\n",
      "fold:  3 , epoch:  7 , val loss:  2.621761268528644e-05\n",
      "fold:  3 , epoch:  8 , val loss:  0.000127066217828542\n",
      "fold:  3 , epoch:  9 , val loss:  8.402918319916353e-05\n",
      "fold:  3 , epoch:  10 , val loss:  6.555128493346274e-05\n",
      "fold:  3 , epoch:  11 , val loss:  3.950015889131464e-05\n",
      "fold:  3 , epoch:  12 , val loss:  3.410662611713633e-05\n",
      "fold:  3 , epoch:  13 , val loss:  0.00013247696915641427\n",
      "fold:  3 , epoch:  14 , val loss:  0.00019528741540852934\n",
      "fold:  3 , epoch:  15 , val loss:  0.00010924783418886364\n",
      "fold:  3 , epoch:  16 , val loss:  0.00013121742813382298\n",
      "fold:  3 , epoch:  17 , val loss:  0.00016469057300128043\n",
      "fold:  3 , epoch:  18 , val loss:  0.00024404596479143947\n",
      "fold:  3 , epoch:  19 , val loss:  6.683838000753894e-05\n",
      "fold:  3 , epoch:  20 , val loss:  1.387306929245824e-05\n",
      "fold:  3 , epoch:  21 , val loss:  3.3349522709613666e-05\n",
      "fold:  3 , epoch:  22 , val loss:  2.8144640964455903e-05\n",
      "fold:  3 , epoch:  23 , val loss:  4.371823160909116e-05\n",
      "fold:  3 , epoch:  24 , val loss:  1.3429644241114147e-05\n",
      "fold:  3 , epoch:  25 , val loss:  3.91870089515578e-05\n",
      "fold:  4 , epoch:  1 , val loss:  2.0288525774958543e-05\n",
      "fold:  4 , epoch:  2 , val loss:  3.95399474655278e-05\n",
      "fold:  4 , epoch:  3 , val loss:  2.2413347323890775e-05\n",
      "fold:  4 , epoch:  4 , val loss:  1.3092463632347062e-05\n",
      "fold:  4 , epoch:  5 , val loss:  9.055235750565771e-06\n",
      "fold:  4 , epoch:  6 , val loss:  3.193976226611994e-05\n",
      "fold:  4 , epoch:  7 , val loss:  5.9721180150518194e-05\n",
      "fold:  4 , epoch:  8 , val loss:  4.688220360549167e-05\n",
      "fold:  4 , epoch:  9 , val loss:  2.98426366498461e-05\n",
      "fold:  4 , epoch:  10 , val loss:  5.333249282557517e-05\n",
      "fold:  4 , epoch:  11 , val loss:  3.573120920918882e-05\n",
      "fold:  4 , epoch:  12 , val loss:  0.00012059386062901467\n",
      "fold:  4 , epoch:  13 , val loss:  2.2085145246819593e-05\n",
      "fold:  4 , epoch:  14 , val loss:  0.00014823702804278582\n",
      "fold:  4 , epoch:  15 , val loss:  3.881341399392113e-05\n",
      "fold:  4 , epoch:  16 , val loss:  0.0001018028924590908\n",
      "fold:  4 , epoch:  17 , val loss:  9.5336654339917e-06\n",
      "fold:  4 , epoch:  18 , val loss:  7.198750608949922e-06\n",
      "fold:  4 , epoch:  19 , val loss:  2.1859388652956113e-05\n",
      "fold:  4 , epoch:  20 , val loss:  1.4978443687141407e-05\n",
      "fold:  4 , epoch:  21 , val loss:  1.2529570994956885e-05\n",
      "fold:  4 , epoch:  22 , val loss:  7.294276656466536e-06\n",
      "fold:  4 , epoch:  23 , val loss:  2.6002968297689222e-05\n",
      "fold:  4 , epoch:  24 , val loss:  0.00015028576308395714\n",
      "fold:  4 , epoch:  25 , val loss:  6.81033925502561e-05\n",
      "fold:  5 , epoch:  1 , val loss:  1.574134876136668e-05\n",
      "fold:  5 , epoch:  2 , val loss:  6.931080133654177e-05\n",
      "fold:  5 , epoch:  3 , val loss:  3.2043019018601626e-05\n",
      "fold:  5 , epoch:  4 , val loss:  2.2005684513715096e-05\n",
      "fold:  5 , epoch:  5 , val loss:  1.101341058529215e-05\n",
      "fold:  5 , epoch:  6 , val loss:  2.221249815193005e-05\n",
      "fold:  5 , epoch:  7 , val loss:  0.0001532404130557552\n",
      "fold:  5 , epoch:  8 , val loss:  3.5310611565364525e-05\n",
      "fold:  5 , epoch:  9 , val loss:  0.00019225117284804583\n",
      "fold:  5 , epoch:  10 , val loss:  2.5487059247097932e-05\n",
      "fold:  5 , epoch:  11 , val loss:  5.6264407248818316e-06\n",
      "fold:  5 , epoch:  12 , val loss:  1.2570442777359858e-05\n",
      "fold:  5 , epoch:  13 , val loss:  9.940015843312722e-06\n",
      "fold:  5 , epoch:  14 , val loss:  3.2626216125208884e-05\n",
      "fold:  5 , epoch:  15 , val loss:  1.4433376236411277e-05\n",
      "fold:  5 , epoch:  16 , val loss:  1.4556230780726764e-05\n",
      "fold:  5 , epoch:  17 , val loss:  1.078614059224492e-05\n",
      "fold:  5 , epoch:  18 , val loss:  3.313739944132976e-05\n",
      "fold:  5 , epoch:  19 , val loss:  9.151515769190155e-06\n",
      "fold:  5 , epoch:  20 , val loss:  4.9661695811664686e-05\n",
      "fold:  5 , epoch:  21 , val loss:  2.0246259737177752e-05\n",
      "fold:  5 , epoch:  22 , val loss:  1.4049477613298222e-05\n",
      "fold:  5 , epoch:  23 , val loss:  1.6332089217030443e-05\n",
      "fold:  5 , epoch:  24 , val loss:  6.535507054650225e-06\n",
      "fold:  5 , epoch:  25 , val loss:  0.00011119542614324018\n",
      "Model results:  {'hidden_size': 400, 'n_layers': 8, 'act_fun': 'ELU', 'init_methods': 'xavier normal', 'mean_val_result': 0.00016382971678103786, 'std_val_result': 0.000359046173291583} \n",
      "\n",
      "Model:  {'hidden_size': 600, 'n_layers': 8, 'act_fun': 'ReLU', 'init_methods': 'xavier normal'}\n",
      "fold:  1 , epoch:  1 , val loss:  0.0002058864920400083\n",
      "fold:  1 , epoch:  2 , val loss:  9.418313857167959e-05\n",
      "fold:  1 , epoch:  3 , val loss:  5.523219078895636e-05\n",
      "fold:  1 , epoch:  4 , val loss:  0.00017945337458513677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  1 , epoch:  5 , val loss:  0.000120751210488379\n",
      "fold:  1 , epoch:  6 , val loss:  5.0785969506250694e-05\n",
      "fold:  1 , epoch:  7 , val loss:  4.1924522520275787e-05\n",
      "fold:  1 , epoch:  8 , val loss:  2.522069371480029e-05\n",
      "fold:  1 , epoch:  9 , val loss:  7.866224041208625e-05\n",
      "fold:  1 , epoch:  10 , val loss:  3.6710946005769074e-05\n",
      "fold:  1 , epoch:  11 , val loss:  0.0003915123816113919\n",
      "fold:  1 , epoch:  12 , val loss:  2.9533979613916017e-05\n",
      "fold:  1 , epoch:  13 , val loss:  8.494159555993974e-05\n",
      "fold:  1 , epoch:  14 , val loss:  0.00011854091280838475\n",
      "fold:  1 , epoch:  15 , val loss:  2.777911868179217e-05\n",
      "fold:  1 , epoch:  16 , val loss:  5.338281698641367e-05\n",
      "fold:  1 , epoch:  17 , val loss:  2.9934028134448454e-05\n",
      "fold:  1 , epoch:  18 , val loss:  1.9110157154500484e-05\n",
      "fold:  1 , epoch:  19 , val loss:  2.0902354663121514e-05\n",
      "fold:  1 , epoch:  20 , val loss:  5.140591019880958e-05\n",
      "fold:  1 , epoch:  21 , val loss:  4.419676406541839e-05\n",
      "fold:  1 , epoch:  22 , val loss:  3.5819339245790616e-05\n",
      "fold:  1 , epoch:  23 , val loss:  3.433428719290532e-05\n",
      "fold:  1 , epoch:  24 , val loss:  1.9402019461267628e-05\n",
      "fold:  1 , epoch:  25 , val loss:  1.3517123079509474e-05\n",
      "fold:  2 , epoch:  1 , val loss:  5.6818924349499866e-05\n",
      "fold:  2 , epoch:  2 , val loss:  2.5853869374259375e-05\n",
      "fold:  2 , epoch:  3 , val loss:  0.00012902135495096445\n",
      "fold:  2 , epoch:  4 , val loss:  0.00011642323806881905\n",
      "fold:  2 , epoch:  5 , val loss:  0.00011913853813894093\n",
      "fold:  2 , epoch:  6 , val loss:  8.622350833320525e-06\n",
      "fold:  2 , epoch:  7 , val loss:  4.82545729028061e-05\n",
      "fold:  2 , epoch:  8 , val loss:  1.811548281693831e-05\n",
      "fold:  2 , epoch:  9 , val loss:  1.6560004951315932e-05\n",
      "fold:  2 , epoch:  10 , val loss:  1.4181198821461294e-05\n",
      "fold:  2 , epoch:  11 , val loss:  1.8088892829837278e-05\n",
      "fold:  2 , epoch:  12 , val loss:  1.164573313872097e-05\n",
      "fold:  2 , epoch:  13 , val loss:  4.631157571566291e-05\n",
      "fold:  2 , epoch:  14 , val loss:  3.3158663427457213e-05\n",
      "fold:  2 , epoch:  15 , val loss:  0.0001477221812820062\n",
      "fold:  2 , epoch:  16 , val loss:  6.032519377185963e-05\n",
      "fold:  2 , epoch:  17 , val loss:  1.278070794796804e-05\n",
      "fold:  2 , epoch:  18 , val loss:  1.8251534129376523e-05\n",
      "fold:  2 , epoch:  19 , val loss:  1.4443885447690263e-05\n",
      "fold:  2 , epoch:  20 , val loss:  8.093649739748798e-06\n",
      "fold:  2 , epoch:  21 , val loss:  1.640172558836639e-05\n",
      "fold:  2 , epoch:  22 , val loss:  3.147414099657908e-05\n",
      "fold:  2 , epoch:  23 , val loss:  6.479308649431914e-05\n",
      "fold:  2 , epoch:  24 , val loss:  1.2014007552352268e-05\n",
      "fold:  2 , epoch:  25 , val loss:  7.224704313557595e-05\n",
      "fold:  3 , epoch:  1 , val loss:  8.585001523897517e-06\n",
      "fold:  3 , epoch:  2 , val loss:  8.987256296677515e-05\n",
      "fold:  3 , epoch:  3 , val loss:  2.052440686384216e-05\n",
      "fold:  3 , epoch:  4 , val loss:  2.287324969074689e-05\n",
      "fold:  3 , epoch:  5 , val loss:  2.5227653168258257e-05\n",
      "fold:  3 , epoch:  6 , val loss:  3.033576467714738e-05\n",
      "fold:  3 , epoch:  7 , val loss:  2.1175908841541968e-05\n",
      "fold:  3 , epoch:  8 , val loss:  6.462160399678396e-06\n",
      "fold:  3 , epoch:  9 , val loss:  8.20520017441595e-06\n",
      "fold:  3 , epoch:  10 , val loss:  3.0376375434570946e-05\n",
      "fold:  3 , epoch:  11 , val loss:  5.99120676270104e-06\n",
      "fold:  3 , epoch:  12 , val loss:  5.279543984215707e-06\n",
      "fold:  3 , epoch:  13 , val loss:  6.809249953221297e-06\n",
      "fold:  3 , epoch:  14 , val loss:  7.6386286309571e-06\n",
      "fold:  3 , epoch:  15 , val loss:  6.922556622157572e-06\n",
      "fold:  3 , epoch:  16 , val loss:  8.077964594122022e-06\n",
      "fold:  3 , epoch:  17 , val loss:  2.0889920051558875e-05\n",
      "fold:  3 , epoch:  18 , val loss:  5.091132607049076e-06\n",
      "fold:  3 , epoch:  19 , val loss:  5.997963398840511e-06\n",
      "fold:  3 , epoch:  20 , val loss:  2.99888397421455e-05\n",
      "fold:  3 , epoch:  21 , val loss:  6.4494815887883306e-06\n",
      "fold:  3 , epoch:  22 , val loss:  1.9484754375298508e-05\n",
      "fold:  3 , epoch:  23 , val loss:  6.459009910031455e-06\n",
      "fold:  3 , epoch:  24 , val loss:  2.1052388547104783e-05\n",
      "fold:  3 , epoch:  25 , val loss:  1.5540668755420484e-05\n",
      "fold:  4 , epoch:  1 , val loss:  6.831373866589274e-06\n",
      "fold:  4 , epoch:  2 , val loss:  1.7722381016938016e-05\n",
      "fold:  4 , epoch:  3 , val loss:  4.345275101513835e-06\n",
      "fold:  4 , epoch:  4 , val loss:  7.998764885996934e-06\n",
      "fold:  4 , epoch:  5 , val loss:  7.298912350961473e-06\n",
      "fold:  4 , epoch:  6 , val loss:  1.264831007574685e-05\n",
      "fold:  4 , epoch:  7 , val loss:  6.18726116954349e-05\n",
      "fold:  4 , epoch:  8 , val loss:  5.755481652158778e-06\n",
      "fold:  4 , epoch:  9 , val loss:  1.7863001630757935e-05\n",
      "fold:  4 , epoch:  10 , val loss:  1.5775845895404927e-05\n",
      "fold:  4 , epoch:  11 , val loss:  8.377224730793387e-06\n",
      "fold:  4 , epoch:  12 , val loss:  2.0411638615769334e-05\n",
      "fold:  4 , epoch:  13 , val loss:  2.477355519658886e-05\n",
      "fold:  4 , epoch:  14 , val loss:  2.6197014449280687e-05\n",
      "fold:  4 , epoch:  15 , val loss:  0.00013812789984513074\n",
      "fold:  4 , epoch:  16 , val loss:  1.4394642676052172e-05\n",
      "fold:  4 , epoch:  17 , val loss:  8.673049705976155e-06\n",
      "fold:  4 , epoch:  18 , val loss:  6.67176527713309e-06\n",
      "fold:  4 , epoch:  19 , val loss:  1.5365401850431226e-05\n",
      "fold:  4 , epoch:  20 , val loss:  2.9584634830825962e-06\n",
      "fold:  4 , epoch:  21 , val loss:  3.265069381086505e-06\n",
      "fold:  4 , epoch:  22 , val loss:  7.8607017712784e-06\n",
      "fold:  4 , epoch:  23 , val loss:  4.36952677773661e-06\n",
      "fold:  4 , epoch:  24 , val loss:  5.29902399648563e-06\n",
      "fold:  4 , epoch:  25 , val loss:  5.013853751734132e-06\n",
      "fold:  5 , epoch:  1 , val loss:  4.235094365867553e-06\n",
      "fold:  5 , epoch:  2 , val loss:  2.990018401760608e-06\n",
      "fold:  5 , epoch:  3 , val loss:  8.174547474482097e-06\n",
      "fold:  5 , epoch:  4 , val loss:  2.5870926947391126e-06\n",
      "fold:  5 , epoch:  5 , val loss:  3.612787850215682e-06\n",
      "fold:  5 , epoch:  6 , val loss:  3.982715952588478e-06\n",
      "fold:  5 , epoch:  7 , val loss:  2.400351604592288e-06\n",
      "fold:  5 , epoch:  8 , val loss:  3.1509268865193008e-06\n",
      "fold:  5 , epoch:  9 , val loss:  2.924883119703736e-06\n",
      "fold:  5 , epoch:  10 , val loss:  3.6861390526610194e-06\n",
      "fold:  5 , epoch:  11 , val loss:  1.1440189155109692e-05\n",
      "fold:  5 , epoch:  12 , val loss:  2.23404890675738e-06\n",
      "fold:  5 , epoch:  13 , val loss:  2.3469378902518656e-06\n",
      "fold:  5 , epoch:  14 , val loss:  2.975229335788754e-06\n",
      "fold:  5 , epoch:  15 , val loss:  3.4851120744860964e-06\n",
      "fold:  5 , epoch:  16 , val loss:  2.649404677868006e-06\n",
      "fold:  5 , epoch:  17 , val loss:  2.10547818824125e-06\n",
      "fold:  5 , epoch:  18 , val loss:  2.2610838641412556e-06\n",
      "fold:  5 , epoch:  19 , val loss:  1.7735912479110993e-05\n",
      "fold:  5 , epoch:  20 , val loss:  9.900677468976937e-06\n",
      "fold:  5 , epoch:  21 , val loss:  8.77375714480877e-06\n",
      "fold:  5 , epoch:  22 , val loss:  9.106478501053061e-06\n",
      "fold:  5 , epoch:  23 , val loss:  3.06167385133449e-06\n",
      "fold:  5 , epoch:  24 , val loss:  5.176406375539955e-06\n",
      "fold:  5 , epoch:  25 , val loss:  5.445701390272006e-06\n",
      "Model results:  {'hidden_size': 600, 'n_layers': 8, 'act_fun': 'ReLU', 'init_methods': 'xavier normal', 'mean_val_result': 3.1963921241185745e-05, 'std_val_result': 4.9728871931501565e-05} \n",
      "\n",
      "Model:  {'hidden_size': 400, 'n_layers': 4, 'act_fun': 'ReLU', 'init_methods': 'xavier uniform'}\n",
      "fold:  1 , epoch:  1 , val loss:  0.000397579773562029\n",
      "fold:  1 , epoch:  2 , val loss:  0.00015485790208913386\n",
      "fold:  1 , epoch:  3 , val loss:  0.00010603287228150293\n",
      "fold:  1 , epoch:  4 , val loss:  7.182664558058605e-05\n",
      "fold:  1 , epoch:  5 , val loss:  5.180521839065477e-05\n",
      "fold:  1 , epoch:  6 , val loss:  4.37196358689107e-05\n",
      "fold:  1 , epoch:  7 , val loss:  3.816074604401365e-05\n",
      "fold:  1 , epoch:  8 , val loss:  4.0631730371387675e-05\n",
      "fold:  1 , epoch:  9 , val loss:  3.381073474884033e-05\n",
      "fold:  1 , epoch:  10 , val loss:  2.7512893211678602e-05\n",
      "fold:  1 , epoch:  11 , val loss:  5.785034954897128e-05\n",
      "fold:  1 , epoch:  12 , val loss:  2.656543620105367e-05\n",
      "fold:  1 , epoch:  13 , val loss:  2.309983392478898e-05\n",
      "fold:  1 , epoch:  14 , val loss:  2.966833380924072e-05\n",
      "fold:  1 , epoch:  15 , val loss:  2.660744394233916e-05\n",
      "fold:  1 , epoch:  16 , val loss:  1.8687836927711032e-05\n",
      "fold:  1 , epoch:  17 , val loss:  2.5225441277143545e-05\n",
      "fold:  1 , epoch:  18 , val loss:  1.944026917044539e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  1 , epoch:  19 , val loss:  1.601023723196704e-05\n",
      "fold:  1 , epoch:  20 , val loss:  1.4632341844844632e-05\n",
      "fold:  1 , epoch:  21 , val loss:  1.7366759493597783e-05\n",
      "fold:  1 , epoch:  22 , val loss:  2.783955460472498e-05\n",
      "fold:  1 , epoch:  23 , val loss:  1.9506540411384776e-05\n",
      "fold:  1 , epoch:  24 , val loss:  2.0179870261927135e-05\n",
      "fold:  1 , epoch:  25 , val loss:  1.2945416528964415e-05\n",
      "fold:  2 , epoch:  1 , val loss:  1.3896257769374643e-05\n",
      "fold:  2 , epoch:  2 , val loss:  1.536909803689923e-05\n",
      "fold:  2 , epoch:  3 , val loss:  1.3058765944151673e-05\n",
      "fold:  2 , epoch:  4 , val loss:  1.05908356999862e-05\n",
      "fold:  2 , epoch:  5 , val loss:  1.0512671906326432e-05\n",
      "fold:  2 , epoch:  6 , val loss:  1.5011098184913862e-05\n",
      "fold:  2 , epoch:  7 , val loss:  1.816241092456039e-05\n",
      "fold:  2 , epoch:  8 , val loss:  9.669908649811987e-06\n",
      "fold:  2 , epoch:  9 , val loss:  9.547574336465914e-06\n",
      "fold:  2 , epoch:  10 , val loss:  9.8920918389922e-06\n",
      "fold:  2 , epoch:  11 , val loss:  1.9809231162071228e-05\n",
      "fold:  2 , epoch:  12 , val loss:  1.7115082300733775e-05\n",
      "fold:  2 , epoch:  13 , val loss:  3.576101516955532e-05\n",
      "fold:  2 , epoch:  14 , val loss:  1.4285345059761312e-05\n",
      "fold:  2 , epoch:  15 , val loss:  8.190647349692881e-06\n",
      "fold:  2 , epoch:  16 , val loss:  1.997733306779992e-05\n",
      "fold:  2 , epoch:  17 , val loss:  8.171465196937788e-06\n",
      "fold:  2 , epoch:  18 , val loss:  8.290128789667506e-06\n",
      "fold:  2 , epoch:  19 , val loss:  2.292945828230586e-05\n",
      "fold:  2 , epoch:  20 , val loss:  8.275894288090058e-06\n",
      "fold:  2 , epoch:  21 , val loss:  8.891843208402861e-06\n",
      "fold:  2 , epoch:  22 , val loss:  2.0140463675488718e-05\n",
      "fold:  2 , epoch:  23 , val loss:  7.241527328005759e-06\n",
      "fold:  2 , epoch:  24 , val loss:  1.3079372365609743e-05\n",
      "fold:  2 , epoch:  25 , val loss:  7.020112207101192e-06\n",
      "fold:  3 , epoch:  1 , val loss:  1.076019907486625e-05\n",
      "fold:  3 , epoch:  2 , val loss:  1.7154463421320543e-05\n",
      "fold:  3 , epoch:  3 , val loss:  1.1974696462857537e-05\n",
      "fold:  3 , epoch:  4 , val loss:  7.307496161956806e-06\n",
      "fold:  3 , epoch:  5 , val loss:  6.938676051504444e-06\n",
      "fold:  3 , epoch:  6 , val loss:  8.097896170511376e-06\n",
      "fold:  3 , epoch:  7 , val loss:  7.131733127607731e-06\n",
      "fold:  3 , epoch:  8 , val loss:  8.482485100103077e-06\n",
      "fold:  3 , epoch:  9 , val loss:  3.318787639727816e-05\n",
      "fold:  3 , epoch:  10 , val loss:  1.5456123946933076e-05\n",
      "fold:  3 , epoch:  11 , val loss:  7.746818482701201e-06\n",
      "fold:  3 , epoch:  12 , val loss:  6.560317615367239e-06\n",
      "fold:  3 , epoch:  13 , val loss:  7.282338174263714e-06\n",
      "fold:  3 , epoch:  14 , val loss:  8.604243703302927e-06\n",
      "fold:  3 , epoch:  15 , val loss:  6.045695045031607e-06\n",
      "fold:  3 , epoch:  16 , val loss:  5.556988071475644e-06\n",
      "fold:  3 , epoch:  17 , val loss:  5.723827143810922e-06\n",
      "fold:  3 , epoch:  18 , val loss:  5.580222023127135e-06\n",
      "fold:  3 , epoch:  19 , val loss:  5.647324087476591e-06\n",
      "fold:  3 , epoch:  20 , val loss:  6.8761842157982755e-06\n",
      "fold:  3 , epoch:  21 , val loss:  7.188974905147916e-06\n",
      "fold:  3 , epoch:  22 , val loss:  6.2226326917880215e-06\n",
      "fold:  3 , epoch:  23 , val loss:  2.9009461286477745e-05\n",
      "fold:  3 , epoch:  24 , val loss:  7.587686923216097e-06\n",
      "fold:  3 , epoch:  25 , val loss:  7.198940238595242e-06\n",
      "fold:  4 , epoch:  1 , val loss:  6.2319927565113176e-06\n",
      "fold:  4 , epoch:  2 , val loss:  4.512232862907695e-06\n",
      "fold:  4 , epoch:  3 , val loss:  6.038841092959046e-06\n",
      "fold:  4 , epoch:  4 , val loss:  9.392689207743388e-06\n",
      "fold:  4 , epoch:  5 , val loss:  4.522033123066649e-06\n",
      "fold:  4 , epoch:  6 , val loss:  1.3631600268126931e-05\n",
      "fold:  4 , epoch:  7 , val loss:  6.95592052579741e-06\n",
      "fold:  4 , epoch:  8 , val loss:  1.1929604625038337e-05\n",
      "fold:  4 , epoch:  9 , val loss:  1.419519139744807e-05\n",
      "fold:  4 , epoch:  10 , val loss:  3.852471309073735e-06\n",
      "fold:  4 , epoch:  11 , val loss:  4.149156211497029e-06\n",
      "fold:  4 , epoch:  12 , val loss:  3.81631843993091e-06\n",
      "fold:  4 , epoch:  13 , val loss:  4.45757132183644e-06\n",
      "fold:  4 , epoch:  14 , val loss:  1.3257514183351304e-05\n",
      "fold:  4 , epoch:  15 , val loss:  8.93544165592175e-06\n",
      "fold:  4 , epoch:  16 , val loss:  4.6079208004812244e-06\n",
      "fold:  4 , epoch:  17 , val loss:  4.429467935551656e-06\n",
      "fold:  4 , epoch:  18 , val loss:  4.742778855870711e-06\n",
      "fold:  4 , epoch:  19 , val loss:  8.996188626042567e-06\n",
      "fold:  4 , epoch:  20 , val loss:  1.316135694651166e-05\n",
      "fold:  4 , epoch:  21 , val loss:  3.0921550205675885e-05\n",
      "fold:  4 , epoch:  22 , val loss:  1.0209896572632715e-05\n",
      "fold:  4 , epoch:  23 , val loss:  4.236228051013313e-06\n",
      "fold:  4 , epoch:  24 , val loss:  2.2477977836388163e-05\n",
      "fold:  4 , epoch:  25 , val loss:  2.6609082851791754e-05\n",
      "fold:  5 , epoch:  1 , val loss:  8.886519026418682e-06\n",
      "fold:  5 , epoch:  2 , val loss:  1.967297612281982e-05\n",
      "fold:  5 , epoch:  3 , val loss:  7.758179890515748e-06\n",
      "fold:  5 , epoch:  4 , val loss:  9.29464295040816e-06\n",
      "fold:  5 , epoch:  5 , val loss:  6.922156444488792e-06\n",
      "fold:  5 , epoch:  6 , val loss:  4.4196636736160144e-05\n",
      "fold:  5 , epoch:  7 , val loss:  5.878201136511052e-06\n",
      "fold:  5 , epoch:  8 , val loss:  5.410997800936457e-06\n",
      "fold:  5 , epoch:  9 , val loss:  4.26804217568133e-06\n",
      "fold:  5 , epoch:  10 , val loss:  6.495961315522436e-06\n",
      "fold:  5 , epoch:  11 , val loss:  5.2676723498734646e-06\n",
      "fold:  5 , epoch:  12 , val loss:  6.263725481403526e-06\n",
      "fold:  5 , epoch:  13 , val loss:  4.181042186246486e-06\n",
      "fold:  5 , epoch:  14 , val loss:  5.348473223421024e-06\n",
      "fold:  5 , epoch:  15 , val loss:  3.6245298815629212e-06\n",
      "fold:  5 , epoch:  16 , val loss:  8.96832989383256e-06\n",
      "fold:  5 , epoch:  17 , val loss:  4.44655233877711e-06\n",
      "fold:  5 , epoch:  18 , val loss:  4.745291334984358e-06\n",
      "fold:  5 , epoch:  19 , val loss:  3.621253199526109e-06\n",
      "fold:  5 , epoch:  20 , val loss:  3.468955355856451e-06\n",
      "fold:  5 , epoch:  21 , val loss:  6.346640020638006e-06\n",
      "fold:  5 , epoch:  22 , val loss:  8.54063455335563e-06\n",
      "fold:  5 , epoch:  23 , val loss:  7.435358384100255e-06\n",
      "fold:  5 , epoch:  24 , val loss:  5.370659437176073e-06\n",
      "fold:  5 , epoch:  25 , val loss:  6.163593297969783e-06\n",
      "Model results:  {'hidden_size': 400, 'n_layers': 4, 'act_fun': 'ReLU', 'init_methods': 'xavier uniform', 'mean_val_result': 1.891699842235539e-05, 'std_val_result': 3.896380891668022e-05} \n",
      "\n",
      "Model:  {'hidden_size': 600, 'n_layers': 8, 'act_fun': 'LeakyReLU', 'init_methods': 'xavier normal'}\n",
      "fold:  1 , epoch:  1 , val loss:  0.00021138257579877973\n",
      "fold:  1 , epoch:  2 , val loss:  8.896180224837735e-05\n",
      "fold:  1 , epoch:  3 , val loss:  6.604124064324424e-05\n",
      "fold:  1 , epoch:  4 , val loss:  0.0001215147931361571\n",
      "fold:  1 , epoch:  5 , val loss:  4.2118976125493646e-05\n",
      "fold:  1 , epoch:  6 , val loss:  0.0002375394687987864\n",
      "fold:  1 , epoch:  7 , val loss:  6.097812729422003e-05\n",
      "fold:  1 , epoch:  8 , val loss:  2.6400341084809043e-05\n",
      "fold:  1 , epoch:  9 , val loss:  2.7359250452718697e-05\n",
      "fold:  1 , epoch:  10 , val loss:  3.414809543755837e-05\n",
      "fold:  1 , epoch:  11 , val loss:  0.00016455254808533937\n",
      "fold:  1 , epoch:  12 , val loss:  3.188211485394277e-05\n",
      "fold:  1 , epoch:  13 , val loss:  0.00010079527419293299\n",
      "fold:  1 , epoch:  14 , val loss:  4.848489334108308e-05\n",
      "fold:  1 , epoch:  15 , val loss:  0.00010033618309535086\n",
      "fold:  1 , epoch:  16 , val loss:  0.00013682665303349495\n",
      "fold:  1 , epoch:  17 , val loss:  0.00010035196464741603\n",
      "fold:  1 , epoch:  18 , val loss:  2.0787354515050538e-05\n",
      "fold:  1 , epoch:  19 , val loss:  1.4149412891129032e-05\n",
      "fold:  1 , epoch:  20 , val loss:  1.7887070498545654e-05\n",
      "fold:  1 , epoch:  21 , val loss:  6.89957887516357e-05\n",
      "fold:  1 , epoch:  22 , val loss:  4.4825086661148816e-05\n",
      "fold:  1 , epoch:  23 , val loss:  6.233223393792287e-05\n",
      "fold:  1 , epoch:  24 , val loss:  6.314354686765e-05\n",
      "fold:  1 , epoch:  25 , val loss:  2.772911284409929e-05\n",
      "fold:  2 , epoch:  1 , val loss:  3.1434781703865156e-05\n",
      "fold:  2 , epoch:  2 , val loss:  3.4178094210801646e-05\n",
      "fold:  2 , epoch:  3 , val loss:  7.361381722148508e-05\n",
      "fold:  2 , epoch:  4 , val loss:  2.053438947768882e-05\n",
      "fold:  2 , epoch:  5 , val loss:  3.162202119710855e-05\n",
      "fold:  2 , epoch:  6 , val loss:  1.540409903100226e-05\n",
      "fold:  2 , epoch:  7 , val loss:  4.0865576011128724e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  2 , epoch:  8 , val loss:  2.193654108850751e-05\n",
      "fold:  2 , epoch:  9 , val loss:  3.263246253482066e-05\n",
      "fold:  2 , epoch:  10 , val loss:  0.0001368016382912174\n",
      "fold:  2 , epoch:  11 , val loss:  3.435228791204281e-05\n",
      "fold:  2 , epoch:  12 , val loss:  4.556195926852524e-05\n",
      "fold:  2 , epoch:  13 , val loss:  3.079640373471193e-05\n",
      "fold:  2 , epoch:  14 , val loss:  2.648264307936188e-05\n",
      "fold:  2 , epoch:  15 , val loss:  1.154280107584782e-05\n",
      "fold:  2 , epoch:  16 , val loss:  3.979731991421431e-05\n",
      "fold:  2 , epoch:  17 , val loss:  2.0016113921883516e-05\n",
      "fold:  2 , epoch:  18 , val loss:  2.0485775166889653e-05\n",
      "fold:  2 , epoch:  19 , val loss:  3.160139749525115e-05\n",
      "fold:  2 , epoch:  20 , val loss:  6.27650078968145e-05\n",
      "fold:  2 , epoch:  21 , val loss:  5.783419692306779e-05\n",
      "fold:  2 , epoch:  22 , val loss:  1.0325024959456641e-05\n",
      "fold:  2 , epoch:  23 , val loss:  3.284899867139757e-05\n",
      "fold:  2 , epoch:  24 , val loss:  2.5148687200271524e-05\n",
      "fold:  2 , epoch:  25 , val loss:  1.221122238348471e-05\n",
      "fold:  3 , epoch:  1 , val loss:  1.6139974832185544e-05\n",
      "fold:  3 , epoch:  2 , val loss:  0.00019449037790764123\n",
      "fold:  3 , epoch:  3 , val loss:  2.7388234229874797e-05\n",
      "fold:  3 , epoch:  4 , val loss:  2.8810827643610537e-05\n",
      "fold:  3 , epoch:  5 , val loss:  1.7456133718951605e-05\n",
      "fold:  3 , epoch:  6 , val loss:  8.3871836977778e-06\n",
      "fold:  3 , epoch:  7 , val loss:  8.497765520587564e-06\n",
      "fold:  3 , epoch:  8 , val loss:  3.1637715437682346e-05\n",
      "fold:  3 , epoch:  9 , val loss:  7.285610536200693e-06\n",
      "fold:  3 , epoch:  10 , val loss:  5.612462700810283e-06\n",
      "fold:  3 , epoch:  11 , val loss:  2.3969549147295766e-05\n",
      "fold:  3 , epoch:  12 , val loss:  1.1481440196803305e-05\n",
      "fold:  3 , epoch:  13 , val loss:  1.7725860743667e-05\n",
      "fold:  3 , epoch:  14 , val loss:  1.0456521522428375e-05\n",
      "fold:  3 , epoch:  15 , val loss:  1.4330265003081877e-05\n",
      "fold:  3 , epoch:  16 , val loss:  6.948270311113447e-06\n",
      "fold:  3 , epoch:  17 , val loss:  0.00011086571612395346\n",
      "fold:  3 , epoch:  18 , val loss:  2.3971892005647533e-05\n",
      "fold:  3 , epoch:  19 , val loss:  1.2402424545143731e-05\n",
      "fold:  3 , epoch:  20 , val loss:  5.490613330039196e-05\n",
      "fold:  3 , epoch:  21 , val loss:  3.152459976263344e-05\n",
      "fold:  3 , epoch:  22 , val loss:  8.883758709998801e-06\n",
      "fold:  3 , epoch:  23 , val loss:  3.9744154491927475e-06\n",
      "fold:  3 , epoch:  24 , val loss:  1.7534706785227172e-05\n",
      "fold:  3 , epoch:  25 , val loss:  6.815039796492783e-06\n",
      "fold:  4 , epoch:  1 , val loss:  4.446247112355195e-05\n",
      "fold:  4 , epoch:  2 , val loss:  1.0154903065995313e-05\n",
      "fold:  4 , epoch:  3 , val loss:  2.6412411898490973e-05\n",
      "fold:  4 , epoch:  4 , val loss:  1.3300173122843262e-05\n",
      "fold:  4 , epoch:  5 , val loss:  5.442389920062851e-06\n",
      "fold:  4 , epoch:  6 , val loss:  2.179979310312774e-05\n",
      "fold:  4 , epoch:  7 , val loss:  3.504521737340838e-05\n",
      "fold:  4 , epoch:  8 , val loss:  1.7873882825369947e-05\n",
      "fold:  4 , epoch:  9 , val loss:  5.353714368538931e-05\n",
      "fold:  4 , epoch:  10 , val loss:  1.5198595974652562e-05\n",
      "fold:  4 , epoch:  11 , val loss:  4.73015388706699e-05\n",
      "fold:  4 , epoch:  12 , val loss:  7.33593333279714e-06\n",
      "fold:  4 , epoch:  13 , val loss:  4.288950549380388e-06\n",
      "fold:  4 , epoch:  14 , val loss:  9.03235104487976e-06\n",
      "fold:  4 , epoch:  15 , val loss:  1.5773577615618706e-05\n",
      "fold:  4 , epoch:  16 , val loss:  1.1798143532359973e-05\n",
      "fold:  4 , epoch:  17 , val loss:  7.414067567879101e-06\n",
      "fold:  4 , epoch:  18 , val loss:  1.5068675565999001e-05\n",
      "fold:  4 , epoch:  19 , val loss:  1.302219334320398e-05\n",
      "fold:  4 , epoch:  20 , val loss:  4.031943899462931e-05\n",
      "fold:  4 , epoch:  21 , val loss:  1.3228870557213668e-05\n",
      "fold:  4 , epoch:  22 , val loss:  2.6477243864064803e-06\n",
      "fold:  4 , epoch:  23 , val loss:  2.279188038301072e-06\n",
      "fold:  4 , epoch:  24 , val loss:  4.968568646290805e-06\n",
      "fold:  4 , epoch:  25 , val loss:  2.753594571913709e-06\n",
      "fold:  5 , epoch:  1 , val loss:  2.5423430543014547e-06\n",
      "fold:  5 , epoch:  2 , val loss:  2.99765270028729e-06\n",
      "fold:  5 , epoch:  3 , val loss:  3.339995600981638e-06\n",
      "fold:  5 , epoch:  4 , val loss:  2.7163912818650715e-05\n",
      "fold:  5 , epoch:  5 , val loss:  8.466986400890164e-06\n",
      "fold:  5 , epoch:  6 , val loss:  3.6890796764055267e-06\n",
      "fold:  5 , epoch:  7 , val loss:  2.187981863244204e-06\n",
      "fold:  5 , epoch:  8 , val loss:  2.6769125724968035e-06\n",
      "fold:  5 , epoch:  9 , val loss:  2.8097661925130524e-05\n",
      "fold:  5 , epoch:  10 , val loss:  1.271305518457666e-05\n",
      "fold:  5 , epoch:  11 , val loss:  4.4171511035528965e-06\n",
      "fold:  5 , epoch:  12 , val loss:  3.6479968912317418e-06\n",
      "fold:  5 , epoch:  13 , val loss:  3.0712794796272647e-06\n",
      "fold:  5 , epoch:  14 , val loss:  1.8923976767837303e-06\n",
      "fold:  5 , epoch:  15 , val loss:  9.211128599417862e-06\n",
      "fold:  5 , epoch:  16 , val loss:  3.5269140425953083e-06\n",
      "fold:  5 , epoch:  17 , val loss:  5.565531409956748e-06\n",
      "fold:  5 , epoch:  18 , val loss:  2.328197524548159e-06\n",
      "fold:  5 , epoch:  19 , val loss:  5.892004992347211e-06\n",
      "fold:  5 , epoch:  20 , val loss:  5.7198371905542444e-06\n",
      "fold:  5 , epoch:  21 , val loss:  2.3981240246939706e-06\n",
      "fold:  5 , epoch:  22 , val loss:  6.858583674329566e-06\n",
      "fold:  5 , epoch:  23 , val loss:  5.432281795947347e-06\n",
      "fold:  5 , epoch:  24 , val loss:  4.595419341058005e-06\n",
      "fold:  5 , epoch:  25 , val loss:  1.4681618267786689e-05\n",
      "Model results:  {'hidden_size': 600, 'n_layers': 8, 'act_fun': 'LeakyReLU', 'init_methods': 'xavier normal', 'mean_val_result': 3.3083103166063665e-05, 'std_val_result': 4.192814903984493e-05} \n",
      "\n",
      "Model:  {'hidden_size': 400, 'n_layers': 8, 'act_fun': 'ELU', 'init_methods': 'xavier uniform'}\n",
      "fold:  1 , epoch:  1 , val loss:  0.0028394407127052546\n",
      "fold:  1 , epoch:  2 , val loss:  0.0010534931207075715\n",
      "fold:  1 , epoch:  3 , val loss:  0.0005178094725124538\n",
      "fold:  1 , epoch:  4 , val loss:  0.0002953394432552159\n",
      "fold:  1 , epoch:  5 , val loss:  0.00026283375336788595\n",
      "fold:  1 , epoch:  6 , val loss:  0.0003446013433858752\n",
      "fold:  1 , epoch:  7 , val loss:  0.00028256981750018895\n",
      "fold:  1 , epoch:  8 , val loss:  0.00038810117985121906\n",
      "fold:  1 , epoch:  9 , val loss:  0.00038349616806954145\n",
      "fold:  1 , epoch:  10 , val loss:  0.0003016547707375139\n",
      "fold:  1 , epoch:  11 , val loss:  0.000331994378939271\n",
      "fold:  1 , epoch:  12 , val loss:  0.000435563299106434\n",
      "fold:  1 , epoch:  13 , val loss:  0.0001658064720686525\n",
      "fold:  1 , epoch:  14 , val loss:  0.00020375468011479825\n",
      "fold:  1 , epoch:  15 , val loss:  0.00010281546565238386\n",
      "fold:  1 , epoch:  16 , val loss:  0.0003333984059281647\n",
      "fold:  1 , epoch:  17 , val loss:  0.00017448770813643932\n",
      "fold:  1 , epoch:  18 , val loss:  7.66977173043415e-05\n",
      "fold:  1 , epoch:  19 , val loss:  0.0003175472083967179\n",
      "fold:  1 , epoch:  20 , val loss:  0.00013244028377812356\n",
      "fold:  1 , epoch:  21 , val loss:  0.00010830779501702636\n",
      "fold:  1 , epoch:  22 , val loss:  0.00010892663703998551\n",
      "fold:  1 , epoch:  23 , val loss:  0.0002252267877338454\n",
      "fold:  1 , epoch:  24 , val loss:  0.00017423476674593985\n",
      "fold:  1 , epoch:  25 , val loss:  0.00035697894054464996\n",
      "fold:  2 , epoch:  1 , val loss:  2.7987365683657117e-05\n",
      "fold:  2 , epoch:  2 , val loss:  3.071778701269068e-05\n",
      "fold:  2 , epoch:  3 , val loss:  0.00010884899529628456\n",
      "fold:  2 , epoch:  4 , val loss:  4.346352579887025e-05\n",
      "fold:  2 , epoch:  5 , val loss:  0.00011940775584662333\n",
      "fold:  2 , epoch:  6 , val loss:  4.141623867326416e-05\n",
      "fold:  2 , epoch:  7 , val loss:  1.9392164176679216e-05\n",
      "fold:  2 , epoch:  8 , val loss:  0.00016786286141723394\n",
      "fold:  2 , epoch:  9 , val loss:  9.179204789688811e-05\n",
      "fold:  2 , epoch:  10 , val loss:  2.5558474590070546e-05\n",
      "fold:  2 , epoch:  11 , val loss:  0.0002682514605112374\n",
      "fold:  2 , epoch:  12 , val loss:  0.00021050292707514018\n",
      "fold:  2 , epoch:  13 , val loss:  5.2548100939020514e-05\n",
      "fold:  2 , epoch:  14 , val loss:  4.161457400186919e-05\n",
      "fold:  2 , epoch:  15 , val loss:  9.908257925417274e-05\n",
      "fold:  2 , epoch:  16 , val loss:  0.000279866682831198\n",
      "fold:  2 , epoch:  17 , val loss:  1.3457041859510355e-05\n",
      "fold:  2 , epoch:  18 , val loss:  2.179823786718771e-05\n",
      "fold:  2 , epoch:  19 , val loss:  8.812091982690617e-05\n",
      "fold:  2 , epoch:  20 , val loss:  0.00011169302160851657\n",
      "fold:  2 , epoch:  21 , val loss:  7.842671766411513e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  2 , epoch:  22 , val loss:  1.280612195841968e-05\n",
      "fold:  2 , epoch:  23 , val loss:  9.154409781331196e-06\n",
      "fold:  2 , epoch:  24 , val loss:  0.00024645408848300576\n",
      "fold:  2 , epoch:  25 , val loss:  2.70529963017907e-05\n",
      "fold:  3 , epoch:  1 , val loss:  1.2643630725506227e-05\n",
      "fold:  3 , epoch:  2 , val loss:  5.25939030922018e-05\n",
      "fold:  3 , epoch:  3 , val loss:  1.0130000191566069e-05\n",
      "fold:  3 , epoch:  4 , val loss:  1.1279546015430242e-05\n",
      "fold:  3 , epoch:  5 , val loss:  3.207470217603259e-05\n",
      "fold:  3 , epoch:  6 , val loss:  3.215340984752402e-05\n",
      "fold:  3 , epoch:  7 , val loss:  4.898651604889892e-05\n",
      "fold:  3 , epoch:  8 , val loss:  3.414863385842182e-05\n",
      "fold:  3 , epoch:  9 , val loss:  6.669776485068724e-05\n",
      "fold:  3 , epoch:  10 , val loss:  1.6042353308876045e-05\n",
      "fold:  3 , epoch:  11 , val loss:  1.368981884297682e-05\n",
      "fold:  3 , epoch:  12 , val loss:  0.00011881098907906562\n",
      "fold:  3 , epoch:  13 , val loss:  1.1313275535940193e-05\n",
      "fold:  3 , epoch:  14 , val loss:  9.408831829205155e-06\n",
      "fold:  3 , epoch:  15 , val loss:  0.0001079619032680057\n",
      "fold:  3 , epoch:  16 , val loss:  9.911090273817535e-06\n",
      "fold:  3 , epoch:  17 , val loss:  1.1888307199114934e-05\n",
      "fold:  3 , epoch:  18 , val loss:  3.5434626624919474e-05\n",
      "fold:  3 , epoch:  19 , val loss:  4.292007361073047e-05\n",
      "fold:  3 , epoch:  20 , val loss:  5.174910256755538e-05\n",
      "fold:  3 , epoch:  21 , val loss:  1.600092218723148e-05\n",
      "fold:  3 , epoch:  22 , val loss:  0.00022640622046310455\n",
      "fold:  3 , epoch:  23 , val loss:  9.142659837380052e-05\n",
      "fold:  3 , epoch:  24 , val loss:  1.2531932952697389e-05\n",
      "fold:  3 , epoch:  25 , val loss:  6.2779417930869386e-06\n",
      "fold:  4 , epoch:  1 , val loss:  1.7528074749861844e-05\n",
      "fold:  4 , epoch:  2 , val loss:  7.1781255428504664e-06\n",
      "fold:  4 , epoch:  3 , val loss:  5.262825288809836e-05\n",
      "fold:  4 , epoch:  4 , val loss:  6.4304604165954515e-06\n",
      "fold:  4 , epoch:  5 , val loss:  2.0386605683597736e-05\n",
      "fold:  4 , epoch:  6 , val loss:  1.2912068996229209e-05\n",
      "fold:  4 , epoch:  7 , val loss:  1.1517815437400714e-05\n",
      "fold:  4 , epoch:  8 , val loss:  6.2549474932893645e-06\n",
      "fold:  4 , epoch:  9 , val loss:  8.40259890537709e-05\n",
      "fold:  4 , epoch:  10 , val loss:  1.3457368368108291e-05\n",
      "fold:  4 , epoch:  11 , val loss:  5.002309080737177e-06\n",
      "fold:  4 , epoch:  12 , val loss:  0.0001607817830517888\n",
      "fold:  4 , epoch:  13 , val loss:  4.705619630840374e-06\n",
      "fold:  4 , epoch:  14 , val loss:  1.7019285223796032e-05\n",
      "fold:  4 , epoch:  15 , val loss:  1.0062836736324243e-05\n",
      "fold:  4 , epoch:  16 , val loss:  1.5218024600471836e-05\n",
      "fold:  4 , epoch:  17 , val loss:  7.849335815990344e-06\n",
      "fold:  4 , epoch:  18 , val loss:  4.7066663682926446e-05\n",
      "fold:  4 , epoch:  19 , val loss:  6.909030344104394e-05\n",
      "fold:  4 , epoch:  20 , val loss:  1.728278584778309e-05\n",
      "fold:  4 , epoch:  21 , val loss:  2.910493094532285e-05\n",
      "fold:  4 , epoch:  22 , val loss:  2.5255278160329908e-05\n",
      "fold:  4 , epoch:  23 , val loss:  1.4884960364724975e-05\n",
      "fold:  4 , epoch:  24 , val loss:  2.3557711756438948e-05\n",
      "fold:  4 , epoch:  25 , val loss:  3.4627687455213163e-06\n",
      "fold:  5 , epoch:  1 , val loss:  5.0830138206947595e-05\n",
      "fold:  5 , epoch:  2 , val loss:  3.596468013711274e-05\n",
      "fold:  5 , epoch:  3 , val loss:  2.9819959308952093e-05\n",
      "fold:  5 , epoch:  4 , val loss:  8.956208148447331e-06\n",
      "fold:  5 , epoch:  5 , val loss:  1.4296408153313678e-05\n",
      "fold:  5 , epoch:  6 , val loss:  4.9748159653972834e-05\n",
      "fold:  5 , epoch:  7 , val loss:  4.1780299397942144e-06\n",
      "fold:  5 , epoch:  8 , val loss:  4.946226454194402e-06\n",
      "fold:  5 , epoch:  9 , val loss:  2.2702848582412116e-05\n",
      "fold:  5 , epoch:  10 , val loss:  2.490579936420545e-05\n",
      "fold:  5 , epoch:  11 , val loss:  3.983893111580983e-05\n",
      "fold:  5 , epoch:  12 , val loss:  0.00015419773990288377\n",
      "fold:  5 , epoch:  13 , val loss:  1.208221601700643e-05\n",
      "fold:  5 , epoch:  14 , val loss:  1.5157775123952888e-05\n",
      "fold:  5 , epoch:  15 , val loss:  1.1167522643518168e-05\n",
      "fold:  5 , epoch:  16 , val loss:  5.875648639630526e-05\n",
      "fold:  5 , epoch:  17 , val loss:  1.984487971640192e-05\n",
      "fold:  5 , epoch:  18 , val loss:  1.4746107808605302e-05\n",
      "fold:  5 , epoch:  19 , val loss:  4.934533535561059e-06\n",
      "fold:  5 , epoch:  20 , val loss:  6.794258297304623e-06\n",
      "fold:  5 , epoch:  21 , val loss:  9.101976502279285e-06\n",
      "fold:  5 , epoch:  22 , val loss:  3.291860411991365e-05\n",
      "fold:  5 , epoch:  23 , val loss:  1.7859276340459473e-05\n",
      "fold:  5 , epoch:  24 , val loss:  2.368951027165167e-05\n",
      "fold:  5 , epoch:  25 , val loss:  7.721269867033698e-06\n",
      "Model results:  {'hidden_size': 400, 'n_layers': 8, 'act_fun': 'ELU', 'init_methods': 'xavier uniform', 'mean_val_result': 0.00011676082696794765, 'std_val_result': 0.00028168000344494434} \n",
      "\n",
      "Model:  {'hidden_size': 200, 'n_layers': 8, 'act_fun': 'LeakyReLU', 'init_methods': 'xavier normal'}\n",
      "fold:  1 , epoch:  1 , val loss:  0.0009324128041043878\n",
      "fold:  1 , epoch:  2 , val loss:  0.0003778848040383309\n",
      "fold:  1 , epoch:  3 , val loss:  0.00022884903592057526\n",
      "fold:  1 , epoch:  4 , val loss:  0.00016759878781158477\n",
      "fold:  1 , epoch:  5 , val loss:  0.00013238034443929791\n",
      "fold:  1 , epoch:  6 , val loss:  0.00011109928891528398\n",
      "fold:  1 , epoch:  7 , val loss:  9.463531750952825e-05\n",
      "fold:  1 , epoch:  8 , val loss:  9.653780580265447e-05\n",
      "fold:  1 , epoch:  9 , val loss:  7.537732017226517e-05\n",
      "fold:  1 , epoch:  10 , val loss:  7.05041820765473e-05\n",
      "fold:  1 , epoch:  11 , val loss:  0.0001558027433929965\n",
      "fold:  1 , epoch:  12 , val loss:  7.308215572265908e-05\n",
      "fold:  1 , epoch:  13 , val loss:  5.9436337323859334e-05\n",
      "fold:  1 , epoch:  14 , val loss:  5.889699968975037e-05\n",
      "fold:  1 , epoch:  15 , val loss:  8.167310443241149e-05\n",
      "fold:  1 , epoch:  16 , val loss:  5.445291390060447e-05\n",
      "fold:  1 , epoch:  17 , val loss:  5.3299852879717946e-05\n",
      "fold:  1 , epoch:  18 , val loss:  5.370795406633988e-05\n",
      "fold:  1 , epoch:  19 , val loss:  5.2944473281968385e-05\n",
      "fold:  1 , epoch:  20 , val loss:  3.8613437936874107e-05\n",
      "fold:  1 , epoch:  21 , val loss:  0.0001545497652841732\n",
      "fold:  1 , epoch:  22 , val loss:  5.581771983997896e-05\n",
      "fold:  1 , epoch:  23 , val loss:  0.00013721658615395427\n",
      "fold:  1 , epoch:  24 , val loss:  0.0001024825032800436\n",
      "fold:  1 , epoch:  25 , val loss:  0.00011145437747472897\n",
      "fold:  2 , epoch:  1 , val loss:  9.041527664521709e-05\n",
      "fold:  2 , epoch:  2 , val loss:  3.0323340979521163e-05\n",
      "fold:  2 , epoch:  3 , val loss:  2.622521969897207e-05\n",
      "fold:  2 , epoch:  4 , val loss:  0.00018980067397933453\n",
      "fold:  2 , epoch:  5 , val loss:  7.240387640194967e-05\n",
      "fold:  2 , epoch:  6 , val loss:  5.7903333072317764e-05\n",
      "fold:  2 , epoch:  7 , val loss:  5.1286304369568825e-05\n",
      "fold:  2 , epoch:  8 , val loss:  3.3468735637143254e-05\n",
      "fold:  2 , epoch:  9 , val loss:  3.670158184831962e-05\n",
      "fold:  2 , epoch:  10 , val loss:  2.5470983018749394e-05\n",
      "fold:  2 , epoch:  11 , val loss:  2.5724857550812885e-05\n",
      "fold:  2 , epoch:  12 , val loss:  2.1039168132119812e-05\n",
      "fold:  2 , epoch:  13 , val loss:  2.8722392016788945e-05\n",
      "fold:  2 , epoch:  14 , val loss:  2.3794609660399146e-05\n",
      "fold:  2 , epoch:  15 , val loss:  3.4041921026073396e-05\n",
      "fold:  2 , epoch:  16 , val loss:  2.5736469979165122e-05\n",
      "fold:  2 , epoch:  17 , val loss:  2.6668483769753948e-05\n",
      "fold:  2 , epoch:  18 , val loss:  3.0035093004698865e-05\n",
      "fold:  2 , epoch:  19 , val loss:  5.723250433220528e-05\n",
      "fold:  2 , epoch:  20 , val loss:  2.4227541871368885e-05\n",
      "fold:  2 , epoch:  21 , val loss:  3.656607441371307e-05\n",
      "fold:  2 , epoch:  22 , val loss:  1.594523200765252e-05\n",
      "fold:  2 , epoch:  23 , val loss:  6.426671461667866e-05\n",
      "fold:  2 , epoch:  24 , val loss:  4.458645707927644e-05\n",
      "fold:  2 , epoch:  25 , val loss:  2.8288935936870985e-05\n",
      "fold:  3 , epoch:  1 , val loss:  2.1287560230121017e-05\n",
      "fold:  3 , epoch:  2 , val loss:  2.7530699298949912e-05\n",
      "fold:  3 , epoch:  3 , val loss:  0.00010934353485936299\n",
      "fold:  3 , epoch:  4 , val loss:  6.82471800246276e-05\n",
      "fold:  3 , epoch:  5 , val loss:  3.9615799323655665e-05\n",
      "fold:  3 , epoch:  6 , val loss:  2.0928950107190758e-05\n",
      "fold:  3 , epoch:  7 , val loss:  2.9209413696662523e-05\n",
      "fold:  3 , epoch:  8 , val loss:  1.3531708646041807e-05\n",
      "fold:  3 , epoch:  9 , val loss:  1.1505857401061803e-05\n",
      "fold:  3 , epoch:  10 , val loss:  1.8449893104843795e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  3 , epoch:  11 , val loss:  3.146986273350194e-05\n",
      "fold:  3 , epoch:  12 , val loss:  1.4691865544591565e-05\n",
      "fold:  3 , epoch:  13 , val loss:  5.664492346113548e-05\n",
      "fold:  3 , epoch:  14 , val loss:  0.00012884302122984082\n",
      "fold:  3 , epoch:  15 , val loss:  1.2547247933980543e-05\n",
      "fold:  3 , epoch:  16 , val loss:  2.5638193619670346e-05\n",
      "fold:  3 , epoch:  17 , val loss:  1.3617508557217661e-05\n",
      "fold:  3 , epoch:  18 , val loss:  1.1544309018063359e-05\n",
      "fold:  3 , epoch:  19 , val loss:  2.1275562176015228e-05\n",
      "fold:  3 , epoch:  20 , val loss:  1.611373409104999e-05\n",
      "fold:  3 , epoch:  21 , val loss:  1.431594409950776e-05\n",
      "fold:  3 , epoch:  22 , val loss:  1.6287227481370792e-05\n",
      "fold:  3 , epoch:  23 , val loss:  1.4558628208760638e-05\n",
      "fold:  3 , epoch:  24 , val loss:  9.323383892478887e-06\n",
      "fold:  3 , epoch:  25 , val loss:  1.645852353249211e-05\n",
      "fold:  4 , epoch:  1 , val loss:  1.1346380233590025e-05\n",
      "fold:  4 , epoch:  2 , val loss:  9.728254553920124e-06\n",
      "fold:  4 , epoch:  3 , val loss:  8.685330612934195e-06\n",
      "fold:  4 , epoch:  4 , val loss:  1.0402318366686814e-05\n",
      "fold:  4 , epoch:  5 , val loss:  8.922388587961905e-06\n",
      "fold:  4 , epoch:  6 , val loss:  8.539058399037458e-06\n",
      "fold:  4 , epoch:  7 , val loss:  1.1809409443230834e-05\n",
      "fold:  4 , epoch:  8 , val loss:  9.408328878635075e-06\n",
      "fold:  4 , epoch:  9 , val loss:  9.301304999098647e-06\n",
      "fold:  4 , epoch:  10 , val loss:  3.3191234251717106e-05\n",
      "fold:  4 , epoch:  11 , val loss:  1.617212183191441e-05\n",
      "fold:  4 , epoch:  12 , val loss:  9.562333616486285e-06\n",
      "fold:  4 , epoch:  13 , val loss:  0.00012623540533240885\n",
      "fold:  4 , epoch:  14 , val loss:  0.0001154325800598599\n",
      "fold:  4 , epoch:  15 , val loss:  8.821028131933417e-06\n",
      "fold:  4 , epoch:  16 , val loss:  8.356776561413426e-06\n",
      "fold:  4 , epoch:  17 , val loss:  7.496105808968423e-06\n",
      "fold:  4 , epoch:  18 , val loss:  1.0250390005239751e-05\n",
      "fold:  4 , epoch:  19 , val loss:  9.835014679993037e-06\n",
      "fold:  4 , epoch:  20 , val loss:  1.6294843590003438e-05\n",
      "fold:  4 , epoch:  21 , val loss:  8.380116014450323e-06\n",
      "fold:  4 , epoch:  22 , val loss:  2.0431629309314303e-05\n",
      "fold:  4 , epoch:  23 , val loss:  9.302386388299055e-06\n",
      "fold:  4 , epoch:  24 , val loss:  1.8459722923580557e-05\n",
      "fold:  4 , epoch:  25 , val loss:  1.4820291653450113e-05\n",
      "fold:  5 , epoch:  1 , val loss:  0.0001341178285656497\n",
      "fold:  5 , epoch:  2 , val loss:  2.36355081142392e-05\n",
      "fold:  5 , epoch:  3 , val loss:  1.1420452210586518e-05\n",
      "fold:  5 , epoch:  4 , val loss:  1.2060176231898367e-05\n",
      "fold:  5 , epoch:  5 , val loss:  5.452863479149528e-05\n",
      "fold:  5 , epoch:  6 , val loss:  2.5047227609320544e-05\n",
      "fold:  5 , epoch:  7 , val loss:  6.070806193747558e-05\n",
      "fold:  5 , epoch:  8 , val loss:  3.122635098407045e-05\n",
      "fold:  5 , epoch:  9 , val loss:  2.4622517230454832e-05\n",
      "fold:  5 , epoch:  10 , val loss:  1.420186526956968e-05\n",
      "fold:  5 , epoch:  11 , val loss:  1.666699245106429e-05\n",
      "fold:  5 , epoch:  12 , val loss:  2.344579297641758e-05\n",
      "fold:  5 , epoch:  13 , val loss:  1.629033613426145e-05\n",
      "fold:  5 , epoch:  14 , val loss:  1.1716348126356024e-05\n",
      "fold:  5 , epoch:  15 , val loss:  9.808382856135722e-06\n",
      "fold:  5 , epoch:  16 , val loss:  8.974237971415278e-06\n",
      "fold:  5 , epoch:  17 , val loss:  8.086172783805523e-06\n",
      "fold:  5 , epoch:  18 , val loss:  9.38287666940596e-06\n",
      "fold:  5 , epoch:  19 , val loss:  7.656146408407949e-06\n",
      "fold:  5 , epoch:  20 , val loss:  1.0550897968641948e-05\n",
      "fold:  5 , epoch:  21 , val loss:  9.940687959897332e-06\n",
      "fold:  5 , epoch:  22 , val loss:  1.2948457879247144e-05\n",
      "fold:  5 , epoch:  23 , val loss:  2.7221951313549653e-05\n",
      "fold:  5 , epoch:  24 , val loss:  1.8800803445628844e-05\n",
      "fold:  5 , epoch:  25 , val loss:  1.0675990779418498e-05\n",
      "Model results:  {'hidden_size': 200, 'n_layers': 8, 'act_fun': 'LeakyReLU', 'init_methods': 'xavier normal', 'mean_val_result': 5.207589105339139e-05, 'std_val_result': 9.489658926948296e-05} \n",
      "\n",
      "Model:  {'hidden_size': 200, 'n_layers': 4, 'act_fun': 'ELU', 'init_methods': 'xavier normal'}\n",
      "fold:  1 , epoch:  1 , val loss:  0.007863244973123074\n",
      "fold:  1 , epoch:  2 , val loss:  0.0038858240004628897\n",
      "fold:  1 , epoch:  3 , val loss:  0.0023412525188177824\n",
      "fold:  1 , epoch:  4 , val loss:  0.0014619699213653803\n",
      "fold:  1 , epoch:  5 , val loss:  0.0009822824504226446\n",
      "fold:  1 , epoch:  6 , val loss:  0.0007120863301679492\n",
      "fold:  1 , epoch:  7 , val loss:  0.0005425808485597372\n",
      "fold:  1 , epoch:  8 , val loss:  0.0004107468412257731\n",
      "fold:  1 , epoch:  9 , val loss:  0.00033793161856010556\n",
      "fold:  1 , epoch:  10 , val loss:  0.00027785799466073513\n",
      "fold:  1 , epoch:  11 , val loss:  0.00023502096883021295\n",
      "fold:  1 , epoch:  12 , val loss:  0.00020011636661365628\n",
      "fold:  1 , epoch:  13 , val loss:  0.00017434531764592975\n",
      "fold:  1 , epoch:  14 , val loss:  0.00015839436673559248\n",
      "fold:  1 , epoch:  15 , val loss:  0.00015307427383959293\n",
      "fold:  1 , epoch:  16 , val loss:  0.00014936199295334518\n",
      "fold:  1 , epoch:  17 , val loss:  0.00015161404735408723\n",
      "fold:  1 , epoch:  18 , val loss:  0.00012577424058690667\n",
      "fold:  1 , epoch:  19 , val loss:  9.997709275921807e-05\n",
      "fold:  1 , epoch:  20 , val loss:  9.147618402494118e-05\n",
      "fold:  1 , epoch:  21 , val loss:  9.02753890841268e-05\n",
      "fold:  1 , epoch:  22 , val loss:  8.743458602111787e-05\n",
      "fold:  1 , epoch:  23 , val loss:  8.484222053084522e-05\n",
      "fold:  1 , epoch:  24 , val loss:  8.228251681430265e-05\n",
      "fold:  1 , epoch:  25 , val loss:  7.690014172112569e-05\n",
      "fold:  2 , epoch:  1 , val loss:  7.375863788183779e-05\n",
      "fold:  2 , epoch:  2 , val loss:  6.74900074955076e-05\n",
      "fold:  2 , epoch:  3 , val loss:  6.400369602488354e-05\n",
      "fold:  2 , epoch:  4 , val loss:  6.171224231366068e-05\n",
      "fold:  2 , epoch:  5 , val loss:  5.9964615502394736e-05\n",
      "fold:  2 , epoch:  6 , val loss:  5.844248516950756e-05\n",
      "fold:  2 , epoch:  7 , val loss:  5.709029210265726e-05\n",
      "fold:  2 , epoch:  8 , val loss:  5.639400114887394e-05\n",
      "fold:  2 , epoch:  9 , val loss:  5.6736778788035735e-05\n",
      "fold:  2 , epoch:  10 , val loss:  5.763358058175072e-05\n",
      "fold:  2 , epoch:  11 , val loss:  5.843755207024515e-05\n",
      "fold:  2 , epoch:  12 , val loss:  5.8545443607727066e-05\n",
      "fold:  2 , epoch:  13 , val loss:  5.7025514252018183e-05\n",
      "fold:  2 , epoch:  14 , val loss:  5.323282675817609e-05\n",
      "fold:  2 , epoch:  15 , val loss:  4.8432611947646365e-05\n",
      "fold:  2 , epoch:  16 , val loss:  4.4062966480851173e-05\n",
      "fold:  2 , epoch:  17 , val loss:  4.0866761992219836e-05\n",
      "fold:  2 , epoch:  18 , val loss:  3.837015538010746e-05\n",
      "fold:  2 , epoch:  19 , val loss:  3.6095050745643675e-05\n",
      "fold:  2 , epoch:  20 , val loss:  3.4305398003198206e-05\n",
      "fold:  2 , epoch:  21 , val loss:  3.306238795630634e-05\n",
      "fold:  2 , epoch:  22 , val loss:  3.219189966330305e-05\n",
      "fold:  2 , epoch:  23 , val loss:  3.1626372219761834e-05\n",
      "fold:  2 , epoch:  24 , val loss:  3.1441788451047614e-05\n",
      "fold:  2 , epoch:  25 , val loss:  3.1747895263833925e-05\n",
      "fold:  3 , epoch:  1 , val loss:  2.7562389732338488e-05\n",
      "fold:  3 , epoch:  2 , val loss:  2.804635551001411e-05\n",
      "fold:  3 , epoch:  3 , val loss:  2.8478831154643558e-05\n",
      "fold:  3 , epoch:  4 , val loss:  3.0019014957360923e-05\n",
      "fold:  3 , epoch:  5 , val loss:  3.34873293468263e-05\n",
      "fold:  3 , epoch:  6 , val loss:  3.7464498745976016e-05\n",
      "fold:  3 , epoch:  7 , val loss:  4.251916107023135e-05\n",
      "fold:  3 , epoch:  8 , val loss:  4.436245217220858e-05\n",
      "fold:  3 , epoch:  9 , val loss:  4.0906790673034266e-05\n",
      "fold:  3 , epoch:  10 , val loss:  3.278680378571153e-05\n",
      "fold:  3 , epoch:  11 , val loss:  2.9381300919339992e-05\n",
      "fold:  3 , epoch:  12 , val loss:  3.3382097171852365e-05\n",
      "fold:  3 , epoch:  13 , val loss:  2.053409298241604e-05\n",
      "fold:  3 , epoch:  14 , val loss:  5.208360744290985e-05\n",
      "fold:  3 , epoch:  15 , val loss:  5.504594082594849e-05\n",
      "fold:  3 , epoch:  16 , val loss:  2.9343047572183423e-05\n",
      "fold:  3 , epoch:  17 , val loss:  4.7672350774519145e-05\n",
      "fold:  3 , epoch:  18 , val loss:  5.129165583639406e-05\n",
      "fold:  3 , epoch:  19 , val loss:  5.380804213928059e-05\n",
      "fold:  3 , epoch:  20 , val loss:  5.312530629453249e-05\n",
      "fold:  3 , epoch:  21 , val loss:  4.757136048283428e-05\n",
      "fold:  3 , epoch:  22 , val loss:  4.471540523809381e-05\n",
      "fold:  3 , epoch:  23 , val loss:  5.8800465922104195e-05\n",
      "fold:  3 , epoch:  24 , val loss:  4.6146040403982624e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  3 , epoch:  25 , val loss:  4.187091326457448e-05\n",
      "fold:  4 , epoch:  1 , val loss:  3.85563907912001e-05\n",
      "fold:  4 , epoch:  2 , val loss:  4.8259898903779685e-05\n",
      "fold:  4 , epoch:  3 , val loss:  3.580267002689652e-05\n",
      "fold:  4 , epoch:  4 , val loss:  4.7057470510480925e-05\n",
      "fold:  4 , epoch:  5 , val loss:  2.7675498131429777e-05\n",
      "fold:  4 , epoch:  6 , val loss:  3.0850449547870085e-05\n",
      "fold:  4 , epoch:  7 , val loss:  5.180664447834715e-05\n",
      "fold:  4 , epoch:  8 , val loss:  4.343307591625489e-05\n",
      "fold:  4 , epoch:  9 , val loss:  4.856322630075738e-05\n",
      "fold:  4 , epoch:  10 , val loss:  4.093089228263125e-05\n",
      "fold:  4 , epoch:  11 , val loss:  2.479388058418408e-05\n",
      "fold:  4 , epoch:  12 , val loss:  2.6433379389345646e-05\n",
      "fold:  4 , epoch:  13 , val loss:  2.9633980375365354e-05\n",
      "fold:  4 , epoch:  14 , val loss:  4.960068326909095e-05\n",
      "fold:  4 , epoch:  15 , val loss:  2.0436302293092012e-05\n",
      "fold:  4 , epoch:  16 , val loss:  2.3494811102864332e-05\n",
      "fold:  4 , epoch:  17 , val loss:  1.9686860468937084e-05\n",
      "fold:  4 , epoch:  18 , val loss:  2.4104316253215075e-05\n",
      "fold:  4 , epoch:  19 , val loss:  1.886162681330461e-05\n",
      "fold:  4 , epoch:  20 , val loss:  1.5742218238301575e-05\n",
      "fold:  4 , epoch:  21 , val loss:  1.5748470104881562e-05\n",
      "fold:  4 , epoch:  22 , val loss:  3.393113729543984e-05\n",
      "fold:  4 , epoch:  23 , val loss:  3.626401667133905e-05\n",
      "fold:  4 , epoch:  24 , val loss:  3.73465045413468e-05\n",
      "fold:  4 , epoch:  25 , val loss:  2.3351247364189476e-05\n",
      "fold:  5 , epoch:  1 , val loss:  1.1642589925031643e-05\n",
      "fold:  5 , epoch:  2 , val loss:  1.5402860299218446e-05\n",
      "fold:  5 , epoch:  3 , val loss:  1.3305567335919477e-05\n",
      "fold:  5 , epoch:  4 , val loss:  1.0076987564389128e-05\n",
      "fold:  5 , epoch:  5 , val loss:  1.2114828678022604e-05\n",
      "fold:  5 , epoch:  6 , val loss:  2.267707714054268e-05\n",
      "fold:  5 , epoch:  7 , val loss:  1.2259189134056214e-05\n",
      "fold:  5 , epoch:  8 , val loss:  1.4521255252475385e-05\n",
      "fold:  5 , epoch:  9 , val loss:  2.697313357202802e-05\n",
      "fold:  5 , epoch:  10 , val loss:  1.0518943781789858e-05\n",
      "fold:  5 , epoch:  11 , val loss:  2.034334647760261e-05\n",
      "fold:  5 , epoch:  12 , val loss:  2.7087127818958834e-05\n",
      "fold:  5 , epoch:  13 , val loss:  6.319199746940285e-05\n",
      "fold:  5 , epoch:  14 , val loss:  1.413002064509783e-05\n",
      "fold:  5 , epoch:  15 , val loss:  2.9554750653915107e-05\n",
      "fold:  5 , epoch:  16 , val loss:  1.125688140746206e-05\n",
      "fold:  5 , epoch:  17 , val loss:  1.0105200090038124e-05\n",
      "fold:  5 , epoch:  18 , val loss:  1.1093992725363933e-05\n",
      "fold:  5 , epoch:  19 , val loss:  1.5950949091347866e-05\n",
      "fold:  5 , epoch:  20 , val loss:  1.600989344296977e-05\n",
      "fold:  5 , epoch:  21 , val loss:  1.762962892826181e-05\n",
      "fold:  5 , epoch:  22 , val loss:  9.337830306321848e-06\n",
      "fold:  5 , epoch:  23 , val loss:  9.208616575051565e-06\n",
      "fold:  5 , epoch:  24 , val loss:  1.387524935125839e-05\n",
      "fold:  5 , epoch:  25 , val loss:  3.891015876433812e-05\n",
      "Model results:  {'hidden_size': 200, 'n_layers': 4, 'act_fun': 'ELU', 'init_methods': 'xavier normal', 'mean_val_result': 0.0001943942971774959, 'std_val_result': 0.0008118713406348279} \n",
      "\n",
      "Model:  {'hidden_size': 400, 'n_layers': 6, 'act_fun': 'ELU', 'init_methods': 'xavier normal'}\n",
      "fold:  1 , epoch:  1 , val loss:  0.0031333230435848236\n",
      "fold:  1 , epoch:  2 , val loss:  0.0012763908598572016\n",
      "fold:  1 , epoch:  3 , val loss:  0.0007082962547428906\n",
      "fold:  1 , epoch:  4 , val loss:  0.0004846207157243043\n",
      "fold:  1 , epoch:  5 , val loss:  0.000257554289419204\n",
      "fold:  1 , epoch:  6 , val loss:  0.0002656960568856448\n",
      "fold:  1 , epoch:  7 , val loss:  0.00033151800744235516\n",
      "fold:  1 , epoch:  8 , val loss:  0.00027328752912580967\n",
      "fold:  1 , epoch:  9 , val loss:  0.00013377914729062468\n",
      "fold:  1 , epoch:  10 , val loss:  0.00016160013910848647\n",
      "fold:  1 , epoch:  11 , val loss:  0.00015665976388845593\n",
      "fold:  1 , epoch:  12 , val loss:  0.00024274959287140518\n",
      "fold:  1 , epoch:  13 , val loss:  0.00022295894450508058\n",
      "fold:  1 , epoch:  14 , val loss:  8.787595288595185e-05\n",
      "fold:  1 , epoch:  15 , val loss:  0.000271400815108791\n",
      "fold:  1 , epoch:  16 , val loss:  9.446954936720431e-05\n",
      "fold:  1 , epoch:  17 , val loss:  0.00010908805415965617\n",
      "fold:  1 , epoch:  18 , val loss:  0.0001080755828297697\n",
      "fold:  1 , epoch:  19 , val loss:  0.00015761275426484644\n",
      "fold:  1 , epoch:  20 , val loss:  0.0002956572570838034\n",
      "fold:  1 , epoch:  21 , val loss:  0.00023256748681887984\n",
      "fold:  1 , epoch:  22 , val loss:  0.00024205760564655066\n",
      "fold:  1 , epoch:  23 , val loss:  0.0003059488662984222\n",
      "fold:  1 , epoch:  24 , val loss:  0.0001958229549927637\n",
      "fold:  1 , epoch:  25 , val loss:  6.605865200981498e-05\n",
      "fold:  2 , epoch:  1 , val loss:  6.7243876401335e-05\n",
      "fold:  2 , epoch:  2 , val loss:  4.777195499627851e-05\n",
      "fold:  2 , epoch:  3 , val loss:  0.00019849026284646243\n",
      "fold:  2 , epoch:  4 , val loss:  9.971116378437728e-05\n",
      "fold:  2 , epoch:  5 , val loss:  0.00010163353726966307\n",
      "fold:  2 , epoch:  6 , val loss:  9.014346869662404e-05\n",
      "fold:  2 , epoch:  7 , val loss:  7.905088568804786e-05\n",
      "fold:  2 , epoch:  8 , val loss:  5.702950875274837e-05\n",
      "fold:  2 , epoch:  9 , val loss:  4.0925817302195355e-05\n",
      "fold:  2 , epoch:  10 , val loss:  0.0001115140039473772\n",
      "fold:  2 , epoch:  11 , val loss:  0.00021278188796713948\n",
      "fold:  2 , epoch:  12 , val loss:  0.0001016211390378885\n",
      "fold:  2 , epoch:  13 , val loss:  0.00047726783668622375\n",
      "fold:  2 , epoch:  14 , val loss:  0.0001664153824094683\n",
      "fold:  2 , epoch:  15 , val loss:  0.00016052601858973503\n",
      "fold:  2 , epoch:  16 , val loss:  0.00010821974865393713\n",
      "fold:  2 , epoch:  17 , val loss:  6.920705345692113e-05\n",
      "fold:  2 , epoch:  18 , val loss:  0.0007680793642066419\n",
      "fold:  2 , epoch:  19 , val loss:  4.6300399844767526e-05\n",
      "fold:  2 , epoch:  20 , val loss:  4.0343275031773373e-05\n",
      "fold:  2 , epoch:  21 , val loss:  6.714257324347273e-05\n",
      "fold:  2 , epoch:  22 , val loss:  0.00021987163927406073\n",
      "fold:  2 , epoch:  23 , val loss:  7.599145465064794e-05\n",
      "fold:  2 , epoch:  24 , val loss:  0.0001158078302978538\n",
      "fold:  2 , epoch:  25 , val loss:  0.00022070662816986442\n",
      "fold:  3 , epoch:  1 , val loss:  0.0001235388481291011\n",
      "fold:  3 , epoch:  2 , val loss:  4.910137067781761e-05\n",
      "fold:  3 , epoch:  3 , val loss:  0.00012801912089344114\n",
      "fold:  3 , epoch:  4 , val loss:  0.00011579308920772746\n",
      "fold:  3 , epoch:  5 , val loss:  2.7875537853105925e-05\n",
      "fold:  3 , epoch:  6 , val loss:  0.00016652006888762116\n",
      "fold:  3 , epoch:  7 , val loss:  0.00011173301754752174\n",
      "fold:  3 , epoch:  8 , val loss:  3.268521322752349e-05\n",
      "fold:  3 , epoch:  9 , val loss:  4.229299884173088e-05\n",
      "fold:  3 , epoch:  10 , val loss:  9.647809201851487e-05\n",
      "fold:  3 , epoch:  11 , val loss:  0.00010753000242402777\n",
      "fold:  3 , epoch:  12 , val loss:  5.703627903130837e-05\n",
      "fold:  3 , epoch:  13 , val loss:  2.4245169697678648e-05\n",
      "fold:  3 , epoch:  14 , val loss:  5.5167536629596725e-05\n",
      "fold:  3 , epoch:  15 , val loss:  4.44944562332239e-05\n",
      "fold:  3 , epoch:  16 , val loss:  0.00012841324496548623\n",
      "fold:  3 , epoch:  17 , val loss:  4.386455111671239e-05\n",
      "fold:  3 , epoch:  18 , val loss:  3.0867362511344254e-05\n",
      "fold:  3 , epoch:  19 , val loss:  2.0997080355300568e-05\n",
      "fold:  3 , epoch:  20 , val loss:  0.00010859504982363433\n",
      "fold:  3 , epoch:  21 , val loss:  0.00012578167661558837\n",
      "fold:  3 , epoch:  22 , val loss:  4.729622014565393e-05\n",
      "fold:  3 , epoch:  23 , val loss:  8.019207598408684e-05\n",
      "fold:  3 , epoch:  24 , val loss:  1.8199107216787525e-05\n",
      "fold:  3 , epoch:  25 , val loss:  5.069990947959013e-05\n",
      "fold:  4 , epoch:  1 , val loss:  0.0001248871994903311\n",
      "fold:  4 , epoch:  2 , val loss:  2.7401887564337812e-05\n",
      "fold:  4 , epoch:  3 , val loss:  2.9036522391834296e-05\n",
      "fold:  4 , epoch:  4 , val loss:  4.314139732741751e-05\n",
      "fold:  4 , epoch:  5 , val loss:  5.7758690672926605e-05\n",
      "fold:  4 , epoch:  6 , val loss:  1.6003910786821507e-05\n",
      "fold:  4 , epoch:  7 , val loss:  7.136945350794122e-05\n",
      "fold:  4 , epoch:  8 , val loss:  4.2280957131879404e-05\n",
      "fold:  4 , epoch:  9 , val loss:  1.478623289585812e-05\n",
      "fold:  4 , epoch:  10 , val loss:  2.7442811187938787e-05\n",
      "fold:  4 , epoch:  11 , val loss:  3.5972407204099e-05\n",
      "fold:  4 , epoch:  12 , val loss:  2.6140598492929712e-05\n",
      "fold:  4 , epoch:  13 , val loss:  3.277420182712376e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  4 , epoch:  14 , val loss:  5.334925663191825e-05\n",
      "fold:  4 , epoch:  15 , val loss:  1.3055963790975511e-05\n",
      "fold:  4 , epoch:  16 , val loss:  3.177545659127645e-05\n",
      "fold:  4 , epoch:  17 , val loss:  2.1771613319288008e-05\n",
      "fold:  4 , epoch:  18 , val loss:  1.5791856640134938e-05\n",
      "fold:  4 , epoch:  19 , val loss:  1.3307469089340884e-05\n",
      "fold:  4 , epoch:  20 , val loss:  0.00011406256089685485\n",
      "fold:  4 , epoch:  21 , val loss:  4.772954707732424e-05\n",
      "fold:  4 , epoch:  22 , val loss:  8.146541222231463e-05\n",
      "fold:  4 , epoch:  23 , val loss:  6.579519686056301e-05\n",
      "fold:  4 , epoch:  24 , val loss:  2.3045982743497007e-05\n",
      "fold:  4 , epoch:  25 , val loss:  8.44261194288265e-06\n",
      "fold:  5 , epoch:  1 , val loss:  4.1428640543017536e-05\n",
      "fold:  5 , epoch:  2 , val loss:  1.9503420844557695e-05\n",
      "fold:  5 , epoch:  3 , val loss:  9.160751687886659e-06\n",
      "fold:  5 , epoch:  4 , val loss:  1.6469864931423217e-05\n",
      "fold:  5 , epoch:  5 , val loss:  1.878477087302599e-05\n",
      "fold:  5 , epoch:  6 , val loss:  8.87787427927833e-06\n",
      "fold:  5 , epoch:  7 , val loss:  7.738154090475291e-05\n",
      "fold:  5 , epoch:  8 , val loss:  1.7441670934204012e-05\n",
      "fold:  5 , epoch:  9 , val loss:  1.6344018149538897e-05\n",
      "fold:  5 , epoch:  10 , val loss:  7.787871254549827e-06\n",
      "fold:  5 , epoch:  11 , val loss:  2.761711220955476e-05\n",
      "fold:  5 , epoch:  12 , val loss:  2.2061973140807822e-05\n",
      "fold:  5 , epoch:  13 , val loss:  2.2284813894657418e-05\n",
      "fold:  5 , epoch:  14 , val loss:  2.8429782105376944e-05\n",
      "fold:  5 , epoch:  15 , val loss:  1.9574064936023206e-05\n",
      "fold:  5 , epoch:  16 , val loss:  1.715748840069864e-05\n",
      "fold:  5 , epoch:  17 , val loss:  1.5529918528045528e-05\n",
      "fold:  5 , epoch:  18 , val loss:  1.006159891403513e-05\n",
      "fold:  5 , epoch:  19 , val loss:  3.295932037872262e-05\n",
      "fold:  5 , epoch:  20 , val loss:  4.21139775426127e-05\n",
      "fold:  5 , epoch:  21 , val loss:  1.5522888134000823e-05\n",
      "fold:  5 , epoch:  22 , val loss:  1.0842594747373369e-05\n",
      "fold:  5 , epoch:  23 , val loss:  1.4341443602461368e-05\n",
      "fold:  5 , epoch:  24 , val loss:  1.051979143085191e-05\n",
      "fold:  5 , epoch:  25 , val loss:  9.519160812487826e-06\n",
      "Model results:  {'hidden_size': 400, 'n_layers': 6, 'act_fun': 'ELU', 'init_methods': 'xavier normal', 'mean_val_result': 0.000135732713744801, 'std_val_result': 0.00031346399662521545} \n",
      "\n",
      "Model:  {'hidden_size': 200, 'n_layers': 8, 'act_fun': 'ELU', 'init_methods': 'xavier uniform'}\n",
      "fold:  1 , epoch:  1 , val loss:  0.00491265207529068\n",
      "fold:  1 , epoch:  2 , val loss:  0.001673555583693087\n",
      "fold:  1 , epoch:  3 , val loss:  0.0009602448553778231\n",
      "fold:  1 , epoch:  4 , val loss:  0.000543760193977505\n",
      "fold:  1 , epoch:  5 , val loss:  0.0004887265968136489\n",
      "fold:  1 , epoch:  6 , val loss:  0.0004104279796592891\n",
      "fold:  1 , epoch:  7 , val loss:  0.00029963505221530795\n",
      "fold:  1 , epoch:  8 , val loss:  0.0002458430826663971\n",
      "fold:  1 , epoch:  9 , val loss:  0.00023782539938110858\n",
      "fold:  1 , epoch:  10 , val loss:  0.00018106019706465304\n",
      "fold:  1 , epoch:  11 , val loss:  0.0001779732119757682\n",
      "fold:  1 , epoch:  12 , val loss:  0.00015647978580091149\n",
      "fold:  1 , epoch:  13 , val loss:  0.00014971043856348842\n",
      "fold:  1 , epoch:  14 , val loss:  0.00014170569193083793\n",
      "fold:  1 , epoch:  15 , val loss:  0.00011348097905283794\n",
      "fold:  1 , epoch:  16 , val loss:  0.00014506409934256226\n",
      "fold:  1 , epoch:  17 , val loss:  0.0002032326301559806\n",
      "fold:  1 , epoch:  18 , val loss:  0.00012663076631724834\n",
      "fold:  1 , epoch:  19 , val loss:  0.00011442737741163\n",
      "fold:  1 , epoch:  20 , val loss:  9.626876999391243e-05\n",
      "fold:  1 , epoch:  21 , val loss:  8.849953883327544e-05\n",
      "fold:  1 , epoch:  22 , val loss:  6.672468589385971e-05\n",
      "fold:  1 , epoch:  23 , val loss:  8.865343261277303e-05\n",
      "fold:  1 , epoch:  24 , val loss:  0.00011965222074650228\n",
      "fold:  1 , epoch:  25 , val loss:  8.087304013315588e-05\n",
      "fold:  2 , epoch:  1 , val loss:  0.00010250916238874197\n",
      "fold:  2 , epoch:  2 , val loss:  9.460344153922051e-05\n",
      "fold:  2 , epoch:  3 , val loss:  5.403906834544614e-05\n",
      "fold:  2 , epoch:  4 , val loss:  7.652187923667952e-05\n",
      "fold:  2 , epoch:  5 , val loss:  5.478586535900831e-05\n",
      "fold:  2 , epoch:  6 , val loss:  6.221516377991065e-05\n",
      "fold:  2 , epoch:  7 , val loss:  6.308617594186217e-05\n",
      "fold:  2 , epoch:  8 , val loss:  9.032633533934131e-05\n",
      "fold:  2 , epoch:  9 , val loss:  6.584131915587932e-05\n",
      "fold:  2 , epoch:  10 , val loss:  3.681978341774084e-05\n",
      "fold:  2 , epoch:  11 , val loss:  8.812850865069777e-05\n",
      "fold:  2 , epoch:  12 , val loss:  3.646519689937122e-05\n",
      "fold:  2 , epoch:  13 , val loss:  6.800644041504711e-05\n",
      "fold:  2 , epoch:  14 , val loss:  0.0001511048903921619\n",
      "fold:  2 , epoch:  15 , val loss:  0.00010724483581725508\n",
      "fold:  2 , epoch:  16 , val loss:  3.3909753256011754e-05\n",
      "fold:  2 , epoch:  17 , val loss:  6.118608143879101e-05\n",
      "fold:  2 , epoch:  18 , val loss:  0.00013301051512826234\n",
      "fold:  2 , epoch:  19 , val loss:  3.3908727345988154e-05\n",
      "fold:  2 , epoch:  20 , val loss:  5.509502807399258e-05\n",
      "fold:  2 , epoch:  21 , val loss:  8.236798748839647e-05\n",
      "fold:  2 , epoch:  22 , val loss:  2.8142732844571583e-05\n",
      "fold:  2 , epoch:  23 , val loss:  9.477652929490432e-05\n",
      "fold:  2 , epoch:  24 , val loss:  0.00017430767184123397\n",
      "fold:  2 , epoch:  25 , val loss:  5.678477100445889e-05\n",
      "fold:  3 , epoch:  1 , val loss:  4.181555050308816e-05\n",
      "fold:  3 , epoch:  2 , val loss:  3.067331272177398e-05\n",
      "fold:  3 , epoch:  3 , val loss:  1.8196567907580175e-05\n",
      "fold:  3 , epoch:  4 , val loss:  4.695326424553059e-05\n",
      "fold:  3 , epoch:  5 , val loss:  0.0001299556897720322\n",
      "fold:  3 , epoch:  6 , val loss:  3.0691160645801574e-05\n",
      "fold:  3 , epoch:  7 , val loss:  3.954054045607336e-05\n",
      "fold:  3 , epoch:  8 , val loss:  3.199027560185641e-05\n",
      "fold:  3 , epoch:  9 , val loss:  2.4007022147998214e-05\n",
      "fold:  3 , epoch:  10 , val loss:  5.2617862820625305e-05\n",
      "fold:  3 , epoch:  11 , val loss:  1.6155225239344873e-05\n",
      "fold:  3 , epoch:  12 , val loss:  2.1092233509989455e-05\n",
      "fold:  3 , epoch:  13 , val loss:  4.2887066229013726e-05\n",
      "fold:  3 , epoch:  14 , val loss:  5.308857362251729e-05\n",
      "fold:  3 , epoch:  15 , val loss:  2.9516038921428844e-05\n",
      "fold:  3 , epoch:  16 , val loss:  3.236506745452061e-05\n",
      "fold:  3 , epoch:  17 , val loss:  2.521801980037708e-05\n",
      "fold:  3 , epoch:  18 , val loss:  4.1467308619758114e-05\n",
      "fold:  3 , epoch:  19 , val loss:  2.678051714610774e-05\n",
      "fold:  3 , epoch:  20 , val loss:  2.6915291527984664e-05\n",
      "fold:  3 , epoch:  21 , val loss:  1.117401825467823e-05\n",
      "fold:  3 , epoch:  22 , val loss:  3.739299063454382e-05\n",
      "fold:  3 , epoch:  23 , val loss:  1.6958572814473882e-05\n",
      "fold:  3 , epoch:  24 , val loss:  1.2638374755624682e-05\n",
      "fold:  3 , epoch:  25 , val loss:  3.869121064781211e-05\n",
      "fold:  4 , epoch:  1 , val loss:  8.758626790950075e-06\n",
      "fold:  4 , epoch:  2 , val loss:  9.546388355374802e-06\n",
      "fold:  4 , epoch:  3 , val loss:  2.2495034500025213e-05\n",
      "fold:  4 , epoch:  4 , val loss:  4.118085416848771e-05\n",
      "fold:  4 , epoch:  5 , val loss:  1.250627883564448e-05\n",
      "fold:  4 , epoch:  6 , val loss:  1.5145461475185584e-05\n",
      "fold:  4 , epoch:  7 , val loss:  1.2364926078589633e-05\n",
      "fold:  4 , epoch:  8 , val loss:  1.757982863637153e-05\n",
      "fold:  4 , epoch:  9 , val loss:  1.5202029317151755e-05\n",
      "fold:  4 , epoch:  10 , val loss:  8.572218575864099e-06\n",
      "fold:  4 , epoch:  11 , val loss:  3.5897610359825194e-05\n",
      "fold:  4 , epoch:  12 , val loss:  1.7023714462993667e-05\n",
      "fold:  4 , epoch:  13 , val loss:  6.783049229852622e-06\n",
      "fold:  4 , epoch:  14 , val loss:  1.0604554518067744e-05\n",
      "fold:  4 , epoch:  15 , val loss:  1.2112593140045647e-05\n",
      "fold:  4 , epoch:  16 , val loss:  3.9328428101725876e-05\n",
      "fold:  4 , epoch:  17 , val loss:  2.5757453840924427e-05\n",
      "fold:  4 , epoch:  18 , val loss:  1.0474784176039975e-05\n",
      "fold:  4 , epoch:  19 , val loss:  1.223451727128122e-05\n",
      "fold:  4 , epoch:  20 , val loss:  2.8264097636565566e-05\n",
      "fold:  4 , epoch:  21 , val loss:  2.4535562261007726e-05\n",
      "fold:  4 , epoch:  22 , val loss:  9.177487299893983e-06\n",
      "fold:  4 , epoch:  23 , val loss:  1.0877864951908123e-05\n",
      "fold:  4 , epoch:  24 , val loss:  5.337146376405144e-06\n",
      "fold:  4 , epoch:  25 , val loss:  7.24777637515217e-05\n",
      "fold:  5 , epoch:  1 , val loss:  1.1791818906203844e-05\n",
      "fold:  5 , epoch:  2 , val loss:  9.187692739942577e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  5 , epoch:  3 , val loss:  1.3437806046567857e-05\n",
      "fold:  5 , epoch:  4 , val loss:  5.999774657539092e-06\n",
      "fold:  5 , epoch:  5 , val loss:  6.815914275648538e-06\n",
      "fold:  5 , epoch:  6 , val loss:  2.0813336959690787e-05\n",
      "fold:  5 , epoch:  7 , val loss:  1.04509426819277e-05\n",
      "fold:  5 , epoch:  8 , val loss:  6.6681118369160686e-06\n",
      "fold:  5 , epoch:  9 , val loss:  5.583111033047317e-06\n",
      "fold:  5 , epoch:  10 , val loss:  9.3320086307358e-05\n",
      "fold:  5 , epoch:  11 , val loss:  6.388183464878239e-06\n",
      "fold:  5 , epoch:  12 , val loss:  8.890546268958133e-06\n",
      "fold:  5 , epoch:  13 , val loss:  6.518696409330005e-06\n",
      "fold:  5 , epoch:  14 , val loss:  5.4360829381039366e-05\n",
      "fold:  5 , epoch:  15 , val loss:  8.393461939704139e-06\n",
      "fold:  5 , epoch:  16 , val loss:  8.440250894636847e-06\n",
      "fold:  5 , epoch:  17 , val loss:  8.241205250669736e-06\n",
      "fold:  5 , epoch:  18 , val loss:  1.7108835891122e-05\n",
      "fold:  5 , epoch:  19 , val loss:  4.7179546527331695e-06\n",
      "fold:  5 , epoch:  20 , val loss:  8.767397048359271e-06\n",
      "fold:  5 , epoch:  21 , val loss:  0.00019002510816790164\n",
      "fold:  5 , epoch:  22 , val loss:  5.936673460382735e-06\n",
      "fold:  5 , epoch:  23 , val loss:  2.6675417757360265e-05\n",
      "fold:  5 , epoch:  24 , val loss:  7.97136908659013e-06\n",
      "fold:  5 , epoch:  25 , val loss:  3.7727750168414786e-05\n",
      "Model results:  {'hidden_size': 200, 'n_layers': 8, 'act_fun': 'ELU', 'init_methods': 'xavier uniform', 'mean_val_result': 0.00012540438283758704, 'std_val_result': 0.00046797559569111935} \n",
      "\n",
      "Model:  {'hidden_size': 600, 'n_layers': 6, 'act_fun': 'ELU', 'init_methods': 'xavier uniform'}\n",
      "fold:  1 , epoch:  1 , val loss:  0.0019816989079117775\n",
      "fold:  1 , epoch:  2 , val loss:  0.000734892615582794\n",
      "fold:  1 , epoch:  3 , val loss:  0.0006830439087934792\n",
      "fold:  1 , epoch:  4 , val loss:  0.0006107063964009285\n",
      "fold:  1 , epoch:  5 , val loss:  0.0003011602093465626\n",
      "fold:  1 , epoch:  6 , val loss:  0.0003511212707962841\n",
      "fold:  1 , epoch:  7 , val loss:  0.0002504447475075722\n",
      "fold:  1 , epoch:  8 , val loss:  0.0002168326755054295\n",
      "fold:  1 , epoch:  9 , val loss:  0.0003127162635792047\n",
      "fold:  1 , epoch:  10 , val loss:  0.00014860233932267874\n",
      "fold:  1 , epoch:  11 , val loss:  9.515750571154058e-05\n",
      "fold:  1 , epoch:  12 , val loss:  0.00014108522736933082\n",
      "fold:  1 , epoch:  13 , val loss:  8.125470048980787e-05\n",
      "fold:  1 , epoch:  14 , val loss:  0.0002082864666590467\n",
      "fold:  1 , epoch:  15 , val loss:  6.581303750863299e-05\n",
      "fold:  1 , epoch:  16 , val loss:  0.0002431781031191349\n",
      "fold:  1 , epoch:  17 , val loss:  0.00016246939776465297\n",
      "fold:  1 , epoch:  18 , val loss:  0.00012248738494236022\n",
      "fold:  1 , epoch:  19 , val loss:  0.000156008914927952\n",
      "fold:  1 , epoch:  20 , val loss:  0.00011842237290693447\n",
      "fold:  1 , epoch:  21 , val loss:  0.00012124053318984807\n",
      "fold:  1 , epoch:  22 , val loss:  0.00021893363737035543\n",
      "fold:  1 , epoch:  23 , val loss:  3.690652738441713e-05\n",
      "fold:  1 , epoch:  24 , val loss:  7.375986751867458e-05\n",
      "fold:  1 , epoch:  25 , val loss:  7.683665171498433e-05\n",
      "fold:  2 , epoch:  1 , val loss:  9.670697181718424e-05\n",
      "fold:  2 , epoch:  2 , val loss:  0.0004436261369846761\n",
      "fold:  2 , epoch:  3 , val loss:  2.6376643290859647e-05\n",
      "fold:  2 , epoch:  4 , val loss:  0.00016096819308586419\n",
      "fold:  2 , epoch:  5 , val loss:  3.995498627773486e-05\n",
      "fold:  2 , epoch:  6 , val loss:  2.2786551198805682e-05\n",
      "fold:  2 , epoch:  7 , val loss:  2.8135253160144202e-05\n",
      "fold:  2 , epoch:  8 , val loss:  0.00011907720909221098\n",
      "fold:  2 , epoch:  9 , val loss:  9.996661538025364e-05\n",
      "fold:  2 , epoch:  10 , val loss:  3.991293488070369e-05\n",
      "fold:  2 , epoch:  11 , val loss:  0.0001434527221135795\n",
      "fold:  2 , epoch:  12 , val loss:  0.00021117087453603745\n",
      "fold:  2 , epoch:  13 , val loss:  1.954060462594498e-05\n",
      "fold:  2 , epoch:  14 , val loss:  2.6719109882833436e-05\n",
      "fold:  2 , epoch:  15 , val loss:  6.950300303287804e-05\n",
      "fold:  2 , epoch:  16 , val loss:  4.8983132728608325e-05\n",
      "fold:  2 , epoch:  17 , val loss:  4.827031079912558e-05\n",
      "fold:  2 , epoch:  18 , val loss:  1.8769915186567232e-05\n",
      "fold:  2 , epoch:  19 , val loss:  4.041754800709896e-05\n",
      "fold:  2 , epoch:  20 , val loss:  2.4529586880817078e-05\n",
      "fold:  2 , epoch:  21 , val loss:  1.854258334788028e-05\n",
      "fold:  2 , epoch:  22 , val loss:  1.6661033441778272e-05\n",
      "fold:  2 , epoch:  23 , val loss:  4.572285251924768e-05\n",
      "fold:  2 , epoch:  24 , val loss:  9.253614553017542e-05\n",
      "fold:  2 , epoch:  25 , val loss:  1.6837282601045445e-05\n",
      "fold:  3 , epoch:  1 , val loss:  2.0089379177079536e-05\n",
      "fold:  3 , epoch:  2 , val loss:  8.513377906638198e-06\n",
      "fold:  3 , epoch:  3 , val loss:  9.913428584695794e-06\n",
      "fold:  3 , epoch:  4 , val loss:  1.583525227033533e-05\n",
      "fold:  3 , epoch:  5 , val loss:  1.3783109352516476e-05\n",
      "fold:  3 , epoch:  6 , val loss:  3.757830927497707e-05\n",
      "fold:  3 , epoch:  7 , val loss:  2.213487823610194e-05\n",
      "fold:  3 , epoch:  8 , val loss:  1.5043811799841933e-05\n",
      "fold:  3 , epoch:  9 , val loss:  1.9324694221722893e-05\n",
      "fold:  3 , epoch:  10 , val loss:  1.5008337868493982e-05\n",
      "fold:  3 , epoch:  11 , val loss:  8.47704905027058e-06\n",
      "fold:  3 , epoch:  12 , val loss:  6.188558472786099e-06\n",
      "fold:  3 , epoch:  13 , val loss:  6.662426130787935e-06\n",
      "fold:  3 , epoch:  14 , val loss:  9.385292287333868e-06\n",
      "fold:  3 , epoch:  15 , val loss:  6.854452294646762e-06\n",
      "fold:  3 , epoch:  16 , val loss:  1.9090008208877407e-05\n",
      "fold:  3 , epoch:  17 , val loss:  5.378217792895157e-06\n",
      "fold:  3 , epoch:  18 , val loss:  7.194774752861122e-06\n",
      "fold:  3 , epoch:  19 , val loss:  4.4816195440944284e-05\n",
      "fold:  3 , epoch:  20 , val loss:  1.9591880118241534e-05\n",
      "fold:  3 , epoch:  21 , val loss:  0.00014361900684889406\n",
      "fold:  3 , epoch:  22 , val loss:  1.9015571524505503e-05\n",
      "fold:  3 , epoch:  23 , val loss:  0.00012112976401112974\n",
      "fold:  3 , epoch:  24 , val loss:  5.5637527111684904e-05\n",
      "fold:  3 , epoch:  25 , val loss:  1.7676909919828176e-05\n",
      "fold:  4 , epoch:  1 , val loss:  2.4502505766577087e-05\n",
      "fold:  4 , epoch:  2 , val loss:  6.300456789176678e-06\n",
      "fold:  4 , epoch:  3 , val loss:  2.6342429919168353e-05\n",
      "fold:  4 , epoch:  4 , val loss:  1.6847754523041658e-05\n",
      "fold:  4 , epoch:  5 , val loss:  1.2546140169433784e-05\n",
      "fold:  4 , epoch:  6 , val loss:  8.61343287397176e-05\n",
      "fold:  4 , epoch:  7 , val loss:  2.9387103495537303e-05\n",
      "fold:  4 , epoch:  8 , val loss:  3.57155004166998e-05\n",
      "fold:  4 , epoch:  9 , val loss:  0.00011592450027819723\n",
      "fold:  4 , epoch:  10 , val loss:  2.702506935747806e-05\n",
      "fold:  4 , epoch:  11 , val loss:  5.782210337201832e-06\n",
      "fold:  4 , epoch:  12 , val loss:  0.00011928171443287283\n",
      "fold:  4 , epoch:  13 , val loss:  5.426114148576744e-05\n",
      "fold:  4 , epoch:  14 , val loss:  1.050510400091298e-05\n",
      "fold:  4 , epoch:  15 , val loss:  1.4783719961997122e-05\n",
      "fold:  4 , epoch:  16 , val loss:  4.514693500823341e-06\n",
      "fold:  4 , epoch:  17 , val loss:  3.727768489625305e-05\n",
      "fold:  4 , epoch:  18 , val loss:  1.5632211216143332e-05\n",
      "fold:  4 , epoch:  19 , val loss:  1.2015452739433385e-05\n",
      "fold:  4 , epoch:  20 , val loss:  7.4062922976736445e-06\n",
      "fold:  4 , epoch:  21 , val loss:  9.721443348098546e-06\n",
      "fold:  4 , epoch:  22 , val loss:  3.6670764529844746e-05\n",
      "fold:  4 , epoch:  23 , val loss:  4.539770998235326e-06\n",
      "fold:  4 , epoch:  24 , val loss:  1.8720109437708743e-05\n",
      "fold:  4 , epoch:  25 , val loss:  3.904931872966699e-05\n",
      "fold:  5 , epoch:  1 , val loss:  1.1849541806441266e-05\n",
      "fold:  5 , epoch:  2 , val loss:  7.905323400336783e-06\n",
      "fold:  5 , epoch:  3 , val loss:  6.357571237458615e-06\n",
      "fold:  5 , epoch:  4 , val loss:  1.7772326827980578e-05\n",
      "fold:  5 , epoch:  5 , val loss:  7.026341791060986e-06\n",
      "fold:  5 , epoch:  6 , val loss:  8.556945431337226e-06\n",
      "fold:  5 , epoch:  7 , val loss:  3.5588898299465654e-06\n",
      "fold:  5 , epoch:  8 , val loss:  2.8303156796027906e-06\n",
      "fold:  5 , epoch:  9 , val loss:  4.377621280582389e-06\n",
      "fold:  5 , epoch:  10 , val loss:  2.351478542550467e-06\n",
      "fold:  5 , epoch:  11 , val loss:  3.309804242235259e-06\n",
      "fold:  5 , epoch:  12 , val loss:  8.311982128361706e-06\n",
      "fold:  5 , epoch:  13 , val loss:  0.00016446117660962045\n",
      "fold:  5 , epoch:  14 , val loss:  5.202274405746721e-05\n",
      "fold:  5 , epoch:  15 , val loss:  1.4668864423583727e-05\n",
      "fold:  5 , epoch:  16 , val loss:  3.516891592880711e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  5 , epoch:  17 , val loss:  4.8409343435196206e-05\n",
      "fold:  5 , epoch:  18 , val loss:  2.7483396479510702e-05\n",
      "fold:  5 , epoch:  19 , val loss:  4.6788868530711625e-06\n",
      "fold:  5 , epoch:  20 , val loss:  4.404319952300284e-06\n",
      "fold:  5 , epoch:  21 , val loss:  5.827518634760054e-06\n",
      "fold:  5 , epoch:  22 , val loss:  4.20197920902865e-06\n",
      "fold:  5 , epoch:  23 , val loss:  2.9480603188858368e-05\n",
      "fold:  5 , epoch:  24 , val loss:  4.2083620428456925e-06\n",
      "fold:  5 , epoch:  25 , val loss:  3.571508204913698e-05\n",
      "Model results:  {'hidden_size': 600, 'n_layers': 6, 'act_fun': 'ELU', 'init_methods': 'xavier uniform', 'mean_val_result': 9.108797466251417e-05, 'std_val_result': 0.000209640278954211} \n",
      "\n",
      "Model:  {'hidden_size': 400, 'n_layers': 4, 'act_fun': 'LeakyReLU', 'init_methods': 'xavier uniform'}\n",
      "fold:  1 , epoch:  1 , val loss:  0.000314035831252113\n",
      "fold:  1 , epoch:  2 , val loss:  0.00013095929170958698\n",
      "fold:  1 , epoch:  3 , val loss:  0.00011370726133463904\n",
      "fold:  1 , epoch:  4 , val loss:  6.0942107666051015e-05\n",
      "fold:  1 , epoch:  5 , val loss:  8.077372331172228e-05\n",
      "fold:  1 , epoch:  6 , val loss:  0.00012493866961449385\n",
      "fold:  1 , epoch:  7 , val loss:  0.00011407771671656519\n",
      "fold:  1 , epoch:  8 , val loss:  0.00010736980038927868\n",
      "fold:  1 , epoch:  9 , val loss:  0.00010183320409851149\n",
      "fold:  1 , epoch:  10 , val loss:  8.375083416467533e-05\n",
      "fold:  1 , epoch:  11 , val loss:  3.528372326400131e-05\n",
      "fold:  1 , epoch:  12 , val loss:  2.72017641691491e-05\n",
      "fold:  1 , epoch:  13 , val loss:  2.2002863261150196e-05\n",
      "fold:  1 , epoch:  14 , val loss:  2.026142828981392e-05\n",
      "fold:  1 , epoch:  15 , val loss:  5.9268502809572965e-05\n",
      "fold:  1 , epoch:  16 , val loss:  2.600040170364082e-05\n",
      "fold:  1 , epoch:  17 , val loss:  1.8070153601001948e-05\n",
      "fold:  1 , epoch:  18 , val loss:  9.598283213563263e-05\n",
      "fold:  1 , epoch:  19 , val loss:  3.267746797064319e-05\n",
      "fold:  1 , epoch:  20 , val loss:  2.228900666523259e-05\n",
      "fold:  1 , epoch:  21 , val loss:  1.3941376892034896e-05\n",
      "fold:  1 , epoch:  22 , val loss:  1.7011085219564848e-05\n",
      "fold:  1 , epoch:  23 , val loss:  1.6265887097688392e-05\n",
      "fold:  1 , epoch:  24 , val loss:  1.2150262591603678e-05\n",
      "fold:  1 , epoch:  25 , val loss:  2.6093295673490502e-05\n",
      "fold:  2 , epoch:  1 , val loss:  1.8392523998045363e-05\n",
      "fold:  2 , epoch:  2 , val loss:  3.203331652912311e-05\n",
      "fold:  2 , epoch:  3 , val loss:  1.3277736798045225e-05\n",
      "fold:  2 , epoch:  4 , val loss:  1.1360132702975534e-05\n",
      "fold:  2 , epoch:  5 , val loss:  2.6683132091420703e-05\n",
      "fold:  2 , epoch:  6 , val loss:  1.857915958680678e-05\n",
      "fold:  2 , epoch:  7 , val loss:  9.569739631842822e-06\n",
      "fold:  2 , epoch:  8 , val loss:  8.909639291232452e-06\n",
      "fold:  2 , epoch:  9 , val loss:  2.9081740649417043e-05\n",
      "fold:  2 , epoch:  10 , val loss:  9.716821296024136e-06\n",
      "fold:  2 , epoch:  11 , val loss:  1.1209965123271104e-05\n",
      "fold:  2 , epoch:  12 , val loss:  1.4183835446601734e-05\n",
      "fold:  2 , epoch:  13 , val loss:  2.056547782558482e-05\n",
      "fold:  2 , epoch:  14 , val loss:  3.736587314051576e-05\n",
      "fold:  2 , epoch:  15 , val loss:  6.385754386428744e-05\n",
      "fold:  2 , epoch:  16 , val loss:  1.9782277377089486e-05\n",
      "fold:  2 , epoch:  17 , val loss:  1.425596474291524e-05\n",
      "fold:  2 , epoch:  18 , val loss:  1.440621963411104e-05\n",
      "fold:  2 , epoch:  19 , val loss:  2.9956594516988844e-05\n",
      "fold:  2 , epoch:  20 , val loss:  7.771093805786222e-06\n",
      "fold:  2 , epoch:  21 , val loss:  5.8440193242859095e-05\n",
      "fold:  2 , epoch:  22 , val loss:  8.992625225801021e-06\n",
      "fold:  2 , epoch:  23 , val loss:  2.0787587345694192e-05\n",
      "fold:  2 , epoch:  24 , val loss:  1.734221586957574e-05\n",
      "fold:  2 , epoch:  25 , val loss:  9.609499102225527e-06\n",
      "fold:  3 , epoch:  1 , val loss:  1.3325869986147154e-05\n",
      "fold:  3 , epoch:  2 , val loss:  1.4606037439079955e-05\n",
      "fold:  3 , epoch:  3 , val loss:  1.0672613825590815e-05\n",
      "fold:  3 , epoch:  4 , val loss:  1.2363427231321111e-05\n",
      "fold:  3 , epoch:  5 , val loss:  4.123795224586502e-05\n",
      "fold:  3 , epoch:  6 , val loss:  7.111975264706416e-06\n",
      "fold:  3 , epoch:  7 , val loss:  5.869567030458711e-05\n",
      "fold:  3 , epoch:  8 , val loss:  1.4939041648176499e-05\n",
      "fold:  3 , epoch:  9 , val loss:  4.99204043080681e-06\n",
      "fold:  3 , epoch:  10 , val loss:  1.1400232324376702e-05\n",
      "fold:  3 , epoch:  11 , val loss:  5.282812253426528e-06\n",
      "fold:  3 , epoch:  12 , val loss:  5.068131940788589e-06\n",
      "fold:  3 , epoch:  13 , val loss:  8.28738666314166e-06\n",
      "fold:  3 , epoch:  14 , val loss:  1.8222206563223153e-05\n",
      "fold:  3 , epoch:  15 , val loss:  1.568059451528825e-05\n",
      "fold:  3 , epoch:  16 , val loss:  1.1562904546735808e-05\n",
      "fold:  3 , epoch:  17 , val loss:  6.364647106238408e-06\n",
      "fold:  3 , epoch:  18 , val loss:  8.107399480650201e-06\n",
      "fold:  3 , epoch:  19 , val loss:  1.8218283003079705e-05\n",
      "fold:  3 , epoch:  20 , val loss:  1.0288891644449905e-05\n",
      "fold:  3 , epoch:  21 , val loss:  7.655942681594752e-06\n",
      "fold:  3 , epoch:  22 , val loss:  6.392943305399967e-06\n",
      "fold:  3 , epoch:  23 , val loss:  8.675133358337916e-06\n",
      "fold:  3 , epoch:  24 , val loss:  1.2151249393355101e-05\n",
      "fold:  3 , epoch:  25 , val loss:  8.783799785305746e-06\n",
      "fold:  4 , epoch:  1 , val loss:  6.072710220905719e-06\n",
      "fold:  4 , epoch:  2 , val loss:  2.4200013285735622e-05\n",
      "fold:  4 , epoch:  3 , val loss:  4.040794920001645e-06\n",
      "fold:  4 , epoch:  4 , val loss:  9.058345312951133e-06\n",
      "fold:  4 , epoch:  5 , val loss:  6.007146112096962e-06\n",
      "fold:  4 , epoch:  6 , val loss:  5.651801075146068e-06\n",
      "fold:  4 , epoch:  7 , val loss:  4.925557732349262e-06\n",
      "fold:  4 , epoch:  8 , val loss:  4.175050435151206e-06\n",
      "fold:  4 , epoch:  9 , val loss:  6.789273356844205e-06\n",
      "fold:  4 , epoch:  10 , val loss:  7.5146845119888894e-06\n",
      "fold:  4 , epoch:  11 , val loss:  2.0616014808183536e-05\n",
      "fold:  4 , epoch:  12 , val loss:  2.965171188407112e-05\n",
      "fold:  4 , epoch:  13 , val loss:  2.6876397896558046e-05\n",
      "fold:  4 , epoch:  14 , val loss:  1.1550564522622153e-05\n",
      "fold:  4 , epoch:  15 , val loss:  1.2518689800344873e-05\n",
      "fold:  4 , epoch:  16 , val loss:  5.100403086544247e-06\n",
      "fold:  4 , epoch:  17 , val loss:  1.3191167454351671e-05\n",
      "fold:  4 , epoch:  18 , val loss:  5.789247097709449e-06\n",
      "fold:  4 , epoch:  19 , val loss:  3.84285021937103e-06\n",
      "fold:  4 , epoch:  20 , val loss:  1.0753602509794291e-05\n",
      "fold:  4 , epoch:  21 , val loss:  8.38423875393346e-06\n",
      "fold:  4 , epoch:  22 , val loss:  2.330085771973245e-05\n",
      "fold:  4 , epoch:  23 , val loss:  1.7057069271686487e-05\n",
      "fold:  4 , epoch:  24 , val loss:  1.0872679013118614e-05\n",
      "fold:  4 , epoch:  25 , val loss:  4.310318217903841e-06\n",
      "fold:  5 , epoch:  1 , val loss:  2.0627361664082855e-05\n",
      "fold:  5 , epoch:  2 , val loss:  2.9632933546963613e-06\n",
      "fold:  5 , epoch:  3 , val loss:  8.024501767067704e-06\n",
      "fold:  5 , epoch:  4 , val loss:  9.90541866485728e-06\n",
      "fold:  5 , epoch:  5 , val loss:  4.225479642627761e-06\n",
      "fold:  5 , epoch:  6 , val loss:  3.1348163247457705e-06\n",
      "fold:  5 , epoch:  7 , val loss:  3.6870969779556617e-06\n",
      "fold:  5 , epoch:  8 , val loss:  6.211188065208262e-06\n",
      "fold:  5 , epoch:  9 , val loss:  2.795495220198063e-06\n",
      "fold:  5 , epoch:  10 , val loss:  9.873183444142342e-06\n",
      "fold:  5 , epoch:  11 , val loss:  3.699527496792143e-06\n",
      "fold:  5 , epoch:  12 , val loss:  4.341874955571257e-06\n",
      "fold:  5 , epoch:  13 , val loss:  9.136024345934857e-06\n",
      "fold:  5 , epoch:  14 , val loss:  3.2894670312089147e-06\n",
      "fold:  5 , epoch:  15 , val loss:  4.0383361010754015e-06\n",
      "fold:  5 , epoch:  16 , val loss:  1.234213777934201e-05\n",
      "fold:  5 , epoch:  17 , val loss:  4.2730839595606085e-06\n",
      "fold:  5 , epoch:  18 , val loss:  2.725000058489968e-06\n",
      "fold:  5 , epoch:  19 , val loss:  6.5814288063847926e-06\n",
      "fold:  5 , epoch:  20 , val loss:  5.704986051568994e-06\n",
      "fold:  5 , epoch:  21 , val loss:  3.4507274904171936e-06\n",
      "fold:  5 , epoch:  22 , val loss:  2.5456170078541618e-06\n",
      "fold:  5 , epoch:  23 , val loss:  1.0552592357271351e-05\n",
      "fold:  5 , epoch:  24 , val loss:  8.36204162624199e-06\n",
      "fold:  5 , epoch:  25 , val loss:  3.45576586369134e-06\n",
      "Model results:  {'hidden_size': 400, 'n_layers': 4, 'act_fun': 'LeakyReLU', 'init_methods': 'xavier uniform', 'mean_val_result': 2.3850433781262836e-05, 'std_val_result': 3.745011905537972e-05} \n",
      "\n",
      "Model:  {'hidden_size': 600, 'n_layers': 8, 'act_fun': 'ELU', 'init_methods': 'xavier uniform'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  1 , epoch:  1 , val loss:  0.0021956481505185366\n",
      "fold:  1 , epoch:  2 , val loss:  0.0007669304613955319\n",
      "fold:  1 , epoch:  3 , val loss:  0.0011890748282894492\n",
      "fold:  1 , epoch:  4 , val loss:  0.0012491738889366388\n",
      "fold:  1 , epoch:  5 , val loss:  0.0005461494438350201\n",
      "fold:  1 , epoch:  6 , val loss:  0.00019976316252723336\n",
      "fold:  1 , epoch:  7 , val loss:  0.0009781289845705032\n",
      "fold:  1 , epoch:  8 , val loss:  0.0001903671509353444\n",
      "fold:  1 , epoch:  9 , val loss:  0.0001526595588074997\n",
      "fold:  1 , epoch:  10 , val loss:  0.0002948542241938412\n",
      "fold:  1 , epoch:  11 , val loss:  0.0001709515490802005\n",
      "fold:  1 , epoch:  12 , val loss:  0.00010046294482890517\n",
      "fold:  1 , epoch:  13 , val loss:  0.00036627304507419467\n",
      "fold:  1 , epoch:  14 , val loss:  0.00012706322013400495\n",
      "fold:  1 , epoch:  15 , val loss:  0.00014690094394609332\n",
      "fold:  1 , epoch:  16 , val loss:  0.0004330354568082839\n",
      "fold:  1 , epoch:  17 , val loss:  0.0006296837236732244\n",
      "fold:  1 , epoch:  18 , val loss:  0.0001613582280697301\n",
      "fold:  1 , epoch:  19 , val loss:  5.3923442465020344e-05\n",
      "fold:  1 , epoch:  20 , val loss:  9.252114250557497e-05\n",
      "fold:  1 , epoch:  21 , val loss:  9.04309781617485e-05\n",
      "fold:  1 , epoch:  22 , val loss:  0.0004551599267870188\n",
      "fold:  1 , epoch:  23 , val loss:  8.709204121259972e-05\n",
      "fold:  1 , epoch:  24 , val loss:  3.011995431734249e-05\n",
      "fold:  1 , epoch:  25 , val loss:  4.811486724065617e-05\n",
      "fold:  2 , epoch:  1 , val loss:  0.0001856171147665009\n",
      "fold:  2 , epoch:  2 , val loss:  8.14145605545491e-05\n",
      "fold:  2 , epoch:  3 , val loss:  3.6305438698036596e-05\n",
      "fold:  2 , epoch:  4 , val loss:  2.396121089986991e-05\n",
      "fold:  2 , epoch:  5 , val loss:  0.00021647123503498733\n",
      "fold:  2 , epoch:  6 , val loss:  0.00023231576778925955\n",
      "fold:  2 , epoch:  7 , val loss:  0.00012704686378128827\n",
      "fold:  2 , epoch:  8 , val loss:  0.00022138796339277178\n",
      "fold:  2 , epoch:  9 , val loss:  2.6778750907396898e-05\n",
      "fold:  2 , epoch:  10 , val loss:  0.00013776522246189415\n",
      "fold:  2 , epoch:  11 , val loss:  6.361856503644958e-05\n",
      "fold:  2 , epoch:  12 , val loss:  4.9488407967146486e-05\n",
      "fold:  2 , epoch:  13 , val loss:  0.00014958919200580567\n",
      "fold:  2 , epoch:  14 , val loss:  1.6356385458493605e-05\n",
      "fold:  2 , epoch:  15 , val loss:  1.3989132639835589e-05\n",
      "fold:  2 , epoch:  16 , val loss:  0.0002467371814418584\n",
      "fold:  2 , epoch:  17 , val loss:  4.84552001580596e-05\n",
      "fold:  2 , epoch:  18 , val loss:  1.2466276530176401e-05\n",
      "fold:  2 , epoch:  19 , val loss:  0.0002085937449010089\n",
      "fold:  2 , epoch:  20 , val loss:  5.812442395836115e-05\n",
      "fold:  2 , epoch:  21 , val loss:  2.4389006284764037e-05\n",
      "fold:  2 , epoch:  22 , val loss:  1.3446684533846565e-05\n",
      "fold:  2 , epoch:  23 , val loss:  2.6596808311296627e-05\n",
      "fold:  2 , epoch:  24 , val loss:  2.4655082597746514e-05\n",
      "fold:  2 , epoch:  25 , val loss:  1.1021483260265086e-05\n",
      "fold:  3 , epoch:  1 , val loss:  0.0002135126997018233\n",
      "fold:  3 , epoch:  2 , val loss:  3.184753222740255e-05\n",
      "fold:  3 , epoch:  3 , val loss:  4.9501057219458744e-05\n",
      "fold:  3 , epoch:  4 , val loss:  6.050619049347006e-05\n",
      "fold:  3 , epoch:  5 , val loss:  1.3980726180307101e-05\n",
      "fold:  3 , epoch:  6 , val loss:  1.1033152077288833e-05\n",
      "fold:  3 , epoch:  7 , val loss:  9.557264274917543e-05\n",
      "fold:  3 , epoch:  8 , val loss:  0.0001317145797656849\n",
      "fold:  3 , epoch:  9 , val loss:  1.3613406736112665e-05\n",
      "fold:  3 , epoch:  10 , val loss:  5.4135380196385086e-05\n",
      "fold:  3 , epoch:  11 , val loss:  6.2043245634413324e-06\n",
      "fold:  3 , epoch:  12 , val loss:  8.782095392234623e-06\n",
      "fold:  3 , epoch:  13 , val loss:  4.4459487980930135e-05\n",
      "fold:  3 , epoch:  14 , val loss:  3.631603249232285e-05\n",
      "fold:  3 , epoch:  15 , val loss:  7.746050869172905e-06\n",
      "fold:  3 , epoch:  16 , val loss:  7.642525815754198e-06\n",
      "fold:  3 , epoch:  17 , val loss:  4.2253963329130784e-05\n",
      "fold:  3 , epoch:  18 , val loss:  5.483376298798248e-06\n",
      "fold:  3 , epoch:  19 , val loss:  7.138649380067363e-06\n",
      "fold:  3 , epoch:  20 , val loss:  9.352113556815311e-05\n",
      "fold:  3 , epoch:  21 , val loss:  1.0151034985028673e-05\n",
      "fold:  3 , epoch:  22 , val loss:  7.777158316457644e-05\n",
      "fold:  3 , epoch:  23 , val loss:  8.767409781285096e-06\n",
      "fold:  3 , epoch:  24 , val loss:  1.234357387147611e-05\n",
      "fold:  3 , epoch:  25 , val loss:  2.6893971153185703e-05\n",
      "fold:  4 , epoch:  1 , val loss:  0.0001703469461062923\n",
      "fold:  4 , epoch:  2 , val loss:  6.187812232383294e-06\n",
      "fold:  4 , epoch:  3 , val loss:  2.7523574317456223e-05\n",
      "fold:  4 , epoch:  4 , val loss:  2.198310539824888e-05\n",
      "fold:  4 , epoch:  5 , val loss:  7.851383998058736e-06\n",
      "fold:  4 , epoch:  6 , val loss:  6.388699694070965e-05\n",
      "fold:  4 , epoch:  7 , val loss:  4.162852746958379e-06\n",
      "fold:  4 , epoch:  8 , val loss:  5.488844180945307e-06\n",
      "fold:  4 , epoch:  9 , val loss:  8.608835923951119e-05\n",
      "fold:  4 , epoch:  10 , val loss:  1.635679291212e-05\n",
      "fold:  4 , epoch:  11 , val loss:  6.5928284129768144e-06\n",
      "fold:  4 , epoch:  12 , val loss:  2.6727999284048565e-05\n",
      "fold:  4 , epoch:  13 , val loss:  7.505714165745303e-06\n",
      "fold:  4 , epoch:  14 , val loss:  1.792400871636346e-05\n",
      "fold:  4 , epoch:  15 , val loss:  8.314273873111233e-05\n",
      "fold:  4 , epoch:  16 , val loss:  1.327585141552845e-05\n",
      "fold:  4 , epoch:  17 , val loss:  6.131445843493566e-05\n",
      "fold:  4 , epoch:  18 , val loss:  2.8758993721567094e-05\n",
      "fold:  4 , epoch:  19 , val loss:  9.014089300762862e-05\n",
      "fold:  4 , epoch:  20 , val loss:  0.00015018830890767276\n",
      "fold:  4 , epoch:  21 , val loss:  2.3939164748298936e-05\n",
      "fold:  4 , epoch:  22 , val loss:  8.617350977146998e-05\n",
      "fold:  4 , epoch:  23 , val loss:  6.382536957971752e-05\n",
      "fold:  4 , epoch:  24 , val loss:  3.4749133192235604e-05\n",
      "fold:  4 , epoch:  25 , val loss:  4.031597200082615e-06\n",
      "fold:  5 , epoch:  1 , val loss:  1.9705037630046718e-05\n",
      "fold:  5 , epoch:  2 , val loss:  4.657635145122185e-06\n",
      "fold:  5 , epoch:  3 , val loss:  4.70058512291871e-06\n",
      "fold:  5 , epoch:  4 , val loss:  4.883610927208792e-06\n",
      "fold:  5 , epoch:  5 , val loss:  4.046197318530176e-06\n",
      "fold:  5 , epoch:  6 , val loss:  6.397875949915033e-06\n",
      "fold:  5 , epoch:  7 , val loss:  4.761701802635798e-06\n",
      "fold:  5 , epoch:  8 , val loss:  9.337099982076325e-06\n",
      "fold:  5 , epoch:  9 , val loss:  5.6118460634024814e-05\n",
      "fold:  5 , epoch:  10 , val loss:  3.567471503629349e-05\n",
      "fold:  5 , epoch:  11 , val loss:  2.6410540158394724e-05\n",
      "fold:  5 , epoch:  12 , val loss:  7.01687386026606e-05\n",
      "fold:  5 , epoch:  13 , val loss:  2.6084903765877243e-06\n",
      "fold:  5 , epoch:  14 , val loss:  8.110661838145461e-06\n",
      "fold:  5 , epoch:  15 , val loss:  1.0361916793044657e-05\n",
      "fold:  5 , epoch:  16 , val loss:  3.1782947189640254e-06\n",
      "fold:  5 , epoch:  17 , val loss:  3.3708436149026966e-06\n",
      "fold:  5 , epoch:  18 , val loss:  3.8177836358954664e-06\n",
      "fold:  5 , epoch:  19 , val loss:  2.997415322170127e-06\n",
      "fold:  5 , epoch:  20 , val loss:  1.4380990251083858e-05\n",
      "fold:  5 , epoch:  21 , val loss:  5.17737362315529e-06\n",
      "fold:  5 , epoch:  22 , val loss:  1.1089550753240474e-05\n",
      "fold:  5 , epoch:  23 , val loss:  5.8257332966604736e-06\n",
      "fold:  5 , epoch:  24 , val loss:  3.261630808992777e-06\n",
      "fold:  5 , epoch:  25 , val loss:  2.4464892703690566e-05\n",
      "Model results:  {'hidden_size': 600, 'n_layers': 8, 'act_fun': 'ELU', 'init_methods': 'xavier uniform', 'mean_val_result': 0.00012429600493669567, 'std_val_result': 0.0002762271861890905} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "crossval_results = cross_validation(cv_params_, \n",
    "                                    epochs, \n",
    "                                    n_folds, \n",
    "                                    batch_size,\n",
    "                                    X_train,\n",
    "                                    y_train,\n",
    "                                    loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>n_layers</th>\n",
       "      <th>act_fun</th>\n",
       "      <th>init_methods</th>\n",
       "      <th>mean_val_result</th>\n",
       "      <th>std_val_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600</td>\n",
       "      <td>8</td>\n",
       "      <td>ELU</td>\n",
       "      <td>xavier normal</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.000452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>400</td>\n",
       "      <td>8</td>\n",
       "      <td>LeakyReLU</td>\n",
       "      <td>xavier normal</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600</td>\n",
       "      <td>8</td>\n",
       "      <td>ReLU</td>\n",
       "      <td>xavier uniform</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>400</td>\n",
       "      <td>6</td>\n",
       "      <td>LeakyReLU</td>\n",
       "      <td>xavier uniform</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "      <td>ELU</td>\n",
       "      <td>xavier normal</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>LeakyReLU</td>\n",
       "      <td>xavier uniform</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>400</td>\n",
       "      <td>8</td>\n",
       "      <td>LeakyReLU</td>\n",
       "      <td>xavier uniform</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>600</td>\n",
       "      <td>6</td>\n",
       "      <td>ReLU</td>\n",
       "      <td>xavier uniform</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>600</td>\n",
       "      <td>6</td>\n",
       "      <td>LeakyReLU</td>\n",
       "      <td>xavier normal</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>400</td>\n",
       "      <td>8</td>\n",
       "      <td>ReLU</td>\n",
       "      <td>xavier uniform</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>ELU</td>\n",
       "      <td>xavier uniform</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "      <td>ELU</td>\n",
       "      <td>xavier uniform</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>400</td>\n",
       "      <td>6</td>\n",
       "      <td>ELU</td>\n",
       "      <td>xavier uniform</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>400</td>\n",
       "      <td>4</td>\n",
       "      <td>ELU</td>\n",
       "      <td>xavier uniform</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>400</td>\n",
       "      <td>8</td>\n",
       "      <td>ReLU</td>\n",
       "      <td>xavier normal</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>600</td>\n",
       "      <td>4</td>\n",
       "      <td>LeakyReLU</td>\n",
       "      <td>xavier uniform</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>600</td>\n",
       "      <td>4</td>\n",
       "      <td>ReLU</td>\n",
       "      <td>xavier normal</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "      <td>ReLU</td>\n",
       "      <td>xavier normal</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>200</td>\n",
       "      <td>8</td>\n",
       "      <td>LeakyReLU</td>\n",
       "      <td>xavier uniform</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>400</td>\n",
       "      <td>6</td>\n",
       "      <td>LeakyReLU</td>\n",
       "      <td>xavier normal</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>400</td>\n",
       "      <td>8</td>\n",
       "      <td>ELU</td>\n",
       "      <td>xavier normal</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>600</td>\n",
       "      <td>8</td>\n",
       "      <td>ReLU</td>\n",
       "      <td>xavier normal</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>400</td>\n",
       "      <td>4</td>\n",
       "      <td>ReLU</td>\n",
       "      <td>xavier uniform</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>600</td>\n",
       "      <td>8</td>\n",
       "      <td>LeakyReLU</td>\n",
       "      <td>xavier normal</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>400</td>\n",
       "      <td>8</td>\n",
       "      <td>ELU</td>\n",
       "      <td>xavier uniform</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>200</td>\n",
       "      <td>8</td>\n",
       "      <td>LeakyReLU</td>\n",
       "      <td>xavier normal</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>ELU</td>\n",
       "      <td>xavier normal</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>400</td>\n",
       "      <td>6</td>\n",
       "      <td>ELU</td>\n",
       "      <td>xavier normal</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>200</td>\n",
       "      <td>8</td>\n",
       "      <td>ELU</td>\n",
       "      <td>xavier uniform</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>600</td>\n",
       "      <td>6</td>\n",
       "      <td>ELU</td>\n",
       "      <td>xavier uniform</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>400</td>\n",
       "      <td>4</td>\n",
       "      <td>LeakyReLU</td>\n",
       "      <td>xavier uniform</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>600</td>\n",
       "      <td>8</td>\n",
       "      <td>ELU</td>\n",
       "      <td>xavier uniform</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hidden_size n_layers    act_fun    init_methods  mean_val_result  \\\n",
       "0          600        8        ELU   xavier normal         0.000228   \n",
       "1          400        8  LeakyReLU   xavier normal         0.000039   \n",
       "2          600        8       ReLU  xavier uniform         0.000028   \n",
       "3          400        6  LeakyReLU  xavier uniform         0.000024   \n",
       "4          200        6        ELU   xavier normal         0.000115   \n",
       "5          200        4  LeakyReLU  xavier uniform         0.000039   \n",
       "6          400        8  LeakyReLU  xavier uniform         0.000022   \n",
       "7          600        6       ReLU  xavier uniform         0.000024   \n",
       "8          600        6  LeakyReLU   xavier normal         0.000044   \n",
       "9          400        8       ReLU  xavier uniform         0.000026   \n",
       "10         200        4        ELU  xavier uniform         0.000192   \n",
       "11         200        6        ELU  xavier uniform         0.000159   \n",
       "12         400        6        ELU  xavier uniform         0.000125   \n",
       "13         400        4        ELU  xavier uniform         0.000124   \n",
       "14         400        8       ReLU   xavier normal         0.000036   \n",
       "15         600        4  LeakyReLU  xavier uniform         0.000024   \n",
       "16         600        4       ReLU   xavier normal         0.000025   \n",
       "17         200        6       ReLU   xavier normal         0.000070   \n",
       "18         200        8  LeakyReLU  xavier uniform         0.000029   \n",
       "19         400        6  LeakyReLU   xavier normal         0.000034   \n",
       "20         400        8        ELU   xavier normal         0.000164   \n",
       "21         600        8       ReLU   xavier normal         0.000032   \n",
       "22         400        4       ReLU  xavier uniform         0.000019   \n",
       "23         600        8  LeakyReLU   xavier normal         0.000033   \n",
       "24         400        8        ELU  xavier uniform         0.000117   \n",
       "25         200        8  LeakyReLU   xavier normal         0.000052   \n",
       "26         200        4        ELU   xavier normal         0.000194   \n",
       "27         400        6        ELU   xavier normal         0.000136   \n",
       "28         200        8        ELU  xavier uniform         0.000125   \n",
       "29         600        6        ELU  xavier uniform         0.000091   \n",
       "30         400        4  LeakyReLU  xavier uniform         0.000024   \n",
       "31         600        8        ELU  xavier uniform         0.000124   \n",
       "\n",
       "    std_val_result  \n",
       "0         0.000452  \n",
       "1         0.000059  \n",
       "2         0.000059  \n",
       "3         0.000030  \n",
       "4         0.000409  \n",
       "5         0.000126  \n",
       "6         0.000029  \n",
       "7         0.000029  \n",
       "8         0.000068  \n",
       "9         0.000040  \n",
       "10        0.000805  \n",
       "11        0.000417  \n",
       "12        0.000307  \n",
       "13        0.000326  \n",
       "14        0.000069  \n",
       "15        0.000031  \n",
       "16        0.000033  \n",
       "17        0.000160  \n",
       "18        0.000061  \n",
       "19        0.000050  \n",
       "20        0.000359  \n",
       "21        0.000050  \n",
       "22        0.000039  \n",
       "23        0.000042  \n",
       "24        0.000282  \n",
       "25        0.000095  \n",
       "26        0.000812  \n",
       "27        0.000313  \n",
       "28        0.000468  \n",
       "29        0.000210  \n",
       "30        0.000037  \n",
       "31        0.000276  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_res = crossval_results.groupby(by=['hidden_size', 'n_layers', 'act_fun', 'init_methods'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean_val_result</th>\n",
       "      <th>std_val_result</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hidden_size</th>\n",
       "      <th>n_layers</th>\n",
       "      <th>act_fun</th>\n",
       "      <th>init_methods</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">200</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">4</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">ELU</th>\n",
       "      <th>xavier normal</th>\n",
       "      <th>26</th>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xavier uniform</th>\n",
       "      <th>10</th>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LeakyReLU</th>\n",
       "      <th>xavier uniform</th>\n",
       "      <th>5</th>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">6</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">ELU</th>\n",
       "      <th>xavier normal</th>\n",
       "      <th>4</th>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xavier uniform</th>\n",
       "      <th>11</th>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU</th>\n",
       "      <th>xavier normal</th>\n",
       "      <th>17</th>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">8</th>\n",
       "      <th>ELU</th>\n",
       "      <th>xavier uniform</th>\n",
       "      <th>28</th>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LeakyReLU</th>\n",
       "      <th>xavier normal</th>\n",
       "      <th>25</th>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xavier uniform</th>\n",
       "      <th>18</th>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"13\" valign=\"top\">400</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">4</th>\n",
       "      <th>ELU</th>\n",
       "      <th>xavier uniform</th>\n",
       "      <th>13</th>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LeakyReLU</th>\n",
       "      <th>xavier uniform</th>\n",
       "      <th>30</th>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU</th>\n",
       "      <th>xavier uniform</th>\n",
       "      <th>22</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">6</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">ELU</th>\n",
       "      <th>xavier normal</th>\n",
       "      <th>27</th>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xavier uniform</th>\n",
       "      <th>12</th>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LeakyReLU</th>\n",
       "      <th>xavier normal</th>\n",
       "      <th>19</th>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xavier uniform</th>\n",
       "      <th>3</th>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">8</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">ELU</th>\n",
       "      <th>xavier normal</th>\n",
       "      <th>20</th>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xavier uniform</th>\n",
       "      <th>24</th>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">LeakyReLU</th>\n",
       "      <th>xavier normal</th>\n",
       "      <th>1</th>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xavier uniform</th>\n",
       "      <th>6</th>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ReLU</th>\n",
       "      <th>xavier normal</th>\n",
       "      <th>14</th>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xavier uniform</th>\n",
       "      <th>9</th>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">600</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>LeakyReLU</th>\n",
       "      <th>xavier uniform</th>\n",
       "      <th>15</th>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU</th>\n",
       "      <th>xavier normal</th>\n",
       "      <th>16</th>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">6</th>\n",
       "      <th>ELU</th>\n",
       "      <th>xavier uniform</th>\n",
       "      <th>29</th>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LeakyReLU</th>\n",
       "      <th>xavier normal</th>\n",
       "      <th>8</th>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU</th>\n",
       "      <th>xavier uniform</th>\n",
       "      <th>7</th>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">8</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">ELU</th>\n",
       "      <th>xavier normal</th>\n",
       "      <th>0</th>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.000452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xavier uniform</th>\n",
       "      <th>31</th>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LeakyReLU</th>\n",
       "      <th>xavier normal</th>\n",
       "      <th>23</th>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ReLU</th>\n",
       "      <th>xavier normal</th>\n",
       "      <th>21</th>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xavier uniform</th>\n",
       "      <th>2</th>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  mean_val_result  \\\n",
       "hidden_size n_layers act_fun   init_methods                         \n",
       "200         4        ELU       xavier normal  26         0.000194   \n",
       "                               xavier uniform 10         0.000192   \n",
       "                     LeakyReLU xavier uniform 5          0.000039   \n",
       "            6        ELU       xavier normal  4          0.000115   \n",
       "                               xavier uniform 11         0.000159   \n",
       "                     ReLU      xavier normal  17         0.000070   \n",
       "            8        ELU       xavier uniform 28         0.000125   \n",
       "                     LeakyReLU xavier normal  25         0.000052   \n",
       "                               xavier uniform 18         0.000029   \n",
       "400         4        ELU       xavier uniform 13         0.000124   \n",
       "                     LeakyReLU xavier uniform 30         0.000024   \n",
       "                     ReLU      xavier uniform 22         0.000019   \n",
       "            6        ELU       xavier normal  27         0.000136   \n",
       "                               xavier uniform 12         0.000125   \n",
       "                     LeakyReLU xavier normal  19         0.000034   \n",
       "                               xavier uniform 3          0.000024   \n",
       "            8        ELU       xavier normal  20         0.000164   \n",
       "                               xavier uniform 24         0.000117   \n",
       "                     LeakyReLU xavier normal  1          0.000039   \n",
       "                               xavier uniform 6          0.000022   \n",
       "                     ReLU      xavier normal  14         0.000036   \n",
       "                               xavier uniform 9          0.000026   \n",
       "600         4        LeakyReLU xavier uniform 15         0.000024   \n",
       "                     ReLU      xavier normal  16         0.000025   \n",
       "            6        ELU       xavier uniform 29         0.000091   \n",
       "                     LeakyReLU xavier normal  8          0.000044   \n",
       "                     ReLU      xavier uniform 7          0.000024   \n",
       "            8        ELU       xavier normal  0          0.000228   \n",
       "                               xavier uniform 31         0.000124   \n",
       "                     LeakyReLU xavier normal  23         0.000033   \n",
       "                     ReLU      xavier normal  21         0.000032   \n",
       "                               xavier uniform 2          0.000028   \n",
       "\n",
       "                                                  std_val_result  \n",
       "hidden_size n_layers act_fun   init_methods                       \n",
       "200         4        ELU       xavier normal  26        0.000812  \n",
       "                               xavier uniform 10        0.000805  \n",
       "                     LeakyReLU xavier uniform 5         0.000126  \n",
       "            6        ELU       xavier normal  4         0.000409  \n",
       "                               xavier uniform 11        0.000417  \n",
       "                     ReLU      xavier normal  17        0.000160  \n",
       "            8        ELU       xavier uniform 28        0.000468  \n",
       "                     LeakyReLU xavier normal  25        0.000095  \n",
       "                               xavier uniform 18        0.000061  \n",
       "400         4        ELU       xavier uniform 13        0.000326  \n",
       "                     LeakyReLU xavier uniform 30        0.000037  \n",
       "                     ReLU      xavier uniform 22        0.000039  \n",
       "            6        ELU       xavier normal  27        0.000313  \n",
       "                               xavier uniform 12        0.000307  \n",
       "                     LeakyReLU xavier normal  19        0.000050  \n",
       "                               xavier uniform 3         0.000030  \n",
       "            8        ELU       xavier normal  20        0.000359  \n",
       "                               xavier uniform 24        0.000282  \n",
       "                     LeakyReLU xavier normal  1         0.000059  \n",
       "                               xavier uniform 6         0.000029  \n",
       "                     ReLU      xavier normal  14        0.000069  \n",
       "                               xavier uniform 9         0.000040  \n",
       "600         4        LeakyReLU xavier uniform 15        0.000031  \n",
       "                     ReLU      xavier normal  16        0.000033  \n",
       "            6        ELU       xavier uniform 29        0.000210  \n",
       "                     LeakyReLU xavier normal  8         0.000068  \n",
       "                     ReLU      xavier uniform 7         0.000029  \n",
       "            8        ELU       xavier normal  0         0.000452  \n",
       "                               xavier uniform 31        0.000276  \n",
       "                     LeakyReLU xavier normal  23        0.000042  \n",
       "                     ReLU      xavier normal  21        0.000050  \n",
       "                               xavier uniform 2         0.000059  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparam_res.apply(lambda x : x.nsmallest(3, 'mean_val_result')).drop(['hidden_size', 'n_layers', 'act_fun', 'init_methods'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval_results.to_csv('../results/hyperparams_optimization_res.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 5 Models\n",
    "\n",
    "- `{'n_hidden': 400, 'n_layers': 8, 'act_fun': 'LeakyReLU', 'init_method': 'xavier uniform'}`\n",
    "- `{'n_hidden': 400, 'n_layers': 4, 'act_fun': 'ReLU', 'init_method': 'xavier uniform'}`\n",
    "- `{'n_hidden': 400, 'n_layers': 4, 'act_fun': 'LeakyReLU', 'init_method': 'xavier uniform'}`\n",
    "- `{'n_hidden': 400, 'n_layers': 6, 'act_fun': 'LeakyReLU', 'init_method': 'xavier uniform'}`\n",
    "- `{'n_hidden': 400, 'n_layers': 8, 'act_fun': 'LeakyReLU', 'init_method': 'xavier uniform'}`"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hyperparams-optimization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
